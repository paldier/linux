From 656046744a226bcc3266c85ca7f60ead5e90481e Mon Sep 17 00:00:00 2001
From: Hua Ma <hua.ma@linux.intel.com>
Date: Thu, 21 Jun 2018 17:37:51 +0800
Subject: [PATCH] Add support for lantiq eth driver

---
 drivers/net/ethernet/lantiq/Kconfig                |  100 +
 drivers/net/ethernet/lantiq/Makefile               |   13 +
 drivers/net/ethernet/lantiq/lantiq_eth_framework.c |  575 +++++
 drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.c   | 2250 ++++++++++++++++++++
 drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.h   |  124 ++
 drivers/net/ethernet/lantiq_eth_drv.c              | 1678 +++++++++++++++
 include/net/lantiq_eth_framework.h                 |   90 +
 7 files changed, 4830 insertions(+)

diff --git a/drivers/net/ethernet/lantiq/Kconfig b/drivers/net/ethernet/lantiq/Kconfig
new file mode 100644
index 000000000000..f7a03432b3ba
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/Kconfig
@@ -0,0 +1,100 @@
+
+
+config NET_VENDOR_LANTIQ
+        bool "Lantiq network devices"
+        default y
+        depends on  SOC_XWAY || SOC_GRX500
+        ---help---
+          If you have a network (Ethernet) card belonging to this class, say Y
+          and read the Ethernet-HOWTO, available from
+          <http://www.tldp.org/docs.html#howto>.
+
+if NET_VENDOR_LANTIQ
+
+config LANTIQ_VRX318
+	tristate "VRX318 SmartPHY PCIe EP driver"
+	depends on PCIE_LANTIQ
+	default n
+	---help---
+	Supported VRX318 smartPHY PCIe EP
+
+config LANITQ_VRX318_PCIE_SWITCH_DSL_BONDING
+	tristate "VRX318 SmartPHY DSL bonding with PCIe Switch"
+	depends on LANTIQ_VRX318
+	default n
+	---help---
+	Supported VRX318 smartPHY PCIe DSL Bonding with PCIe switch
+
+config LANTIQ_ETH_FRAMEWORK
+	bool "Lantiq framework for ethernet drivers"
+	depends on LANTIQ
+	default n
+	---help---
+	Lantiq framework for ethernet drivers
+
+config LTQ_ETH_XRX500
+        tristate "Lantiq Ethernet driver for XRX500 series"
+        depends on LANTIQ && SOC_GRX500 && LTQ_ETHSW_API && (LTQ_CBM || LTQ_DATAPATH_LIBRARY)
+        default n
+        ---help---
+        Lantiq Ethernet driver for XRX500 series.
+
+config XRX500_ETH_DRV_COC_SUPPORT
+		bool "CoC support in the ethernet driver"
+        depends on LTQ_ETH_XRX500 && LTQ_DATAPATH_CPUFREQ
+		default n
+		---help---
+		CoC support in the Ethernet driver of XRX500 series
+
+config SW_ROUTING_MODE
+        bool "Enable the SW routing mode in ethernet driver"
+	depends on LTQ_ETH_XRX500
+	default y
+        ---help---
+        Lantiq Ethernet driver routing mode
+
+config HAPS_CPU_LOOPBACK_TEST 
+        bool "Enable CPU enqueue and dequeue loopback"
+	depends on LTQ_ETH_XRX500
+	default n
+        ---help---
+        Lantiq Ethernet driver CPU Enqueue and Dequeue test
+
+config XRX500_PHY_FW
+	tristate "XRX500 PHY firmware loader"
+	depends on SOC_GRX500
+	default n
+        ---help---
+        GPHY FW loader on GRX500 platforms
+
+config INTEL_UMT_CQEM_MODE
+        bool "Intel UMT in CQEM mode"
+        depends on FALCONMX_CQM
+        help
+          In cqem mode, UMT (User Message Transfer) HW
+          is able to support max three UMT port.
+          CBM port and DMA channels that associated with
+          the UMT port can be configurable.
+
+config LTQ_TOE_DRIVER
+	bool "Enable the TOE (TCP Offload Engine) driver for XRX500"
+        depends on LTQ_ETH_XRX500
+        default n
+        ---help---
+        Lantiq TOE (TCP Offload Engine) driver for XRX500 series.
+
+config INTEL_XPCS
+	tristate "Intel XPCS driver support"
+        select GENERIC_PHY
+	---help---
+	  This driver provides support for Xpcs for 10G.
+
+
+source "drivers/net/ethernet/lantiq/datapath/Kconfig"
+source "drivers/net/ethernet/lantiq/switch-api/Kconfig"
+source "drivers/net/ethernet/lantiq/cqm/Kconfig"
+source "drivers/net/ethernet/lantiq/tmu/Kconfig"
+source "drivers/net/ethernet/lantiq/ppv4/Kconfig"
+source "drivers/net/ethernet/lantiq/ppa/Kconfig"
+source "drivers/net/ethernet/lantiq/directconnect_dp/Kconfig"
+endif # NET_VENDOR_LANTIQ
diff --git a/drivers/net/ethernet/lantiq/Makefile b/drivers/net/ethernet/lantiq/Makefile
new file mode 100644
index 000000000000..9ab57cc47da4
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/Makefile
@@ -0,0 +1,13 @@
+obj-$(CONFIG_LANTIQ_VRX318) += ltq_vrx318.o
+obj-$(CONFIG_LANTIQ_ETH_FRAMEWORK) += lantiq_eth_framework.o
+obj-$(CONFIG_INTEL_XPCS) += xpcs/
+obj-$(CONFIG_LTQ_ETHSW_API) += switch-api/
+obj-$(CONFIG_LTQ_DATAPATH) += datapath/
+obj-$(CONFIG_LTQ_TMU) += tmu/
+obj-$(CONFIG_LTQ_PPV4) += ppv4/
+obj-$(CONFIG_LTQ_CBM) += cqm/
+obj-$(CONFIG_LTQ_ETH_XRX500) += ltq_eth_drv_xrx500.o
+obj-$(CONFIG_XRX500_PHY_FW) += xrx500_phy_fw.o
+obj-$(CONFIG_PPA) += ppa/
+obj-$(CONFIG_INTEL_UMT_CQEM_MODE) += umt/intel_umt_cqem.o
+obj-$(CONFIG_LTQ_TOE_DRIVER) += ltq_toe_drv.o
diff --git a/drivers/net/ethernet/lantiq/lantiq_eth_framework.c b/drivers/net/ethernet/lantiq/lantiq_eth_framework.c
new file mode 100644
index 000000000000..1597d5462b9b
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/lantiq_eth_framework.c
@@ -0,0 +1,575 @@
+/******************************************************************************
+**
+** FILE NAME    : ifxmips_eth_framework.c
+** PROJECT      : UEIP
+** MODULES      : ETH
+**
+** DATE         : 2 Nov 2010
+** AUTHOR       : Xu Liang
+** DESCRIPTION  : IFX ETH driver framework source file
+** COPYRIGHT    :              Copyright (c) 2009
+**                          Lantiq Deutschland GmbH
+**                   Am Campeon 3; 85579 Neubiberg, Germany
+**
+**   For licensing information, see the file 'LICENSE' in the root folder of
+**   this software module.
+**
+** HISTORY
+** $Date        $Author         $Comment
+** 02 NOV 2010  Xu Liang        Init Version
+*******************************************************************************/
+
+
+
+/*
+ * ####################################
+ *              Head File
+ * ####################################
+ */
+
+/*
+ *  Common Head File
+ */
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/delay.h>
+
+#include <lantiq_eth_framework.h>
+
+/*
+ * ####################################
+ *              Data Type
+ * ####################################
+ */
+
+struct ifx_eth_fw_priv_data {
+    struct net_device              *dev;
+    void                           *priv;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+    struct net_device_ops           netdev_ops;
+    struct napi_struct              napi;
+#endif
+
+    ifx_eth_fw_poll_ret_t (*poll)(struct net_device *dev, int work_to_do, int *work_done);
+    int (*open)(struct net_device *dev);
+    int (*stop)(struct net_device *dev);
+    struct net_device_stats *(*get_stats)(struct net_device *dev);
+
+    struct list_head                list;
+    int                             sizeof_priv;
+    unsigned int                    malloc_size;
+#define ETHFW_PRIV_DATA_FLAG_ALLOC          0
+#define ETHFW_PRIV_DATA_FLAG_REG            1
+#define ETHFW_PRIV_DATA_FLAG_REG_NETDEV     2
+    unsigned long                   flags;
+
+    struct net_device_stats         stats;
+    struct net_device_stats         stats_bak;
+};
+
+/*
+ * ####################################
+ *             Declaration
+ * ####################################
+ */
+
+/*
+ *  Network Operations
+ */
+static int eth_open(struct net_device *);
+static int eth_stop(struct net_device *);
+static int eth_start_xmit(struct sk_buff *, struct net_device *);
+static int eth_ioctl(struct net_device *, struct ifreq *, int);
+struct net_device_stats * eth_get_stats(struct net_device *);
+static void eth_tx_timeout(struct net_device *);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+  static int eth_poll(struct net_device *, int *);
+#else
+  static int eth_poll(struct napi_struct *, int);
+#endif
+
+static struct net_device *eth_alloc_netdev(int, const char *);
+
+
+
+/*
+ * ####################################
+ *            Local Variable
+ * ####################################
+ */
+
+static DEFINE_SPINLOCK(g_netdev_list_lock);
+static LIST_HEAD(g_netdev_list);
+
+
+
+/*
+ * ####################################
+ *            Local Function
+ * ####################################
+ */
+
+static int eth_open(struct net_device *dev)
+{
+    int ret = 0;
+    struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+    if ( priv->poll != NULL )
+        napi_enable(&priv->napi);
+#endif
+    if ( priv->open != NULL )
+        ret = priv->open(dev);
+    netif_start_queue(dev);
+
+    return ret;
+}
+
+static int eth_stop(struct net_device *dev)
+{
+    struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+
+    if ( priv->stop != NULL )
+        priv->stop(dev);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+    if ( priv->poll != NULL )
+        napi_disable(&priv->napi);
+#endif
+    netif_stop_queue(dev);
+
+    return 0;
+}
+
+static int eth_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+    struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+
+    priv->stats_bak.tx_dropped++;
+    dev_kfree_skb_any(skb);
+
+    return NETDEV_TX_OK;
+}
+
+static int eth_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+    return ENOIOCTLCMD;
+}
+
+struct net_device_stats * eth_get_stats(struct net_device *dev)
+{
+    struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+
+    if ( test_bit(ETHFW_PRIV_DATA_FLAG_REG, &priv->flags) && priv->get_stats != NULL ) {
+        struct net_device_stats *stats = priv->get_stats(dev);
+        if ( stats != NULL )
+            priv->stats = *stats;
+    }
+    else
+        priv->stats = priv->stats_bak;
+
+    return &priv->stats;
+}
+
+static void eth_tx_timeout(struct net_device *dev)
+{
+    netif_wake_queue(dev);
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+static int eth_poll(struct net_device *dev, int *quota)
+{
+    struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+    unsigned int work_to_do = min(dev->quota, *quota);
+    unsigned int work_done = 0;
+    ifx_eth_fw_poll_ret_t poll_ret;
+
+    poll_ret = priv->poll(dev, work_to_do, &work_done);
+
+    *quota -= work_done;
+    dev->quota -= work_done;
+
+    if ( poll_ret == IFX_ETH_FW_POLL_CONTINUE && !netif_running(dev) ) {
+        netif_rx_complete(dev);
+        return IFX_ETH_FW_POLL_COMPLETE;
+    }
+
+    return poll_ret;
+}
+#else
+static int eth_poll(struct napi_struct *napi, int budget)
+{
+    struct net_device *dev = napi->dev;
+    struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+    unsigned int work_done = 0;
+    ifx_eth_fw_poll_ret_t poll_ret;
+
+    poll_ret = priv->poll(dev, budget, &work_done);
+    if ( poll_ret == IFX_ETH_FW_POLL_CONTINUE ) {
+        if ( netif_running(dev) )
+            return work_done;
+        napi_complete(napi);
+    }
+    return 0;   //  complete, to workaround improper "list_move_tail(&n->poll_list, list);" in "net_rx_action"
+}
+#endif
+
+static struct net_device *eth_alloc_netdev(int sizeof_priv, const char *name)
+{
+    unsigned long sys_flags;
+    struct list_head *list;
+    struct ifx_eth_fw_priv_data *priv;
+    struct net_device *dev;
+
+    spin_lock_irqsave(&g_netdev_list_lock, sys_flags);
+    list_for_each(list, &g_netdev_list) {
+        priv = list_entry(list, struct ifx_eth_fw_priv_data, list);
+        if ( strcmp(priv->dev->name, name) == 0 ) {
+            spin_unlock_irqrestore(&g_netdev_list_lock, sys_flags);
+            if ( test_and_set_bit(ETHFW_PRIV_DATA_FLAG_ALLOC, &priv->flags) )
+                return NULL;
+            if ( priv->sizeof_priv >= sizeof_priv ) {
+                if ( priv->malloc_size > 0 ) {
+                    kfree(priv->priv);
+                    priv->malloc_size = 0;
+                }
+                priv->priv = (char *)priv + sizeof(struct ifx_eth_fw_priv_data);
+                memset(priv->priv, 0, sizeof_priv);
+            }
+            else if ( priv->malloc_size < sizeof_priv ) {
+                if ( priv->malloc_size > 0 ) {
+                    kfree(priv->priv);
+                    priv->malloc_size = 0;
+                }
+                priv->priv = kzalloc(sizeof_priv, GFP_KERNEL);
+                if ( priv->priv == NULL ) {
+                    clear_bit(ETHFW_PRIV_DATA_FLAG_ALLOC, &priv->flags);
+                    return NULL;
+                }
+                priv->malloc_size = sizeof_priv;
+            }
+            return priv->dev;
+        }
+    }
+    spin_unlock_irqrestore(&g_netdev_list_lock, sys_flags);
+
+    dev = alloc_netdev(sizeof(struct ifx_eth_fw_priv_data) + sizeof_priv, name, ether_setup);
+    if ( dev != NULL ) {
+        priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+        priv->dev           = dev;
+        priv->priv          = (char *)priv + sizeof(struct ifx_eth_fw_priv_data);
+        priv->sizeof_priv   = sizeof_priv;
+        set_bit(ETHFW_PRIV_DATA_FLAG_ALLOC, &priv->flags);
+
+        spin_lock_irqsave(&g_netdev_list_lock, sys_flags);
+        list_add_tail(&priv->list, &g_netdev_list);
+        spin_unlock_irqrestore(&g_netdev_list_lock, sys_flags);
+    }
+    return dev;
+}
+
+
+
+/*
+ * ####################################
+ *           Global Function
+ * ####################################
+ */
+
+void *ifx_eth_fw_netdev_priv(struct net_device *dev)
+{
+    return dev == NULL ? NULL : ((struct ifx_eth_fw_priv_data *)netdev_priv(dev))->priv;
+}
+EXPORT_SYMBOL(ifx_eth_fw_netdev_priv);
+
+struct net_device *ifx_eth_fw_alloc_netdev(int sizeof_priv, const char *name, struct ifx_eth_fw_netdev_ops *ops)
+{
+    struct net_device *dev;
+
+    if ( ops == NULL )
+        return NULL;
+
+    if ( name == NULL )
+        name = "eth%d";
+
+    dev = eth_alloc_netdev(sizeof_priv, name);
+    if ( dev != NULL ) {
+        struct ifx_eth_fw_priv_data *priv = netdev_priv(dev);
+
+        if ( test_bit(ETHFW_PRIV_DATA_FLAG_REG_NETDEV, &priv->flags) && ops->init != NULL )
+            ops->init(dev);
+
+        priv->open      = ops->open;
+        priv->stop      = ops->stop;
+        priv->get_stats = ops->get_stats;
+
+        dev->watchdog_timeo = ops->watchdog_timeo;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+        dev->init               = ops->init;
+        dev->uninit             = ops->uninit;
+        dev->open               = eth_open;
+        dev->stop               = eth_stop;
+        dev->hard_start_xmit    = ops->start_xmit;
+        dev->set_multicast_list = ops->set_multicast_list;
+        if ( ops->set_mac_address != NULL )
+            dev->set_mac_address= ops->set_mac_address;
+        dev->do_ioctl           = ops->do_ioctl;
+        dev->set_config         = ops->set_config;
+        if ( ops->change_mtu != NULL )
+            dev->change_mtu     = ops->change_mtu;
+        dev->neigh_setup        = ops->neigh_setup;
+        dev->get_stats          = eth_get_stats;
+  #ifdef CONFIG_NET_POLL_CONTROLLER
+        dev->poll_controller    = ops->poll_controller;
+  #endif
+        dev->tx_timeout         = ops->tx_timeout;
+
+        if ( ops->poll && ops->weight >= 0 ) {
+            priv->poll = ops->poll;
+            dev->poll           = eth_poll;
+            dev->weight         = ops->weight;
+        }
+#else
+        priv->netdev_ops.ndo_init               = ops->init;
+        priv->netdev_ops.ndo_uninit             = ops->uninit;
+        priv->netdev_ops.ndo_open               = eth_open;
+        priv->netdev_ops.ndo_stop               = eth_stop;
+        priv->netdev_ops.ndo_start_xmit         = ops->start_xmit;
+  #if LINUX_VERSION_CODE < KERNEL_VERSION(3,2,0)
+        priv->netdev_ops.ndo_set_multicast_list = ops->set_multicast_list;
+  #else
+        priv->netdev_ops.ndo_set_rx_mode        = ops->set_multicast_list;
+  #endif
+        priv->netdev_ops.ndo_set_mac_address    = ops->set_mac_address == NULL ? eth_mac_addr : ops->set_mac_address;
+        priv->netdev_ops.ndo_validate_addr      = eth_validate_addr;
+        priv->netdev_ops.ndo_do_ioctl           = ops->do_ioctl;
+        priv->netdev_ops.ndo_set_config         = ops->set_config;
+        priv->netdev_ops.ndo_change_mtu         = ops->change_mtu == NULL ? eth_change_mtu : ops->change_mtu;
+        priv->netdev_ops.ndo_neigh_setup        = ops->neigh_setup;
+        priv->netdev_ops.ndo_get_stats          = eth_get_stats;
+  #ifdef CONFIG_NET_POLL_CONTROLLER
+        priv->netdev_ops.ndo_poll_controller    = ops->poll_controller;
+  #endif
+        priv->netdev_ops.ndo_tx_timeout         = ops->tx_timeout;
+
+        if ( ops->poll && ops->weight >= 0 ) {
+            priv->poll = ops->poll;
+            netif_napi_add(dev, &priv->napi, eth_poll, ops->weight);
+        }
+
+        dev->netdev_ops = &priv->netdev_ops;
+#endif
+    }
+
+    return dev;
+}
+EXPORT_SYMBOL(ifx_eth_fw_alloc_netdev);
+
+void ifx_eth_fw_free_netdev(struct net_device *dev, int force)
+{
+    struct ifx_eth_fw_priv_data *priv;
+
+    if ( dev == NULL )
+        return;
+
+    priv = netdev_priv(dev);
+
+    if ( !test_bit(ETHFW_PRIV_DATA_FLAG_ALLOC, &priv->flags) )
+        return;
+
+    ifx_eth_fw_unregister_netdev(dev, force);
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+    if ( priv->poll != NULL )
+        netif_napi_del(&priv->napi);
+#endif
+    priv->poll = NULL;
+    clear_bit(ETHFW_PRIV_DATA_FLAG_ALLOC, &priv->flags);
+
+    if ( force ) {
+        unsigned long sys_flags;
+
+        spin_lock_irqsave(&g_netdev_list_lock, sys_flags);
+        list_del(&priv->list);
+        spin_unlock_irqrestore(&g_netdev_list_lock, sys_flags);
+
+        if ( priv->malloc_size > 0 )
+            kfree(priv->priv);
+
+        free_netdev(dev);
+    }
+}
+EXPORT_SYMBOL(ifx_eth_fw_free_netdev);
+
+int ifx_eth_fw_register_netdev(struct net_device *dev)
+{
+    struct ifx_eth_fw_priv_data *priv;
+    int ret;
+
+    if ( dev == NULL )
+        return -EINVAL;
+
+    priv = netdev_priv(dev);
+
+    if ( test_and_set_bit(ETHFW_PRIV_DATA_FLAG_REG, &priv->flags) )
+        return -ENFILE; //  in use
+
+    if ( test_and_set_bit(ETHFW_PRIV_DATA_FLAG_REG_NETDEV, &priv->flags) ) {
+        struct net_device_stats *stats = priv->get_stats(dev);
+        if ( stats != NULL )
+            *stats = priv->stats_bak;
+        if ( netif_running(dev) )
+            eth_open(dev);
+        return 0;
+    }
+
+    ret = register_netdev(dev);
+    if ( ret != 0 )
+        clear_bit(ETHFW_PRIV_DATA_FLAG_REG_NETDEV, &priv->flags);
+
+    return ret;
+}
+EXPORT_SYMBOL(ifx_eth_fw_register_netdev);
+
+void ifx_eth_fw_unregister_netdev(struct net_device *dev, int force)
+{
+    struct ifx_eth_fw_priv_data *priv;
+    struct net_device_stats *stats;
+
+    if ( dev == NULL )
+        return;
+
+    priv = netdev_priv(dev);
+
+    if ( force ) {
+        if ( test_bit(ETHFW_PRIV_DATA_FLAG_REG_NETDEV, &priv->flags) ) {
+            unregister_netdev(dev);
+            clear_bit(ETHFW_PRIV_DATA_FLAG_REG_NETDEV, &priv->flags);
+        }
+        clear_bit(ETHFW_PRIV_DATA_FLAG_REG, &priv->flags);
+        return;
+    }
+
+    if ( !test_bit(ETHFW_PRIV_DATA_FLAG_REG, &priv->flags) )
+        return;
+
+    if ( netif_running(dev) ) {
+        priv->stop(dev);
+        msleep(1);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,32)
+        if ( priv->poll != NULL && test_bit(NAPI_STATE_SCHED, &priv->napi.state) )
+            napi_complete(&priv->napi);
+#endif
+    }
+    stats = priv->get_stats(dev);
+    if ( stats != NULL )
+        priv->stats_bak = *stats;
+    priv->get_stats = NULL;
+    priv->open      = NULL;
+    priv->stop      = NULL;
+    /*SET_ETHTOOL_OPS(dev, NULL);*/
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+    if ( dev->uninit != NULL )
+        dev->uninit(dev);
+    dev->init               = NULL;
+    dev->uninit             = NULL;
+    dev->hard_start_xmit    = eth_start_xmit;
+    dev->set_multicast_list = NULL;
+    dev->set_mac_address    = NULL;
+    dev->do_ioctl           = eth_ioctl;
+    dev->set_config         = NULL;
+    dev->change_mtu         = NULL;
+    dev->neigh_setup        = NULL;
+  #ifdef CONFIG_NET_POLL_CONTROLLER
+    dev->poll_controller    = NULL;
+  #endif
+    dev->tx_timeout         = eth_tx_timeout;
+#else
+    if ( priv->netdev_ops.ndo_uninit != NULL )
+        priv->netdev_ops.ndo_uninit(dev);
+    priv->netdev_ops.ndo_init               = NULL;
+    priv->netdev_ops.ndo_uninit             = NULL;
+    priv->netdev_ops.ndo_start_xmit         = eth_start_xmit;
+  #if LINUX_VERSION_CODE < KERNEL_VERSION(3,2,0)
+    priv->netdev_ops.ndo_set_multicast_list = NULL;
+  #else
+    priv->netdev_ops.ndo_set_rx_mode        = NULL;
+  #endif
+    priv->netdev_ops.ndo_set_mac_address    = eth_mac_addr;
+    priv->netdev_ops.ndo_do_ioctl           = eth_ioctl;
+    priv->netdev_ops.ndo_set_config         = NULL;
+    priv->netdev_ops.ndo_change_mtu         = eth_change_mtu;
+    priv->netdev_ops.ndo_neigh_setup        = NULL;
+  #ifdef CONFIG_NET_POLL_CONTROLLER
+    priv->netdev_ops.ndo_poll_controller    = NULL;
+  #endif
+    priv->netdev_ops.ndo_tx_timeout         = eth_tx_timeout;
+#endif
+    clear_bit(ETHFW_PRIV_DATA_FLAG_REG, &priv->flags);
+}
+EXPORT_SYMBOL(ifx_eth_fw_unregister_netdev);
+
+int ifx_eth_fw_poll_schedule(struct net_device *dev)
+{
+    if ( dev == NULL )
+        return -EINVAL;
+    else {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+        netif_rx_schedule(dev);
+#else
+        struct ifx_eth_fw_priv_data *priv;
+
+        priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+        napi_schedule(&priv->napi);
+#endif
+        return 0;
+    }
+}
+EXPORT_SYMBOL(ifx_eth_fw_poll_schedule);
+
+int ifx_eth_fw_poll_complete(struct net_device *dev)
+{
+    if ( dev == NULL )
+        return -EINVAL;
+    else {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+        if ( test_bit(__LINK_STATE_RX_SCHED, &dev->state) )
+            netif_rx_complete(dev);
+#else
+        struct ifx_eth_fw_priv_data *priv = (struct ifx_eth_fw_priv_data *)netdev_priv(dev);
+
+        if ( test_bit(NAPI_STATE_SCHED, &priv->napi.state) )
+            napi_complete(&priv->napi);
+#endif
+        return 0;
+    }
+}
+EXPORT_SYMBOL(ifx_eth_fw_poll_complete);
+
+
+
+/*
+ * ####################################
+ *           Init/Cleanup API
+ * ####################################
+ */
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,32)
+static int __init ifx_eth_fw_init(void)
+#else
+static int __devinit ifx_eth_fw_init(void)
+#endif
+{
+    return 0;
+}
+
+static void __exit ifx_eth_fw_exit(void)
+{
+}
+
+module_init(ifx_eth_fw_init);
+module_exit(ifx_eth_fw_exit);
diff --git a/drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.c b/drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.c
new file mode 100644
index 000000000000..7d79cebb5626
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.c
@@ -0,0 +1,2250 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright (C) 2009~2015 Lantiq Deutschland GmbH
+ * Copyright (C) 2016~2018 Intel Corporation.
+ */
+
+#define CONFIG_XRX500_MDIO_SUPPORT
+#undef CONFIG_USERSPACE_LINK_NOTIFICATION
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h> /* printk() */
+#include <linux/types.h>  /* size_t */
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/etherdevice.h> /* eth_type_trans */
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/of_net.h>
+#include <linux/of_mdio.h>
+#include <linux/of_irq.h>
+#include <linux/of_device.h>
+
+#ifdef CONFIG_USERSPACE_LINK_NOTIFICATION
+#include <net/genetlink.h>
+#endif
+
+#include <lantiq.h>
+#include <net/datapath_api.h>
+#include <net/lantiq_cbm_api.h>
+#include <net/switch_api/lantiq_gsw_api.h>
+#include <net/switch_api/gsw_dev.h>
+#include "xrx500_phy_fw.h"
+#include "ltq_eth_drv_xrx500.h"
+
+#define LTQ_ETH_MAX_DATA_LEN 9000
+
+#define DRV_MODULE_NAME		"lantiq_eth_drv_xrx500"
+#define DRV_MODULE_VERSION	 "1.1"
+
+/* length of time before we decide the hardware is borked,
+ * and dev->eth_tx_timeout() should be called to fix the problem
+ */
+#define LTQ_TX_TIMEOUT		(10 * HZ)
+#define MY_ETH0_ADDR g_my_ethaddr
+#define LTQ_ETHWAN_PORT 6
+#define MDIO_PHY_ADDR_MASK	0x001f
+#define MDIO_PHY_LINK_DOWN	0x4000
+#define MDIO_PHY_LINK_UP	0x2000
+
+#define MDIO_PHY_FDUP_EN	0x0600
+#define MDIO_PHY_FDUP_DIS	0x0200
+
+#define LTQ_ETH_NUM_INTERRUPTS 5
+
+/* Init of the network device */
+static int ltq_eth_init(struct net_device *dev);
+/* Start the network device interface queue */
+static int ltq_eth_open(struct net_device *dev);
+/* Stop the network device interface queue */
+static int ltq_eth_stop(struct net_device *dev);
+/* Uninit the network device interface queue */
+static void ltq_eth_uninit(struct net_device *dev);
+/* Transmit packet from Tx Queue to MAC */
+static int ltq_start_xmit(struct sk_buff *skb, struct net_device *dev);
+/* Hardware specific IOCTL's  */
+static int ltq_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
+/* Get the network device statistics */
+static
+struct rtnl_link_stats64 *ltq_get_stats(struct net_device *dev,
+					struct rtnl_link_stats64 *storage);
+/* change MTU values */
+static int ltq_change_mtu(struct net_device *dev, int new_mtu);
+/*  Set mac address*/
+static int ltq_set_mac_address(struct net_device *dev, void *p);
+/* Transmit timeout*/
+static void ltq_tx_timeout(struct net_device *dev);
+
+/* interface change event handler */
+static int phy_netdevice_event(struct notifier_block *nb, unsigned long action,
+			       void *ptr);
+static int xrx500_mdio_probe(struct net_device *dev, struct xrx500_port *port);
+static int ltq_gsw_pmac_init(void);
+
+/**
+ *  Datapath directpath functions
+ */
+static int32_t dp_fp_stop_tx(struct net_device *);
+static int32_t dp_fp_restart_tx(struct net_device *);
+static int32_t dp_fp_rx(struct net_device *, struct net_device *,
+			struct sk_buff *, int32_t);
+
+#ifdef CONFIG_XRX500_ETH_DRV_COC_SUPPORT
+static int32_t dp_fp_coc_confirm(enum ltq_cpufreq_state new_state,
+				 enum ltq_cpufreq_state old_state, u32 flags);
+DECLARE_BITMAP(g_ltq_eth_intr_type, LTQ_ETH_NUM_INTERRUPTS);
+static u32 g_ltq_eth_gswl_irq;
+static struct tasklet_struct gswl_tasklet;
+
+DECLARE_BITMAP(g_ltq_pae_intr_type, LTQ_ETH_NUM_INTERRUPTS);
+static u32 g_ltq_pae_irq;
+static struct tasklet_struct pae_tasklet;
+static enum ltq_cpufreq_state g_ltq_eth_drv_coc_state = LTQ_CPUFREQ_PS_D0;
+#endif
+
+static struct xrx500_hw xrx500_hw;
+
+static char wan_iface[IFNAMSIZ] = "eth1";
+static u8 g_my_ethaddr[MAX_ADDR_LEN * 2] = {0};
+
+#ifndef CONFIG_XRX500_MDIO_SUPPORT
+static struct net_device *eth_dev[NUM_ETH_INF];
+#endif
+static struct module g_ltq_eth_module[NUM_ETH_INF];
+static u32 g_rx_csum_offload;
+static u32 g_eth_switch_mode;
+static struct ltq_net_soc_data g_soc_data;
+
+static const struct net_device_ops ltq_eth_drv_ops = {
+	.ndo_init		= ltq_eth_init,
+	.ndo_open		= ltq_eth_open,
+	.ndo_stop		= ltq_eth_stop,
+	.ndo_uninit		= ltq_eth_uninit,
+	.ndo_start_xmit		= ltq_start_xmit,
+	.ndo_set_mac_address	= ltq_set_mac_address,
+	.ndo_change_mtu		= ltq_change_mtu,
+	.ndo_get_stats64	= ltq_get_stats,
+	.ndo_do_ioctl		= ltq_ioctl,
+	.ndo_tx_timeout		= ltq_tx_timeout,
+};
+
+static struct notifier_block netdevice_notifier = {
+	.notifier_call = phy_netdevice_event
+};
+
+#undef DUMP_PACKET
+
+#ifdef DUMP_PACKET
+/**
+ * \brief dump skb data
+ * \param[in] len length of the data buffer
+ * \param[in] p_data Pointer to data to dump
+ *
+ * \return void No Value
+ */
+static inline void dump_skb(u32 len, char *p_data)
+{
+	int i;
+
+	for (i = 0; i < len; i++) {
+		pr_info("%2.2x ", (u8)(p_data[i]));
+
+		if (i % 16 == 15)
+			pr_info("\n");
+	}
+
+	pr_info("\n");
+}
+#endif
+
+/* Get the driver information, used by ethtool_ops  */
+static void get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)
+{
+	/* driver driver short name (Max 32 characters) */
+	strcpy(info->driver, DRV_MODULE_NAME);
+	/* driver version(Max 32 characters) */
+	strcpy(info->version, DRV_MODULE_VERSION);
+}
+
+/* Get the network device settings  */
+static int get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct ltq_switch_priv_t *priv;
+	int i;
+
+	priv = netdev_priv(dev);
+
+	for (i = 0; i < priv->num_port; i++)
+		if (priv->port[i].phydev)
+			return phy_ethtool_gset(priv->port[i].phydev, cmd);
+
+	return -ENODEV;
+}
+
+/* Set the network device settings */
+static int set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct ltq_switch_priv_t *priv;
+	int i;
+
+	priv = netdev_priv(dev);
+	pr_info("%s: called\n", __func__);
+
+	for (i = 0; i < priv->num_port; i++)
+		if (priv->port[i].phydev)
+			return phy_ethtool_sset(priv->port[i].phydev, cmd);
+
+	return -ENODEV;
+}
+
+/* Reset the device */
+static int nway_reset(struct net_device *dev)
+{
+	/*TODO*/
+	return 0;
+}
+
+/* Structure of the ether tool operation  */
+static const struct ethtool_ops ethtool_ops = {
+	.get_drvinfo		= get_drvinfo,
+	.get_settings		= get_settings,
+	.set_settings		= set_settings,
+	.nway_reset		= nway_reset,
+	.get_link		= ethtool_op_get_link,
+};
+
+/* open the network device interface*/
+static int ltq_eth_open(struct net_device *dev)
+{
+	int ret;
+	int flags = 1;  /* flag 1 for enable */
+
+	pr_debug("%s called for device %s\n", __func__, dev->name);
+#ifdef CONFIG_GRX500_CBM
+	/* Enable the p2p channel at CBM */
+	if (!cbm_turn_on_DMA_p2p())
+		pr_info("p2p channel turned ON !\n");
+	else
+		pr_info("p2p channel already ON !\n");
+#endif
+
+	ret = dp_rx_enable(dev, dev->name, flags);
+
+	if (ret != DP_SUCCESS) {
+		pr_err("%s: failed to enable for device: %s ret %d\n",
+		       __func__, dev->name, ret);
+		return -1;
+	}
+
+	return 0;
+}
+
+/* Stop the network device interface*/
+static int ltq_eth_stop(struct net_device *dev)
+{
+	int ret;
+	int flags = 0;  /* flag 0 for disable */
+
+	pr_debug("%s called for device %s\n", __func__, dev->name);
+	ret = dp_rx_enable(dev, dev->name, flags);
+
+	if (ret != DP_SUCCESS) {
+		pr_err("%s: failed to disable for device: %s ret %d\n",
+		       __func__, dev->name, ret);
+		return -1;
+	}
+	/* netif_stop_queue(dev); */
+
+	return 0;
+}
+
+/* Uninit the network device interface*/
+static void ltq_eth_uninit(struct net_device *dev)
+{
+	struct ltq_switch_priv_t *priv;
+	int ret;
+
+	pr_debug("%s called for device %s\n", __func__, dev->name);
+	priv = netdev_priv(dev);
+	priv->dp_subif.subif = 0;
+	priv->dp_subif.port_id = priv->dp_port_id;
+
+	if (priv->dp_port_id == DP_FAILURE) {
+		pr_debug("dp port id (%d) is invalid. ignore the deregister.\n",
+			 priv->dp_port_id);
+		return;
+	}
+	ret = dp_register_subif(priv->owner, dev, dev->name, &priv->dp_subif,
+				DP_F_DEREGISTER);
+
+	if (ret != DP_SUCCESS) {
+		pr_err("%s: failed to close for device: %s ret %d\n",
+		       __func__, dev->name, ret);
+	}
+}
+
+/* Send the packet to netwrok rx queue */
+static void eth_rx(struct net_device *dev, int len, struct sk_buff *skb)
+{
+	struct ltq_switch_priv_t *priv;
+
+	priv = netdev_priv(dev);
+	skb->dev = dev;
+	skb->protocol = eth_type_trans(skb, dev);
+
+	if (dev->features & NETIF_F_RXCSUM)
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	pr_debug("passing to stack: protocol: %x\n", skb->protocol);
+	netif_rx(skb);
+	priv->stats.rx_packets++;
+	priv->stats.rx_bytes += len;
+}
+
+static int32_t dp_fp_stop_tx(struct net_device *netif)
+{
+	return 0;
+}
+
+static int32_t dp_fp_restart_tx(struct net_device *netif)
+{
+	return 0;
+}
+
+static int32_t dp_fp_rx(struct net_device *rxif, struct net_device *txif,
+			struct sk_buff *skb, int32_t len)
+{
+	/*skb_put(skb,len);*/
+#ifdef DUMP_PACKET
+	if (skb->data) {
+		pr_ifo("raw data len:%d\n", len);
+		dump_skb(len, (char *)skb->data);
+	}
+
+#endif
+
+	if (skb) {
+		/*Remove PMAC to DMA header */
+		len -= (sizeof(ltq_pmac_header_t));
+		skb_pull(skb, (sizeof(ltq_pmac_header_t)));
+	} else {
+		pr_err("%s: skb from DP is null !\n", __func__);
+		goto rx_err_exit;
+	}
+
+	/* Pass it to the stack */
+#ifdef DUMP_PACKET
+
+	if (skb->data) {
+		pr_info("data sent to stack.\n");
+		dump_skb(len, (char *)skb->data);
+	}
+
+#endif
+
+	if (rxif) {
+		pr_debug("%s: rxed a packet from DP lib on interface %s\n",
+			 __func__, rxif->name);
+		eth_rx(rxif, len, skb);
+	} else {
+		pr_err("%s: error: rxed a packet from DP lib on interface %x\n",
+		       __func__, (unsigned int)rxif);
+		goto rx_err_exit;
+	}
+
+	return 0;
+rx_err_exit:
+
+	if (skb)
+		dev_kfree_skb_any(skb);
+
+	return -1;
+}
+
+/* Get the network device stats information */
+static struct
+rtnl_link_stats64 *ltq_get_stats(struct net_device *dev,
+				 struct rtnl_link_stats64 *storage)
+{
+#ifndef CONFIG_LTQ_DATAPATH_MIB
+	struct ltq_switch_priv_t *priv = netdev_priv(dev);
+	*storage = priv->stats;
+#else
+	dp_get_netif_stats(dev, NULL, storage, 0);
+#endif
+	return storage;
+}
+
+/* Trasmit timeout */
+static void ltq_tx_timeout(struct net_device *dev)
+{
+}
+
+/* Set the MAC address */
+static int ltq_set_mac_address(struct net_device *dev, void *p)
+{
+	struct sockaddr *addr = p;
+
+	if (netif_running(dev))
+		return -EBUSY;
+
+	if (!is_valid_ether_addr(addr->sa_data))
+		return -EINVAL;
+
+	memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+
+	return 0;
+}
+
+void gsw_reg_set_bit(struct core_ops *ops,  u16 nRegAddr, u16	nData)
+{
+	GSW_register_t reg_cfg;
+
+	memset((void *)&reg_cfg, 0x00, sizeof(reg_cfg));
+	reg_cfg.nRegAddr = nRegAddr;
+	ops->gsw_common_ops.RegisterGet(ops, &reg_cfg);
+	reg_cfg.nData |= nData;
+	ops->gsw_common_ops.RegisterSet(ops, &reg_cfg);
+}
+
+void gsw_reg_clr_bit(struct core_ops *ops, u16 nRegAddr, u16 nData)
+{
+	GSW_register_t reg_cfg;
+
+	memset((void *)&reg_cfg, 0x00, sizeof(reg_cfg));
+	reg_cfg.nRegAddr = nRegAddr;
+	ops->gsw_common_ops.RegisterGet(ops, &reg_cfg);
+	reg_cfg.nData &= ~nData;
+	ops->gsw_common_ops.RegisterSet(ops, &reg_cfg);
+}
+
+void gsw_reg_set_val(struct core_ops *ops, u16 nRegAddr, u16 nData)
+{
+	GSW_register_t reg_cfg;
+
+	memset((void *)&reg_cfg, 0x00, sizeof(reg_cfg));
+	reg_cfg.nRegAddr = nRegAddr;
+	reg_cfg.nData = nData;
+	ops->gsw_common_ops.RegisterSet(ops, &reg_cfg);
+}
+
+u16 gsw_reg_get_val(struct core_ops *ops, u16 nRegAddr)
+{
+	GSW_register_t reg_cfg;
+
+	memset((void *)&reg_cfg, 0x00, sizeof(reg_cfg));
+	reg_cfg.nRegAddr = nRegAddr;
+	ops->gsw_common_ops.RegisterGet(ops, &reg_cfg);
+
+	return reg_cfg.nData;
+}
+
+static int ltq_enable_gsw_l_jumbo(struct net_device *dev)
+{
+	struct ltq_switch_priv_t *priv = netdev_priv(dev);
+	struct core_ops *ops;
+
+	pr_info("%s called for id: %d\n", __func__, priv->id);
+
+	/* Do the GSW-L configuration */
+	pr_info("doing the GSW-L configuration for jumbo\n");
+	ops = gsw_get_swcore_ops(0);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	/* Set the MAC control register 2 to enable Jumbo frames */
+	gsw_reg_set_bit(ops, (0x8f9 + (0xc * (priv->id + 1))), 0x8);
+
+	/* PMAC control register 2 to enable jumbo frames */
+	pr_info("doing the PMAC configuration for jumbo at GSW-L\n");
+	gsw_reg_set_bit(ops, 0xd05, 0x8);
+
+	/* Set the frame length */
+	gsw_reg_set_val(ops, 0xd06, 9216);
+
+	return 0;
+}
+
+static int ltq_disable_gsw_l_jumbo(struct net_device *dev)
+{
+	struct ltq_switch_priv_t *priv = netdev_priv(dev);
+	struct core_ops *ops;
+
+	pr_info("%s called for id: %d\n", __func__, priv->id);
+
+	/* Do the GSW-L configuration */
+	pr_info("doing the GSW-L configuration for jumbo\n");
+	ops = gsw_get_swcore_ops(0);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	/* Set the MAC control register 2 to enable Jumbo frames */
+	gsw_reg_clr_bit(ops, (0x8f9 + (0xc * (priv->id + 1))), 0x8);
+
+	return 0;
+}
+
+static int ltq_enable_gsw_r_pmac_jumbo(struct net_device *dev)
+{
+	/* Do the GSW-R configuration */
+	struct core_ops *ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	/* PMAC control register 2 to enable jumbo frames */
+	pr_info("doing the PMAC configuration for jumbo at GSW-R\n");
+	gsw_reg_set_bit(ops, 0xd05, 0x8);
+
+	/* Set the frame length */
+	gsw_reg_set_val(ops, 0xd06, 1630);
+
+	return 0;
+}
+
+static int ltq_enable_gsw_r_jumbo(struct net_device *dev)
+{
+	/* Do the GSW-R configuration */
+	struct core_ops *ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	/* Set the MAC control register 2 to enable Jumbo frames */
+	pr_info("doing the GSW-R configuration for jumbo\n");
+	gsw_reg_set_bit(ops, 0x905, 0x8);
+
+	return 0;
+}
+
+static int ltq_disable_gsw_r_jumbo(struct net_device *dev)
+{
+	/* Do the GSW-R configuration */
+	struct core_ops *ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	/* Set the MAC control register 2 to enable Jumbo frames */
+	pr_info("doing the GSW-R configuration for jumbo\n");
+	gsw_reg_clr_bit(ops, 0x905, 0x8);
+
+	return 0;
+}
+
+/* Change the MTU value of the netwrok device interfaces */
+static int ltq_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct ltq_switch_priv_t *priv = netdev_priv(dev);
+
+	if (new_mtu < ETH_ZLEN || new_mtu > LTQ_ETH_MAX_DATA_LEN)
+		return -EINVAL;
+
+	/* if the MTU > 1500, do the jumbo config in switch */
+	if (new_mtu > ETH_DATA_LEN && !(priv->jumbo_enabled)) {
+		if (priv->wan) {
+			if (ltq_enable_gsw_r_jumbo(dev) < 0)
+				return -EIO;
+		} else {
+			if (ltq_enable_gsw_l_jumbo(dev) < 0)
+				return -EIO;
+		}
+
+		ltq_enable_gsw_r_pmac_jumbo(dev);
+		priv->jumbo_enabled = 1;
+	} else if (priv->jumbo_enabled) {
+		if (priv->wan)
+			ltq_disable_gsw_r_jumbo(dev);
+		else
+			ltq_disable_gsw_l_jumbo(dev);
+
+		priv->jumbo_enabled = 0;
+	}
+
+	dev->mtu = new_mtu;
+	return 0;
+}
+
+static int ltq_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct ltq_switch_priv_t *priv = netdev_priv(dev);
+	int ret;
+	int len;
+
+	/* Call the Datapath Library's TX function */
+	((struct dma_tx_desc_1 *)&skb->DW1)->field.ep = priv->dp_subif.port_id;
+	((struct dma_tx_desc_0 *)&skb->DW0)->field.dest_sub_if_id =
+		priv->dp_subif.subif;
+
+	len = skb->len;
+
+	if (dev->features & NETIF_F_HW_CSUM) {
+		ret = dp_xmit(dev, &priv->dp_subif, skb, skb->len,
+			      DP_TX_CAL_CHKSUM);
+	} else {
+		ret = dp_xmit(dev, &priv->dp_subif, skb, skb->len, 0);
+	}
+	if (!ret) {
+		priv->stats.tx_packets++;
+		priv->stats.tx_bytes += len;
+	} else {
+		priv->stats.tx_dropped++;
+	}
+	return 0;
+}
+
+/* Platform specific IOCTL's handler */
+static int ltq_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+	return -EOPNOTSUPP;
+}
+
+/* init of the network device */
+static int ltq_eth_init(struct net_device *dev)
+{
+#ifdef CONFIG_XRX500_MDIO_SUPPORT
+	int i;
+	struct ltq_switch_priv_t *priv;
+	int ret;
+
+	priv = netdev_priv(dev);
+	pr_debug("probing for number of ports = %d\n", priv->num_port);
+	pr_debug("%s called for device %s\n", __func__, dev->name);
+
+	for (i = 0; i < priv->num_port; i++) {
+		if (xrx500_mdio_probe(dev, &priv->port[i])) {
+			pr_warn("xrx500-mdio: probing phy of port %d failed\n",
+				priv->port[i].num);
+		} else {
+			dev->ethtool_ops = &ethtool_ops;
+		}
+	}
+
+	priv->dp_subif.subif = 0;
+	priv->dp_subif.port_id = priv->dp_port_id;
+
+	ret = dp_register_subif(priv->owner, dev, dev->name, &priv->dp_subif,
+				0);
+
+	if (ret != DP_SUCCESS) {
+		pr_err("%s: failed to open for device: %s ret %d\n",
+		       __func__, dev->name, ret);
+		return -1;
+	}
+
+#endif
+	return 0;
+}
+
+static int ltq_gsw_pmac_init(void)
+{
+	u8 i = 0, j = 0, k = 0;
+	GSW_PMAC_Eg_Cfg_t eg_cfg;
+	GSW_PMAC_Ig_Cfg_t ig_cfg;
+	GSW_CPU_PortCfg_t cpu_port_cfg;
+	GSW_portCfg_t gsw_port_cfg;
+
+	/* Do the GSW-L configuration */
+	struct core_ops *ops = gsw_get_swcore_ops(0);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	memset((void *)&eg_cfg, 0x00, sizeof(eg_cfg));
+	memset((void *)&ig_cfg, 0x00, sizeof(ig_cfg));
+	memset((void *)&cpu_port_cfg, 0x00, sizeof(cpu_port_cfg));
+
+	/**
+	 * 1. GSWIP-L PMAC Egress Configuration Table
+	 * Entry:
+	 * Address: (i from 0 to 15, j from 0 to 3)
+	 * Destination Port = 0, Traffic Class = i, Others field = j
+	 * Value:
+	 * DMA Channel = if i < 3? i: 3
+	 * PMAC_Flag = 1
+	 * Other fields = 0
+	 */
+	pr_info("PMAC_EG_CFG_SET for GSW-L\n");
+
+	for (i = 0; i <= 15; i++) {
+		for (j = 0; j <= 3; j++) {
+			memset((void *)&eg_cfg, 0x00, sizeof(eg_cfg));
+#if defined(SINGLE_RX_CH0_ONLY) && SINGLE_RX_CH0_ONLY
+			eg_cfg.nRxDmaChanId  = 0;
+#else
+			eg_cfg.nRxDmaChanId  = (i < 3) ? i : 3;
+#endif
+			eg_cfg.bRemL2Hdr	 = 0;
+			eg_cfg.numBytesRem   = 0;
+			eg_cfg.bFcsEna	   = 0;
+			eg_cfg.bPmacEna	  = 1;
+			eg_cfg.nResDW1	   = 0;
+			eg_cfg.nRes1DW0	  = 0;
+			eg_cfg.nRes2DW0	  = 0;
+			eg_cfg.nDestPortId   = 0;
+			eg_cfg.nTrafficClass = i;
+			eg_cfg.nFlowIDMsb	= j;
+			eg_cfg.bDecFlag	  = 0;
+			eg_cfg.bEncFlag	  = 0;
+			eg_cfg.bMpe1Flag	 = 0;
+			eg_cfg.bMpe2Flag	 = 0;
+			eg_cfg.bTCEnable	 = 1;
+			ops->gsw_pmac_ops.Pmac_Eg_CfgSet(ops, &eg_cfg);
+		}
+	}
+
+	/**
+	 * 2. GSWIP-L PMAC Ingress Configuration Table
+	 * Entry:
+	 * Address: (i from 0 to 15)
+	 * DMA Channel = i
+	 * Value:
+	 * PMAC_Flag = 1
+	 * SPPID_Mode = 1
+	 * SUBID_Mode = 1
+	 * CLASSEN_Mode = 1
+	 * CLASS_Mode = 1
+	 * PMAPEN_Mode = 1
+	 * PMAP_Mode = 1
+	 * TCPERR_DP = 1
+	 * DF_PMAC_HD.PMAP_EN = 1, DF_PMAC_HD.PMAP = 1 << i[2:0],
+	 * DF_PMAC_HD.CLASS_EN = 1, DF_PMAC_HD.CLASS = i[3]*2 + 1
+	 * Other fields = 0
+	 */
+	pr_info("PMAC_IG_CFG_SET for GSW-L\n");
+
+	for (i = 0; i <= 15; i++) {
+		memset((void *)&ig_cfg, 0x00, sizeof(ig_cfg));
+
+		ig_cfg.nTxDmaChanId = i;
+		ig_cfg.bErrPktsDisc = 1;
+		ig_cfg.bPmapDefault = 1;
+		ig_cfg.bPmapEna	= 1;
+		ig_cfg.bClassDefault = 1;
+		ig_cfg.bClassEna	 = 1;
+		ig_cfg.eSubId = 1;
+		ig_cfg.bSpIdDefault  = 1;
+		ig_cfg.bPmacPresent  = 1;
+		ig_cfg.defPmacHdr[0] = 0;
+		ig_cfg.defPmacHdr[1] = 0;
+		ig_cfg.defPmacHdr[2] = ((((i & 8) >> 3) * 2) + 1);/* 1/3 */
+		/* (1 << 7) | (1 << 4); */
+		ig_cfg.defPmacHdr[3] = 0x90;
+		ig_cfg.defPmacHdr[4] = 0;
+		ig_cfg.defPmacHdr[5] = 0;
+		/*if ( i >= 8)
+		 *ig_cfg.defPmacHdr[6] = 1 << (i & 0x7);
+		 *else
+		 */
+		ig_cfg.defPmacHdr[7] = 1 << (i & 0x7);
+		ops->gsw_pmac_ops.Pmac_Ig_CfgSet(ops, &ig_cfg);
+	}
+
+	/* Enable the Ingress Special Tag */
+	cpu_port_cfg.nPortId = 0;
+	cpu_port_cfg.bCPU_PortValid = 0;
+	cpu_port_cfg.bSpecialTagIngress = 1;
+	cpu_port_cfg.bSpecialTagEgress = 0;
+	cpu_port_cfg.bFcsCheck = 0;
+	cpu_port_cfg.bFcsGenerate = 1;
+	ops->gsw_common_ops.CPU_PortCfgSet(ops, &cpu_port_cfg);
+
+#ifdef CONFIG_USE_EMULATOR
+	/* Add some extra register writes for the 1.4.1 */
+	gsw_reg_set_val(ops, 0x90f, 0x182);
+
+	gsw_reg_set_val(ops, 0x91b, 0x182);
+
+	gsw_reg_set_val(ops, 0x927, 0x182);
+
+	gsw_reg_set_val(ops, 0x933, 0x182);
+
+	gsw_reg_set_val(ops, 0x93f, 0x182);
+
+#endif
+
+	/* Enable the CPU port MAC address spoofing detection */
+	gsw_reg_set_bit(ops, 0x480, 0x4000);
+
+	/* Do the GSW-R configuration */
+	ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	/**
+	 * 3. GSWIP-R PMAC Egress Configuration Table
+	 * Entry:
+	 * Address: (k i from 0 to 15,j from 0 to 63)
+	 * Destination Port = k, Others field = j
+	 * Value:
+	 * DMA Channel = if k <= 13? 0: k
+	 * PMAC_Flag = if k ==15 or k < 7? 1: 0
+	 * FCS_Mode = if k ==13? PTM_Bonding_Mode:0
+	 * L2_HD_RM = if k == 12 or k == 14? 1:0
+	 * L2_HD_Bytes = if k == 14? CAPWAP_HD_BYTES:0
+	 * Other fields = 0
+	 */
+	pr_info("PMAC_EG_CFG_SET for GSW-R\n");
+
+	for (k = 0; k <= 15; k++) {
+		for (i = 0; i <= 15; i++) {
+			for (j = 0; j <= 3; j++) {
+				memset((void *)&eg_cfg, 0x00, sizeof(eg_cfg));
+#ifdef CONFIG_USE_EMULATOR
+				eg_cfg.nRxDmaChanId  = (k <= 14) ? 0 : 5;
+#else
+
+				if (ltq_get_soc_rev() == 2)
+					eg_cfg.nRxDmaChanId = (k <= 13) ? 0 : 5;
+				else
+					eg_cfg.nRxDmaChanId = (k <= 13) ? 0 : k;
+
+#endif
+				/*((k == 15) || (k < 7)) ? 1 : 0; */
+				eg_cfg.bPmacEna = 1;
+				/*PTM_Bonding_Mode*/
+				eg_cfg.bFcsEna = (k == 13) ? 1 : 0;
+				eg_cfg.bRemL2Hdr = ((k == 12) ||
+						    (k == 14)) ? 1 : 0;
+				/*CAPWAP_HD_BYTES*/
+				eg_cfg.numBytesRem = (k == 14) ? 1 : 0;
+				eg_cfg.nResDW1	   = 0;
+				eg_cfg.nRes1DW0	  = 0;
+				eg_cfg.nRes2DW0	  = 0;
+				eg_cfg.nDestPortId   = k;
+				eg_cfg.nTrafficClass = i;
+				eg_cfg.bMpe1Flag	 = 0;
+				eg_cfg.bMpe2Flag	 = 0;
+				eg_cfg.bEncFlag	  = 0;
+				eg_cfg.bDecFlag	  = 0;
+				eg_cfg.nFlowIDMsb	= j;
+				eg_cfg.bTCEnable		= 1;
+
+				ops->gsw_pmac_ops.Pmac_Eg_CfgSet(ops, &eg_cfg);
+			}
+		}
+	}
+
+	/**
+	 * 4. GSWIP-R PMAC Ingress Configuration Table
+	 * Entry:
+	 * Address: (i from 0 to 15)
+	 * DMA Channel  = i
+	 * Value:
+	 * PMAC_Flag = if 5 < i < 15? 0: 1
+	 * SPPID_Mode = 0
+	 * SUBID_Mode = If 7 <= i <=8? 0: 1
+	 * CLASSEN_Mode = 0
+	 * CLASS_Mode = 0
+	 * PMAPEN_Mode = if i < 4 or i == 15? 1:0
+	 * PMAP_Mode = if i < 4 or i == 15? 1:0
+	 * TCPERR_DP = 1
+	 * DF_PMAC_HD.SPPID = i, DF_PMAC_HD.PMAP = if i == 15? 0x8000:0xFFFF
+	 * DF_PMAC_HD.PMAC_EN = if i==15?1:0
+	 * Other fields = 0
+	 */
+	pr_info("PMAC_IG_CFG_SET for GSW-R\n");
+
+	for (i = 0; i <= 15; i++) {
+		memset((void *)&ig_cfg, 0x00, sizeof(ig_cfg));
+
+		ig_cfg.nTxDmaChanId  = i;
+		ig_cfg.bPmacPresent  = 1; /*((i > 5) && (i < 15)) ? 0 : 1; */
+		/*ig_cfg.bSpIdDefault  = 0; */
+		/* For channel 15, use source port ID from default PMAC header*/
+		ig_cfg.bSpIdDefault = (i == 15) ? 1 : 0;
+		ig_cfg.eSubId = 0; /*((i == 6) || (i == 13)) ? 0 : 1;*/
+		ig_cfg.bClassDefault = 0;
+		ig_cfg.bClassEna	 = 0;
+		ig_cfg.bErrPktsDisc  = 1;
+
+		ig_cfg.bPmapDefault  = ((i < 4) || (i == 15)) ? 1 : 0;
+		ig_cfg.bPmapEna	  = ((i < 4) || (i == 15)) ? 1 : 0;
+
+		ig_cfg.defPmacHdr[0] = 0;
+		ig_cfg.defPmacHdr[1] = 0;
+		/*ig_cfg.defPmacHdr[2] = (i << 4); // Byte 2 (Bits 7:4)*/
+		/* For channel 15, source port is 0. */
+		ig_cfg.defPmacHdr[2] = (i == 15) ? 0 : (i << 4);
+		ig_cfg.defPmacHdr[3] = (i == 15) ? 0x80 : 0; /*Byte 3 (Bit 7) */
+		ig_cfg.defPmacHdr[4] = 0;
+		ig_cfg.defPmacHdr[5] = 0;
+		ig_cfg.defPmacHdr[6] = (i == 15) ? 0x80 : 0xFF;
+		ig_cfg.defPmacHdr[7] = (i == 15) ? 0x00 : 0xFF;
+
+		ops->gsw_pmac_ops.Pmac_Ig_CfgSet(ops, &ig_cfg);
+	}
+
+	/* Enable the Ingress Special Tag */
+	for (k = 0; k < 15; k++) {
+		memset((void *)&cpu_port_cfg, 0x00, sizeof(cpu_port_cfg));
+
+		cpu_port_cfg.nPortId = k;
+
+		/* get the current values first */
+		ops->gsw_common_ops.CPU_PortCfgGet(ops, &cpu_port_cfg);
+
+		/* change the required values and set it back */
+		cpu_port_cfg.bCPU_PortValid = 0;
+		cpu_port_cfg.bSpecialTagIngress = 1;
+		cpu_port_cfg.bSpecialTagEgress = 0;
+		cpu_port_cfg.bFcsCheck = 0;
+		cpu_port_cfg.bFcsGenerate = 1;
+		ops->gsw_common_ops.CPU_PortCfgSet(ops, &cpu_port_cfg);
+	}
+
+	/* Disable the Learning in the GSWIP-R */
+	for (k = 0; k < 15; k++) {
+		memset((void *)&gsw_port_cfg, 0x00, sizeof(gsw_port_cfg));
+
+		gsw_port_cfg.nPortId = k;
+		ops->gsw_common_ops.PortCfgGet(ops, &gsw_port_cfg);
+
+		gsw_port_cfg.bLearning = 1;
+		ops->gsw_common_ops.PortCfgSet(ops, &gsw_port_cfg);
+	}
+
+#ifdef CONFIG_USE_EMULATOR
+	/* Add some extra register writes for the 1.4.1 */
+	gsw_reg_set_val(ops, 0x903, 0x182);
+#endif
+
+	gsw_reg_set_val(ops, 0x454, 0x1);
+
+	gsw_reg_set_val(ops, 0x455, 0x1);
+
+	pr_info("\n\t GSW PMAC Init Done!!!\n");
+	return 0;
+}
+
+static void ltq_eth_drv_eth_addr_setup(struct net_device *dev, int port)
+{
+	u8 *ethaddr;
+	u32 val;
+	int i;
+
+	if (port == LTQ_ETHWAN_PORT)
+		ethaddr = MY_ETH0_ADDR + MAX_ADDR_LEN;
+	else
+		ethaddr = MY_ETH0_ADDR;
+
+	/*  read MAC address from the MAC table and put them into device */
+	for (i = 0, val = 0; i < 6; i++)
+		val += dev->dev_addr[i];
+
+	if (val == 0) {
+		for (i = 0, val = 0; i < 6; i++)
+			val += ethaddr[i];
+
+		if (val == 0) {
+			/*  ethaddr not set in u-boot   */
+			dev->dev_addr[0] = 0x00;
+			dev->dev_addr[1] = 0x20;
+			dev->dev_addr[2] = 0xda;
+			dev->dev_addr[3] = 0x86;
+			dev->dev_addr[4] = 0x23;
+			dev->dev_addr[5] = 0x74 + port;
+		} else {
+			for (i = 0; i < 5; i++)
+				dev->dev_addr[i] = ethaddr[i];
+
+			dev->dev_addr[5] = ethaddr[i] + port;
+		}
+	}
+}
+
+#ifdef CONFIG_USERSPACE_LINK_NOTIFICATION
+enum eth_cmd {
+	ETH_C_UNSPEC,
+	ETH_C_NOTIFY,
+	__ETH_C_MAX,
+};
+
+#define ETH_C_MAX (__ETH_C_MAX - 1)
+
+enum eth_attr {
+	ETH_A_UNSPEC,
+	ETH_A_LINK_NAME,
+	ETH_A_LINK_STATUS,
+	ETH_A_LINK_SPEED,
+	__ETH_A_MAX,
+};
+
+#define ETH_LINK_A_MAX (__ETH_A_MAX - 1)
+
+/* VRX318 TC message genelink family */
+struct genl_family eth_gnl_family = {
+	.id = GENL_ID_GENERATE, /* To generate an id for the family*/
+	.hdrsize = 0,
+	.name = "eth_drv_notify", /*family name, used by userspace application*/
+	.version = 1, /*version number  */
+	.maxattr = ETH_LINK_A_MAX,
+};
+
+/* VRX318 TC message multicast group */
+struct genl_multicast_group eth_grp = {
+	.name = "eth_mcgrp",
+};
+
+/* API definition for the driver to send TC notify messages to user application
+ * using genetlink method.
+ * pid: process id
+ * tc_msg: 1-link is up,0- link is down
+ * ln_no: interface name
+ */
+int ltq_eth_nl_msg_send(int pid, int link_status, int speed, char *if_name)
+{
+	struct sk_buff *skb;
+	int ret;
+	void *msg_head;
+
+	skb = genlmsg_new(NLMSG_GOODSIZE, GFP_KERNEL);
+
+	if (!skb)
+		return -ENOMEM;
+
+	/* create the message headers */
+	msg_head = genlmsg_put(skb, 0, 0,
+			       &eth_gnl_family, 0, ETH_C_NOTIFY);
+
+	if (!msg_head) {
+		ret = -ENOMEM;
+		pr_err("create message header fail!\n");
+		goto out;
+	}
+
+	nla_put_string(skb, ETH_A_LINK_NAME, if_name);
+
+	if (link_status) {
+		nla_put_string(skb, ETH_A_LINK_STATUS, "up");
+		nla_put_u16(skb, ETH_A_LINK_SPEED, speed);
+	} else {
+		nla_put_string(skb, ETH_A_LINK_STATUS, "down");
+	}
+	genlmsg_end(skb, msg_head);
+	ret = genlmsg_multicast(skb, pid, eth_grp.id, GFP_KERNEL);
+
+	if (ret != 0 && ret != -ESRCH) {
+		pr_err("failed to send out the multicast message:ret = %d\n",
+		       ret);
+		goto out;
+	}
+
+	return 0;
+out:
+	return ret;
+}
+
+int ltq_eth_genetlink_init(void)
+{
+	int ret;
+
+	/*register new family*/
+	ret = genl_register_family(&eth_gnl_family);
+
+	if (ret != 0) {
+		pr_err("Family registeration fail:%s\n",
+		       eth_gnl_family.name);
+		goto failure;
+	}
+
+	ret = genl_register_mc_group(&eth_gnl_family, &eth_grp);
+
+	if (ret != 0) {
+		pr_err("register mc group fail: %i, grp name: %s\n",
+		       ret, eth_grp.name);
+		genl_unregister_family(&eth_gnl_family);
+		goto failure;
+	} else
+		pr_info("register mc group pass: %i, grp name: %s, grp id:%d\n",
+			ret, eth_grp.name, eth_grp.id);
+
+	return 0;
+
+failure:
+	return ret;
+}
+
+void ltq_eth_genetlink_exit(void)
+{
+	int ret;
+
+	/* unregister mc groups */
+	genl_unregister_mc_group(&eth_gnl_family, &eth_grp);
+
+	/*unregister the family*/
+	ret = genl_unregister_family(&eth_gnl_family);
+
+	if (ret != 0)
+		pr_err("unregister Genetlink family %i\n", ret);
+}
+#endif
+
+/* This function is event handler for net_device change notify */
+static int phy_netdevice_event(struct notifier_block *nb, unsigned long action,
+			       void *ptr)
+{
+	struct ltq_switch_priv_t *priv = NULL;
+	struct net_device *dev = NULL;
+
+	if (!ptr)
+		return 0;
+
+	dev = (struct net_device *)ptr;
+
+	switch (action) {
+	case NETDEV_CHANGENAME: {
+		priv = netdev_priv(dev);
+
+		if (priv && priv->wan) {
+			pr_debug("\nUpdate WAN iface from [%s] to [%s]\n",
+				 wan_iface, dev->name);
+			memcpy(wan_iface, dev->name, IFNAMSIZ);
+		}
+	}
+	}
+
+	return NOTIFY_OK;
+}
+
+#ifdef CONFIG_XRX500_MDIO_SUPPORT
+static
+void xrx500_of_port(struct ltq_switch_priv_t *priv, struct device_node *port)
+{
+	const __be32 *addr, *id = of_get_property(port, "reg", NULL);
+	struct xrx500_port *p = &priv->port[priv->num_port];
+	struct resource irqres;
+
+	if (!id)
+		return;
+
+	memset(p, 0, sizeof(struct xrx500_port));
+	p->phy_node = of_parse_phandle(port, "phy-handle", 0);
+	addr = of_get_property(p->phy_node, "reg", NULL);
+
+	if (!addr) {
+		pr_info("no real internal PHY attached to this interface !\n");
+		return;
+	}
+
+	p->num = *id;
+	p->phy_addr = *addr;
+	p->phy_if = of_get_phy_mode(port);
+
+	if (of_irq_to_resource_table(port, &irqres, 1) == 1)
+		p->irq_num = irqres.start;
+	else
+		pr_err("couldn't get irq number for gphy !!\n");
+
+	priv->num_port++;
+
+	/* is this port a wan port ? */
+	if (priv->wan)
+		priv->hw->wan_map |= BIT(p->num);
+
+	priv->port_map |= BIT(p->num);
+
+	/* store the port id in the hw struct so we can map ports -> devices */
+	priv->hw->port_map[p->num] = priv->hw->num_devs;
+}
+
+static int xrx500_of_iface(struct xrx500_hw *hw, struct device_node *iface,
+			   struct platform_device *pdev)
+{
+	struct ltq_switch_priv_t *priv;
+	struct device_node *port;
+	const __be32 *wan;
+	u32 dp_dev_port_param, dp_port_id_param;
+	dp_cb_t cb = {0};
+	u32 dp_port_id = 0;
+	char name[16];
+	int ret;
+
+	/* alloc the network device */
+	hw->devs[hw->num_devs] = alloc_etherdev(sizeof(ltq_switch_priv_t));
+
+	if (!hw->devs[hw->num_devs]) {
+		pr_debug("allocated failed for interface %d\n",
+			 hw->num_devs);
+		return -ENOMEM;
+	}
+
+	priv = netdev_priv(hw->devs[hw->num_devs]);
+
+	/* is this the wan interface ? */
+	wan = of_get_property(iface, "lantiq,wan", NULL);
+
+	if (wan && (*wan == 1))
+		priv->wan = 1;
+	else
+		priv->wan = 0;
+
+	/* setup the network device */
+	if (priv->wan)
+		snprintf(name, sizeof(name), wan_iface);
+	else
+		snprintf(name, sizeof(name), "eth0_%d", hw->num_devs);
+
+	ret = of_property_read_u32(iface, "dp-dev-port",
+				   &dp_dev_port_param);
+	if (ret < 0) {
+		pr_info("ERROR : Property dp-dev-port could not be read from DT for if %s\n",
+			name);
+		return ret;
+	}
+
+	ret = of_property_read_u32(iface, "dp-port-id",
+				   &dp_port_id_param);
+	if (ret < 0) {
+		pr_info("ERROR : Property dp-port-id could not be read from DT for if %s\n",
+			name);
+		return ret;
+	}
+
+	strcpy(hw->devs[hw->num_devs]->name, name);
+	hw->devs[hw->num_devs]->netdev_ops = &ltq_eth_drv_ops;
+	hw->devs[hw->num_devs]->watchdog_timeo = LTQ_TX_TIMEOUT;
+	hw->devs[hw->num_devs]->needed_headroom = sizeof(ltq_pmac_header_t);
+	SET_NETDEV_DEV(hw->devs[hw->num_devs], &pdev->dev);
+
+	/* setup our private data */
+	priv->hw = hw;
+	priv->id = hw->num_devs;
+	spin_lock_init(&priv->lock);
+
+	priv->owner = &g_ltq_eth_module[hw->num_devs];
+	sprintf(priv->owner->name, "module%02d", priv->id);
+
+	if (priv->wan)
+		dp_port_id  = dp_alloc_port(priv->owner, hw->devs[hw->num_devs],
+					    dp_dev_port_param, dp_port_id_param,
+					    NULL, DP_F_FAST_ETH_WAN);
+	else
+		dp_port_id  = dp_alloc_port(priv->owner, hw->devs[hw->num_devs],
+					    dp_dev_port_param, dp_port_id_param,
+					    NULL, DP_F_FAST_ETH_LAN);
+
+	if (dp_port_id == DP_FAILURE) {
+		pr_err("dp_alloc_port failed for %s with port_id %d\n",
+		       hw->devs[hw->num_devs]->name, priv->id + 1);
+		return -ENODEV;
+	}
+
+	priv->dp_port_id = dp_port_id;
+	cb.stop_fn = (dp_stop_tx_fn_t)dp_fp_stop_tx;
+	cb.restart_fn  = (dp_restart_tx_fn_t)dp_fp_restart_tx;
+	cb.rx_fn = (dp_rx_fn_t)dp_fp_rx;
+#ifdef CONFIG_XRX500_ETH_DRV_COC_SUPPORT
+	cb.dp_coc_confirm_stat_fn = (dp_coc_confirm_stat) dp_fp_coc_confirm;
+#endif
+
+	if (dp_register_dev(priv->owner, dp_port_id, &cb, 0) != DP_SUCCESS) {
+		pr_err("dp_register_dev failed for %s\n and port_id %d",
+		       hw->devs[hw->num_devs]->name, dp_port_id);
+		dp_alloc_port(priv->owner, hw->devs[hw->num_devs],
+			      dp_dev_port_param, dp_port_id_param,
+			      NULL, DP_F_DEREGISTER);
+		return -ENODEV;
+	}
+
+	/* load the ports that are part of the interface */
+	for_each_child_of_node(iface, port) {
+		if (of_device_is_compatible(port, "lantiq,xrx500-pdi-port"))
+			xrx500_of_port(priv, port);
+	}
+
+#ifdef CONFIG_LTQ_TOE_DRIVER
+	hw->devs[hw->num_devs]->features = NETIF_F_SG | NETIF_F_TSO |
+					   NETIF_F_HW_CSUM;
+	hw->devs[hw->num_devs]->hw_features = NETIF_F_SG | NETIF_F_TSO |
+					      NETIF_F_HW_CSUM;
+	hw->devs[hw->num_devs]->vlan_features = NETIF_F_SG | NETIF_F_TSO |
+						NETIF_F_HW_CSUM;
+	hw->devs[hw->num_devs]->gso_max_size  = GSO_MAX_SIZE;
+#else
+	hw->devs[hw->num_devs]->features = NETIF_F_SG;
+	hw->devs[hw->num_devs]->hw_features = NETIF_F_SG;
+	if (g_soc_data.hw_checksum) {
+		hw->devs[hw->num_devs]->features |= NETIF_F_HW_CSUM;
+		hw->devs[hw->num_devs]->hw_features |= NETIF_F_HW_CSUM;
+		pr_debug("%s: hw csum offload is enabled!\n", __func__);
+	} else {
+		pr_debug("%s: hw csum offload is disable!\n", __func__);
+	}
+#endif
+
+	if (g_rx_csum_offload) {
+		pr_info("%s: rx csum offload is enabled !\n", __func__);
+		hw->devs[hw->num_devs]->features |= NETIF_F_RXCSUM;
+		hw->devs[hw->num_devs]->hw_features |= NETIF_F_RXCSUM;
+	} else {
+		pr_info("%s: rx csum offload is disabled !\n", __func__);
+	}
+	ltq_eth_drv_eth_addr_setup(hw->devs[hw->num_devs], priv->id);
+
+	/* register the actual device */
+	if (!register_netdev(hw->devs[hw->num_devs]))
+		hw->num_devs++;
+
+	return 0;
+}
+
+static int xrx500_mdio_pae_wr(struct mii_bus *bus, int addr, int reg, u16 val)
+{
+	GSW_MDIO_data_t mmd_data;
+	struct core_ops *ops;
+
+	pr_debug("%s called with phy addr:%d and reg: %x and val: %x\n",
+		 __func__, addr, reg, val);
+
+	ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	memset((void *)&mmd_data, 0x00, sizeof(mmd_data));
+	mmd_data.nAddressDev = addr;
+	mmd_data.nAddressReg = reg;
+	mmd_data.nData = val;
+	ops->gsw_common_ops.MDIO_DataWrite(ops, &mmd_data);
+
+	return 0;
+}
+
+static int xrx500_mdio_pae_rd(struct mii_bus *bus, int addr, int reg)
+{
+	GSW_MDIO_data_t mmd_data;
+	struct core_ops *ops;
+
+	pr_debug("%s called with phy addr:%d and reg: %x\n",
+		 __func__, addr, reg);
+
+	ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	memset((void *)&mmd_data, 0x00, sizeof(mmd_data));
+	mmd_data.nAddressDev = addr;
+	mmd_data.nAddressReg = reg;
+	ops->gsw_common_ops.MDIO_DataRead(ops, &mmd_data);
+
+	pr_debug("returing: %x\n", mmd_data.nData);
+	return mmd_data.nData;
+}
+
+static int xrx500_mdio_wr(struct mii_bus *bus, int addr, int reg, u16 val)
+{
+	GSW_MDIO_data_t mmd_data;
+	struct core_ops *ops;
+
+	pr_debug("%s called with phy addr:%d and reg: %x and val: %x\n",
+		 __func__, addr, reg, val);
+
+	ops = gsw_get_swcore_ops(0);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	memset((void *)&mmd_data, 0x00, sizeof(mmd_data));
+	mmd_data.nAddressDev = addr;
+	mmd_data.nAddressReg = reg;
+	mmd_data.nData = val;
+	ops->gsw_common_ops.MDIO_DataWrite(ops, &mmd_data);
+
+	return 0;
+}
+
+static int xrx500_mdio_rd(struct mii_bus *bus, int addr, int reg)
+{
+	GSW_MDIO_data_t mmd_data;
+	struct core_ops *ops;
+
+	pr_debug("%s called with phy addr:%d and reg: %x\n",
+		 __func__, addr, reg);
+
+	ops = gsw_get_swcore_ops(0);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	memset((void *)&mmd_data, 0x00, sizeof(mmd_data));
+	mmd_data.nAddressDev = addr;
+	mmd_data.nAddressReg = reg;
+	ops->gsw_common_ops.MDIO_DataRead(ops, &mmd_data);
+
+	pr_debug("returing: %x\n", mmd_data.nData);
+	return mmd_data.nData;
+}
+
+static int xrx500_of_mdio(struct xrx500_hw *hw, struct device_node *np)
+{
+	hw->mii_bus = mdiobus_alloc();
+
+	if (!hw->mii_bus)
+		return -ENOMEM;
+
+	hw->mii_bus->read = xrx500_mdio_rd;
+	hw->mii_bus->write = xrx500_mdio_wr;
+	hw->mii_bus->name = "lantiq,xrx500-mdio";
+	snprintf(hw->mii_bus->id, MII_BUS_ID_SIZE, "%x", 0);
+
+	pr_info("registering one of MII bus\n");
+
+	if (of_mdiobus_register(hw->mii_bus, np)) {
+		mdiobus_free(hw->mii_bus);
+		return -ENXIO;
+	}
+
+	return 0;
+}
+
+static int xrx500_of_mdio_pae(struct xrx500_hw *hw, struct device_node *np)
+{
+	hw->mii_bus_pae = mdiobus_alloc();
+
+	if (!hw->mii_bus_pae)
+		return -ENOMEM;
+
+	hw->mii_bus_pae->read = xrx500_mdio_pae_rd;
+	hw->mii_bus_pae->write = xrx500_mdio_pae_wr;
+	hw->mii_bus_pae->name = "lantiq,xrx500-mdio-pae";
+	snprintf(hw->mii_bus_pae->id, MII_BUS_ID_SIZE, "%x", 1);
+
+	pr_info("registering PAE MII bus\n");
+
+	if (of_mdiobus_register(hw->mii_bus_pae, np)) {
+		mdiobus_free(hw->mii_bus_pae);
+		return -ENXIO;
+	}
+
+	return 0;
+}
+
+#ifdef SW_POLLING
+static void xrx500_gmac_update(struct xrx500_port *port)
+{
+	u16 phyaddr = port->phydev->addr & MDIO_PHY_ADDR_MASK;
+
+	if (port->phydev->link)
+		phyaddr |= MDIO_PHY_LINK_UP;
+	else
+		phyaddr |= MDIO_PHY_LINK_DOWN;
+
+	if (port->phydev->duplex == DUPLEX_FULL)
+		phyaddr |= MDIO_PHY_FDUP_EN;
+	else
+		phyaddr |= MDIO_PHY_FDUP_DIS;
+
+	udelay(1);
+}
+#else
+static void xrx500_gmac_update(struct xrx500_port *port)
+{
+}
+#endif
+static void xrx500_mdio_link(struct net_device *dev)
+{
+	struct ltq_switch_priv_t *priv;
+	int i;
+
+	priv = netdev_priv(dev);
+	pr_debug("%s called..\n", __func__);
+
+	for (i = 0; i < priv->num_port; i++) {
+		if (!priv->port[i].phydev)
+			continue;
+
+		if (priv->port[i].link != priv->port[i].phydev->link) {
+			xrx500_gmac_update(&priv->port[i]);
+			priv->port[i].link = priv->port[i].phydev->link;
+			/* netdev_info(dev, "port %d %s link\n",
+			 *	priv->port[i].num,
+			 *	(priv->port[i].link)?("got"):("lost"));
+			 */
+#ifdef CONFIG_USERSPACE_LINK_NOTIFICATION
+			ltq_eth_nl_msg_send(0, priv->port[i].link,
+					    priv->port[i].phydev->speed,
+					    dev->name);
+#endif
+			phy_print_status(priv->port[i].phydev);
+		}
+	}
+}
+
+static int xrx500_mdio_probe(struct net_device *dev, struct xrx500_port *port)
+{
+	struct phy_device *phydev = NULL;
+	struct ltq_switch_priv_t *priv = NULL;
+	struct mii_bus *bus = NULL;
+
+	priv = netdev_priv(dev);
+
+	if (priv->wan)
+		bus = priv->hw->mii_bus_pae;
+	else
+		bus = priv->hw->mii_bus;
+
+	if (!bus) {
+		pr_info("No mdio bus defined for this port!\n");
+		return -ENODEV;
+	}
+
+	phydev = mdiobus_get_phy(bus, port->phy_addr);
+	if (!phydev) {
+		netdev_err(dev, "no PHY found\n");
+		return -ENODEV;
+	}
+
+	pr_info("trying to connect: %s to device: %s with irq: %d\n",
+		dev->name, phydev_name(phydev), port->irq_num);
+	phydev->irq = port->irq_num;
+	phydev = phy_connect(dev, phydev_name(phydev), &xrx500_mdio_link,
+			     port->phy_if);
+
+	if (IS_ERR(phydev)) {
+		netdev_err(dev, "Could not attach to PHY\n");
+		return PTR_ERR(phydev);
+	}
+
+	phydev->supported &= (SUPPORTED_10baseT_Half
+			      | SUPPORTED_10baseT_Full
+			      | SUPPORTED_100baseT_Half
+			      | SUPPORTED_100baseT_Full
+			      | SUPPORTED_1000baseT_Half
+			      | SUPPORTED_1000baseT_Full
+			      | SUPPORTED_Autoneg
+			      | SUPPORTED_MII
+			      | SUPPORTED_TP);
+	phydev->advertising = phydev->supported;
+	port->phydev = phydev;
+
+	pr_info("%s: attached PHY [%s] (phy_addr=%s, irq=%d)\n",
+		dev->name, phydev->drv->name,
+		phydev_name(phydev), phydev->irq);
+
+	phy_read_status(phydev);
+	phy_start_aneg(phydev);
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_XRX500_ETH_DRV_COC_SUPPORT
+/* switch api related routines */
+/*Base address GSWIP-L */
+static void __iomem *ltq_eth_gswl_base = (void __iomem *)KSEG1ADDR(0x1c000000);
+/* Base address GSWIP-R */
+static void __iomem *ltq_eth_gswr_base = (void __iomem *)KSEG1ADDR(0x1a000000);
+
+/** read the gswitch register */
+static void ltq_eth_gsw_r32(void __iomem *gsw_base, short offset, short shift,
+			    short size, u32 *value)
+{
+	u32 rvalue, mask;
+
+	rvalue = ltq_r32(gsw_base + (offset * 4));
+	mask = (1 << size) - 1;
+	rvalue = (rvalue >> shift);
+	*value = (rvalue & mask);
+}
+
+/** read and update the GSWIP register */
+static void ltq_eth_gsw_w32(void __iomem *gsw_base, short offset, short shift,
+			    short size, u32 value)
+{
+	u32 rvalue, mask;
+
+	rvalue = ltq_r32(gsw_base + (offset * 4));
+	mask = (1 << size) - 1;
+	mask = (mask << shift);
+	value = ((value << shift) & mask);
+	value = ((rvalue & ~mask) | value);
+	ltq_w32(value, (gsw_base + (offset * 4)));
+}
+
+static int32_t dp_fp_coc_confirm(enum ltq_cpufreq_state new_state,
+				 enum ltq_cpufreq_state old_state,
+				 u32 flags)
+{
+	GSW_register_t reg_cfg;
+	int ret;
+
+	if ((new_state != g_ltq_eth_drv_coc_state) &&
+	    (new_state != LTQ_CPUFREQ_PS_D0)) {
+		pr_debug("%s: CoC state changed from: %d to : %d enable irq!\n",
+			 __func__, g_ltq_eth_drv_coc_state, new_state);
+
+		/* Do the GSW-L configuration */
+		struct core_ops *ops = gsw_get_swcore_ops(0);
+
+		if (!ops) {
+			pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+			return -EIO;
+		}
+
+		/* Clear the BM interrupt */
+		gsw_reg_set_val(ops, 0x55, 0x100);
+
+		/* Enable the BM interrupt */
+		gsw_reg_set_bit(ops, 0x14, 0x1);
+
+		/* Enable the QCGN interrupt */
+		gsw_reg_set_bit(ops, 0x54, 0x100);
+
+		/* Do the PAE configuration */
+		ops = gsw_get_swcore_ops(1);
+
+		if (!ops) {
+			pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+			return -EIO;
+		}
+
+		/* Clear all the pending metering interrupt */
+		gsw_reg_set_val(ops, 0x489, 0x100);
+
+		/* Enable the PCE interrupt */
+		gsw_reg_set_bit(ops, 0x14, 0x2);
+
+		/* Enable PCE interrupt for port 0 */
+		gsw_reg_set_bit(ops, 0x465, 0x1);
+
+		/* Enable metering interrupt inside PCE */
+		gsw_reg_set_bit(ops, 0x488, 0x100);
+
+	} else if (g_ltq_eth_drv_coc_state != new_state &&
+		   new_state == LTQ_CPUFREQ_PS_D0) {
+		pr_debug("%s: CoC state changed from : %d to : %d.\n",
+			 __func__, g_ltq_eth_drv_coc_state, new_state);
+		/*disable_irq(g_ltq_eth_gswl_irq);*/
+	} else {
+		pr_debug("duplicate call to confirm to new state: %d!\n",
+			 new_state);
+	}
+
+	g_ltq_eth_drv_coc_state =  new_state;
+	return 0;
+}
+
+static void ltq_eth_gswl_tasklet(unsigned long ptr)
+{
+	GSW_register_t reg_cfg;
+	GSW_API_HANDLE gswl;
+	u32 intr_type, irq_status;
+	int ret = 0;
+
+	pr_debug("tasklet called..\n");
+	/* Do the GSW-L configuration */
+	struct core_ops *ops = gsw_get_swcore_ops(0);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	while (!bitmap_empty(g_ltq_eth_intr_type, LTQ_ETH_NUM_INTERRUPTS)) {
+		intr_type = find_first_bit(g_ltq_eth_intr_type,
+					   LTQ_ETH_NUM_INTERRUPTS);
+
+		/* Read the status */
+		switch (intr_type) {
+		case 1:
+
+			irq_status = gsw_reg_get_val(ops, 0x55);
+			pr_debug("BM interrupt with status: %x!\n", irq_status);
+
+			/* Egress Queue Congestion Status Change */
+			if (irq_status & 0x100) {
+				/* Mask the interrupt */
+				gsw_reg_clr_bit(ops, 0x54, 0x100);
+
+				/* Clear all the interrupts */
+				gsw_reg_set_val(ops, 0x55, irq_status);
+
+				/* Clear at the top level */
+				gsw_reg_set_val(ops, 0x15, 1);
+
+				/* There is some traffic, so call the dp library
+				 * to change the power state to upscale
+				 */
+				dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0,
+						    DP_COC_REQ_ETHERNET);
+
+			} else {
+				pr_err("non QCGN interrupts from BM are not handled !");
+			}
+			clear_bit(1, g_ltq_eth_intr_type);
+			break;
+
+		default:
+			pr_err("%s: this irq is not handled..\n", __func__);
+			break;
+		}
+	}
+}
+
+static irqreturn_t ltq_eth_gswl_isr(int irq, void *dev_id)
+{
+	u32 irq_status, irq_mask;
+
+	ltq_eth_gsw_r32(ltq_eth_gswl_base, 0x15, 0, 16, &irq_status);
+
+	/* Buffer Manager Interrupt */
+	if (irq_status & 0x1) {
+		/* Mask the BM Interrupt */
+		ltq_eth_gsw_r32(ltq_eth_gswl_base, 0x14, 0, 16, &irq_mask);
+
+		irq_mask &= ~0x1;
+		ltq_eth_gsw_w32(ltq_eth_gswl_base, 0x14, 0, 16, irq_mask);
+
+		set_bit(1, g_ltq_eth_intr_type);
+
+		/* Schedule the tasklet */
+		tasklet_schedule(&gswl_tasklet);
+	} else {
+		pr_err("%s: ..........: %x", __func__, irq_status);
+	}
+
+	return IRQ_HANDLED;
+}
+
+/* PAE interrupt related */
+
+static irqreturn_t ltq_eth_pae_isr(int irq, void *dev_id)
+{
+	u32 irq_status, irq_mask;
+
+	ltq_eth_gsw_r32(ltq_eth_gswr_base, 0x15, 0, 16, &irq_status);
+
+	/* PCE interrupt */
+	if (irq_status & 0x2) {
+		ltq_eth_gsw_r32(ltq_eth_gswr_base, 0x14, 0, 16, &irq_mask);
+
+		irq_mask &= ~0x2;
+		ltq_eth_gsw_w32(ltq_eth_gswr_base, 0x14, 0, 16, irq_mask);
+
+		set_bit(2, g_ltq_pae_intr_type);
+
+		/* Schedule the tasklet */
+		tasklet_schedule(&pae_tasklet);
+	} else {
+		pr_err("%s: ..........: %x", __func__, irq_status);
+	}
+	return IRQ_HANDLED;
+}
+
+static void ltq_eth_pae_tasklet(unsigned long ptr)
+{
+	GSW_register_t reg_cfg;
+	GSW_API_HANDLE gswr;
+	u32 intr_type, pce_irq_status;
+	int ret;
+
+	pr_debug("PAE tasklet called..\n");
+	struct core_ops *ops = gsw_get_swcore_ops(1);
+
+	if (!ops) {
+		pr_err("%s: Open SWAPI device FAILED!\n", __func__);
+		return -EIO;
+	}
+
+	while (!bitmap_empty(g_ltq_pae_intr_type, LTQ_ETH_NUM_INTERRUPTS)) {
+		intr_type = find_first_bit(g_ltq_pae_intr_type,
+					   LTQ_ETH_NUM_INTERRUPTS);
+
+		switch (intr_type) {
+		/* PCE interrupt */
+		case 2:
+			/* Find out the port */
+
+			pr_debug("PCE isr_0: %x!\n",
+				 gsw_reg_get_val(ops, 0x467));
+
+			/* Support only for port 0 */
+			if (gsw_reg_get_val(ops, 0x467) & 0x1) {
+				pce_irq_status = gsw_reg_get_val(ops, 0x489);
+				pr_debug("PCE isr_0 internal: %x!\n",
+					 pce_irq_status);
+
+				/* Metering based bp status change interrupt */
+				if (pce_irq_status & 0x100) {
+					/* Mask the interrupt */
+					gsw_reg_clr_bit(ops, 0x488, 0x100);
+
+					/* Clear all the interrupts */
+					gsw_reg_set_val(ops, 0x467, 1);
+
+					gsw_reg_set_val(ops, 0x489,
+							pce_irq_status);
+
+					/* There is some traffic, so call the
+					 * datapth library to change the power
+					 * state to upscale
+					 */
+					dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0,
+							    DP_COC_REQ_ETHERNET);
+
+				} else {
+					pr_err("non metering intr not handled!");
+					break;
+				}
+
+				clear_bit(2, g_ltq_pae_intr_type);
+			} else {
+				pr_err("%s: only port 0 irq is handled..\n",
+				       __func__);
+				return;
+			}
+
+			break;
+
+		default:
+			pr_err("%s: this irq is not handled..\n", __func__);
+			break;
+		}
+	}
+}
+#endif
+
+/* Initialization Ethernet module */
+static int ltq_eth_drv_init(struct platform_device *pdev)
+{
+	int ret = 0;
+	struct device_node *node = pdev->dev.of_node;
+#ifdef CONFIG_XRX500_MDIO_SUPPORT
+	struct device_node *mdio_np, *iface_np;
+	struct mii_bus *bus;
+#else
+	dp_cb_t cb = {0};
+	u32 dp_port_id = 0;
+	int i = 0;
+	struct ltq_switch_priv_t *priv = NULL;
+#endif
+
+#ifdef CONFIG_XRX500_ETH_DRV_COC_SUPPORT
+	struct resource irqres[2];
+#endif
+
+	memset(g_ltq_eth_module, 0, sizeof(g_ltq_eth_module));
+
+	ret = of_property_read_u32(node, "lantiq,eth-switch-mode",
+				   &g_eth_switch_mode);
+
+	if (ret < 0) {
+		pr_info("couldn't get the eth switch mode from DT.");
+		g_eth_switch_mode = 0;
+		ret = 0;
+	}
+
+	if (g_eth_switch_mode > 0) {
+		/* HW init of the Switch */
+		if (ltq_gsw_pmac_init() < 0)
+			pr_info("%s[%d]: switch PMAC init failed..\n",
+				__func__, __LINE__);
+	} else {
+		pr_debug("Ethernet driver do not need to config the switch.\n");
+	}
+
+	ret = of_property_read_u32(node, "lantiq,eth-rx-csum-offload",
+				   &g_rx_csum_offload);
+
+	if (ret < 0) {
+		dev_info(&pdev->dev,
+			 "couldn't get the RX CSUM offload setting from DT.");
+		dev_info(&pdev->dev, " by default its disabled !\n");
+		ret = 0;
+	}
+
+#ifdef CONFIG_XRX500_MDIO_SUPPORT
+	/* bring up the mdio bus */
+	mdio_np = of_find_compatible_node(node, NULL,
+					  "lantiq,xrx500-mdio");
+
+	if (mdio_np) {
+		if (xrx500_of_mdio(&xrx500_hw, mdio_np))
+			dev_err(&pdev->dev, "mdio probe failed\n");
+
+		/* bring up the mdio bus for PAE */
+		mdio_np = of_find_compatible_node(node, NULL,
+						  "lantiq,xrx500-mdio-pae");
+
+		if (mdio_np)
+			if (xrx500_of_mdio_pae(&xrx500_hw, mdio_np))
+				dev_err(&pdev->dev, "mdio probe of PAE failed\n");
+
+	} else {
+		mdio_np = of_find_compatible_node(node, NULL,
+						  "intel,falconmx-mdio");
+
+		if (mdio_np)
+			pr_debug("The mdio bus intel,falconmx-mdio found.\n");
+		else
+			pr_err("No MDIO bus defined!\n");
+	}
+
+	bus = xrx500_hw.mii_bus;
+	if (bus)
+		bus->parent = &pdev->dev;
+
+	/* load the interfaces */
+	/* add a dummy interface */
+	xrx500_hw.num_devs = 0;
+	for_each_available_child_of_node(node, iface_np) {
+		if (of_device_is_compatible(iface_np, "lantiq,xrx500-pdi")) {
+			pr_debug("adding the interface: %d\n",
+				 xrx500_hw.num_devs);
+
+			if (!of_device_is_available(iface_np)) {
+				pr_debug("device not available.\n");
+				continue;
+			}
+			if (xrx500_hw.num_devs < NUM_ETH_INF) {
+				xrx500_of_iface(&xrx500_hw, iface_np, pdev);
+			} else {
+				dev_err(&pdev->dev,
+					"only %d interfaces allowed\n",
+					NUM_ETH_INF);
+			}
+		}
+	}
+
+	if (!xrx500_hw.num_devs) {
+		dev_err(&pdev->dev, "failed to load interfaces\n");
+		return -ENOENT;
+	}
+
+#else
+	for (i = 0; i < NUM_ETH_INF; i++) {
+		static char name[16];
+		int err;
+
+		if (i == 6)
+			sprintf(name, wan_iface);
+		else
+			sprintf(name, "eth0_%d", i);
+
+		eth_dev[i] = alloc_etherdev(sizeof(ltq_switch_priv_t));
+
+		if (!eth_dev[i]) {
+			pr_err("%s[%d]: no memory for eth_dev!!!\n",
+			       __func__, __LINE__);
+			ret = -ENOMEM;
+			break;
+		}
+
+		/* setup the network device */
+		strcpy(eth_dev[i]->name, name);
+		eth_dev[i]->netdev_ops = &ltq_eth_drv_ops;
+		eth_dev[i]->watchdog_timeo = LTQ_TX_TIMEOUT;
+		eth_dev[i]->needed_headroom = sizeof(ltq_pmac_header_t);
+		/*eth_dev[i]->ifindex = i+1;*/
+
+		/* setup the private data */
+		priv = netdev_priv(eth_dev[i]);
+		priv->phy_addr = i;
+
+		/* By default, advertise supported  speed/duplex settings. */
+		priv->flags |= (FLAG_ADV_10HALF |
+				FLAG_ADV_10FULL |
+				FLAG_ADV_100HALF |
+				FLAG_ADV_100FULL |
+				FLAG_ADV_1000HALF |
+				FLAG_ADV_1000FULL);
+
+		/* By default, auto-negotiate PAUSE. */
+		priv->flags |= FLAG_PAUSE_AUTO;
+		spin_lock_init(&priv->lock);
+
+		priv->owner = &g_ltq_eth_module[i];
+		sprintf(priv->owner->name, "module%02d", i);
+
+		if (i == 6) {
+			dp_port_id  = dp_alloc_port(priv->owner, eth_dev[i],
+						    15, 15, NULL,
+						    DP_F_FAST_ETH_WAN);
+		} else {
+			dp_port_id  = dp_alloc_port(priv->owner, eth_dev[i],
+						    i + 1,
+						    i + 1,
+						    NULL,
+						    DP_F_FAST_ETH_LAN);
+		}
+
+		if (dp_port_id == DP_FAILURE) {
+			pr_err("dp_alloc_port failed for %s with port_id %d\n",
+			       eth_dev[i]->name, i + 1);
+			ret = -ENODEV;
+			break;
+		}
+
+		priv->dp_port_id = dp_port_id;
+		cb.stop_fn = (dp_stop_tx_fn_t)dp_fp_stop_tx;
+		cb.restart_fn = (dp_restart_tx_fn_t)dp_fp_restart_tx;
+		cb.rx_fn = (dp_rx_fn_t)dp_fp_rx;
+#ifdef CONFIG_XRX500_ETH_DRV_COC_SUPPORT
+		cb.dp_coc_confirm_stat_fn = dp_fp_coc_confirm;
+#endif
+		ret = dp_register_dev(priv->owner, dp_port_id, &cb, 0);
+
+		if (ret != DP_SUCCESS) {
+			pr_err("dp_register_dev failed for %s\n and port_id %d",
+			       eth_dev[i]->name, dp_port_id);
+			dp_alloc_port(priv->owner, eth_dev[i], i, i + 1,
+				      NULL, DP_F_DEREGISTER);
+			ret = -ENODEV;
+			break;
+		}
+
+#ifdef CONFIG_LTQ_TOE_DRIVER
+		eth_dev[i]->features = NETIF_F_SG | NETIF_F_TSO |
+				       NETIF_F_HW_CSUM;
+		eth_dev[i]->hw_features = NETIF_F_SG | NETIF_F_TSO |
+					  NETIF_F_HW_CSUM;
+		eth_dev[i]->vlan_features = NETIF_F_SG | NETIF_F_TSO |
+					    NETIF_F_HW_CSUM;
+		eth_dev[i]->gso_max_size  = GSO_MAX_SIZE;
+#endif
+
+		if (g_rx_csum_offload) {
+			pr_debug("%s: rx csum offload is enabled\n", __func__);
+			eth_dev[i]->features |= NETIF_F_RXCSUM;
+			eth_dev[i]->hw_features |= NETIF_F_RXCSUM;
+		} else {
+			pr_debug("%s: rx csum offload is disabled\n", __func__);
+		}
+		ltq_eth_drv_eth_addr_setup(eth_dev[i], i);
+		err = register_netdev(eth_dev[i]);
+
+		if (err) {
+			pr_err("%s[%d]: Register with network device failed\n",
+			       __func__, __LINE__);
+			pr_err("err:%d for device: %s!\n", err, name);
+			break;
+		}
+	}
+
+	if (ret) {
+		for (i = 0; i < NUM_ETH_INF; i++) {
+			if (eth_dev[i])
+				free_netdev(eth_dev[i]);
+		}
+
+		return ret;
+	}
+
+#endif
+
+#ifdef CONFIG_USERSPACE_LINK_NOTIFICATION
+	/* Register the netlink notification */
+	ltq_eth_genetlink_init();
+#endif
+
+#ifdef CONFIG_XRX500_ETH_DRV_COC_SUPPORT
+
+	if (of_irq_to_resource_table(node, irqres, 2) == 2) {
+		/* GSW-L interrupt */
+		if (devm_request_irq(&pdev->dev, irqres[0].start,
+				     ltq_eth_gswl_isr, 0,
+				     "gswl_irq", NULL)) {
+			pr_err("%s: failed to request gswl irq - ", __func__);
+			goto err1;
+		}
+
+		tasklet_init(&gswl_tasklet, ltq_eth_gswl_tasklet, 0);
+		bitmap_zero(g_ltq_eth_intr_type, LTQ_ETH_NUM_INTERRUPTS);
+		/* Keep the interrupt disabled till the low power mode*/
+		/*disable_irq(irqres.start);*/
+		g_ltq_eth_gswl_irq = irqres[0].start;
+
+		/* PAE interrupt */
+		if (devm_request_irq(&pdev->dev, irqres[1].start,
+				     ltq_eth_pae_isr, 0,
+				     "pae_irq", NULL)) {
+			pr_err("%s: failed to request pae irq - ",
+			       __func__);
+			goto err1;
+		}
+
+		tasklet_init(&pae_tasklet, ltq_eth_pae_tasklet, 0);
+		bitmap_zero(g_ltq_pae_intr_type, LTQ_ETH_NUM_INTERRUPTS);
+		g_ltq_pae_irq = irqres[1].start;
+	} else {
+		pr_err("%s: couldn't get irq from device tree for CoC.\n",
+		       __func__);
+	}
+
+err1:
+#endif
+	pr_info("Lantiq ethernet driver for XRX500 init.\n");
+	return 0;
+}
+
+static void ltq_eth_drv_exit(struct platform_device *pdev)
+{
+	int i, ret, j;
+
+#ifdef CONFIG_XRX500_MDIO_SUPPORT
+	for (i = 0; i < xrx500_hw.num_devs; i++) {
+		struct ltq_switch_priv_t *priv;
+		struct net_device *dev = xrx500_hw.devs[i];
+
+		if (!dev)
+			continue;
+
+		netif_stop_queue(dev);
+
+		priv = netdev_priv(dev);
+
+		pr_debug("num port %d\n", priv->num_port);
+
+		for (j = 0; j < priv->num_port; j++)
+			if (priv->port[j].phydev) {
+				pr_debug("phy_disconnect phydev(%d) 0x%p\n",
+					 j, priv->port[j].phydev);
+				phy_disconnect(priv->port[j].phydev);
+			}
+
+		pr_debug("ltq_eth_drv_exit i %d dev_id %d port_id %d for device %s\n",
+			 i, priv->dev_port, priv->dp_port_id, dev->name);
+		priv->dp_subif.subif = 0;
+		priv->dp_subif.port_id = priv->dp_port_id;
+
+		ret = dp_register_subif(priv->owner, dev, dev->name,
+					&priv->dp_subif, DP_F_DEREGISTER);
+
+		if (ret != DP_SUCCESS) {
+			pr_err("%s: failed to call deregister subif: %s\n",
+			       __func__, dev->name);
+		}
+		ret = dp_register_dev(priv->owner, priv->dp_port_id, NULL,
+				      DP_F_DEREGISTER);
+		if (ret != DP_SUCCESS) {
+			pr_err("%s: failed to call deregister device: %s\n",
+			       __func__, dev->name);
+		}
+		ret = dp_alloc_port(priv->owner, dev, priv->dev_port,
+				    priv->dp_port_id, NULL, DP_F_DEREGISTER);
+		if (ret != DP_SUCCESS) {
+			pr_err("%s: failed to call dealloc for device : %s\n",
+			       __func__, dev->name);
+		}
+		priv->dp_port_id = DP_FAILURE;
+		unregister_netdev(dev);
+		free_netdev(dev);
+	}
+
+	if (xrx500_hw.mii_bus) {
+		mdiobus_unregister(xrx500_hw.mii_bus);
+		mdiobus_free(xrx500_hw.mii_bus);
+	}
+
+	if (xrx500_hw.mii_bus_pae) {
+		mdiobus_unregister(xrx500_hw.mii_bus_pae);
+		mdiobus_free(xrx500_hw.mii_bus_pae);
+	}
+
+	memset(&xrx500_hw, 0, sizeof(xrx500_hw));
+#else
+	/* unregister the network devices */
+	for (i = 0; i < NUM_ETH_INF; i++) {
+		unregister_netdev(eth_dev[i]);
+		free_netdev(eth_dev[i]);
+	}
+#endif
+
+#ifdef CONFIG_USERSPACE_LINK_NOTIFICATION
+	ltq_eth_genetlink_exit();
+#endif
+	pr_info("Lantiq ethernet driver for XRX500 remove.\n");
+}
+
+static int ltq_eth_drv_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct ltq_net_soc_data *soc_data = NULL;
+
+	soc_data = (struct ltq_net_soc_data *)of_device_get_match_data(dev);
+	if (!soc_data) {
+		pr_err("No data found for ltq eth drv!\n");
+		return -EINVAL;
+	}
+
+	if (soc_data->need_defer && !is_xway_gphy_fw_loaded())
+		return -EPROBE_DEFER;
+
+	memcpy(&g_soc_data, soc_data, sizeof(*soc_data));
+	/* Just do the init */
+	ltq_eth_drv_init(pdev);
+	register_netdevice_notifier(&netdevice_notifier);
+
+	return 0;
+}
+
+static int ltq_eth_drv_remove(struct platform_device *pdev)
+{
+	/* Just do the exit */
+	unregister_netdevice_notifier(&netdevice_notifier);
+	ltq_eth_drv_exit(pdev);
+	return 0;
+}
+
+static const struct ltq_net_soc_data xrx500_net_data = {
+	.need_defer = true,
+	.hw_checksum = true,
+};
+
+static const struct ltq_net_soc_data falconmx_net_data = {
+	.need_defer = false,
+	.hw_checksum = false,
+};
+
+static const struct of_device_id ltq_eth_drv_match[] = {
+	{ .compatible = "lantiq,xrx500-eth", .data = &xrx500_net_data},
+	{ .compatible = "lantiq,falconmx-eth", .data = &falconmx_net_data},
+	{},
+};
+MODULE_DEVICE_TABLE(of, ltq_eth_drv_match);
+
+static struct platform_driver ltq_eth_driver = {
+	.probe = ltq_eth_drv_probe,
+	.remove = ltq_eth_drv_remove,
+	.driver = {
+		.name = "xrx500-eth",
+		.of_match_table = ltq_eth_drv_match,
+		.owner = THIS_MODULE,
+	},
+};
+
+module_platform_driver(ltq_eth_driver);
+
+MODULE_DESCRIPTION("Intel ethernet driver");
+MODULE_LICENSE("GPL v2");
+MODULE_VERSION(DRV_MODULE_VERSION);
diff --git a/drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.h b/drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.h
new file mode 100644
index 000000000000..9e281f921506
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/ltq_eth_drv_xrx500.h
@@ -0,0 +1,124 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  Copyright (C) 2009~2015 Lantiq Deutschland GmbH
+ *  Copyright (C) 2016 Intel Corporation.
+ */
+
+#ifndef _LANTIQ_ETH_DRV_H_
+#define _LANTIQ_ETH_DRV_H_
+
+#ifdef CONFIG_SW_ROUTING_MODE
+    #define CONFIG_PMAC_DMA_ENABLE          1   /*g_pmac_dma */
+    #define CONFIG_DMA_PMAC_ENABLE          1   /*g_dma_pmac*/
+#else
+    #define CONFIG_PMAC_DMA_ENABLE          0   /*g_pmac_dma */
+    #define CONFIG_DMA_PMAC_ENABLE          0   /*g_dma_pmac*/
+#endif
+
+#if defined(CONFIG_PMAC_DMA_ENABLE) && CONFIG_PMAC_DMA_ENABLE
+    #define NUM_ETH_INF                     7
+#else
+    #define NUM_ETH_INF                     1
+#endif
+
+struct xrx500_port {
+	u8 num;
+	u8 phy_addr;
+	u16 flags;
+	phy_interface_t phy_if;
+	int link;
+	int irq_num;
+	struct phy_device *phydev;
+	struct device_node *phy_node;
+};
+
+struct xrx500_hw {
+	struct mii_bus *mii_bus;
+	struct mii_bus *mii_bus_pae;
+	struct net_device *devs[NUM_ETH_INF];
+	int num_devs;
+	int port_map[NUM_ETH_INF];
+	unsigned short wan_map;
+};
+
+/**
+ * This structure is used internal purpose
+ */
+struct ltq_switch_priv_t {
+	/*!< network device interface Statistics */
+	struct rtnl_link_stats64 stats;
+	/*!< structure of dma device information */
+	struct dma_device_info *dma_device;
+	struct sk_buff *skb; /*!< skb buffer structure*/
+	spinlock_t lock; /*!< spin lock */
+	int phy_addr; /*!< interface mdio phy address*/
+	int current_speed; /*!< interface current speed*/
+	int full_duplex; /*!< duplex mode*/
+	int current_duplex; /*!< current interface duplex mode*/
+	void __iomem                *base_addr; /*!< Base address */
+	unsigned int                flags;  /*!< flags */
+	struct module *owner;
+	dp_subif_t dp_subif;
+	s32 dev_port; /*dev  instance */
+	s32 f_dp;   /* status for register to datapath*/
+	u32 dp_port_id;
+	struct xrx500_port port[NUM_ETH_INF];
+	int num_port;
+	struct xrx500_hw				*hw;
+	unsigned short port_map;
+	int id;
+	int wan;
+	int jumbo_enabled;
+	#define FLAG_PAUSE_AUTO         0x00000001
+	#define FLAG_FULL_DUPLEX        0x00000002
+	#define FLAG_10_BASE_T          0x00000010
+	#define FLAG_100_BASE_T         0x00000020
+	#define FLAG_1000_BASE_T        0x00000040
+	#define FLAG_TX_PAUSE           0x00000100
+	#define FLAG_RX_PAUSE           0x00000200
+	#define FLAG_FORCE_LINK         0x00000400
+	#define FLAG_ADV_10HALF         0x00001000
+	#define FLAG_ADV_10FULL         0x00002000
+	#define FLAG_ADV_100HALF        0x00004000
+	#define FLAG_ADV_100FULL        0x08008000
+	#define FLAG_ADV_1000HALF       0x00010000
+	#define FLAG_ADV_1000FULL       0x00020000
+	#define FLAG_INTERNAL_PHY       0x00100000
+} ltq_switch_priv_t;
+
+/**
+ * This structure is used internal purpose
+ */
+struct ltq_pmac_header_t {
+	u32 tcp_checksum	    :1;  /*!< Reserved bits*/
+	u32 ver_done	    :1;  /*!< IP Offset */
+	u32 ip_offset	    :6; /*!< Destination Group and Port Map */
+	u32 tcp_h_offset	    :5; /*!< Source Logical Port ID */
+	u32 tcp_type	    :3; /*!< Reserved bits*/
+	u32 sppid		    :4; /*!< Is Tagged */
+	u32 class_id	    :4; /*!< Reserved bits*/
+	u32 port_map_en	    :1; /*!< Reserved bits*/
+	u32 port_map_sel	    :1; /*!< PPPoE Session Packet */
+	u32 lrn_dis		    :1; /*!< IPv6 Packet */
+	u32 class_en	    :1; /*!< IPv4 Packet */
+	u32 reserved	    :2; /*!< Mirrored */
+	u32 pkt_type	    :2; /*!< Reserved bits*/
+	u32 crcgen_dis	    :1; /* Packet Length High Bits */
+	u32 redirect	    :1; /* Packet Length Low Bits */
+	u32 timestamp	    :1; /*!< Reserved bits*/
+	u32 sub_if_sc_hi	    :5; /*!< Reserved bits*/
+	u32 sub_if_sc_lo	    :8; /*!< Source Physical Port ID */
+	u32 port_map_hi	    :8; /*!< Traffic Class */
+	u32 port_map_lo	    :8; /*!< Traffic Class */
+} ltq_pmac_header_t;
+
+extern int g_xway_gphy_fw_loaded;
+
+struct ltq_net_soc_data {
+	bool need_defer;
+	bool hw_checksum;
+};
+#endif /* _LANTIQ_ETH_DRV_H_ */
diff --git a/drivers/net/ethernet/lantiq_eth_drv.c b/drivers/net/ethernet/lantiq_eth_drv.c
new file mode 100644
index 000000000000..4dc0c7c01004
--- /dev/null
+++ b/drivers/net/ethernet/lantiq_eth_drv.c
@@ -0,0 +1,1678 @@
+/******************************************************************************
+**
+** FILE NAME    : lantiq_eth_drv.c
+** PROJECT      : Lantiq UEIP
+** MODULES      : Lantiq CPE ethernet driver
+** DATE         : 30 July  2009
+** AUTHOR       : Reddy Mallikarjuna
+** DESCRIPTION  : Lantiq Cross-Platform ethernet device driver
+** COPYRIGHT    :       Copyright (c) 2013
+**                      Lantiq Deutschland
+**
+**    This program is free software; you can redistribute it and/or modify
+**    it under the terms of the GNU General Public License as published by
+**    the Free Software Foundation; either version 2 of the License, or
+**    (at your option) any later version.
+**
+** HISTORY
+** $Date                $Author                 $Comment
+** 30 July 2009         Reddy Mallikarjuna  Initial UEIP release
+** 28 July 2011         Kishore Kankipati 	Adapted for HN1
+** 09 September 2013    Suresh Nagaraj		Adapted to Openwrt framework
+*******************************************************************************/
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h> /* printk() */
+#include <linux/types.h>  /* size_t */
+#include <linux/etherdevice.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/etherdevice.h> /* eth_type_trans */
+#include <asm/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+
+#include <linux/of_net.h>
+#include <linux/of_mdio.h>
+#include <linux/of_gpio.h>
+
+#define CONFIG_LTQMIPS_DMA
+#define CONFIG_SW_ROUTING_MODE
+
+#ifdef CONFIG_LTQMIPS_DMA
+#include <xway/lantiq_dma.h>
+#endif
+
+#include "lantiq_eth_drv.h"
+
+#ifdef CONFIG_NAPI_ENABLED
+  #define CONFIG_IFX_NAPI               1
+#endif
+
+#define DRV_MODULE_NAME             "lantiq_eth_drv"
+#define DRV_MODULE_VERSION          "1.1.1"
+static char version[] =
+        DRV_MODULE_NAME ".c:v" DRV_MODULE_VERSION " \n";
+
+/* length of time before we decide the hardware is borked,
+ * and dev->eth_tx_timeout() should be called to fix the problem
+ */
+#define LTQ_TX_TIMEOUT                  (10 * HZ)
+
+#define DMA_TX_BURST_LEN                DMA_BURSTL_4DW
+#define DMA_RX_BURST_LEN                DMA_BURSTL_4DW
+#define ETH_PKT_BUF_SIZE                1568
+
+#ifdef CONFIG_LTQMIPS_DMA
+struct dma_device_info *g_dma_device=NULL;
+#endif
+
+static struct net_device *eth_dev[NUM_ETH_INF];
+/* PMAC header structure */
+cpu_egress_pkt_header_t eg_pkt_hdr;
+cpu_ingress_pkt_header_t ig_pkt_hdr;
+static int g_pmac_dma,g_dma_pmac;
+/* /proc file to debug */
+//#define SNMP_COUNTERS_DEBUG
+#undef SNMP_COUNTERS_DEBUG
+struct proc_dir_entry* g_eth_proc_dir;
+/* Start the  network device interface queue */
+static int ltq_eth_open(struct net_device *dev);
+/* Stop the  network device interface queue */
+static int ltq_eth_close(struct net_device *dev);
+/* Transmit packet from Tx Queue to MAC */
+static int ltq_start_xmit (struct sk_buff *skb, struct net_device *dev);
+/* Hardware specific IOCTL's  */
+static int ltq_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
+/* Get the network device statistics */
+static struct net_device_stats *ltq_get_stats (struct net_device *dev);
+/* change MTU values */
+static int ltq_change_mtu (struct net_device *dev, int new_mtu);
+/*  Set mac address*/
+static int ltq_set_mac_address(struct net_device *dev, void *p);
+/* Transmit timeout*/
+static void ltq_tx_timeout (struct net_device *dev);
+/* select the tx dma channel */
+static int select_tx_chan (struct sk_buff *skb, struct net_device *dev);
+/*open dma rx channel*/
+static void enable_dma_channel(void);
+/*close the dma rx channel*/
+static void disable_dma_channel(void);
+/* Init of the network device */
+static int ltq_switch_init(struct net_device *dev);
+/* Get the ether addr from u-boot */
+static unsigned char my_ethaddr[MAX_ADDR_LEN];
+#ifdef  CONFIG_IFX_NAPI
+static ltq_eth_fw_poll_ret_t ltq_switch_poll(struct net_device *poll_dev, int work_to_do, int *work_done);
+#endif
+
+static int rversion_open (struct inode *inode, struct file *file);
+static int rpce_open (struct inode *inode, struct file *file);
+static int proc_read_pce(struct seq_file *m, void *v);
+static int eth_proc_version(struct seq_file *m, void *v);
+
+struct file_operations rversion_ops = {
+	.open = rversion_open,
+	.read = seq_read,
+	.llseek		= seq_lseek,
+	.release = single_release,
+};
+
+struct file_operations rpce_ops = {
+	.open = rpce_open,
+	.read = seq_read,
+	.llseek		= seq_lseek,
+	.release = single_release,
+};
+
+static struct net_device_ops ltq_eth_drv_ops = {
+        .ndo_init           = ltq_switch_init,
+        .ndo_open           = ltq_eth_open,
+        .ndo_stop           = ltq_eth_close,
+        .ndo_start_xmit     = ltq_start_xmit,
+        .ndo_set_mac_address= ltq_set_mac_address,
+        .ndo_change_mtu     = ltq_change_mtu,
+        .ndo_get_stats      = ltq_get_stats,
+        .ndo_do_ioctl       = ltq_ioctl,
+        .ndo_tx_timeout     = ltq_tx_timeout,
+#ifdef  CONFIG_IFX_NAPI
+        .poll           = ltq_switch_poll,
+        .weight         = 25,
+#endif
+};
+
+static int vr9_7port_sw_hw_init(void)
+{
+    unsigned int reg;
+    struct clk *clk;
+
+    /*Enable Switch Power  */
+	clk = clk_get_sys("1e108000.eth", NULL);
+	clk_enable(clk);
+
+    /*Enable Switch  */
+    SW_WRITE_REG32 ( (SW_READ_REG32(GLOB_CTRL_REG) | GLOB_CTRL_SE), GLOB_CTRL_REG) ;
+
+    /* Disable MDIO auto polling mode for all ports */
+    /*SW_WRITE_REG32 ( 0x0, MDC_CFG_0_REG) ; */
+#if 1
+    {
+	int i;
+	for ( i =0; i < 7; i++) {
+                /*       enable counters  */
+                SW_WRITE_REG32(0x1, (ETHSW_BM_PCFG_REG + (i*8)));
+        }
+    }
+#endif
+    /* Replace default IPG value from 0x85 to ox8B */
+    SW_WRITE_REG32 (0x8B, PMAC_RX_IPG_REG) ;
+
+    reg = SW_READ_REG32(PMAC_HD_CTL_REG );
+    reg |= PMAC_HD_CTL_AC;
+#if defined(CONFIG_PMAC_DMA_ENABLE) && CONFIG_PMAC_DMA_ENABLE
+    SW_WRITE_REG32 ( (SW_READ_REG32(FDMA_PCTRL_PORT6) | FDMA_PCTRL_STEN), FDMA_PCTRL_PORT6) ;
+    reg |= PMAC_HD_CTL_AS;
+#else
+    reg &= ~PMAC_HD_CTL_AS;
+#endif
+#if defined(CONFIG_DMA_PMAC_ENABLE) && CONFIG_DMA_PMAC_ENABLE
+    reg |= PMAC_HD_CTL_RXSH;
+#else
+    reg &= ~PMAC_HD_CTL_RXSH;
+#endif
+    SW_WRITE_REG32( reg, PMAC_HD_CTL_REG);
+
+    for ( reg = 0; reg < 7; reg++ ) {
+        SW_WRITE_REG32((SW_READ_REG32(FDMA_PCTRL_REG(reg)) | 0x01), FDMA_PCTRL_REG(reg));
+        SW_WRITE_REG32((SW_READ_REG32(SDMA_PCTRL_REG(reg)) | 0x01), SDMA_PCTRL_REG(reg));
+    }
+#if defined(CONFIG_DMA_PMAC_ENABLE) && CONFIG_DMA_PMAC_ENABLE
+    SW_WRITE_REG32 ( 0x20, PMAC_EWAN_REG) ;
+#endif
+    return 0;
+}
+
+//#define DUMP_PACKET
+
+#ifdef DUMP_PACKET
+/*
+* \brief	dump skb data
+* \param[in] len length of the data buffer
+* \param[in] pData Pointer to data to dump
+*
+* \return void No Value
+*/
+static inline void dump_skb(u32 len, char *pData){
+	int i;
+	for(i=0;i<len;i++){
+		printk("%2.2x ",(u8)(pData[i]));
+		if (i % 16 == 15)
+			printk("\n");
+	}
+	printk("\n");
+}
+#endif
+
+/* Get the driver information, used by ethtool_ops  */
+static void get_drvinfo (struct net_device *dev, struct ethtool_drvinfo *info)
+{
+    /* driver driver short name (Max 32 characters) */
+    strcpy (info->driver, DRV_MODULE_NAME);
+    /* driver version (Max 32 characters) */
+    strcpy (info->version, DRV_MODULE_VERSION);
+}
+
+/* Get the network device interfcae number */
+static int get_network_dev_num(struct net_device *dev)
+{
+    int dev_index = ( (!strcmp(dev->name, "eth0")) ? 0 : (!strcmp(dev->name, "eth1") ) ? 1 : \
+    (!strcmp(dev->name, "eth2")) ? 2: (!strcmp(dev->name, "eth3"))? 3: \
+    (!strcmp(dev->name, "eth4"))? 4: (!strcmp(dev->name, "eth5"))? 5: -1);
+    return dev_index;
+}
+
+/* Get the network device settings  */
+static int get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+    ltq_switch_priv_t *priv = netdev_priv(dev);
+    unsigned int  port_status;
+    int dev_index = get_network_dev_num(dev);
+    if (dev_index == -1 ) {
+        /* should not be here*/
+        printk(KERN_ERR "%s[%d]: Dev index error(%d)!!!\n", __func__,__LINE__,dev_index);
+        return -ENODEV;
+    }
+
+    cmd->supported = (SUPPORTED_Autoneg | SUPPORTED_TP);
+    cmd->supported |= (SUPPORTED_100baseT_Half |    \
+                    SUPPORTED_100baseT_Full |       \
+                    SUPPORTED_10baseT_Half |        \
+                    SUPPORTED_10baseT_Full |        \
+                    SUPPORTED_1000baseT_Half |      \
+                    SUPPORTED_1000baseT_Full |      \
+                    SUPPORTED_MII);
+
+    cmd->advertising = 0;
+    if (priv->flags & FLAG_ADV_10HALF)
+        cmd->advertising |= ADVERTISED_10baseT_Half;
+    if (priv->flags & FLAG_ADV_10FULL)
+        cmd->advertising |= ADVERTISED_10baseT_Full;
+    if (priv->flags & FLAG_ADV_100HALF)
+        cmd->advertising |= ADVERTISED_100baseT_Half;
+    if (priv->flags & FLAG_ADV_100FULL)
+        cmd->advertising |= ADVERTISED_100baseT_Full;
+
+    if (priv->flags & FLAG_ADV_1000HALF)
+        cmd->advertising |= ADVERTISED_1000baseT_Half;
+    if (priv->flags & FLAG_ADV_1000FULL)
+        cmd->advertising |= ADVERTISED_1000baseT_Full;
+
+    cmd->advertising |= ADVERTISED_Pause | ADVERTISED_Asym_Pause;
+
+    port_status = SW_READ_REG32(MDIO_STAT_0_REG + (dev_index * 4));
+
+    switch ( MDIO_STAT_SPEED(port_status)) {
+        case 0:
+            priv->current_speed=SPEED_10;
+            break;
+        case 1:
+            priv->current_speed=SPEED_100;
+            break;
+        case 2:
+            priv->current_speed=SPEED_1000;
+            break;
+        default: /* should not be here */
+            printk(KERN_ERR "%s[%d]: Port status error(%d)!!!\n", __func__,__LINE__,port_status);
+    }
+    cmd->speed = priv->current_speed;
+    if ( port_status & MDIO_STAT_FDUP )
+        priv->full_duplex=DUPLEX_FULL;
+    else
+        priv->full_duplex=DUPLEX_HALF;
+    cmd->duplex = priv->full_duplex;
+
+    if ( port_status & MDIO_STAT_LSTAT)
+        cmd->reserved[0]    = 0x1;  /*link up bit:0*/
+    else
+        cmd->reserved[0]    = 0x0;  /*link down */
+
+    if (port_status & MDIO_STAT_RXPAUEN )
+        cmd->reserved[0]    |= 0x2; /*flow control enable Bit1:1*/
+    else
+        cmd->reserved[0]    |= 0x0; /*flow control disable*/
+    /* TODO*/
+    cmd->phy_address = dev_index;
+
+    cmd->port = PORT_MII;
+    cmd->transceiver = (priv->flags & FLAG_INTERNAL_PHY) ? XCVR_INTERNAL : XCVR_EXTERNAL;
+    return 0;
+}
+
+/* Set the network device settings */
+static int set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+    ltq_switch_priv_t *priv = netdev_priv(dev);
+    unsigned int  phy_reg;
+    int dev_index = get_network_dev_num(dev);
+    if (dev_index == -1 ) {
+        /* should not be here*/
+        printk(KERN_ERR "%s[%d]: Dev index error(%d)!!!\n", __func__,__LINE__,dev_index);
+        return -ENODEV;
+    }
+    if (cmd->autoneg == AUTONEG_ENABLE) {
+        /*TODO*/
+        return 0;
+    } else if ((cmd->speed != SPEED_100 && cmd->speed != SPEED_10 && cmd->speed != SPEED_1000) \
+            ||(cmd->duplex != DUPLEX_HALF && cmd->duplex != DUPLEX_FULL)) {
+            return -EINVAL;
+    }
+
+    spin_lock_irq(&priv->lock);
+    if (cmd->autoneg != AUTONEG_ENABLE) {
+        phy_reg = SW_READ_REG32(PHY_ADDR_0 - (dev_index * 4));
+        phy_reg &= ~(PHY_ADDR_LINKST_MASK | PHY_ADDR_SPEED_MASK | PHY_ADDR_FDUP_MASK);
+        priv->flags |= FLAG_FORCE_LINK;
+        priv->flags &= ~(FLAG_100_BASE_T |FLAG_1000_BASE_T | FLAG_FULL_DUPLEX);
+        if (cmd->speed == SPEED_100) {
+            priv->flags |= FLAG_100_BASE_T;
+            phy_reg |= PHY_ADDR_SPEED_100;
+        } else if(cmd->speed == SPEED_1000) {
+            priv->flags |= FLAG_1000_BASE_T;
+            phy_reg |= PHY_ADDR_SPEED_1000;
+        }
+        if (cmd->duplex == DUPLEX_FULL) {
+            priv->flags |= FLAG_FULL_DUPLEX;
+            phy_reg |= PHY_ADDR_FDUP_EN;
+        }
+        SW_WRITE_REG32(phy_reg, (PHY_ADDR_0 - (dev_index * 4)) );
+    }
+    spin_unlock_irq(&priv->lock);
+    return 0;
+}
+
+/* Reset the device */
+static int nway_reset(struct net_device *dev)
+{
+     /*TODO*/
+    return 0;
+}
+
+/* Structure of the ether tool operation  */
+static const struct ethtool_ops ethtool_ops = {
+        .get_drvinfo            = get_drvinfo,
+        .get_settings           = get_settings,
+        .set_settings           = set_settings,
+        .nway_reset             = nway_reset,
+        .get_link               = ethtool_op_get_link,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,32)
+        .get_perm_addr          = ethtool_op_get_perm_addr,
+#endif
+};
+
+#ifndef MODULE
+/* Get the ether addr from u-boot */
+static int __init ethaddr_setup(char *line)
+{
+    char *ep;
+    int i;
+    memset(my_ethaddr, 0, MAX_ADDR_LEN);
+    /* there should really be routines to do this stuff */
+    for (i = 0; i < 6; i++)	{
+        my_ethaddr[i] = line ? simple_strtoul(line, &ep, 16) : 0;
+        if (line)
+            line = (*ep) ? ep+1 : ep;
+    }
+    printk("mac address %2x-%2x-%2x-%2x-%2x-%2x \n" \
+        ,my_ethaddr[0]  \
+        ,my_ethaddr[1]  \
+        ,my_ethaddr[2]  \
+        ,my_ethaddr[3]  \
+        ,my_ethaddr[4]  \
+        ,my_ethaddr[5]);
+    return 0;
+}
+__setup("ethaddr=", ethaddr_setup);
+#endif
+
+/* Turn On RX DMA channels */
+static void enable_dma_channel(void)
+{
+#ifdef CONFIG_LTQMIPS_DMA
+    struct dma_device_info* dma_dev=g_dma_device;
+    int i;
+
+    for(i=0; i<dma_dev->max_rx_chan_num; i++) {
+        if ( (dma_dev->rx_chan[i])->control==IFX_DMA_CH_ON )
+            dma_dev->rx_chan[i]->open(dma_dev->rx_chan[i]);
+    }
+#endif
+}
+
+/* Turn Off RX DMA channels */
+static void disable_dma_channel()
+{
+#ifdef CONFIG_LTQMIPS_DMA
+    struct dma_device_info* dma_dev=g_dma_device;
+    int i;
+
+    for (i=0; i<dma_dev->max_rx_chan_num; i++)
+        dma_dev->rx_chan[i]->close(dma_dev->rx_chan[i]);
+#endif
+}
+static int index=0 ;
+/* open the network device interface*/
+static int ltq_eth_open(struct net_device *dev)
+{
+    if(index == 0) {
+        enable_dma_channel();
+    }
+    index++;
+//    netif_start_queue(dev);
+    return 0;
+}
+
+/* Close the network device interface*/
+static int ltq_eth_close(struct net_device *dev)
+{
+    if(index) index--;
+	if(index == 0){
+	    disable_dma_channel();
+	}
+//    netif_stop_queue(dev);
+    return 0;
+}
+
+/* Send the packet to netwrok rx queue, used by  switch_hw_receive function */
+static void eth_rx(struct net_device *dev, int len,struct sk_buff* skb)
+{
+    ltq_switch_priv_t *priv             = netdev_priv(dev);
+
+    skb->dev = dev;
+    skb->protocol = eth_type_trans(skb, dev);
+#ifdef  CONFIG_IFX_NAPI
+    netif_receive_skb(skb);
+#else
+    netif_rx(skb);
+#endif
+    priv->stats.rx_packets++;
+    priv->stats.rx_bytes+=len;
+}
+
+/*
+* This function is called in dma intr handler (DMA RCV_INT interrupt).
+* This function get the data from the DMA device.
+*   if the packet is valid then it will send to upper layer based on  criteria.
+*       The switch CPU port PMAC status header is enabled, then remove the header and
+*           look from which port the packet comes and send to relative network device.
+        if PMAC status header is not enabled, then send the packets eth0 interafce
+*/
+static void switch_hw_receive(struct dma_device_info* dma_dev)
+{
+    unsigned char* buf=NULL;
+    int len=0 ;
+    struct sk_buff *skb=NULL;
+    struct net_device *dev;
+
+#ifdef CONFIG_LTQMIPS_DMA
+    len = dma_device_read(dma_dev,&buf,(void**)&skb);
+#endif
+    if ((len >= 0x600) || (len < 64) ) {
+        printk(KERN_ERR "%s[%d]: Packet is too large/small (%d)!!!\n", __func__,__LINE__,len);
+        goto rx_err_exit;
+    }
+    if (skb == NULL  ) {
+        printk(KERN_ERR "%s[%d]: Can't restore the Packet !!!\n", __func__,__LINE__);
+        goto rx_err_exit;
+    }
+    /* remove CRC */
+    len -= 4;
+    if (len > (skb->end -skb->tail)) {
+        printk(KERN_ERR "%s[%d]: len:%d end:%p tail:%p Err!!!\n", __func__,__LINE__,(len+4), skb->end, skb->tail);
+        goto rx_err_exit;
+    }
+    if (buf) {
+#ifdef DUMP_PACKET
+        printk("rx len:%d\n",len);
+        dump_skb(len, (char *)buf);
+#endif
+    }
+    skb_put(skb,len);
+    if(g_pmac_dma){
+        int sourcePortId;;
+        len -= 8;  /*Remove PMAC to DMA header */
+        skb_pull(skb,8);
+        eg_pkt_hdr = * ((cpu_egress_pkt_header_t *) (buf+2));
+        sourcePortId = (eg_pkt_hdr.SLPID) & 0x7 ;
+        /*sourcePortId = (eg_pkt_hdr.SPPID) & 0x7 ; */
+        if(sourcePortId < NUM_ETH_INF) {
+            switch(sourcePortId) {
+                case 0:
+                    dev = eth_dev[0];
+                    break;
+                case 1:
+                    dev = eth_dev[1];
+                    break;
+                case 2:
+                    dev = eth_dev[2];
+                    break;
+                case 3:
+                    dev = eth_dev[3];
+                    break;
+                case 4:
+                    dev = eth_dev[4];
+                    break;
+                case 5:
+                    dev = eth_dev[5];
+                    break;
+                default:
+                /*printk("%s[%d], SLPID:%d ERROR!!! \n", __FUNCTION__, __LINE__,(eg_pkt_hdr.SLPID) & 0x7);*/
+                /*printk("%s[%d], SPPID:%d ERROR!!! \n", __FUNCTION__, __LINE__,(eg_pkt_hdr.SPPID) & 0x7);  */
+                goto rx_err_exit;
+            }
+        } else {
+            /*printk("%s[%d], SLPID:%d Packet dropped!!! \n", __FUNCTION__, __LINE__,(eg_pkt_hdr.SLPID) & 0x7);*/
+            /*printk("%s[%d], SPPID:%d Packet dropped!!! \n", __FUNCTION__, __LINE__,(eg_pkt_hdr.SPPID) & 0x7); */
+            goto rx_err_exit;
+        }
+    } else
+        dev= eth_dev[0];
+
+    skb->dev = dev;
+    eth_rx(dev,len,skb);
+    return ;
+
+rx_err_exit:
+    if (skb)
+        dev_kfree_skb_any(skb);
+    return ;
+}
+
+/* Get the network device stats information */
+static struct net_device_stats *ltq_get_stats (struct net_device *dev)
+{
+    ltq_switch_priv_t *priv = netdev_priv(dev);
+    return &priv->stats;
+}
+
+/* Trasmit timeout */
+static void ltq_tx_timeout(struct net_device *dev)
+{
+    ltq_switch_priv_t *priv		= netdev_priv(dev);
+#ifdef CONFIG_LTQMIPS_DMA
+    struct dma_device_info* dma_dev = g_dma_device;
+    int i;
+
+    printk(KERN_ERR "%s: transmit timed out, disable the dma channel irq\n", dev->name);
+
+    priv->stats.tx_errors++;
+
+    for (i=0; i<dma_dev->max_tx_chan_num; i++) {
+        dma_dev->tx_chan[i]->disable_irq(dma_dev->tx_chan[i]);
+    }
+    netif_wake_queue(dev);
+#endif
+}
+
+/* Set the MAC address */
+static int ltq_set_mac_address (struct net_device *dev, void *p)
+{
+#if 0
+    ltq_switch_priv_t *priv		= netdev_priv(dev);
+#endif
+    struct sockaddr *addr = p;
+
+    if (netif_running(dev))
+        return -EBUSY;
+
+    if (!is_valid_ether_addr(addr->sa_data))
+        return -EINVAL;
+
+    memcpy(dev->dev_addr, addr->sa_data, dev->addr_len);
+#if 0
+    /* TODO: is it required to set MAC address in the HW registers?*/
+    spin_lock_irq(&priv->lock);
+    if (!(dev->flags & IFF_PROMISC)) {
+        __set_mac_addr(dev->dev_addr);
+    }
+    spin_unlock_irq(&priv->lock);
+#endif
+    return 0;
+}
+
+/* Change the MTU value of the netwrok device interfaces */
+static int ltq_change_mtu (struct net_device *dev, int new_mtu)
+{
+    if(new_mtu < ETH_ZLEN || new_mtu > ETH_DATA_LEN)
+        return -EINVAL;
+    dev->mtu = new_mtu;
+    return 0;
+}
+
+/* select the DMA channel numbers, refer dma_setup_init function */
+static int select_tx_chan (struct sk_buff *skb, struct net_device *dev)
+{
+     int chan_no;
+/*TODO: select the channel based on  criteria*/
+    int dev_index = (!strcmp(dev->name, "eth0") ? 0 : 1);
+    if (dev_index)
+        chan_no = 1;
+    else
+        chan_no = 0;
+    return chan_no;
+}
+
+/*
+* Transmit packet over DMA, which comes from the Tx Queue
+* Note: Tx packet based on the interface queue.
+*       if packet comes from eth0, then sendout the packet over Tx DMA channel 0
+*       if packet comes from eth1, then sendout the packet over Tx DMA channel 1
+* refer the function "select_tx_chan" selection of dma channels
+* if switch CPU port PMAC status header is enabled, then set the status header
+*   based on criteria and push the status header infront of header.
+* if head room is not availabe for status header(4-bytes), reallocate the head room
+*   and push status header  infront of the header
+*/
+static int ltq_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+    ltq_switch_priv_t *priv		= netdev_priv(dev);
+    int len , rc = NETDEV_TX_OK;
+    char *data;
+#ifdef CONFIG_LTQMIPS_DMA
+    struct dma_device_info* dma_dev=g_dma_device;
+#endif
+
+    len = skb->len < ETH_ZLEN ? ETH_ZLEN : skb->len;
+
+    if(g_dma_pmac) {
+        memset((void *) &ig_pkt_hdr, 0, sizeof (ig_pkt_hdr));
+        /*if DIRECT is set 1, then packet is directly forward to the physical port based on DPID (no learning),
+		if DIRECT is set 0, then switch will learn and decide forward the packet to which physical port*/
+
+#ifdef CONFIG_SW_ROUTING_MODE
+        ig_pkt_hdr.DPID_EN = 1;
+#else
+        ig_pkt_hdr.DPID_EN = 0;
+#endif
+        if(!(strcmp(dev->name, "eth0"))) {
+            ig_pkt_hdr.SPID= 2;  /*CPU port */
+            ig_pkt_hdr.DPID= 0;  /*Packet send through MII0 interface, valid only when DIRECT is set 1 */
+        } else if(!(strcmp(dev->name, "eth1"))) {
+            ig_pkt_hdr.SPID= 2;  /*CPU port */
+            ig_pkt_hdr.DPID= 1; /* Send packet through  MII1 interface, valid only when DIRECT is set 1 */
+            /*printk("%s[%d], eth1 \n",__FUNCTION__, __LINE__); */
+        } else {
+            /*if eth1 interface is not there, then send through eth0 */
+            printk("%s[%d], Default eth0 \n",__FUNCTION__, __LINE__);
+            ig_pkt_hdr.SPID= 2;
+            ig_pkt_hdr.DPID= 0;  /*Packet send through MII0 interface, valid only when DIRECT is set 1 */
+        }
+        if(skb_headroom(skb)>=4) {
+            /*printk("%s[%d]: [%d] \n",__FUNCTION__,__LINE__,skb_headroom(skb));   */
+            skb_push(skb,4);
+            memcpy(skb->data, (void*)&ig_pkt_hdr, 4);
+            len+=4;
+        } else {
+            struct sk_buff *tmp = skb;
+            skb = skb_realloc_headroom(tmp, 4);
+            if(tmp)
+                dev_kfree_skb_any(tmp);
+            if (skb ==  NULL) {
+                printk("%s skb_realloc_headroom failed\n", __func__);
+                return -ENOMEM;
+            }
+            skb_push(skb, 4);
+            memcpy(skb->data, &ig_pkt_hdr, 4);
+            len += 4;
+        }
+    }
+
+    data = skb->data;
+    priv->skb = skb;
+    dev->trans_start = jiffies;
+
+#ifdef CONFIG_LTQMIPS_DMA
+    /*select the tx channel*/
+    dma_dev->current_tx_chan = select_tx_chan (skb, dev);
+
+    if (dma_device_write(dma_dev, data, len, skb) != len ) {
+        if (skb)
+            dev_kfree_skb_any(skb);
+        priv->stats.tx_errors++;
+        priv->stats.tx_dropped++;
+  /*      rc = NETDEV_TX_BUSY;  */
+    } else {
+        priv->stats.tx_packets++;
+        priv->stats.tx_bytes+=len;
+    }
+#endif
+    return rc;
+}
+
+/* Platform specific IOCTL's handler */
+static int ltq_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+  /* TODO*/
+
+    return -EOPNOTSUPP;
+}
+
+#ifdef CONFIG_LTQMIPS_DMA
+/*
+* DMA Pseudo Interrupt handler.
+* This function handle the DMA pseudo interrupts to handle the data packets Rx/Tx over DMA channels
+* It will handle the following interrupts
+*   RCV_INT: DMA receive the packet interrupt,So get from the PPE peripheral
+*   TX_BUF_FULL_INT: TX channel descriptors are not availabe, so, stop the transmission
+        and enable the Tx channel interrupt.
+*   TRANSMIT_CPT_INT: Tx channel descriptors are availabe and resume the transmission and
+        disable the Tx channel interrupt.
+*/
+int dma_intr_handler(struct dma_device_info* dma_dev,int status)
+{
+    struct net_device* dev;
+    int i;
+
+    switch(status) {
+        case RCV_INT:
+            switch_hw_receive(dma_dev);
+            break;
+        case TX_BUF_FULL_INT:
+            for(i=0; i < NUM_ETH_INF ; i++){
+                dev = eth_dev[i];
+                netif_stop_queue(dev);
+            }
+            for(i=0;i<dma_dev->max_tx_chan_num;i++) {
+                if((dma_dev->tx_chan[i])->control==IFX_DMA_CH_ON)
+                    dma_dev->tx_chan[i]->enable_irq(dma_dev->tx_chan[i]);
+                }
+            break;
+        case TRANSMIT_CPT_INT:
+            for(i=0;i<dma_dev->max_tx_chan_num;i++) {
+                dma_dev->tx_chan[i]->disable_irq(dma_dev->tx_chan[i]);
+            }
+            for(i=0; i < NUM_ETH_INF ; i++){
+                dev = eth_dev[i];
+                netif_wake_queue(dev);
+            }
+            break;
+    }
+    return 0;
+}
+#endif
+
+/*
+* Allocates the buffer for ethernet packet.
+* This function is invoke when DMA callback function to be called
+*   to allocate a new buffer for Rx packets.*/
+unsigned char* sw_dma_buffer_alloc(int len, int* byte_offset,void** opt)
+{
+    unsigned char *buffer=NULL;
+    struct sk_buff *skb=NULL;
+    int offset = 0;
+#ifdef CONFIG_LTQMIPS_DMA
+    int dma_burst_len = g_dma_device->rx_burst_len <<2;
+#else
+    int dma_burst_len = 4;
+#endif
+    /* for reserving 2 bytes in skb buffer, so, set offset 2 bytes infront of data pointer */
+    *byte_offset=2;
+    skb = dev_alloc_skb(ETH_PKT_BUF_SIZE+dma_burst_len);
+    if (skb == NULL) {
+        printk(KERN_ERR "%s[%d]: Buffer allocation failed!!!\n", __func__,__LINE__);
+        return NULL;
+    }
+    if(likely(skb)) {
+        if(((u32)skb->data & (dma_burst_len -1)) != 0) {
+            offset = ~((u32)skb->data+(dma_burst_len -1)) & (dma_burst_len -1);
+        }
+        if(offset != 0 ) {
+            buffer = (unsigned char *)(skb->data+offset);
+            skb_reserve(skb, offset);
+        } else {
+            buffer = (unsigned char*)(skb->data);
+        }
+        skb_reserve(skb, 2);
+        *(int*)opt=(int)skb;
+    }
+    return buffer;
+}
+
+/* Free skb buffer
+* This function frees a buffer previously allocated by the DMA buffer
+*   alloc callback function. */
+int sw_dma_buffer_free(unsigned char* dataptr,void* opt)
+{
+    struct sk_buff *skb=NULL;
+
+    if(opt==NULL){
+        if(dataptr)
+            kfree(dataptr);
+    }else {
+        skb=(struct sk_buff*)opt;
+        if(skb)
+            dev_kfree_skb_any(skb);
+    }
+
+    return 0;
+}
+
+#ifdef  CONFIG_IFX_NAPI
+/* This function scheduled from upper layer when the NAPI is enabled*/
+//static int eth_switch_poll(struct net_device *poll_dev, int *budget)
+//{
+//    int work_to_do, work_done, ret;
+//    struct dma_device_info* dma_dev=g_dma_device;
+//
+//    work_to_do = min(*budget, poll_dev->quota);
+//    work_done = 0;
+//    ret = dma_device_poll(dma_dev, work_to_do, &work_done);
+//    *budget -= work_done;
+//    poll_dev->quota -= work_done;
+//    return ret;
+//}
+static eth_fw_poll_ret_t ltq_switch_poll(struct net_device *poll_dev, int work_to_do, int *work_done)
+{
+    int ret;
+
+#ifdef CONFIG_LTQMIPS_DMA
+    ret = dma_device_poll(g_dma_device, work_to_do, work_done);
+    return ret == 0 ? IFX_ETH_FW_POLL_COMPLETE : IFX_ETH_FW_POLL_CONTINUE;
+#endif
+}
+
+static void switch_activate_poll(struct dma_device_info* dma_dev)
+{
+    struct net_device *dev;
+    int i;
+
+    for(i=0; i < NUM_ETH_INF ; i++) {
+        dev = eth_dev[i];
+//        if ( netif_rx_schedule_prep(dev) )
+//        __netif_rx_schedule(dev);
+        ltq_eth_fw_poll_schedule(dev);
+    }
+}
+
+static void switch_inactivate_poll(struct dma_device_info* dma_dev)
+{
+    struct net_device *dev;
+    int i;
+
+    for(i=0; i < NUM_ETH_INF ; i++) {
+        dev = eth_dev[i];
+//        if(netif_running(dev) )
+//            netif_rx_complete(dev);
+        ltq_eth_fw_poll_complete(dev);
+    }
+}
+#endif
+
+/* Unregister with DMA device core driver */
+static void dma_setup_uninit(void)
+{
+#ifdef CONFIG_LTQMIPS_DMA
+    struct dma_device_info* dma_dev=g_dma_device;
+    if( dma_dev ) {
+        dma_device_unregister(dma_dev);
+        dma_device_release(dma_dev);
+    }
+#endif
+}
+
+#ifdef CONFIG_LTQMIPS_DMA
+/* Register with DMA device core driver */
+static int ltqcpe_dma_setup_init(void)
+{
+    int i, ret = 0;
+
+    g_dma_device=dma_device_reserve("PPE");
+    if(!g_dma_device) {
+        printk(KERN_ERR "%s[%d]: Reserved with DMA core driver failed!!!\n", __func__,__LINE__);
+        return -ENODEV;
+    }
+    g_dma_device->buffer_alloc              =&sw_dma_buffer_alloc;
+    g_dma_device->buffer_free               =&sw_dma_buffer_free;
+    g_dma_device->intr_handler              =&dma_intr_handler;
+    g_dma_device->num_rx_chan               = 4;
+    g_dma_device->num_tx_chan               = 2;
+    g_dma_device->tx_burst_len              = DMA_TX_BURST_LEN;
+    g_dma_device->rx_burst_len              = DMA_RX_BURST_LEN;
+    g_dma_device->tx_endianness_mode        = IFX_DMA_ENDIAN_TYPE3;
+    g_dma_device->rx_endianness_mode        = IFX_DMA_ENDIAN_TYPE3;
+    g_dma_device->port_packet_drop_enable   = 0;
+
+    for (i = 0; i < g_dma_device->num_rx_chan; i++) {
+        g_dma_device->rx_chan[i]->packet_size       =  ETH_PKT_BUF_SIZE;
+        g_dma_device->rx_chan[i]->control           = IFX_DMA_CH_ON;
+    }
+    for (i = 0; i < g_dma_device->num_tx_chan; i++) {
+        if ( (i == 0) || (i == 1)) /* eth0 --> DMA Tx0 channel, eth1--> DMA Tx1 channel*/
+            g_dma_device->tx_chan[i]->control       = IFX_DMA_CH_ON;
+        else
+            g_dma_device->tx_chan[i]->control       = IFX_DMA_CH_OFF;
+    }
+#ifdef  CONFIG_IFX_NAPI
+    g_dma_device->activate_poll     = switch_activate_poll;
+    g_dma_device->inactivate_poll   = switch_inactivate_poll;
+#endif
+    ret = dma_device_register (g_dma_device);
+    if ( ret != 0)
+        printk(KERN_ERR "%s[%d]: Register with DMA core driver Failed!!!\n", __func__,__LINE__);
+
+    return ret;
+}
+#endif
+
+/* init of the network device */
+static int ltq_switch_init(struct net_device *dev)
+{
+    u64 retval;
+    static int macVal=0;
+    int i;
+
+    /*printk("%s up\n",dev->name); */
+
+    SET_ETHTOOL_OPS(dev, &ethtool_ops);
+
+    for ( i = 0, retval = 0; i < 6; i++ )
+        retval += dev->dev_addr[i];
+    if ( retval == 0 ) {
+        /*read the mac address from the mac table and put them into the mac table.*/
+      	for (i = 0; i < 6; i++) {
+    		retval +=my_ethaddr[i];
+    	}
+    	/* if ethaddr not set in u-boot, then use default one */
+    	if (retval == 0) {
+    	    dev->dev_addr[0] = 0x00;
+    		dev->dev_addr[1] = 0x20;
+    		dev->dev_addr[2] = 0xda;
+    		dev->dev_addr[3] = 0x86;
+    		dev->dev_addr[4] = 0x23;
+    		dev->dev_addr[5] = 0x74 + macVal;
+    	} else {
+    	    for (i = 0; i < 6; i++) {
+    	        dev->dev_addr[i] = my_ethaddr[i];
+    	    }
+    	    dev->dev_addr[5] += + macVal ;
+    	}
+    	macVal++;
+    }
+    return 0;
+}
+
+/* Driver version info */
+static inline int eth_drv_ver(char *buf)
+{
+    return sprintf(buf, "Lantiq ethernet driver for XWAY, version %s,(c)2009 Infineon Technologies AG\n", version);
+}
+
+#if defined (SNMP_COUNTERS_DEBUG)
+static int stricmp(const char *p1, const char *p2)
+{
+    int c1, c2;
+
+    while ( *p1 && *p2 ) {
+        c1 = *p1 >= 'A' && *p1 <= 'Z' ? *p1 + 'a' - 'A' : *p1;
+        c2 = *p2 >= 'A' && *p2 <= 'Z' ? *p2 + 'a' - 'A' : *p2;
+        if ( (c1 -= c2) )
+            return c1;
+        p1++;
+        p2++;
+    }
+    return *p1 - *p2;
+}
+
+#define RMON_COUNT_SIZE         64
+
+static unsigned int g_rmon_counter[7][0x30] = {{0}};
+
+void clear_rmon_counter(int port)
+{
+    int i;
+    unsigned int  val0=0, val1=0, val2=0, val3=0, data=0;
+
+    for(i=0;i<RMON_COUNT_SIZE;i++) {
+        SW_WRITE_REG32(i, ETHSW_BM_RAM_ADDR_REG);
+        SW_WRITE_REG32((0x8000| port), ETHSW_BM_RAM_CTRL_REG);
+        while(  (SW_READ_REG32(ETHSW_BM_RAM_CTRL_REG) & 0x8000) == 1  ) {
+            ;
+        }
+        val3 = SW_READ_REG32(ETHSW_BM_RAM_VAL_3_REG);
+        val2 = SW_READ_REG32(ETHSW_BM_RAM_VAL_2_REG);
+        val0 = SW_READ_REG32(ETHSW_BM_RAM_VAL_0_REG);
+        val1 = SW_READ_REG32(ETHSW_BM_RAM_VAL_1_REG);
+        data = (val1 << 16) | (val0);
+        g_rmon_counter[port][i] = data;
+    }
+}
+
+int print_rmon_counter(int  port)
+{
+    int i;
+    unsigned int  val0=0, val1=0, val2=0, val3=0, data=0;
+    printk("RMON counter for Port: %d\n",port);
+    for(i=0;i<RMON_COUNT_SIZE;i++) {
+        SW_WRITE_REG32(i, ETHSW_BM_RAM_ADDR_REG);
+        SW_WRITE_REG32((0x8000| port), ETHSW_BM_RAM_CTRL_REG);
+        while(  (SW_READ_REG32(ETHSW_BM_RAM_CTRL_REG) & 0x8000) == 1  ) {
+            ;
+        }
+        val3 = SW_READ_REG32(ETHSW_BM_RAM_VAL_3_REG);
+        val2 = SW_READ_REG32(ETHSW_BM_RAM_VAL_2_REG);
+        val0 = SW_READ_REG32(ETHSW_BM_RAM_VAL_0_REG);
+        val1 = SW_READ_REG32(ETHSW_BM_RAM_VAL_1_REG);
+        data = (val1 << 16) | (val0);
+        data -= g_rmon_counter[port][i];
+        switch(i) {
+            case 0x1F :
+                printk("Receive Frame Count                    :0x%08x\n", data);
+                break;
+            case 0x23 :
+                printk("Receive Unicast Frame Count            :0x%08x\n",data);
+                break;
+            case 0x22 :
+                printk("Receive Multicast Frame Count          :0x%08x\n",data);
+                break;
+            case 0x21 :
+                printk("Receive CRC errors Count               :0x%08x\n",data);
+                break;
+            case 0x1D :
+                printk("Receive Undersize good Count           :0x%08x\n",data);
+                break;
+            case 0x1E :
+                printk("Receive Undersize bad Count            :0x%08x\n",data);
+                break;
+            case 0x1B :
+                printk("Receive Oversize good Count            :0x%08x\n",data);
+                break;
+            case 0x1C :
+                printk("Receive Oversize bad Count             :0x%08x\n",data);
+                break;
+            case 0x20 :
+                printk("Receive Pause good Count               :0x%08x\n",data);
+                break;
+            case 0x1A :
+                printk("Receive Alignment errors Count         :0x%08x\n",data);
+                break;
+            case 0x12 :
+                printk("Receive size 64Bytes Frame Count       :0x%08x\n",data);
+                break;
+            case 0x13 :
+                printk("Receive size 65-127Bytes Frame Count   :0x%08x\n",data);
+                break;
+            case 0x14 :
+                printk("Receive size 128-255Bytes Frame Count  :0x%08x\n",data);
+                break;
+            case 0x15 :
+                printk("Receive size 256-511Bytes Frame Count  :0x%08x\n",data);
+                break;
+            case 0x16 :
+                printk("Receive size 512-1023Bytes Frame Count :%08x\n",data);
+                break;
+            case 0x17 :
+                printk("Receive size >1024Bytes Frame Count    :%08x\n",data);
+                break;
+            case 0x18 :
+                printk("Receive Discard (Tail-Drop) frame Count:0x%08x\n",data);
+                break;
+            case 0x19 :
+                printk("Receive Drop ( Filter) frame Count     :0x%08x\n",data);
+                break;
+            case 0x24 :
+                printk("Receive Good Byte Count (Low)          :%08x\n",data);
+                break;
+            case 0x25 :
+                printk("Receive Good Byte Count(High)          :%08x\n",data);
+                break;
+            case 0x26 :
+                printk("Receive Bad Byte Count (Low)           :%08x\n",data);
+                break;
+            case 0x27 :
+                printk("Receive Bad Byte Count(High)           :%08x\n",data);
+                break;
+            case 0x11 :
+                printk("Receive Discard (Acive Congestion Management) frame Count:%08x\n",data);
+                break;
+            case 0x0C :
+                printk("Transmit Frame Count                        :%08x\n",data);
+                break;
+            case 0x06 :
+                printk("Transmit Unicast Frame Count                :%08x\n",data);
+                break;
+            case 0x07 :
+                printk("Transmit Multicast Frame Count              :%08x\n",data);
+                break;
+            case 0x00 :
+                printk("Transmit size 64Bytes Frame Count           :%08x\n",data);
+                break;
+            case 0x01 :
+                printk("Transmit size 65-127Bytes Frame Count       :%08x\n",data);
+                break;
+            case 0x02 :
+                printk("Transmit size 128-255Bytes Frame Count      :%08x\n",data);
+                break;
+            case 0x03 :
+                printk("Transmit size 256-511Bytes Frame Count      :%08x\n",data);
+                break;
+            case 0x04 :
+                printk("Transmit size 512-1023Bytes Frame Count     :%08x\n",data);
+                break;
+            case 0x05 :
+                printk("Transmit size >1024Bytes Frame Count        :%08x\n",data);
+                break;
+            case 0x08 :
+                printk("Transmit Single Collision Count             :%08x\n",data);
+                break;
+            case 0x09 :
+                printk("Transmit Multiple Collision Count           :%08x\n",data);
+                break;
+            case 0x0A :
+                printk("Transmit Late Collision Count               :%08x\n",data);
+                break;
+            case 0x0B :
+                printk("Transmit Excessive Collision Count          :%08x\n",data);
+                break;
+            case 0x0D :
+                printk("Transmit Pause Frame Count                  :%08x\n",data);
+                break;
+            case 0x10 :
+                printk("Transmit Dropped Frame Count                :%08x\n",data);
+                break;
+            case 0x0E :
+                printk("Transmit Good Byte Count (Low)              :%08x\n",data);
+                break;
+            case 0x0F :
+                printk("Transmit Good Byte Count(High)              :%08x\n",data);
+                break;
+            }
+        }
+        return 0;
+}
+
+static int get_token(char **p1, char **p2, int *len, int *colon)
+{
+    int tlen = 0;
+    while ( *len && !((**p1 >= 'A' && **p1 <= 'Z')
+            || (**p1 >= 'a' && **p1<= 'z')
+            || (**p1 >= '0' && **p1<= '9')) ) {
+        (*p1)++;
+        (*len)--;
+    }
+    if ( !*len )
+        return 0;
+    if ( *colon ) {
+        *colon = 0;
+        *p2 = *p1;
+        while ( *len && **p2 > ' ' && **p2 != ',' ) {
+            if ( **p2 == ':' ) {
+                *colon = 1;
+                break;
+            }
+            (*p2)++;
+            (*len)--;
+            tlen++;
+        }
+        **p2 = 0;
+    } else {
+        *p2 = *p1;
+        while ( *len && **p2 > ' ' && **p2 != ',' ) {
+            (*p2)++;
+            (*len)--;
+            tlen++;
+        }
+        **p2 = 0;
+    }
+    return tlen;
+}
+
+static int proc_read_rmon(struct file *file, const char *buf, unsigned long count, void *data)
+{
+    char local_buf[2048];
+    int len, colon = 0, port = -1;
+    char *p1, *p2;
+
+    len = sizeof(local_buf) < count ? sizeof(local_buf) - 1 : count;
+    len = len - copy_from_user(local_buf, buf, len);
+    local_buf[len] = 0;
+    p1 = local_buf;
+    while ( get_token(&p1, &p2, &len, &colon) ) {
+        if ( stricmp(p1, "p0") == 0 ) {
+            port= 0;
+        } else if ( stricmp(p1, "p1") == 0 ) {
+            port= 1;
+        } else if ( stricmp(p1, "p2") == 0 ) {
+            port= 2;
+        } else if ( stricmp(p1, "p3") == 0 ) {
+            port= 3;
+        } else if ( stricmp(p1, "p4") == 0 ) {
+            port= 4;
+        } else if ( stricmp(p1, "p5") == 0 ) {
+            port= 5;
+        } else if ( stricmp(p1, "p6") == 0 ) {
+            port= 6;
+        } else if ( stricmp(p1, "clear") == 0 || stricmp(p1, "clean") == 0 ) {
+            int i;
+
+            for ( i = 0; i < 7; i++ )
+                clear_rmon_counter(i);
+            break;
+        } else if ( stricmp(p1, "help") == 0 || strcmp(p1, "?") == 0 ) {
+            printk("echo px[x:0~6] > /proc/driver/7port_sw/read_rmon_counters\n");
+            printk("echo clean > /proc/driver/7port_sw/read_rmon_counters\n");
+            break;
+        }
+        p1 = p2;
+    }
+
+    if (port >= 0 && port <= 6)
+        print_rmon_counter(port);
+    return count;
+}
+#endif /*SNMP_COUNTERS_DEBUG*/
+
+/* Displays the version of ETH module via proc file */
+static int eth_proc_version(struct seq_file *m, void *v)
+{
+    /* No sanity check cos length is smaller than one page */
+    seq_printf (m, "Lantiq ethernet driver for XWAY, version %s,(c)2009 Infineon Technologies AG\n", version);
+    return 0;
+}
+
+static int print_pce_entry(char *buf, int index)
+{
+#define VR9_SWIP_MACRO                          (KSEG1 | 0x1E108000)
+#define VR9_SWIP_MACRO_REG(off)                 ((volatile u32*)(VR9_SWIP_MACRO + (off) * 4))
+#define VR9_SWIP_TOP                            (VR9_SWIP_MACRO | (0x0C40 * 4))
+#define VR9_SWIP_TOP_REG(off)                   ((volatile u32*)(VR9_SWIP_TOP + (off) * 4))
+//  Parser & Classification Engine
+#define PCE_TBL_KEY(n)                          VR9_SWIP_MACRO_REG(0x440 + 7 - (n))                 //  n < 7
+#define PCE_TBL_MASK                            VR9_SWIP_MACRO_REG(0x448)
+#define PCE_TBL_VAL(n)                          VR9_SWIP_MACRO_REG(0x449 + 4 - (n))                 //  n < 4;
+#define PCE_TBL_ADDR                            VR9_SWIP_MACRO_REG(0x44E)
+#define PCE_TBL_CTRL                            VR9_SWIP_MACRO_REG(0x44F)
+#define PCE_TBL_STAT                            VR9_SWIP_MACRO_REG(0x450)
+#define PCE_GCTRL_REG(reg)                      VR9_SWIP_MACRO_REG(0x456 + (reg))
+#define PCE_PCTRL_REG(port, reg)                VR9_SWIP_MACRO_REG(0x480 + (port) * 0xA + (reg))    //  port < 12, reg < 4
+
+    static char *out_fields[] = {
+        "OUT_MAC0  ",   //  0
+        "OUT_MAC1  ",   //  1
+        "OUT_MAC2  ",   //  2
+        "OUT_MAC3  ",   //  3
+        "OUT_MAC4  ",   //  4
+        "OUT_MAC5  ",   //  5
+        "OUT_ETHTYP",   //  6
+        "OUT_VTAG0 ",   //  7
+        "OUT_VTAG1 ",   //  8
+        "OUT_ITAG0 ",   //  9
+        "OUT_ITAG1 ",   //  10
+        "OUT_ITAG2 ",   //  11
+        "OUT_ITAG3 ",   //  12
+        "OUT_IP0   ",   //  13
+        "OUT_IP1   ",   //  14
+        "OUT_IP2   ",   //  15
+        "OUT_IP3   ",   //  16
+        "OUT_SIP0  ",   //  17
+        "OUT_SIP1  ",   //  18
+        "OUT_SIP2  ",   //  19
+        "OUT_SIP3  ",   //  20
+        "OUT_SIP4  ",   //  21
+        "OUT_SIP5  ",   //  22
+        "OUT_SIP6  ",   //  23
+        "OUT_SIP7  ",   //  24
+        "OUT_DIP0  ",   //  25
+        "OUT_DIP1  ",   //  26
+        "OUT_DIP2  ",   //  27
+        "OUT_DIP3  ",   //  28
+        "OUT_DIP4  ",   //  29
+        "OUT_DIP5  ",   //  30
+        "OUT_DIP6  ",   //  31
+        "OUT_DIP7  ",   //  32
+        "OUT_SESID ",   //  33
+        "OUT_PROT  ",   //  34
+        "OUT_APP0  ",   //  35
+        "OUT_APP1  ",   //  36
+        "OUT_IGMP0 ",   //  37
+        "OUT_IGMP1 ",   //  38
+        "OUT_IPOFF ",   //  39
+        "OUT_NONE  ",   //  63
+    };
+    static char *types[] = {
+        "INSTR  ",  //  0
+        "IPV6   ",  //  1
+        "LENACCU",  //  2
+    };
+    static char *flags[] = {
+        "FLAG_ITAG ",  //  0
+        "FLAG_VLAN ",  //  1
+        "FLAG_SNAP ",  //  2
+        "FLAG_PPPOE",  //  3
+        "FLAG_IPV6 ",  //  4
+        "FLAG_IPV6F",  //  5
+        "FLAG_IPV4 ",  //  6
+        "FLAG_IGMP ",  //  7
+        "FLAG_TU   ",  //  8
+        "FLAG_HOP  ",  //  9
+        "FLAG_NN1  ",  //  10
+        "FLAG_NN2  ",  //  11
+        "FLAG_END  ",  //  12
+        "FLAG_NO   ",  //  13
+    };
+    static char *titles[] = {
+        "0 : IFXTAG    ",
+        "1 : C_VTAG    ",
+        "2 : ET_IPV4   ",
+        "3 : ET_IPV6   ",
+        "4 : ET_PPPOE_S",
+        "5 : ET_PPPOE_D",
+        "6 : S_VTAG    ",
+        "7 : C_VTAG2   ",
+        "8 : EL_LES_800",
+        "9 : ET_OTHER  ",
+        "10: EL_GRE_600",
+        "11: EL_LES_600",
+        "12: SNAP1     ",
+        "13: NO_SNAP1  ",
+        "14: SNAP2     ",
+        "15: NO_SNAP2  ",
+        "16: SESID_IGN ",
+        "17: SESID     ",
+        "18: PPPOE_IP  ",
+        "19: PPPOE_NOIP",
+        "20: IPV4_VER  ",
+        "21: IPV6_VER  ",
+        "22: NO_IP     ",
+        "23: IPV4_UDP1 ",
+        "24: IPV4_TCP  ",
+        "25: IPV4_IGMP1",
+        "26: IPV4_OTH1 ",
+        "27: IPV4_UDP2 ",
+        "28: IPV4_UDP3 ",
+        "29: IPV4_OTH2 ",
+        "30: IPV4_OTH3 ",
+        "31: IPV4_IGMP2",
+        "32: IPV4_IGMP3",
+        "33: IPV4_IGMP4",
+        "34: IPV6_UDP  ",
+        "35: IPV6_TCP  ",
+        "36: IPV6_HOP  ",
+        "37: IPV6_ROU  ",
+        "38: IPV6_DES  ",
+        "39: IPV6_OTH  ",
+        "40: NXT_HD_UDP",
+        "41: NXT_HD_TCP",
+        "42: NXT_HD_HOP",
+        "43: NXT_HD_ROU",
+        "44: NXT_HD_DES",
+        "45: NXT_HD_OTH",
+        "46: TU_IP     ",
+        "47: TU_PORTS  ",
+        "48: IPV6_IP   ",
+        "49: END       ",
+        "50: END       ",
+        "51: END       ",
+        "52: END       ",
+        "53: END       ",
+        "54: END       ",
+        "55: END       ",
+        "56: END       ",
+        "57: END       ",
+        "58: END       ",
+        "59: END       ",
+        "60: END       ",
+        "61: END       ",
+        "62: END       ",
+        "63: END       ",
+    };
+
+    int len = 0;
+    unsigned int val[4];
+    unsigned int value;
+    unsigned int mask;
+    unsigned int ns;
+    char *p_out_field;
+    unsigned int L;
+    char *p_type;
+    char *p_flag;
+    unsigned int ipv4_len;
+    char *p_title;
+    unsigned int tmp;
+
+    if ( index < 0 )
+    {
+        len += sprintf(buf + len, "//------------------------------------------------------------------------------------------\n");
+        len += sprintf(buf + len, "//                value    mask   ns  out_fields   L  type     flags       ipv4_len\n");
+        len += sprintf(buf + len, "//------------------------------------------------------------------------------------------\n");
+    }
+    else
+    {
+        while ( (*PCE_TBL_CTRL & (1 << 15)) );
+        *PCE_TBL_ADDR   = index;
+        *PCE_TBL_CTRL   = 0x8000;   //  read micro code
+        while ( (*PCE_TBL_CTRL & (1 << 15)) );
+        val[3] = *PCE_TBL_VAL(3);
+        val[2] = *PCE_TBL_VAL(2);
+        val[1] = *PCE_TBL_VAL(1);
+        val[0] = *PCE_TBL_VAL(0);
+
+        value = val[3] & 0xFFFF;
+        mask = val[2] & 0xFFFF;
+        ns = (val[1] >> 10) & ((1 << 6) - 1);
+        tmp = (val[1] >> 4) & ((1 << 6) - 1);
+        if ( tmp <= 39 )
+            p_out_field = out_fields[tmp];
+        else if ( tmp == 63 )
+            p_out_field = out_fields[40];
+        else
+            p_out_field = "reserved";
+        L = ((val[1] & ((1 << 4) - 1)) << 1) | ((val[0] >> 15) & 0x01);
+        tmp = (val[0] >> 13) & ((1 << 2) - 1);
+        if ( tmp <= sizeof(types) / sizeof(*types) )
+            p_type = types[tmp];
+        else
+            p_type = "reserved";
+        tmp = (val[0] >> 9) & ((1 << 4) - 1);
+        if ( tmp <= sizeof(flags) / sizeof(*flags) )
+            p_flag = flags[tmp];
+        else
+            p_flag = "reserved";
+        ipv4_len = (val[0] >> 8) & 0x01;
+        tmp = index;
+        if ( tmp <= sizeof(titles) / sizeof(*titles) )
+            p_title = titles[tmp];
+        else
+            p_title = "reserved";
+        len += sprintf(buf + len, "LANTIQ_FLOW_PCE_MC_M(0x%04X, 0x%04X, %-2d, %s, %2d, %s, %s, %d),   // %s\n",
+                       value, mask, ns, p_out_field, L, p_type, p_flag, ipv4_len, p_title);
+    }
+
+    return len;
+}
+
+static int proc_read_pce(struct seq_file *m, void *v)
+{
+
+#if 0
+    int len = 0;
+    int len_max = off + count;
+    char *pstr;
+    char str[1024];
+    int llen;
+
+    int i;
+
+    pstr = *start = page;
+
+    for ( i = -1; i < 64; i++ )
+    {
+        llen = print_pce_entry(str, i);
+        if ( len <= off && len + llen > off )
+        {
+            memcpy(pstr, str + off - len, len + llen - off);
+            pstr += len + llen - off;
+        }
+        else if ( len > off )
+        {
+            memcpy(pstr, str, llen);
+            pstr += llen;
+        }
+        len += llen;
+        if ( len >= len_max )
+            goto PROC_READ_PCE_OVERRUN_END;
+    }
+
+    *eof = 1;
+
+    return len - off;
+
+PROC_READ_PCE_OVERRUN_END:
+    return len - llen - off;
+#endif
+	return 0;
+}
+
+static int rversion_open (struct inode *inode, struct file *file)
+{
+	return single_open(file, eth_proc_version, NULL);
+}
+
+static int rpce_open (struct inode *inode, struct file *file)
+{
+	return single_open(file, proc_read_pce, NULL);
+}
+
+
+/* create proc for debug  info, eth_module_init */
+static int eth_proc_create(void)
+{
+    /* procfs */
+    g_eth_proc_dir = proc_mkdir("driver/7port_sw",NULL);
+    if (g_eth_proc_dir == NULL) {
+        printk(KERN_ERR "%s: Create proc directory (/driver/7port_sw) failed!!!\n", __func__);
+        return -EIO;
+    }
+    //create_proc_read_entry("version", 0, g_eth_proc_dir, eth_proc_version,  NULL);
+    proc_create ("version", S_IRUGO, g_eth_proc_dir, &rversion_ops);
+#if defined (SNMP_COUNTERS_DEBUG)
+    {
+        struct proc_dir_entry *res;
+        res = create_proc_entry("read_rmon_counters", 0, g_eth_proc_dir );
+        if ( res ) {
+            res->read_proc  = NULL;
+            res->write_proc = proc_read_rmon;
+        }
+    }
+#endif /* SNMP_COUNTERS_DEBUG */
+    //create_proc_read_entry("pce", 0, g_eth_proc_dir, proc_read_pce,  NULL);
+    proc_create ("pce", S_IRUGO, g_eth_proc_dir, &rpce_ops);
+    return 0;
+}
+
+/* remove of the proc entries, eth_module_exit */
+static void eth_proc_delete(void)
+{
+
+    remove_proc_entry("version", g_eth_proc_dir);
+#if defined (SNMP_COUNTERS_DEBUG)
+    remove_proc_entry("read_rmon_counters", g_eth_proc_dir);
+#endif
+    remove_proc_entry("pce", g_eth_proc_dir);
+    remove_proc_entry("driver/7port_sw",  NULL);
+}
+
+/* Initilization  Ethernet module */
+static int ltq_eth_drv_init (void)
+{
+    int  i,  err;
+    unsigned int reg;
+    char ver_str[128] = {0};
+    ltq_switch_priv_t* priv;
+    g_pmac_dma = 0;
+    g_dma_pmac = 0;
+
+#ifdef CONFIG_LTQMIPS_DMA
+     /* Register with DM core driver */
+   err = ltqcpe_dma_setup_init();
+#endif
+
+     /* HW init of the Switch */
+    vr9_7port_sw_hw_init();
+
+    for (i = 0; i < NUM_ETH_INF ; i++) {
+        char name[16];
+        sprintf(name, "eth%d", i);
+        eth_dev[i] = alloc_etherdev(sizeof(ltq_switch_priv_t));
+        if (!eth_dev[i]) {
+            printk(KERN_ERR "%s[%d]: no memory for eth_dev!!!\n", __func__,__LINE__);
+            err = -ENOMEM;
+            goto err_out_free_res;
+        }
+
+		/* setup the network device */
+		strcpy(eth_dev[i]->name, name);
+		eth_dev[i]->netdev_ops = &ltq_eth_drv_ops;
+		eth_dev[i]->watchdog_timeo = LTQ_TX_TIMEOUT;
+
+		/* setup the private data */
+        priv = netdev_priv(eth_dev[i]);
+        priv->phy_addr = i;
+
+        /* By default, advertise supported  speed/duplex settings. */
+        priv->flags |= (FLAG_ADV_10HALF         \
+                        | FLAG_ADV_10FULL       \
+                        | FLAG_ADV_100HALF      \
+                        | FLAG_ADV_100FULL      \
+                        | FLAG_ADV_1000HALF     \
+                        | FLAG_ADV_1000FULL);
+
+    	/* By default, auto-negotiate PAUSE. */
+        priv->flags |= FLAG_PAUSE_AUTO;
+        spin_lock_init(&priv->lock);
+        err = register_netdev(eth_dev[i]);
+        if ( err ) {
+            printk(KERN_ERR "%s[%d]: Register with network device failed!!!\n", __func__,__LINE__);
+            goto err_out_free_res;
+        }
+    }
+
+    reg = SW_READ_REG32(PMAC_HD_CTL_REG );
+    if (reg  & PMAC_HD_CTL_AS )
+        g_pmac_dma = 1;
+    if (reg  & PMAC_HD_CTL_RXSH )
+        g_dma_pmac = 1;
+
+    if (eth_proc_create() != 0 )
+        goto err_out_free_res;
+ /* Print the driver version info */
+    eth_drv_ver(ver_str);
+    printk(KERN_INFO "%s", ver_str);
+    printk("g_dma_pmac:%d, g_pmac_dma:%d, reg:0x%08x !!!\n",g_dma_pmac, g_pmac_dma,reg);
+    return  0;
+
+err_out_free_res:
+/*Unregister with DMA core driver */
+    dma_setup_uninit();
+    /* unregister the network devices */
+    for (i=0; i< NUM_ETH_INF ; i++) {
+        if(eth_dev[i])
+            free_netdev(eth_dev[i]);
+    }
+    return err;
+}
+
+static void  ltq_eth_drv_exit (void)
+{
+    int i;
+
+    /* unregister the network devices */
+    for (i=0; i< NUM_ETH_INF ; i++) {
+        unregister_netdev(eth_dev[i]);
+        free_netdev(eth_dev[i]);
+    }
+    /*Unregister with DMA core driver */
+    dma_setup_uninit();
+    /* remove of the proc entries */
+    eth_proc_delete();
+}
+
+static int ltq_eth_drv_probe(struct platform_device *pdev)
+{
+
+	/* Just do the init */
+	ltq_eth_drv_init ();
+
+	return 0;
+}
+
+static int ltq_eth_drv_remove(struct platform_device *pdev)
+{
+	/* Just do the exit */
+	ltq_eth_drv_exit ();
+	return 0;
+}
+
+static const struct of_device_id ltq_eth_drv_match[] = {
+	{ .compatible = "lantiq,xway-net" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, ltq_eth_drv_match);
+
+static struct platform_driver ltq_eth_driver = {
+	.probe = ltq_eth_drv_probe,
+	.remove = ltq_eth_drv_remove,
+	.driver = {
+		.name = "xway-net",
+		.of_match_table = ltq_eth_drv_match,
+		.owner = THIS_MODULE,
+	},
+};
+
+module_platform_driver(ltq_eth_driver);
+
+MODULE_AUTHOR("Reddy Mallikarjuna");
+MODULE_DESCRIPTION("Lantiq ethernet driver (Supported XRX200/XRX3XX)");
+MODULE_LICENSE("GPL");
+MODULE_VERSION(DRV_MODULE_VERSION);
diff --git a/include/net/lantiq_eth_framework.h b/include/net/lantiq_eth_framework.h
new file mode 100644
index 000000000000..77b0facbd766
--- /dev/null
+++ b/include/net/lantiq_eth_framework.h
@@ -0,0 +1,90 @@
+/******************************************************************************
+**
+** FILE NAME    : ifx_eth_framework.h
+** PROJECT      : UEIP
+** MODULES      : ETH
+**
+** DATE         : 2 Nov 2010
+** AUTHOR       : Xu Liang
+** DESCRIPTION  : Global ETH driver framework header file
+** COPYRIGHT    :              Copyright (c) 2009
+**                          Lantiq Deutschland GmbH
+**                   Am Campeon 3; 85579 Neubiberg, Germany
+**
+**   For licensing information, see the file 'LICENSE' in the root folder of
+**   this software module.
+**
+** HISTORY
+** $Date        $Author         $Comment
+** 02 NOV 2010  Xu Liang        Init Version
+*******************************************************************************/
+
+
+
+#ifndef IFX_ETH_FRAMEWORK_H
+#define IFX_ETH_FRAMEWORK_H
+
+
+
+/*
+ * ####################################
+ *              Data Type
+ * ####################################
+ */
+
+typedef enum {
+    IFX_ETH_FW_POLL_COMPLETE = 0,
+    IFX_ETH_FW_POLL_CONTINUE = 1,
+} ifx_eth_fw_poll_ret_t;
+
+struct ifx_eth_fw_netdev_ops {
+    //  routines usually implemented by IFX ETH/PPE drivers
+    //  not all routines defined in net_device/net_device_ops are covered
+    int             (*init)(struct net_device *dev);
+    void            (*uninit)(struct net_device *dev);
+
+    int             (*open)(struct net_device *dev);
+    int	            (*stop)(struct net_device *dev);
+
+    int             (*start_xmit)(struct sk_buff *skb, struct net_device *dev);
+
+    void            (*set_multicast_list)(struct net_device *dev);
+    int             (*set_mac_address)(struct net_device *dev, void *addr);
+    int             (*do_ioctl)(struct net_device *dev, struct ifreq *ifr, int cmd);
+    int             (*set_config)(struct net_device *dev, struct ifmap *map);
+    int             (*change_mtu)(struct net_device *dev, int new_mtu);
+    int	            (*neigh_setup)(struct net_device *dev, struct neigh_parms *);
+
+    struct net_device_stats*
+                    (*get_stats)(struct net_device *dev);
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+    void            (*poll_controller)(struct net_device *dev);
+#endif
+    ifx_eth_fw_poll_ret_t
+                    (*poll)(struct net_device *dev, int work_to_do, int *work_done);
+    int             weight;
+
+    void            (*tx_timeout)(struct net_device *dev);
+    int             watchdog_timeo;
+};
+
+
+
+/*
+ * ####################################
+ *             Declaration
+ * ####################################
+ */
+
+extern void *ifx_eth_fw_netdev_priv(struct net_device *dev);
+extern struct net_device *ifx_eth_fw_alloc_netdev(int sizeof_priv, const char *name, struct ifx_eth_fw_netdev_ops *ops);
+extern void ifx_eth_fw_free_netdev(struct net_device *dev, int force);
+extern int ifx_eth_fw_register_netdev(struct net_device *dev);
+void ifx_eth_fw_unregister_netdev(struct net_device *dev, int force);
+extern int ifx_eth_fw_poll_schedule(struct net_device *dev);
+extern int ifx_eth_fw_poll_complete(struct net_device *dev);
+
+
+
+#endif  //  IFX_ETH_FRAMEWORK_H

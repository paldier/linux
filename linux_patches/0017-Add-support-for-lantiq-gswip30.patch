From 7f490e300452909c2f372cff17a27082c5275895 Mon Sep 17 00:00:00 2001
From: Hua Ma <hua.ma@linux.intel.com>
Date: Thu, 21 Jun 2018 17:37:48 +0800
Subject: [PATCH] Add support for lantiq gswip30

---
 .../net/ethernet/lantiq/datapath/gswip30/Kconfig   |   25 +
 .../net/ethernet/lantiq/datapath/gswip30/Makefile  |   12 +
 .../lantiq/datapath/gswip30/datapath_coc.c         |  951 ++++++
 .../lantiq/datapath/gswip30/datapath_gswip.c       |  405 +++
 .../lantiq/datapath/gswip30/datapath_lookup_proc.c |  630 ++++
 .../lantiq/datapath/gswip30/datapath_mib.c         | 2197 +++++++++++++
 .../lantiq/datapath/gswip30/datapath_mib.h         |   20 +
 .../lantiq/datapath/gswip30/datapath_misc.c        |  680 ++++
 .../lantiq/datapath/gswip30/datapath_misc.h        |   82 +
 .../lantiq/datapath/gswip30/datapath_proc.c        | 3385 ++++++++++++++++++++
 .../lantiq/datapath/gswip30/datapath_proc.h        |    8 +
 include/net/datapath_api_gswip30.h                 |  425 +++
 12 files changed, 8820 insertions(+)

diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig b/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig
new file mode 100644
index 000000000000..1a081c65ddb4
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig
@@ -0,0 +1,25 @@
+menuconfig LTQ_DATAPATH_HAL_GSWIP30
+	bool "Datapath HAL_GSWIP30"
+	default y
+	depends on LTQ_DATAPATH && GRX500_CBM
+	---help---
+	  Datapath Lib is to provide common rx/tx wrapper Lib without taking
+	  care of much HW knowledge and also provide common interface for legacy
+	  devices and different HW like to CBM or LRO.
+	  Take note: All devices need to register to datapath Lib first
+
+if LTQ_DATAPATH_HAL_GSWIP30
+config LTQ_DATAPATH_HAL_GSWIP30_MIB
+	bool "Datapath aggregated mib support"
+	depends on LTQ_DATAPATH_HAL_GSWIP30 && SOC_GRX500 && LTQ_TMU && LTQ_PPA_TMU_MIB_SUPPORT
+	default y
+	---help---
+	  It is to aggregate GSWIP-L/R, TMU and driver's MIB counter
+
+config LTQ_DATAPATH_HAL_GSWIP30_CPUFREQ
+	bool "Datapath DFS(COC) support"
+	depends on LTQ_DATAPATH && LTQ_CPUFREQ && LTQ_ETHSW_API
+	default y
+	---help---
+	  It is to support DFS(COC) in Datapath
+endif
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile b/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile
new file mode 100644
index 000000000000..4827ba29537e
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile
@@ -0,0 +1,12 @@
+obj-$(CONFIG_LTQ_DATAPATH) += datapath_misc.o datapath_gswip.o datapath_proc.o datapath_lookup_proc.o
+
+ifneq ($(CONFIG_LTQ_DATAPATH_HAL_GSWIP30_MIB),)
+obj-$(CONFIG_LTQ_DATAPATH) += datapath_mib.o
+endif
+
+ifneq ($(CONFIG_LTQ_DATAPATH_HAL_GSWIP30_COC),)
+obj-$(CONFIG_LTQ_DATAPATH) += datapath_coc.o
+endif
+
+
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_coc.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_coc.c
new file mode 100644
index 000000000000..3514effff3c5
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_coc.c
@@ -0,0 +1,951 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/module.h>
+#include <linux/types.h>	/* size_t */
+#include <linux/timer.h>
+#include <net/datapath_api.h>
+#include <net/datapath_proc_api.h>
+#include "../datapath.h"
+
+#define DP_MODULE  LTQ_CPUFREQ_MODULE_DP
+#define DP_ID 0	 /* this ID should represent the Datapath interface No. */
+static struct timer_list dp_coc_timer;
+static u32 polling_period;	/*seconds */
+static int rmon_timer_en;
+static spinlock_t dp_coc_lock;
+
+/* threshold data for D0:D3 */
+struct ltq_cpufreq_threshold rmon_threshold = { 0, 30, 20, 10 }; /*packets */
+
+/* driver is busy and needs highest performance */
+static int dp_coc_init_stat;	/*DP COC is Initialized or not */
+static int dp_coc_ena;		/*DP COC is enabled or not */
+enum ltq_cpufreq_state dp_coc_ps_curr = LTQ_CPUFREQ_PS_UNDEF;/*current state*/
+/*new statue wanted to switch to */
+enum ltq_cpufreq_state dp_coc_ps_new = LTQ_CPUFREQ_PS_UNDEF;
+
+static GSW_RMON_Port_cnt_t rmon_last[PMAC_MAX_NUM];
+static u64 last_rmon_rx;
+
+/*meter */
+#define PCE_OVERHD 20
+static u32 meter_id;
+/*3 ~ 4 packet size */
+static u32 meter_ncbs = 0x8000 + (1514 + PCE_OVERHD) * 3 + 200;
+/*1 ~ 2 packet size */
+static u32 meter_nebs = 0x8000 + (1514 + PCE_OVERHD) * 1 + 200;
+/*k bits */
+static u32 meter_nrate[4] = { 0/*D0 */, 700/*D1*/, 600/*D2*/, 500/*D3*/};
+
+static int dp_coc_cpufreq_notifier(struct notifier_block *nb,
+				   unsigned long val, void *data);
+static int dp_coc_stateget(enum ltq_cpufreq_state *state);
+static int dp_coc_fss_ena(int ena);
+static int apply_meter_rate(u32 rate, enum ltq_cpufreq_state new_state);
+static int enable_meter_interrupt(void);
+static int clear_meter_interrupt(void);
+int dp_set_meter_rate(enum ltq_cpufreq_state stat, unsigned int rate)
+{/*set the rate for upscaling to D0 from specified stat */
+	if (stat == LTQ_CPUFREQ_PS_D1)
+		meter_nrate[1] = rate;
+	else if (stat == LTQ_CPUFREQ_PS_D2)
+		meter_nrate[2] = rate;
+	else if (stat == LTQ_CPUFREQ_PS_D3)
+		meter_nrate[3] = rate;
+	else
+		return -1;
+	if (dp_coc_ps_curr == stat)
+		apply_meter_rate(-1, stat);
+	return 0;
+}
+EXPORT_SYMBOL(dp_set_meter_rate);
+
+static struct notifier_block dp_coc_cpufreq_notifier_block = {
+	.notifier_call = dp_coc_cpufreq_notifier
+};
+
+static inline void coc_lock(void)
+{
+	if (unlikely(in_irq())) {
+		PR_ERR("Not allowed to call COC API in_irq mode\n");
+		return;
+	}
+	spin_lock_bh(&dp_coc_lock);
+}
+
+static inline void coc_unlock(void)
+{
+	spin_unlock_bh(&dp_coc_lock);
+}
+
+struct ltq_cpufreq_module_info dp_coc_feature_fss = {
+	.name = "Datapath FSS",
+	.pmcuModule = DP_MODULE,
+	.pmcuModuleNr = DP_ID,
+	.powerFeatureStat = 1,
+	.ltq_cpufreq_state_get = dp_coc_stateget,
+	.ltq_cpufreq_pwr_feature_switch = dp_coc_fss_ena,
+};
+
+#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+static char *get_sub_module_str(uint32_t flag)
+{
+	if (flag == DP_COC_REQ_DP)
+		return "DP";
+	else if (flag == DP_COC_REQ_ETHERNET)
+		return "Ethernet";
+	else if (flag == DP_COC_REQ_VRX318)
+		return "VRX318";
+	else
+		return "Unknown";
+}
+#endif
+
+static char *get_coc_stat_string(enum ltq_cpufreq_state stat)
+{
+	if (stat == LTQ_CPUFREQ_PS_D0)
+		return "D0";
+	else if (stat == LTQ_CPUFREQ_PS_D1)
+		return "D1";
+	else if (stat == LTQ_CPUFREQ_PS_D2)
+		return "D2";
+	else if (stat == LTQ_CPUFREQ_PS_D3)
+		return "D3";
+	else if (stat == LTQ_CPUFREQ_PS_D0D3)
+		return "D0D3-NotCare";
+	else if (stat == LTQ_CPUFREQ_PS_BOOST)
+		return "Boost";
+	else
+		return "Undef";
+}
+
+static void dp_rmon_polling(unsigned long data)
+{
+	GSW_RMON_Port_cnt_t curr;
+	int i;
+	u64 rx = 0;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		memset(&curr, 0, sizeof(curr));
+		get_gsw_port_rmon(i, GSWIP_R, &curr);
+
+		coc_lock();
+		/*wrapround handling */
+		if (curr.nRxGoodPkts >= rmon_last[i].nRxGoodPkts)
+			rx += curr.nRxGoodPkts - rmon_last[i].nRxGoodPkts;
+		else
+			rx +=
+			    (u64)0xFFFFFFFF + (u64)curr.nRxGoodPkts -
+			    rmon_last[i].nRxGoodPkts;
+
+		if (curr.nRxDroppedPkts >= rmon_last[i].nRxDroppedPkts)
+			rx +=
+			    curr.nRxDroppedPkts - rmon_last[i].nRxDroppedPkts;
+		else
+			rx +=
+			    (u64)0xFFFFFFFF + (u64)curr.nRxDroppedPkts -
+			    rmon_last[i].nRxDroppedPkts;
+
+		memcpy(&rmon_last[i], &curr, sizeof(curr));
+		coc_unlock();
+	}
+	last_rmon_rx = rx;
+	if (dp_coc_ps_curr != LTQ_CPUFREQ_PS_UNDEF) {
+		if (rx < rmon_threshold.th_d3) {
+			if (dp_coc_new_stat_req
+			    (LTQ_CPUFREQ_PS_D3, DP_COC_REQ_DP) == 0) {
+				coc_lock();
+				rmon_timer_en = 0;
+				coc_unlock();
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "Request to D3:rx (%u) < th_d3 %d\n",
+					 (unsigned int)rx,
+					 rmon_threshold.th_d3);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "req to D3 fail for dp_coc_new_stat_req\n");
+		} else if (rx < rmon_threshold.th_d2) {
+			if (dp_coc_new_stat_req
+			    (LTQ_CPUFREQ_PS_D2, DP_COC_REQ_DP) == 0) {
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "req to D2: rx (%u) < th_d2 %d\n",
+					 (unsigned int)rx,
+					 rmon_threshold.th_d2);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "req to D2 fail for dp_coc_new_stat_req\n");
+		} else if (rx < rmon_threshold.th_d1) {
+			if (dp_coc_new_stat_req
+			    (LTQ_CPUFREQ_PS_D1, DP_COC_REQ_DP) == 0) {
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "req to D1 since rx (%u) < th_d1 %d\n",
+					 (unsigned int)rx,
+					 rmon_threshold.th_d1);
+			} else
+				DP_DEBUG(DP_DBG_FLAG_COC,
+					 "req to D1 fail: dp_coc_new_stat_req\n");
+		} else
+			DP_DEBUG(DP_DBG_FLAG_COC,
+				 "Stat no change:rx(%u)>=any thresholds %d_%d_%d\n",
+				 (unsigned int)rx, rmon_threshold.th_d3,
+				 rmon_threshold.th_d2, rmon_threshold.th_d1);
+	} else
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "DP COC not get its initial power state yet\n");
+
+	coc_lock();
+
+	if (rmon_timer_en)
+		mod_timer(&dp_coc_timer,
+			  jiffies + msecs_to_jiffies(polling_period * 1000));
+	else
+		last_rmon_rx = 0;
+
+	coc_unlock();
+}
+
+static int dp_coc_stateget(enum ltq_cpufreq_state *state)
+{
+	DP_DEBUG(DP_DBG_FLAG_COC, "dp_coc_stateget with %d(%s)\n",
+		 dp_coc_ps_curr, get_coc_stat_string(dp_coc_ps_curr));
+	coc_lock();
+	*state = dp_coc_ps_curr;
+	coc_unlock();
+	return LTQ_CPUFREQ_RETURN_SUCCESS;
+}
+
+static int dp_coc_fss_ena(int ena)
+{
+	DP_DEBUG(DP_DBG_FLAG_COC,
+		 "dp_coc_fss_ena: %d(%s frequency scaling)\n", ena,
+		 ena ? "enable" : "disable");
+	coc_lock();
+	dp_coc_ena = ena;
+	coc_unlock();
+	return LTQ_CPUFREQ_RETURN_SUCCESS;
+}
+
+void update_rmon_last(void)
+{
+	int i;
+
+	for (i = 0; i < PMAC_MAX_NUM; i++)
+		get_gsw_port_rmon(i, GSWIP_R, &rmon_last[i]);
+}
+
+int update_coc_rmon_timer(enum ltq_cpufreq_state new_state, uint32_t flag)
+{
+	if (new_state == LTQ_CPUFREQ_PS_D0) {
+		/*enable rmon timer */
+		if (!rmon_timer_en)
+			update_rmon_last();
+		mod_timer(&dp_coc_timer,
+			  jiffies + msecs_to_jiffies(polling_period * 1000));
+		rmon_timer_en = 1;
+
+		/*disable meter */
+		apply_meter_rate(0, 0);
+	} else if (new_state == LTQ_CPUFREQ_PS_D1 ||
+		   new_state == LTQ_CPUFREQ_PS_D2) {
+		/*enable rmon timer */
+		if (!rmon_timer_en)
+			update_rmon_last();
+		mod_timer(&dp_coc_timer,
+			  jiffies + msecs_to_jiffies(polling_period * 1000));
+		rmon_timer_en = 1;
+
+		/*enable meter, but first disable to fix red color issue
+		 * if last already triggered
+		 */
+		apply_meter_rate(0, 0);
+		apply_meter_rate(-1, new_state);	/*enable again */
+	} else if (new_state == LTQ_CPUFREQ_PS_D3) {
+		/*disable rmon timer */
+		del_timer(&dp_coc_timer);
+		rmon_timer_en = 0;
+		last_rmon_rx = 0;
+
+		/*enable meter */
+		/*enable meter, but first disable to fix red color issue
+		 * if last already triggered
+		 */
+		apply_meter_rate(0, 0);
+		apply_meter_rate(-1, new_state);	/*enable again */
+	}
+
+	return 0;
+}
+
+static int update_coc_cfg(enum ltq_cpufreq_state new_state,
+			  enum ltq_cpufreq_state old_state, uint32_t flag)
+{
+	update_coc_up_sub_module(new_state, old_state, flag);
+	update_coc_rmon_timer(new_state, flag);
+	return 0;
+}
+
+static int dp_coc_prechange(enum ltq_cpufreq_module module,
+			    enum ltq_cpufreq_state new_state,
+			    enum ltq_cpufreq_state old_state, u8 flags)
+{
+	int res = -1;
+
+	/*check whether can be switched or not */
+	if (!dp_coc_init_stat || !dp_coc_ena) {
+		res = 0;
+	} else if ((flags & CPUFREQ_PM_NO_DENY) ||
+		   (dp_coc_ps_curr == LTQ_CPUFREQ_PS_UNDEF) ||
+		   (dp_coc_ps_new == LTQ_CPUFREQ_PS_UNDEF) ||
+		   (dp_coc_ps_new == LTQ_CPUFREQ_PS_D0D3)) { /*accept */
+		res = 0;
+	} else if (dp_coc_ps_new >= new_state) {
+		/* Accept any upscale request */
+		res = 0;
+	}
+
+	DP_DEBUG(DP_DBG_FLAG_COC,
+		 "dp_coc_prechange:%s to switch from %s to %s\n",
+		 res ? "Deny" : "Accept", get_coc_stat_string(old_state),
+		 get_coc_stat_string(new_state));
+
+	return res;
+}
+
+static int dp_coc_postchange(enum ltq_cpufreq_module module,
+			     enum ltq_cpufreq_state new_state,
+			     enum ltq_cpufreq_state old_state, u8 flags)
+{
+	if (!dp_coc_init_stat || !dp_coc_ena)
+		return 0;
+
+	DP_DEBUG(DP_DBG_FLAG_COC, "dp_coc_postchange:switch from %s to %s\n",
+		 get_coc_stat_string(old_state),
+		 get_coc_stat_string(new_state));
+
+	coc_lock();
+	dp_coc_ps_curr = new_state;
+	dp_coc_ps_new = LTQ_CPUFREQ_PS_UNDEF;
+	update_coc_cfg(new_state, old_state, flags);/*don't lock before it */
+	coc_unlock();
+
+	return 0;
+}
+
+/* keep track of frequency transitions */
+static int dp_coc_cpufreq_notifier(struct notifier_block *nb,
+				   unsigned long val, void *data)
+{
+	struct cpufreq_freqs *freq = data;
+	enum ltq_cpufreq_state new_state, old_state;
+
+	new_state = ltq_cpufreq_get_ps_from_khz(freq->new);
+
+	if (new_state == LTQ_CPUFREQ_PS_UNDEF) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier new_state=UNDEF with val=%u\n",
+			 (unsigned int)val);
+		return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	}
+
+	old_state = ltq_cpufreq_get_ps_from_khz(freq->old);
+
+	if (old_state == LTQ_CPUFREQ_PS_UNDEF) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "new_state=%s old_state=UNDEF with val=%u\n",
+			 get_coc_stat_string(new_state), (unsigned int)val);
+		return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	}
+
+	if (val == CPUFREQ_PRECHANGE) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier prechange from %s to %s\n",
+			 get_coc_stat_string(old_state),
+			 get_coc_stat_string(new_state));
+
+		if (dp_coc_prechange
+		    (DP_MODULE, new_state, old_state, freq->flags))
+			return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	} else if (val == CPUFREQ_POSTCHANGE) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "dp_coc_cpufreq_notifier postchange from %s to %s\n",
+			 get_coc_stat_string(old_state),
+			 get_coc_stat_string(new_state));
+
+		if (dp_coc_postchange
+		    (DP_MODULE, new_state, old_state, freq->flags))
+			return NOTIFY_STOP_MASK | (DP_MODULE << 4);
+	}
+
+	return NOTIFY_OK | (DP_MODULE << 4);
+}
+
+void proc_coc_read(struct seq_file *s)
+{
+	GSW_register_t reg;
+	GSW_QoS_meterCfg_t meter_cfg;
+	struct core_ops *gsw_handle;
+
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	seq_puts(s, "  Basic DP COC Info:\n");
+	seq_printf(s, "    dp_coc_ena=%d @ 0x%p (DP %s)\n", dp_coc_ena,
+		   &dp_coc_ena, dp_coc_ena ? "COC Enabled" : "COC Disabled");
+	seq_printf(s, "    Rmon timer interval: %u sec (Timer %s)\n",
+		   (unsigned int)polling_period,
+		   rmon_timer_en ? "enabled" : "disabled");
+	/*seq_printf(s, "    RMON D0 Threshold: %d\n", rmon_threshold.th_d0); */
+	seq_printf(s, "    RMON D1 Threshold: %d\n", rmon_threshold.th_d1);
+	seq_printf(s, "    RMON D2 Threshold: %d\n", rmon_threshold.th_d2);
+	seq_printf(s, "    RMON D3 Threshold: %d\n", rmon_threshold.th_d3);
+	seq_printf(s, "    dp_coc_init_stat=%d @ %p (%s)\n", dp_coc_init_stat,
+		   &dp_coc_init_stat,
+		   dp_coc_init_stat ? "initialized ok" : "Not initialized");
+	seq_printf(s, "    dp_coc_ps_curr=%d (%s) @ 0x%p\n", dp_coc_ps_curr,
+		   get_coc_stat_string(dp_coc_ps_curr), &dp_coc_ps_curr);
+	seq_printf(s, "    dp_coc_ps_new=%d (%s)@ 0x%p\n", dp_coc_ps_new,
+		   get_coc_stat_string(dp_coc_ps_new), &dp_coc_ps_new);
+	seq_printf(s, "    last_rmon_rx=%llu pkts@ 0x%p (%s)\n", last_rmon_rx,
+		   &last_rmon_rx, rmon_timer_en ? "Valid" : "Not valid");
+
+	seq_puts(s, "    Metering Info:\n");
+	/*PCE_OVERHD */
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x46C;	/*PCE_OVERHD */
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	seq_printf(s, "    PCE_OVERHD=%d\n", reg.nData);
+
+	meter_cfg.nMeterId = meter_id;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops.QoS_MeterCfgGet,
+		     gsw_handle, &meter_cfg);
+	seq_printf(s, "    meter id=%u (%s)\n", meter_id,
+		   meter_cfg.bEnable ? "Enabled" : "Disabled");
+	seq_printf(s, "    meter nCbs=%u\n", meter_cfg.nCbs);
+	seq_printf(s, "    meter nEbs=%u\n", meter_cfg.nEbs);
+	seq_printf(s, "    meter nRate=%u\n", meter_cfg.nRate);
+	seq_printf(s, "    meter nPiRate=%u\n", meter_cfg.nPiRate);
+	seq_printf(s, "    meter eMtrType=%u\n", (int)meter_cfg.eMtrType);
+	seq_printf(s, "    D1 nRate=%u\n", meter_nrate[1]);
+	seq_printf(s, "    D2 nRate=%u\n", meter_nrate[2]);
+	seq_printf(s, "    D3 nRate=%u\n", meter_nrate[3]);
+
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x489 + meter_id * 10;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	seq_printf(s, "    PCE_PISR(0x%x)=%u(0x%x)-interrupt %s\n",
+		   reg.nRegAddr, reg.nData, reg.nData,
+		   (reg.nData & 0x100) ? "on" : "off");
+
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0xE11;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	seq_printf(s, "    GSW_PCE_TCM_STAT(0x%x)=%u(0x%x)-backpress %s\n",
+		   reg.nRegAddr, reg.nData, reg.nData,
+		   (reg.nData & 1) ? "on" : "off");
+}
+
+int dp_set_rmon_threshold(struct ltq_cpufreq_threshold *threshold,
+			  uint32_t flags)
+{
+	if (!threshold)
+		return -1;
+
+	memcpy((void *)&rmon_threshold, (void *)threshold,
+	       sizeof(rmon_threshold));
+	return 0;
+}
+EXPORT_SYMBOL(dp_set_rmon_threshold);
+
+ssize_t proc_coc_write(struct file *file, const char *buf, size_t count,
+		       loff_t *ppos)
+{
+	int len, num;
+	char str[64];
+	char *param_list[3];
+#define MIN_POLL_TIME 1
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if (dp_strncmpi(param_list[0], "timer", strlen("timer")) == 0) {
+		polling_period = dp_atoi(param_list[1]);
+
+		if (polling_period < MIN_POLL_TIME)
+			polling_period = MIN_POLL_TIME;
+
+		coc_lock();
+
+		if (rmon_timer_en) {
+			mod_timer(&dp_coc_timer,
+				  jiffies +
+				  msecs_to_jiffies(polling_period * 1000));
+		}
+
+		coc_unlock();
+	} else if (dp_strncmpi(param_list[0], "threshold0", strlen("threshold0")) == 0) {
+		coc_lock();
+		rmon_threshold.th_d0 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d0)
+			rmon_threshold.th_d0 = 1;
+
+		coc_unlock();
+	} else if (dp_strncmpi(param_list[0], "threshold1", strlen("threshold1")) == 0) {
+		coc_lock();
+		rmon_threshold.th_d1 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d1)
+			rmon_threshold.th_d1 = 1;
+
+		coc_unlock();
+	} else if (dp_strncmpi(param_list[0], "threshold2",strlen("threshold2")) == 0) {
+		coc_lock();
+		rmon_threshold.th_d2 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d2)
+			rmon_threshold.th_d2 = 1;
+
+		coc_unlock();
+	} else if (dp_strncmpi(param_list[0], "threshold3", strlen("threshold3")) == 0) {
+		coc_lock();
+		rmon_threshold.th_d3 = dp_atoi(param_list[1]);
+
+		if (!rmon_threshold.th_d3)
+			rmon_threshold.th_d3 = 1;
+
+		coc_unlock();
+	} else if (dp_strncmpi(param_list[0], "D0", 2) == 0) {
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0, DP_COC_REQ_DP);
+	} else if (dp_strncmpi(param_list[0], "D1", 2) == 0) {
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D1, DP_COC_REQ_DP);
+	} else if (dp_strncmpi(param_list[0], "D2", 2) == 0) {
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D2, DP_COC_REQ_DP);
+	} else if (dp_strncmpi(param_list[0], "D3", 2) == 0) {
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D3, DP_COC_REQ_DP);
+	} else if (dp_strncmpi(param_list[0], "rate", strlen("rate")) == 0) {
+		/*meter rate */
+		u32 rate = dp_atoi(param_list[1]);
+
+		if (!rate) {
+			PR_INFO("rate should not be zero\n");
+			return count;
+		}
+		if (dp_strncmpi(param_list[0], "rate1", strlen("rate1")) == 0) {
+			dp_set_meter_rate(LTQ_CPUFREQ_PS_D1, rate);
+
+		} else if (dp_strncmpi(param_list[0], "rate2", strlen("rate2")) == 0) {
+			dp_set_meter_rate(LTQ_CPUFREQ_PS_D2, rate);
+		} else if ((dp_strncmpi(param_list[0], "rate3", strlen("rate3")) == 0) ||
+			   (dp_strncmpi(param_list[0], "rate", strlen("rate")) ==
+			    0) /*back-compatiable */) {
+			dp_set_meter_rate(LTQ_CPUFREQ_PS_D3, rate);
+		} else {
+			PR_INFO
+			    ("Wrong COC state, it should be D1/D2/D3 only\n");
+		}
+	} else if (dp_strncmpi(param_list[0], "interrupt", strlen("interrupt")) == 0) {/*meter */
+		enable_meter_interrupt();
+		PR_INFO("Enabled meter interurpt\n");
+	} else if (dp_strncmpi(param_list[0], "clear", strlen("clear")) == 0) {	/*meter */
+		clear_meter_interrupt();
+		PR_INFO("Clear meter interurpt src\n");
+	} else {
+		goto help;
+	}
+	return count;
+
+ help:
+	PR_INFO("Datapath COC Proc Usage:\n");
+	PR_INFO("  echo timer polling_interval_in_seconds > /proc/dp/coc\n");
+	PR_INFO("  echo <thresholdx> its_threshold_value > /proc/dp/coc\n");
+	PR_INFO("       Note:Valid x of ranage: 1 2 3\n");
+	PR_INFO
+	    ("            For downscale to D<x> if rmon<threshold<x>'s cfg\n");
+	PR_INFO("            threshold1's >= threshold'2 > threshold'3\n");
+	PR_INFO("  echo <ratex> <meter_rate_in_knps> /proc/dp/coc\n");
+	PR_INFO("       Note:Valid x of ranage: 1 2 3\n");
+	PR_INFO
+	  ("            For upscale to D0 from D<x> if rmon>=rate<x>'s cfg\n");
+	PR_INFO("            Rate1's >= Rate2's > D3's threshold\n");
+	PR_INFO
+	  ("  echo interrupt > /proc/dp/coc:enable/disable meter interrupt\n");
+	PR_INFO("  echo clear > /proc/dp/coc  :clear meter interrupt\n");
+	return count;
+}
+
+int clear_meter_interrupt(void)
+{
+	GSW_register_t reg;
+	struct core_ops *gsw_handle;
+
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x489 + meter_id * 10;
+	reg.nData = -1;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterSet,
+		     gsw_handle, &reg);
+	return 0;
+}
+
+int enable_meter_interrupt(void)
+{
+	GSW_register_t reg;
+	struct core_ops *gsw_handle;
+
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	/*#Enable PCE Interrupt
+	 *  switch_cli GSW_REGISTER_SET nRegAddr=0x14 nData=0x2 dev=1
+	 */
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x14;	/*ETHSW_IER */
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	reg.nRegAddr |= 1 << 1; /*Enable PCEIE */
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterSet,
+		     gsw_handle, &reg);
+
+	/*#Enable PCE Port Interrupt
+	 *  switch_cli GSW_REGISTER_SET nRegAddr=0x465 nData=0x1 dev=1
+	 */
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x465;	/*PCE_IER_0 */
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	reg.nRegAddr |= 1 << 0; /*Enable PCE Port 0 */
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterSet,
+		     gsw_handle, &reg);
+
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x488;	/*PCE_PIER */
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	/*Enable Metering Based Backpressure Status Change Interrupt Enable */
+	reg.nRegAddr |= 1 << 8;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterSet,
+		     gsw_handle, &reg);
+
+	return 0;
+}
+
+/* rate      0: disable meter
+ * -1: enable meter
+ * others: really change rate.
+ */
+int apply_meter_rate(u32 rate, enum ltq_cpufreq_state new_state)
+{
+	GSW_QoS_meterCfg_t meter_cfg;
+	struct core_ops *gsw_handle;
+
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	memset(&meter_cfg, 0, sizeof(meter_cfg));
+	meter_cfg.nMeterId = meter_id;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops.QoS_MeterCfgGet,
+		     gsw_handle, &meter_cfg);
+	if (rate == 0) {		/*only need to disable the meter */
+		meter_cfg.bEnable = 0;
+	} else if (rate == -1) {
+		meter_cfg.bEnable = 1;
+		/*set PAE metering */
+		if (new_state == LTQ_CPUFREQ_PS_D1) {
+			meter_cfg.nRate = meter_nrate[1];
+		} else if (new_state == LTQ_CPUFREQ_PS_D2) {
+			meter_cfg.nRate = meter_nrate[2];
+		} else if (new_state == LTQ_CPUFREQ_PS_D3) {
+			meter_cfg.nRate = meter_nrate[3];
+		} else {
+			DP_DEBUG(DP_DBG_FLAG_COC,
+				 "Why still try to enable meter with status %s\n",
+				 get_coc_stat_string(dp_coc_ps_curr));
+
+			return -1;
+		}
+	} else {
+		return -1;
+	}
+
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops.QoS_MeterCfgSet,
+		     gsw_handle, &meter_cfg);
+
+	return 0;
+}
+
+int meter_set_default(void)
+{
+	int i;
+	GSW_QoS_WRED_PortCfg_t wred_p;
+	GSW_QoS_WRED_QueueCfg_t wred_q;
+	GSW_QoS_WRED_Cfg_t wred_cfg;
+	GSW_QoS_meterCfg_t meter_cfg;
+	GSW_QoS_meterPort_t meter_port;
+	GSW_register_t reg;
+	struct core_ops *gsw_handle;
+
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	/*#currently directly change global setting, later should use
+	 * GSW_QOS_WRED_PORT_CFG_SET instead
+	 * switch_cli dev=1 GSW_REGISTER_SET nRegAddr=0x4a nData=0x518
+	 */
+	memset(&wred_p, 0, sizeof(wred_p));
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {/*cp green setting to yellow/red*/
+		wred_p.nPortId = i;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops
+			     .QoS_WredPortCfgGet, gsw_handle,
+			     &wred_p);
+		wred_p.nYellow_Min = wred_p.nGreen_Min;
+		wred_p.nYellow_Max = wred_p.nGreen_Max;
+		wred_p.nRed_Min = wred_p.nGreen_Min;
+		wred_p.nRed_Max = wred_p.nGreen_Max;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops
+			     .QoS_WredPortCfgSet, gsw_handle,
+			     &wred_p);
+	}
+
+	/*#Enable Meter 0, configure the rate
+	 * switch_cli GSW_QOS_METER_CFG_SET bEnable=1
+	 *	nMeterId=0 nCbs=0xA000 nEbs=0x9000 nRate=500 dev=1
+	 */
+	memset(&meter_cfg, 0, sizeof(meter_cfg));
+	/*tmp.meter_cfg.bEnable = 1; */
+	meter_cfg.nMeterId = meter_id;
+	meter_cfg.nCbs = meter_ncbs;
+	meter_cfg.nEbs = meter_nebs;
+	meter_cfg.nRate = meter_nrate[3];
+	meter_cfg.nPiRate = 0xFFFFFF; /* try to set maximum */
+	meter_cfg.eMtrType = GSW_QOS_Meter_trTCM;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops.QoS_MeterCfgSet,
+		     gsw_handle, &meter_cfg);
+
+	/*#Assign Port0 ingress to Meter 0
+	 * switch_cli GSW_QOS_METER_PORT_ASSIGN nMeterId=0 eDir=1
+	 *	nPortIngressId=0 dev=1
+	 */
+	memset(&meter_port, 0, sizeof(meter_port));
+
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		meter_port.nMeterId = meter_id;
+		meter_port.eDir = 1;
+		meter_port.nPortIngressId = i;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops
+			     .QoS_MeterPortAssign, gsw_handle, &meter_port);
+	}
+
+	/*#Enable Port 0 Meter Based Flow control (Bit 2 MFCEN)
+	 *  switch_cli GSW_REGISTER_SET nRegAddr=0xBC0 nData=0x5107 dev=1
+	 */
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0xBC0;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterGet,
+		     gsw_handle, &reg);
+	reg.nData |= 1 << 2;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterSet,
+		     gsw_handle, &reg);
+
+	/*#Configure Red and Yellow watermark for each queue
+	 *  (Yellow and Red shall not be 0 in CoC case in order to avoid
+	 *  packet drop)
+	 *  i=0
+	 *  while [$i -lt 32]
+	 *  do
+	 *  switch_cli GSW_QOS_WRED_QUEUE_CFG_SET nQueueId=$i nRed_Min=0x40
+	 *  nRed_Max=0x40 nYellow_Min=0x40 nYellow_Max=0x40 nGreen_Min=0x40
+	 *  nGreen_Max=0x40 dev=1
+	 *  i=$(($i+1))
+	 *  done
+	 */
+	memset(&wred_q, 0, sizeof(wred_q));
+	for (i = 0; i < 32; i++) {	/*copy green setting to yellow/red */
+		wred_q.nQueueId = i;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops
+			     .QoS_WredQueueCfgGet, gsw_handle,
+			     &tmp);
+		wred_q.nYellow_Min = wred_q.nGreen_Min;
+		wred_q.nYellow_Max = wred_q.nGreen_Max;
+		wred_q.nRed_Min = wred_q.nGreen_Min;
+		wred_q.nRed_Max = wred_q.nGreen_Max;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops
+			     .QoS_WredQueueCfgSet, gsw_handle,
+			     &wred_q);
+	}
+
+	/*Configure Red and Yellow watermark for each queue (Yellow and Red
+	 * shall not be 0 in CoC case in order to avoid packet drop)
+	 * switch_cli GSW_QOS_WRED_CFG_SET nRed_Min=255 nRed_Max=255
+	 * nYellow_Min=255 nYellow_Max=255  nGreen_Min=255 nGreen_Max=255 dev=1
+	 */
+	memset(&wred_cfg, 0, sizeof(wred_cfg));
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops.QoS_WredCfgGet,
+		     gsw_handle, &wred_cfg);
+	wred_cfg.nYellow_Min = wred_cfg.nGreen_Min;
+	wred_cfg.nYellow_Max = wred_cfg.nGreen_Max;
+	wred_cfg.nRed_Min = wred_cfg.nGreen_Min;
+	wred_cfg.nRed_Max = wred_cfg.nGreen_Max;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops.QoS_WredCfgSet,
+		     gsw_handle, &wred_cfg);
+
+	/*#Configure OVERHEAD */
+	memset(&reg, 0, sizeof(reg));
+	reg.nRegAddr = 0x46C;	/*PCE_OVERHD */
+	reg.nData = PCE_OVERHD;
+	gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.RegisterSet,
+		     gsw_handle, &reg);
+
+	return 0;
+}
+
+/* For Datapth's sub-module to request power state change, esp for
+ *  Ethernet/VRX318 driver to call it if there is state change needed.
+ *   The flag can be:
+ *     DP_COC_REQ_DP
+ *     DP_COC_REQ_ETHERNET
+ *     DP_COC_REQ_VRX318
+ */
+int dp_coc_new_stat_req(enum ltq_cpufreq_state new_state, uint32_t flag)
+{
+	int ret;
+
+	DP_DEBUG(DP_DBG_FLAG_COC,
+		 "SubModular [%s] requesting to switch from %s to %s\n",
+		 get_sub_module_str(flag),
+		 get_coc_stat_string(dp_coc_ps_curr),
+		 get_coc_stat_string(new_state));
+
+	if (unlikely(in_irq())) {
+		PR_ERR
+		    ("Not allowed to cal dp_coc_new_stat_req in_irq mode\n");
+		return -1;
+	}
+
+	if (!dp_coc_init_stat) {
+		PR_ERR("COC is not initialized yet in DP\n");
+		return -1;
+	}
+
+	if (!dp_coc_ena) {
+		PR_ERR("COC is not enabled in DP yet\n");
+		return -1;
+	}
+
+	coc_lock();
+
+	if (dp_coc_ps_curr == new_state) {
+		/*Workaround: if no change but this API still is called,
+		 *it means need to update interrupt enable/disable status
+		 */
+		DP_DEBUG(DP_DBG_FLAG_COC, "No change\n");
+		update_coc_cfg(new_state, new_state, flag);
+		coc_unlock();
+		return 0;
+	}
+
+	dp_coc_ps_new = new_state;
+	coc_unlock();
+
+	DP_DEBUG(DP_DBG_FLAG_COC, "ltq_cpufreq_state_req(%d,%d,%d)\n",
+		 DP_MODULE, DP_ID, new_state);
+	ret = ltq_cpufreq_state_req(DP_MODULE, DP_ID, new_state);
+
+	if (ret != LTQ_CPUFREQ_RETURN_SUCCESS) {
+		DP_DEBUG(DP_DBG_FLAG_COC,
+			 "Power stat req to %d(%s) fail via ltq_cpufreq_state_req?\n",
+			 new_state, get_coc_stat_string(new_state));
+		DP_DEBUG(DP_DBG_FLAG_COC, "return value: %d ??\n", ret);
+		return -1;
+	}
+
+	return 0;
+}
+EXPORT_SYMBOL(dp_coc_new_stat_req);
+
+int dp_coc_cpufreq_init(void)
+{
+	struct ltq_cpufreq *dp_coc_cpufreq_p;
+	struct ltq_cpufreq_threshold *th_data;
+
+	pr_debug("enter dp_coc_cpufreq_init\n");
+	spin_lock_init(&dp_coc_lock);
+	dp_coc_init_stat = 0;
+	dp_coc_ena = 0;
+	dp_coc_cpufreq_p = ltq_cpufreq_get();
+
+	if (!dp_coc_cpufreq_p) {
+		PR_ERR("dp_coc_cpufreq_init failed:ltq_cpufreq_get failed?\n");
+		return -1;
+	}
+
+	if (cpufreq_register_notifier
+	    (&dp_coc_cpufreq_notifier_block, CPUFREQ_TRANSITION_NOTIFIER)) {
+		PR_ERR("cpufreq_register_notifier failed?\n");
+		return -1;
+	}
+
+	ltq_cpufreq_mod_list(&dp_coc_feature_fss.list, LTQ_CPUFREQ_LIST_ADD);
+
+	th_data = ltq_cpufreq_get_threshold(DP_MODULE, DP_ID);
+	if (th_data) {		/*copy threshold to local */
+		rmon_threshold.th_d0 = th_data->th_d0;
+		rmon_threshold.th_d1 = th_data->th_d1;
+		rmon_threshold.th_d2 = th_data->th_d2;
+		rmon_threshold.th_d3 = th_data->th_d3;
+	}
+	/*santity check */
+	if (rmon_threshold.th_d2 < rmon_threshold.th_d3)
+		rmon_threshold.th_d2 = rmon_threshold.th_d3 + 100;
+	if (rmon_threshold.th_d1 < rmon_threshold.th_d2)
+		rmon_threshold.th_d1 = rmon_threshold.th_d2 + 100;
+
+	polling_period = ltq_cpufreq_get_poll_period(DP_MODULE, DP_ID);
+
+	if (!polling_period)
+		polling_period = 2;
+
+	meter_set_default();
+	/*Set to D0 Stage from the beginning */
+	dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0, 0);
+	init_timer_on_stack(&dp_coc_timer);
+	dp_coc_timer.data = 0;
+	dp_coc_timer.function = dp_rmon_polling;
+	dp_coc_init_stat = 1;
+	dp_coc_ena = 1;
+	pr_debug("Register DP to CPUFREQ successfully.\n");
+	return 0;
+}
+
+int dp_coc_cpufreq_exit(void)
+{
+	if (dp_coc_init_stat) {
+		int ret;
+
+		coc_lock();
+		ret = del_timer(&dp_coc_timer);
+
+		if (ret)
+			PR_ERR("The timer is still in use...\n");
+
+		dp_coc_new_stat_req(LTQ_CPUFREQ_PS_D0D3, 0);/*dont care mode */
+
+		if (cpufreq_unregister_notifier
+		    (&dp_coc_cpufreq_notifier_block,
+		     CPUFREQ_TRANSITION_NOTIFIER))
+			PR_ERR("CPUFREQ unregistration failed.");
+
+		ltq_cpufreq_mod_list(&dp_coc_feature_fss.list,
+				     LTQ_CPUFREQ_LIST_DEL);
+		dp_coc_init_stat = 0;
+		dp_coc_ena = 0;
+		coc_unlock();
+	}
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c
new file mode 100644
index 000000000000..62fe4b585147
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c
@@ -0,0 +1,405 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/etherdevice.h>
+#include <net/lantiq_cbm_api.h>
+#include <net/datapath_api.h>
+#include "../datapath.h"
+#include "datapath_misc.h"
+
+/*This API is only for GSWIP-R PMAC modification, not for GSWIP-L */
+int dp_pmac_set_30(int inst, u32 port, dp_pmac_cfg_t *pmac_cfg)
+{
+	GSW_PMAC_Eg_Cfg_t egcfg;
+	GSW_PMAC_Ig_Cfg_t igcfg;
+	int i, j, k;
+	u32 flag = 0;
+	cbm_dq_port_res_t dqport;
+	s32 ret;
+	struct core_ops *gswr_r;
+	GSW_PMAC_Glbl_Cfg_t pmac_glb;
+
+	if (!pmac_cfg || !port) {
+		PR_ERR("dp_pmac_set:wrong parameter(pmac_cfg/port NULL)\n");
+		return -1;
+	}
+
+	if (!pmac_cfg->ig_pmac_flags && !pmac_cfg->eg_pmac_flags)
+		return 0;
+
+	memset(&dqport, 0, sizeof(cbm_dq_port_res_t));
+
+	/* Get GSWIP device handler */
+	if ((port >= 1) && (port <= 6))
+		gswr_r = dp_port_prop[inst].ops[0];
+	else
+		gswr_r = dp_port_prop[inst].ops[1];
+	if (!gswr_r) {
+		PR_ERR("why gswr_r NULL\n");
+		return -1;
+	}
+
+	/*set ingress port via DMA tx channel */
+	if (pmac_cfg->ig_pmac_flags) {
+		/*Read back igcfg from gsw first */
+		ret = cbm_dequeue_port_resources_get(port, &dqport, flag);
+
+		if (ret == -1) {
+			PR_ERR("cbm_dequeue_port_resources_get failed\n");
+			return -1;
+		}
+
+		memset(&igcfg, 0, sizeof(GSW_PMAC_Ig_Cfg_t));
+
+		for (i = 0; i < dqport.num_deq_ports; i++) {
+			igcfg.nTxDmaChanId = dqport.deq_info[i].dma_tx_chan;
+			if (igcfg.nTxDmaChanId == (u8)-1) {
+				igcfg.nTxDmaChanId =
+					pmac_cfg->ig_pmac.tx_dma_chan;
+			}
+			gsw_core_api((dp_gsw_cb)gswr_r->gsw_pmac_ops
+				     .Pmac_Ig_CfgGet, gswr_r, &igcfg);
+
+			/*update igcfg and write back to gsw */
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_ERR_DISC)
+				igcfg.bErrPktsDisc =
+				    pmac_cfg->ig_pmac.err_disc;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PRESENT)
+				igcfg.bPmacPresent = pmac_cfg->ig_pmac.pmac;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_SUBIF)
+				//igcfg.bSubIdDefault =
+				igcfg.eSubId =
+				    pmac_cfg->ig_pmac.def_pmac_subifid;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_SPID)
+				igcfg.bSpIdDefault =
+				    pmac_cfg->ig_pmac.def_pmac_src_port;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_CLASSENA)
+				igcfg.bClassEna =
+				    pmac_cfg->ig_pmac.def_pmac_en_tc;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_CLASS)
+				igcfg.bClassDefault =
+				    pmac_cfg->ig_pmac.def_pmac_tc;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMAPENA)
+				igcfg.bPmapEna =
+				    pmac_cfg->ig_pmac.def_pmac_en_pmap;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMAP)
+				igcfg.bPmapDefault =
+				    pmac_cfg->ig_pmac.def_pmac_pmap;
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR1)
+				igcfg.defPmacHdr[0] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[0];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR2)
+				igcfg.defPmacHdr[1] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[1];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR3)
+				igcfg.defPmacHdr[2] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[2];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR4)
+				igcfg.defPmacHdr[3] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[3];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR5)
+				igcfg.defPmacHdr[4] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[4];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR6)
+				igcfg.defPmacHdr[5] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[5];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR7)
+				igcfg.defPmacHdr[6] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[6];
+
+			if (pmac_cfg->ig_pmac_flags & IG_PMAC_F_PMACHDR8)
+				igcfg.defPmacHdr[7] =
+				    pmac_cfg->ig_pmac.def_pmac_hdr[7];
+
+			DP_DEBUG(DP_DBG_FLAG_DBG,
+				 "\nPMAC %d igcfg configuration:\n", port);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.nTxDmaChanId=%d\n",
+				 igcfg.nTxDmaChanId);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bErrPktsDisc=%d\n",
+				 igcfg.bErrPktsDisc);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bPmapDefault=%d\n",
+				 igcfg.bPmapDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bPmapEna=%d\n",
+				 igcfg.bPmapEna);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bClassDefault=%d\n",
+				 igcfg.bClassDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bClassEna=%d\n",
+				 igcfg.bClassEna);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bSubIdDefault=%d\n",
+				 //igcfg.bSubIdDefault);
+				 igcfg.eSubId);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bSpIdDefault=%d\n",
+				 igcfg.bSpIdDefault);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.bPmacPresent=%d\n",
+				 igcfg.bPmacPresent);
+			DP_DEBUG(DP_DBG_FLAG_DBG, "igcfg.defPmacHdr=");
+
+			for (k = 0;
+			     k <
+			     sizeof(igcfg.defPmacHdr) /
+			     sizeof(igcfg.defPmacHdr[0]); k++)
+				DP_DEBUG(DP_DBG_FLAG_DBG, "0x%x ",
+					 igcfg.defPmacHdr[k]);
+
+			DP_DEBUG(DP_DBG_FLAG_DBG, "\n");
+
+			gsw_core_api((dp_gsw_cb)gswr_r->gsw_pmac_ops
+				     .Pmac_Ig_CfgSet, gswr_r, &igcfg);
+		}
+
+		kfree(dqport.deq_info);
+	}
+
+	/*set egress port via pmac port id */
+	if (!pmac_cfg->eg_pmac_flags)
+		return 0;
+
+	for (i = 0; i <= 15; i++) {	/*traffic class */
+		for (j = 0; j <= 3; j++) {	/* flow */
+			/*read back egcfg first from gsw */
+			memset(&egcfg, 0, sizeof(GSW_PMAC_Eg_Cfg_t));
+			egcfg.nDestPortId = port;
+			egcfg.nTrafficClass = i;
+			egcfg.nFlowIDMsb = j;
+
+			memset(&pmac_glb, 0, sizeof(pmac_glb));
+			gsw_core_api((dp_gsw_cb)gswr_r->gsw_pmac_ops
+				     .Pmac_Gbl_CfgGet, gswr_r, &pmac_glb);
+			egcfg.bProcFlagsSelect = pmac_glb.bProcFlagsEgCfgEna;
+			DP_DEBUG(DP_DBG_FLAG_DBG, "bProcFlagsSelect=%u\n",
+				 egcfg.bProcFlagsSelect);
+
+			/*update egcfg and write back to gsw */
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_FCS)
+				egcfg.bFcsEna = pmac_cfg->eg_pmac.fcs;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_L2HDR_RM) {
+				egcfg.bRemL2Hdr = pmac_cfg->eg_pmac.rm_l2hdr;
+				egcfg.numBytesRem =
+				    pmac_cfg->eg_pmac.num_l2hdr_bytes_rm;
+			}
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_PMAC)
+				egcfg.bPmacEna = pmac_cfg->eg_pmac.pmac;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RXID)
+				egcfg.nRxDmaChanId =
+				    pmac_cfg->eg_pmac.rx_dma_chan;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RESDW1)
+				egcfg.nResDW1 = pmac_cfg->eg_pmac.res_dw1;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RES1DW0)
+				egcfg.nRes1DW0 = pmac_cfg->eg_pmac.res1_dw0;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_RES2DW0)
+				egcfg.nRes2DW0 = pmac_cfg->eg_pmac.res2_dw0;
+
+			/*if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_TCENA)
+			 *  egcfg.bTCEnable = pmac_cfg->eg_pmac.tc_enable;
+			 */
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_DECFLG)
+				egcfg.bDecFlag = pmac_cfg->eg_pmac.dec_flag;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_ENCFLG)
+				egcfg.bEncFlag = pmac_cfg->eg_pmac.enc_flag;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_MPE1FLG)
+				egcfg.bMpe1Flag = pmac_cfg->eg_pmac.mpe1_flag;
+
+			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_MPE2FLG)
+				egcfg.bMpe2Flag = pmac_cfg->eg_pmac.mpe2_flag;
+#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+			if (dp_dbg_flag) {
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "\nPMAC %d egcfg configuration:\n",
+					 port);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nRxDmaChanId=%d\n",
+					 egcfg.nRxDmaChanId);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bRemL2Hdr=%d\n",
+					 egcfg.bRemL2Hdr);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.numBytesRem=%d\n",
+					 egcfg.numBytesRem);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bFcsEna=%d\n", egcfg.bFcsEna);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bPmacEna=%d\n",
+					 egcfg.bPmacEna);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nResDW1=%d\n", egcfg.nResDW1);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nRes1DW0=%d\n",
+					 egcfg.nRes1DW0);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nRes2DW0=%d\n",
+					 egcfg.nRes2DW0);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nDestPortId=%d\n",
+					 egcfg.nDestPortId);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bTCEnable=%d\n",
+					 egcfg.bTCEnable);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nTrafficClass=%d\n",
+					 egcfg.nTrafficClass);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.nFlowIDMsb=%d\n",
+					 egcfg.nFlowIDMsb);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bDecFlag=%d\n",
+					 egcfg.bDecFlag);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bEncFlag=%d\n",
+					 egcfg.bEncFlag);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bMpe1Flag=%d\n",
+					 egcfg.bMpe1Flag);
+				DP_DEBUG(DP_DBG_FLAG_DBG,
+					 "egcfg.bMpe2Flag=%d\n",
+					 egcfg.bMpe2Flag);
+			}
+#endif
+			gsw_core_api((dp_gsw_cb)gswr_r->gsw_pmac_ops
+				     .Pmac_Eg_CfgSet, gswr_r, &egcfg);
+
+			;
+		}
+	}
+
+	return 0;
+}
+
+/*flag: bit 0 for cpu
+ *      bit 1 for mpe1,bit 2 for mpe2, bit 3 for mpe3;
+ */
+#define GSW_L_BASE_ADDR        (0xBC000000)
+#define GSW_R_BASE_ADDR        (0xBA000000)
+#define FDMA_PASR_ADDR         (0xA47)
+
+int dp_set_gsw_parser_30(u8 flag, u8 cpu, u8 mpe1,
+			 u8 mpe2, u8 mpe3)
+{
+	GSW_CPU_PortCfg_t param = {0};
+	struct core_ops *gsw_handle = dp_port_prop[0].ops[1]; /*pae*/
+
+	if (gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops
+			 .CPU_PortCfgGet, gsw_handle, &param)) {
+		PR_ERR("Failed GSW_CPU_PORT_CFG_GET\n");
+		return -1;
+	}
+	DP_DEBUG(DP_DBG_FLAG_DBG, "old flag=0x%x cpu=%d mpe1/2/3=%d/%d/%d\n",
+		 flag, param.eNoMPEParserCfg,
+		 param.eMPE1ParserCfg, param.eMPE2ParserCfg,
+		 param.eMPE1MPE2ParserCfg);
+	DP_DEBUG(DP_DBG_FLAG_DBG, "new flag=0x%x cpu=%d mpe1/2/3=%d/%d/%d\n",
+		 flag, cpu, mpe1, mpe2, mpe3);
+	if (flag & F_MPE_NONE)
+		param.eNoMPEParserCfg = cpu;
+
+	if (flag & F_MPE1_ONLY)
+		param.eMPE1ParserCfg = mpe1;
+
+	if (flag & F_MPE2_ONLY)
+		param.eMPE2ParserCfg = mpe2;
+
+	if (flag & F_MPE1_MPE2)
+		param.eMPE1MPE2ParserCfg = mpe3;
+
+	if (gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops
+			 .CPU_PortCfgSet, gsw_handle, &param)) {
+		PR_ERR("Failed GSW_CPU_PORT_CFG_SET\n");
+		return -1;
+	}
+	dp_parser_info_refresh(param.eNoMPEParserCfg,
+			       param.eMPE1ParserCfg,
+			       param.eMPE2ParserCfg,
+			       param.eMPE1MPE2ParserCfg, 0);
+	return 0;
+}
+
+int dp_get_gsw_parser_30(u8 *cpu, u8 *mpe1, u8 *mpe2,
+			 u8 *mpe3)
+{
+	GSW_CPU_PortCfg_t param = {0};
+	struct core_ops *gsw_handle = dp_port_prop[0].ops[1]; /*pae*/
+
+	if (gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops
+			 .CPU_PortCfgGet, gsw_handle, &param)) {
+		PR_ERR("Failed GSW_CPU_PORT_CFG_GET\n");
+		return -1;
+	}
+	dp_parser_info_refresh(param.eNoMPEParserCfg,
+			       param.eMPE1ParserCfg,
+			       param.eMPE2ParserCfg,
+			       param.eMPE1MPE2ParserCfg, 1);
+
+	if (cpu) {
+		*cpu = param.eNoMPEParserCfg;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  cpu=%d\n", *cpu);
+	}
+
+	if (mpe1) {
+		*mpe1 = param.eMPE1ParserCfg;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  mpe1=%d\n", *mpe1);
+	}
+
+	if (mpe2) {
+		*mpe2 = param.eMPE2ParserCfg;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  mpe2=%d\n", *mpe2);
+	}
+
+	if (mpe3) {
+		*mpe3 = param.eMPE1MPE2ParserCfg;
+		DP_DEBUG(DP_DBG_FLAG_DBG, "  mpe3=%d\n", *mpe3);
+	}
+	return 0;
+}
+
+int gsw_mib_reset_30(int dev, u32 flag)
+{
+	struct core_ops *gsw_handle;
+	GSW_return_t ret;
+	GSW_RMON_clear_t rmon_clear;
+
+	if (dev == 0)
+		gsw_handle = dp_port_prop[0].ops[0];
+
+	else
+		gsw_handle = dp_port_prop[0].ops[1];
+	rmon_clear.eRmonType = GSW_RMON_ALL_TYPE;
+	ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_rmon_ops.RMON_Clear,
+			   gsw_handle, &rmon_clear);
+
+	if (ret != GSW_statusOk) {
+		PR_ERR("R:GSW_RMON_CLEAR failed for GSW_RMON_ALL_TYPE\n");
+		return -1;
+	}
+	return ret;
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c
new file mode 100644
index 000000000000..96d1363673d9
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c
@@ -0,0 +1,630 @@
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/version.h>
+#include <linux/if_ether.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/if_ether.h>
+#include <linux/if_vlan.h>
+
+#include <linux/clk.h>
+#include <linux/ip.h>
+#include "net/drv_tmu_ll.h"
+
+#include <lantiq.h>
+#include <lantiq_soc.h>
+#include <net/lantiq_cbm_api.h>
+#define DATAPATH_HAL_LAYER   /*must put before include datapath_api.h in
+			      *order to avoid include another platform's
+			      *DMA descriptor and pmac header files
+			      */
+#include <net/lantiq_cbm_api.h>
+#include <net/datapath_api.h>
+#include <net/datapath_api_gswip31.h>
+#include "../datapath.h"
+#include "datapath_proc.h"
+#include "datapath_misc.h"
+#include <net/datapath_proc_api.h>
+
+#define SEQ_PRINTF seq_printf
+
+#define proc_printf(s, fmt, arg...) \
+	do { \
+		if (!s) \
+			PR_INFO(fmt, ##arg); \
+		else \
+			seq_printf(s, fmt, ##arg); \
+	} while (0)
+
+#define CARE_FLAG      0
+#define CARE_NOT_FLAG  1
+#if 1
+#define LIST_ALL_CASES(t, mask, not_care)  \
+	for (t[0] = 0;  t[0] < ((mask[0] == not_care) ? 2 : 1); t[0]++) \
+	for (t[1] = 0;  t[1] < ((mask[1] == not_care) ? 2 : 1); t[1]++) \
+	for (t[2] = 0;  t[2] < ((mask[2] == not_care) ? 2 : 1); t[2]++) \
+	for (t[3] = 0;  t[3] < ((mask[3] == not_care) ? 2 : 1); t[3]++) \
+	for (t[4] = 0;  t[4] < 1; t[4]++) \
+	for (t[5] = 0;  t[5] < 1; t[5]++) \
+	for (t[6] = 0;  t[6] < 1; t[6]++) \
+	for (t[7] = 0;  t[7] < 1; t[7]++) \
+	for (t[8] = 0;  t[8] < ((mask[8] == not_care) ? 2 : 1); t[8]++) \
+	for (t[9] = 0;  t[9] < ((mask[9] == not_care) ? 2 : 1); t[9]++) \
+	for (t[10] = 0; t[10] < ((mask[10] == not_care) ? 2 : 1); t[10]++) \
+	for (t[11] = 0; t[11] < ((mask[11] == not_care) ? 2 : 1); t[11]++) \
+	for (t[12] = 0; t[12] < ((mask[12] == not_care) ? 2 : 1); t[12]++) \
+	for (t[13] = 0; t[13] < ((mask[13] == not_care) ? 2 : 1); t[13]++)
+#else
+#define LIST_ALL_CASES(t, mask, not_care)  \
+	for (t[13] = 0; t[13] < ((mask[13] == not_care) ? 2 : 1); t[13]++) \
+	for (t[12] = 0; t[12] < ((mask[12] == not_care) ? 2 : 1); t[12]++) \
+	for (t[11] = 0; t[11] < ((mask[11] == not_care) ? 2 : 1); t[11]++) \
+	for (t[10] = 0; t[10] < ((mask[10] == not_care) ? 2 : 1); t[10]++) \
+	for (t[9] = 0;  t[9] < ((mask[9] == not_care) ? 2 : 1); t[9]++) \
+	for (t[8] = 0;  t[8] < ((mask[8] == not_care) ? 2 : 1); t[8]++) \
+	for (t[7] = 0;  t[7] < 1; t[7]++) \
+	for (t[6] = 0;  t[6] < 1; t[6]++) \
+	for (t[5] = 0;  t[5] < 1; t[5]++) \
+	for (t[4] = 0;  t[4] < 1; t[4]++) \
+	for (t[3] = 0;  t[3] < ((mask[3] == not_care) ? 2 : 1); t[3]++) \
+	for (t[2] = 0;  t[2] < ((mask[2] == not_care) ? 2 : 1); t[2]++) \
+	for (t[1] = 0;  t[1] < ((mask[1] == not_care) ? 2 : 1); t[1]++) \
+	for (t[0] = 0;  t[0] < ((mask[0] == not_care) ? 2 : 1); t[0]++)
+#endif
+
+/* The purpose of this file is to find the CBM lookup pattern and
+ * print it in the simple way.
+ * Otherway it may print up to 16K lines in the console to get lookup setting
+ *  Lookup table: flow[1] flow[0] dec end mpe2 mpe1 ep(4) class(4)
+ * Idea: We fixed the EP value during finding lookup setting pattern.
+ * method:
+ *     1st: to find the possible don't care bit from flow[2]/dec/enc/mpe2/mpe1
+ *	 and class(4), excluding ep, ie total 10 bits
+ *	       API: c_not_care_walkthrought
+ *		   Note: from big don't care bit number (ie, maximum don't
+ *		   care case) to 1 (minimal don't care case)
+ *
+ *	  2nd: generate tmp_index based on care bits
+ *	       API: list_care_combination
+ *
+ *    3rd: based on tmp_index, check whether there is really pattern which meet
+ *    don't care, ie, mapping to same qid.
+ *
+ */
+
+#define LOOKUP_FIELD_BITS 14
+static int lookup_mask_n;
+#define PATTERN_MATCH_INIT  0
+#define PATTERN_MATCH_START 1
+#define PATTERN_MATCH_FAIL  2
+#define PATTERN_MATCH_PASS  3
+
+#define ENTRY_FILLED 0
+#define ENTRY_USED   1
+
+static int pattern_match_flag;	/*1--start matching  2--failed, 3---match 0k */
+static unsigned char lookup_mask1[LOOKUP_FIELD_BITS];
+
+#define C_ARRAY_SIZE  20
+static int c_tmp_data[C_ARRAY_SIZE];
+
+/*store result */
+#define MAX_PATTERN_NUM 1024
+static int lookup_match_num;
+static unsigned short lookup_match_mask[MAX_PATTERN_NUM];
+/*save tmp_index */
+static unsigned short lookup_match_index[MAX_PATTERN_NUM];
+/*save tmp_index */
+static unsigned char lookup_match_qid[MAX_PATTERN_NUM];
+
+static int tmp_pattern_port_id;
+
+static int left_n;
+/*10 bits lookup table except 4 bits EP */
+static unsigned char lookup_tbl_flags[MAX_PATTERN_NUM * 16];
+
+static void combine_util(int *arr, int *data, int start, int end, int index,
+			 int r);
+static int check_pattern(int *data, int r);
+static void lookup_table_via_qid(int qid);
+static void lookup_table_remap(int old_q, int new_q);
+static int find_pattern(int port_id, struct seq_file *s, int qid);
+static int get_dont_care_lookup(char *s);
+static void lookup_table_recursive(int k, int tmp_index, int set_flag, int qid);
+
+/* The main function that prints all combinations of size r*/
+/* in arr[] of size n. This function mainly uses combine_util()*/
+static void c_not_care_walkthrought(int *arr, int n, int r)
+{
+	/* A temporary array data[] to store all combination one by one */
+
+	/* Print all combination using temprary array 'data[]' */
+	combine_util(arr, c_tmp_data, 0, n - 1, 0, r);
+}
+
+/* arr[]  ---> Input Array
+ * data[] ---> Temporary array to store current combination
+ * start & end ---> Staring and Ending indexes in arr[]
+ * index  ---> Current index in data[]
+ * r ---> Size of a combination to be printed
+ *
+ */
+static void combine_util(int *arr, int *data, int start, int end, int index,
+			 int r)
+{
+	int i;
+
+	/* Current combination is ready to be printed, print it */
+	if (left_n <= 0)
+		return;
+	if (index == r) {/*Find one pattern with specified don't care flag */
+
+		check_pattern(data, r);	/*find a don't care case and
+					 *need further check
+					 */
+		return;
+	}
+	/* replace index with all possible elements. The condition */
+	/* "end-i+1 >= r-index" makes sure that including one element */
+	/* at index will make a combination with remaining elements */
+	/* at remaining positions */
+	for (i = start; i <= end && end - i + 1 >= r - index; i++) {
+		data[index] = arr[i];
+		if (left_n <= 0)
+			break;
+		combine_util(arr, data, i + 1, end, index + 1, r);
+	}
+}
+
+/*Note: when call this API, for those cared bits,
+ * its value already set in tmp_index.
+ */
+static void lookup_pattern_match(int tmp_index)
+{
+	int i;
+	int qid;
+	static int first_qid;
+	int t[LOOKUP_FIELD_BITS] = { 0 };
+	int index;
+
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP,
+		 "trying with tmp_index=0x%x with lookup_match_num=%d\n",
+		 tmp_index, lookup_match_num);
+	pattern_match_flag = PATTERN_MATCH_INIT;
+	lookup_match_index[lookup_match_num] = tmp_index;
+
+	LIST_ALL_CASES(t, lookup_mask1, CARE_NOT_FLAG) {
+		index = tmp_index;
+		for (i = 0; i < LOOKUP_FIELD_BITS; i++)
+			index |= (t[i] << i);
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "don't care[14]=");
+		for (i = 0; i < LOOKUP_FIELD_BITS; i++)
+			DP_DEBUG(DP_DBG_FLAG_LOOKUP, "%d ", t[i]);
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "\n");
+
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "don't care index=%x\n", index);
+
+		if (lookup_tbl_flags[index] == ENTRY_USED) {
+			pattern_match_flag = PATTERN_MATCH_FAIL;
+			goto END;
+		}
+
+		qid = get_lookup_qid_via_index(index);
+
+		if (pattern_match_flag == PATTERN_MATCH_INIT) {
+			pattern_match_flag = PATTERN_MATCH_START;
+			first_qid = qid;
+		} else if (first_qid != qid) {
+			pattern_match_flag = PATTERN_MATCH_FAIL;
+			DP_DEBUG(DP_DBG_FLAG_LOOKUP,
+				 "first_qid(%d) != qid(%d)\n",
+				 first_qid, qid);
+			goto END;
+		}
+	}
+
+ END:
+	/*save the result if necessary here */
+	if (pattern_match_flag == PATTERN_MATCH_START) {
+		/*pass since still not fail yet */
+		pattern_match_flag = PATTERN_MATCH_PASS;
+
+		/*mark the entries */
+		LIST_ALL_CASES(t, lookup_mask1, CARE_NOT_FLAG) {
+			index = tmp_index;
+			for (i = 0; i < LOOKUP_FIELD_BITS; i++)
+				index |= (t[i] << i);
+			if (lookup_tbl_flags[index] == ENTRY_USED)
+				PR_ERR("why already used\n");
+			else
+				lookup_tbl_flags[index] = ENTRY_USED;
+		}
+		/*save status */
+		lookup_match_qid[lookup_match_num] = first_qid;
+		lookup_match_mask[lookup_match_num] = 0;
+		for (i = 0; i < LOOKUP_FIELD_BITS; i++)
+			if (lookup_mask1[i])
+				lookup_match_mask[lookup_match_num] |= 1 << i;
+		lookup_match_num++;
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP,
+			 "left_n=%d lookup_mask_n=%d. Need reduce=%d\n",
+			 left_n, lookup_mask_n, (1 << lookup_mask_n));
+		left_n -= (1 << lookup_mask_n);
+	} else {
+		/*failed */
+	}
+}
+
+/*k--number of don't care flags
+ */
+static int list_care_combination(int tmp_index)
+{
+	int i, k, index;
+	int t[14] = { 0 };
+
+	LIST_ALL_CASES(t, lookup_mask1, CARE_FLAG) {
+		index = tmp_index;
+		for (i = 0; i < LOOKUP_FIELD_BITS; i++)
+			index |= (t[i] << i);
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "care index=%x\n", index);
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "care t[14]=");
+		for (k = 0; k < LOOKUP_FIELD_BITS; k++)
+			DP_DEBUG(DP_DBG_FLAG_LOOKUP, "%d ", t[k]);
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "\n");
+		lookup_pattern_match(index);
+	}
+
+	return 0;
+}
+
+/*based on the don't care list, we try to find the all possible pattern:
+ * for example: bit 13 and bit 11 don't care.
+ * data---the flag index list which is don't care
+ * r -- the flag index length
+ */
+static int check_pattern(int *data, int r)
+{
+	int i;
+
+	memset(lookup_mask1, 0, sizeof(lookup_mask1));
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP, "data:");
+	for (i = 0; i < r; i++) {
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "%d ", data[i]);
+		lookup_mask1[data[i]] = CARE_NOT_FLAG;
+	}
+	lookup_mask_n = r;
+	pattern_match_flag = 0;
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP, "\n");
+
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP, "Don't care flag: ");
+	for (i = 0; i < LOOKUP_FIELD_BITS; i++)
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP,
+			 "%c ", lookup_mask1[i] ? 'x' : '0');
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP, "\n");
+
+	list_care_combination(tmp_pattern_port_id << 4);
+	return 0;
+}
+
+/*qid: -1: match all queues
+ * >=0: only match the specified queue
+ */
+int find_pattern(int port_id, struct seq_file *s, int qid)
+{
+	int r, i, j, n;
+	int f = 0;
+	char *flag_s;
+	char flag_buf[40];
+	struct tmu_equeue_link equeue_link;
+	int arr[] = { 13, 12, 11, 10, 9, 8, /*7,6,5,4, */ 3, 2, 1, 0 };
+					/*remove port id */
+
+	left_n = 1 << (LOOKUP_FIELD_BITS - 4);	/*maximum lookup entried */
+	lookup_match_num = 0;
+	tmp_pattern_port_id = port_id;
+	memset(lookup_tbl_flags, 0, sizeof(lookup_tbl_flags));
+	n = ARRAY_SIZE(arr);
+	/*list all pattern, ie, don't care numbers from 10 to 1 */
+	for (r = n; r >= 0; r--) {
+		if (left_n <= 0)
+			break;
+		c_not_care_walkthrought(arr, n, r);
+		DP_DEBUG(DP_DBG_FLAG_LOOKUP, "left_n=%d\n", left_n);
+		if (!left_n)
+			break;
+	}
+
+	for (i = 0; i < lookup_match_num; i++) {
+		if ((qid >= 0) && (qid != lookup_match_qid[i]))
+			continue;
+		if (!f) {
+			f = 1;
+			proc_printf(s,
+				    "EP%-2d:%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s%5s\n",
+				    tmp_pattern_port_id, "F2", "F1",
+				    "DEC", "ENC", "MPE2", "MPE1", "EP3",
+				    "EP2", "EP1", "EP0", "C3", "C2", "C1",
+				    "C0", "qid", "id");
+		}
+		tmu_equeue_link_get(lookup_match_qid[i], &equeue_link);
+		flag_s =
+		    get_dma_flags_str(equeue_link.epn, flag_buf,
+				      sizeof(flag_buf));
+
+		proc_printf(s, "    ");
+		for (j = LOOKUP_FIELD_BITS - 1; j >= 0; j--) {
+			if ((lookup_match_mask[i] >> j) & 1)
+				proc_printf(s, "%5c", 'x');
+			else
+				proc_printf(s, "%5d",
+					    (lookup_match_index[i] >> j) & 1);
+		}
+		proc_printf(s, "->%-3d(0x%04x)%s\n", lookup_match_qid[i],
+			    lookup_match_index[i], flag_s);
+	}
+	if (s && seq_has_overflowed(s))
+		return -1;
+
+	return 0;
+}
+
+int lookup_start30(void)
+{
+	return 0;
+}
+
+int lookup_dump30(struct seq_file *s, int pos)
+{
+	if (find_pattern(pos, s, -1) < 0)
+		return pos;
+	pos++;
+	if (pos >= 16)
+		pos = -1;
+	return pos;
+}
+
+ssize_t proc_get_qid_via_index30(struct file *file, const char *buf,
+				 size_t count, loff_t *ppos)
+{
+	int err = 0, len = 0;
+	char data[100];
+	unsigned int lookup_index;
+	unsigned int qid = 0;
+	char *param_list[10];
+	int num;
+
+	len = (count >= sizeof(data)) ? (sizeof(data) - 1) : count;
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP, "len=%d\n", len);
+
+	if (len <= 0) {
+		err = -EFAULT;
+		PR_ERR("Wrong len value (%d)\n", len);
+		return count;
+	}
+
+	if (copy_from_user(data, buf, len)) {
+		err = -EFAULT;
+		PR_ERR("copy_from_user fail");
+		return count;
+	}
+
+	data[len - 1] = 0;	/* Make string */
+	num = dp_split_buffer(data, param_list, ARRAY_SIZE(param_list));
+
+	if (num <= 1)
+		goto help;
+	if (!param_list[1])
+		goto help;
+
+	lookup_index = dp_atoi(param_list[1]);
+
+	if ((dp_strncmpi(param_list[0], "set", strlen("set")) == 0) ||
+	    (dp_strncmpi(param_list[0], "write", strlen("write")) == 0)) {
+		if (!param_list[2]) {
+			PR_ERR("wrong command\n");
+			return count;
+		}
+		qid = dp_atoi(param_list[2]);
+
+		/*workaround for mask support */
+		if (get_dont_care_lookup(param_list[1]) == 0) {
+			lookup_table_recursive(LOOKUP_FIELD_BITS - 1, 0, 1,
+					       qid);
+			return count;
+		}
+		set_lookup_qid_via_index(lookup_index, qid);
+		PR_INFO("Set lookup[%u 0x%x] ->     queue[%u]\n",
+			lookup_index, lookup_index, qid);
+	} else if ((dp_strncmpi(param_list[0], "get", strlen("get")) == 0) ||
+		   (dp_strncmpi(param_list[0], "read", strlen("read")) == 0)) {
+		if (get_dont_care_lookup(param_list[1]) == 0) {
+			lookup_table_recursive(LOOKUP_FIELD_BITS - 1, 0, 0,
+					       0);
+			return count;
+		}
+		qid = get_lookup_qid_via_index(lookup_index);
+		PR_INFO("Get lookup[%05u 0x%04x] ->     queue[%u]\n",
+			lookup_index, lookup_index, qid);
+	} else if (dp_strncmpi(param_list[0], "find", strlen("find")) == 0) {
+		/*read out its all flags for specified qid */
+		int i;
+
+		qid = dp_atoi(param_list[1]);
+		for (i = 0; i < 16; i++)
+			find_pattern(i, NULL, qid);
+		return count;
+	} else if (dp_strncmpi(param_list[0], "find2", strlen("find2")) == 0) {
+		/*read out its all flags for specified qid */
+		qid = dp_atoi(param_list[1]);
+		lookup_table_via_qid(qid);
+		return count;
+	} else if (dp_strncmpi(param_list[0], "remap", strlen("remap")) == 0) {
+		int old_q = dp_atoi(param_list[1]);
+		int new_q = dp_atoi(param_list[2]);
+
+		lookup_table_remap(old_q, new_q);
+		return count;
+	}
+	goto help;
+help:
+	PR_INFO("Usage: echo set lookup_flags queue_id > /proc/dp/lookup\n");
+	PR_INFO("     : echo get lookup_flags > /proc/dp/lookup\n");
+	PR_INFO("     : echo find  <x> > /proc/dp/lookup\n");
+	PR_INFO("     : echo find2 <x> > /proc/dp/lookup\n");
+	PR_INFO("     : echo remap <old_q> <new_q> > /proc/dp/lookup\n");
+	PR_INFO("  Hex example: echo set 0x10 10 > /proc/dp/lookup\n");
+	PR_INFO("  Dec:example: echo set 16 10 > /proc/dp/lookup\n");
+	PR_INFO("  Bin:example: echo set b10000 10 > /proc/dp/lookup\n");
+
+	PR_INFO("%s: echo set b1xxxx 10 > /proc/dp/lookup\n",
+		"Special for BIN(Don't care bit)");
+	PR_INFO("Lookup format:\n");
+	PR_INFO("  Bits Index: | %s\n",
+		"13   12 |  11  |  10  |  9   |  8   |7   4 | 3   0 |");
+	PR_INFO("  Fields:     | %s\n",
+		"Flow ID | DEC  | ENC  | MPE2 | MPE1 |  EP  | CLASS |");
+
+	return count;
+}
+
+void lookup_table_via_qid(int qid)
+{
+	u32 index, tmp, i, j, k, f = 0;
+
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP,
+		 "Try to find all lookup flags mapped to qid %d\n", qid);
+	for (i = 0; i < 16; i++) {	/*ep */
+		for (j = 0; j < 16; j++) {	/*class */
+			for (k = 0; k < 64; k++) { /*flow id/dec/enc/mpe2/mpe1*/
+				index = (k << 8) | (i << 4) | j;
+				tmp = get_lookup_qid_via_index(index);
+				if (tmp != qid)
+					continue;
+				f = 1;
+				PR_INFO("Get lookup[%05u 0x%04x]%s[%d]\n",
+					index, index,
+					" ->     queue", qid);
+			}
+		}
+	}
+	if (!f)
+		PR_ERR("No mapping to queue id %d yet ?\n", qid);
+}
+
+void lookup_table_remap(int old_q, int new_q)
+{
+	u32 index, tmp, i, j, k, f = 0;
+
+	DP_DEBUG(DP_DBG_FLAG_LOOKUP,
+		 "Try to remap lookup flags mapped from old_q %d to new_q %d\n",
+		 old_q, new_q);
+	for (i = 0; i < 16; i++) {	/*ep */
+		for (j = 0; j < 16; j++) {	/*class */
+			for (k = 0; k < 64; k++) {/*flow id/dec/enc/mpe2/mpe1*/
+				index = (k << 8) | (i << 4) | j;
+				tmp = get_lookup_qid_via_index(index);
+				if (tmp != old_q)
+					continue;
+				set_lookup_qid_via_index(index, new_q);
+				f = 1;
+				PR_INFO("Remap lookup[%05u 0x%04x] %s[%d]\n",
+					index, index,
+					"->     queue", new_q);
+			}
+		}
+	}
+	if (!f)
+		PR_INFO("No mapping to queue id %d yet\n", new_q);
+}
+
+#define LOOKUP_FIELD_BITS 14
+static u8 lookup_flags2[LOOKUP_FIELD_BITS];
+static u8 lookup_mask2[LOOKUP_FIELD_BITS];
+
+/*return 0: get correct bit mask
+ * -1: no
+ */
+int get_dont_care_lookup(char *s)
+{
+	int len, i, j;
+	int flag = 0;
+
+	if (!s)
+		return -1;
+	len = strlen(s);
+	dp_replace_ch(s, strlen(s), ' ', 0);
+	dp_replace_ch(s, strlen(s), '\r', 0);
+	dp_replace_ch(s, strlen(s), '\n', 0);
+	if (s[0] == 0)
+		return -1;
+	memset(lookup_flags2, 0, sizeof(lookup_flags2));
+	memset(lookup_mask2, 0, sizeof(lookup_mask2));
+	if ((s[0] != 'b') && (s[0] != 'B'))
+		return -1;
+
+	if (len >= LOOKUP_FIELD_BITS + 1)
+		len = LOOKUP_FIELD_BITS + 1;
+	PR_INFO("len=%d\n", len);
+	for (i = len - 1, j = 0; i >= 1; i--, j++) {
+		if ((s[i] == 'x') || (s[i] == 'X')) {
+			lookup_mask2[j] = 1;
+			flag = 1;
+		} else if (('0' <= s[i]) && (s[i] <= '9')) {
+			lookup_flags2[j] = s[i] - '0';
+		} else if (('A' <= s[i]) && (s[i] <= 'F')) {
+			lookup_flags2[j] = s[i] - 'A' + 10;
+		} else if (('a' <= s[i]) && (s[i] <= 'f')) {
+			lookup_flags2[j] = s[i] - '1' + 10;
+		} else {
+			return -1;
+		}
+	}
+	if (flag) {
+		PR_INFO("\nGet lookup flag: ");
+		for (i = LOOKUP_FIELD_BITS - 1; i >= 0; i--) {
+			if (lookup_mask2[i])
+				PR_INFO("x");
+			else
+				PR_INFO("%d", lookup_flags2[i]);
+		}
+		PR_INFO("\n");
+
+		return 0;
+	} else {
+		return -1;
+	}
+}
+
+void lookup_table_recursive(int k, int tmp_index, int set_flag, int qid)
+{
+	int i;
+
+	if (k < 0) {	/*finish recursive and start real read/set action */
+		if (set_flag) {
+			set_lookup_qid_via_index(tmp_index, qid);
+			PR_INFO("Set lookup[%05u 0x%04x] ->     queue[%d]\n",
+				tmp_index, tmp_index, qid);
+		} else {
+			qid = get_lookup_qid_via_index(tmp_index);
+			PR_INFO("Get lookup[%05u 0x%04x] ->     queue[%d]\n",
+				tmp_index, tmp_index, qid);
+		}
+		return;
+	}
+
+	if (lookup_mask2[k]) {
+		for (i = 0; i < 2; i++)
+			lookup_table_recursive(k - 1, tmp_index + (i << k),
+					       set_flag, qid);
+		return;
+	}
+
+	lookup_table_recursive(k - 1, tmp_index + (lookup_flags2[k] << k),
+			       set_flag, qid);
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c
new file mode 100644
index 000000000000..7b4486467c15
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c
@@ -0,0 +1,2197 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+#include<linux/init.h>
+#include<linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/version.h>
+#include <linux/timer.h>
+#include <linux/skbuff.h>
+#include <linux/if_ether.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/if_ether.h>
+#include <linux/clk.h>
+
+#include <lantiq_soc.h>
+#include <net/lantiq_cbm_api.h>
+#include <net/datapath_api.h>
+#include <net/datapath_proc_api.h>
+#include "../datapath.h"
+#include <net/lantiq_cbm_api.h>
+#ifdef CONFIG_LTQ_TMU
+#include <net/drv_tmu_ll.h>
+#endif
+#if IS_ENABLED(CONFIG_LTQ_PPA_TMU_MIB_SUPPORT)
+#include <net/ltq_tmu_hal_api.h>
+#include <net/ltq_mpe_hal.h>
+#endif
+
+static struct gsw_itf itf_assign[] = {
+		{0, 1, 0, 16, 17},
+		{15, 1, 17, 33, 17},
+		{1, 1, 34, 50, 16},
+		{2, 1, 51, 67, 16},
+		{3, 1, 68, 84, 16},
+		{4, 1, 85, 101, 16},
+		{5, 1, 102, 118, 16},
+		{-1, 1, 119, 135, 16},
+		{-1, 1, 136, 152, 16},
+		{-1, 1, 153, 169, 16},
+		{-1, 1, 170, 186, 16},
+		{-1, 1, 187, 203, 16},
+		{-1, 1, 204, 220, 16},
+		{-1, 1, 221, 237, 16},
+		{-1, 1, 238, 255, 17}
+};
+
+#define WRAPAROUND32   0xFFFFFFFF
+/*timer interval for mib wraparound handling:
+ * Most mib counter is 32 bits, ie, maximu ix 0xFFFFFFFF
+ * one pmac port maximum (cpu port) can support less than 3G, ie,
+ * 1488096 * 3 packets for 64 bytes case.
+ * so the time to have 1 wrapround is:
+ * 0xFFFFFFFF / (1488096 * 3) = 962 seconds
+ * If each timer check one port and its subif, then 962/16 = 60 sec.
+ */
+#define POLL_INTERVAL (60 * HZ)
+#define WAN_EP          15	/*WAN Interface's EP value */
+#define MAX_RMON_ITF    256	/*maximum 256 GSW RMON interface supported */
+
+struct mibs_port {
+	u64 rx_good_bytes;
+	u64 rx_bad_bytes;
+	u64 rx_good_pkts;
+	u64 rx_drop_pkts;
+	/*For eth0_x only, for all others, must keep it
+	 * to zero in order to share same algo
+	 */
+	u64 rx_drop_pkts_pae;
+	u64 rx_disc_pkts_redir;	/*for eth1 only */
+	u64 rx_fcs_err_pkts;
+	u64 rx_undersize_good_pkts;
+	u64 rx_oversize_good_pkts;
+	u64 rx_undersize_err_pkts;
+	u64 rx_oversize_err_pkts;
+	u64 rx_align_err_pkts;
+	u64 rx_filter_pkts;
+
+	u64 tx_good_bytes;
+	u64 tx_good_pkts;
+	u64 tx_drop_pkts;
+	/*For eth0_x only, for all others, must keep it
+	 *  to zero in order to share same algo
+	 */
+	u64 tx_drop_pkts_pae;
+	u64 tx_acm_drop_pkts;
+	u64 tx_acm_drop_pkts_pae;	/*for eth0_x only */
+	u64 tx_disc_pkts_redir;	/*for eth1 only */
+	u64 tx_coll_pkts;
+	u64 tx_coll_pkts_pae;	/*for eth0_x only */
+	u64 tx_pkts_redir;	/*for eth1 only */
+	u64 tx_bytes_redir;	/*for eth1 only */
+	u64 rx_fcs_err_pkts_pae;
+	u64 rx_undersize_err_pkts_pae;
+	u64 rx_oversize_err_pkts_pae;
+	u64 rx_align_err_pkts_pae;
+
+	/*tmu related */
+	u64 tx_tmu_drop_pkts;
+	u64 tx_mpe_drop_pkts;
+	u64 tx_tmu_csum_offload_pkts;
+	u64 tx_tmu_csum_offload_bytes;
+
+	/*driver related */
+	u64 rx_drv_drop_pkts;
+	u64 rx_drv_error_pkts;
+	u64 tx_drv_drop_pkts;
+	u64 tx_drv_error_pkts;
+
+	/*for DSL ATM only */
+	u64 tx_drv_pkts;
+	u64 rx_drv_pkts;
+	u64 tx_drv_bytes;
+	u64 rx_drv_bytes;
+};
+
+struct mib_vap {
+	u64 rx_pkts_itf;
+	u64 rx_disc_pkts_itf;
+	u64 rx_disc_pkts_drv;
+	u64 tx_pkts_itf;
+	u64 tx_disc_pkts_itf;
+	u64 tx_disc_pkts_tmu;
+	u64 tx_disc_pkts_mpe;
+	u64 tx_disc_pkts_drv;
+};
+
+struct port_mib {
+	struct mibs_port curr; /*tmp variable used for mib counter cal*/
+	struct mib_vap curr_vap[MAX_SUBIF_PER_PORT];	/*for future */
+};
+
+struct mibs_low_lvl_port {
+	GSW_RMON_Port_cnt_t l;          /*only for ethernet LAN ports */
+	GSW_RMON_Port_cnt_t r;
+	GSW_RMON_Redirect_cnt_t redir; /*only for ethernet WAN port */
+	dp_drv_mib_t drv;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	struct tmu_hal_qos_stats tmu_qos[MAX_SUBIF_PER_PORT];
+	struct tmu_hal_qos_stats tmu_chksum;  /*only for ethernet WAN port */
+	struct mpe_hal_if_stats mpe;
+#endif
+};
+
+struct mibs_low_lvl_vap {
+	GSW_RMON_If_cnt_t gsw_if; /*for pae only(L not support interface mib)*/
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	struct tmu_hal_qos_stats tmu_qos;
+	struct mpe_hal_if_stats mpe;
+#endif
+	dp_drv_mib_t drv;
+};
+
+static unsigned int proc_mib_vap_start_id = 1;
+static unsigned int proc_mib_vap_end_id = PMAC_MAX_NUM - 1;
+static spinlock_t dp_mib_lock;
+static unsigned long poll_interval = POLL_INTERVAL;
+
+/*save port based lower level last mib counter
+ * for wraparound checking
+ */
+struct mibs_low_lvl_port last[PMAC_MAX_NUM];
+/*save vap/sub interface based lower level last mib counter
+ *for wraparound checking
+ */
+struct mibs_low_lvl_vap last_vap[PMAC_MAX_NUM][MAX_SUBIF_PER_PORT];
+/*Save all necessary aggregated basic MIB */
+static struct port_mib aggregate_mib[PMAC_MAX_NUM];
+/*For PAE CPU port only */
+static struct port_mib aggregate_mib_r[1];
+
+#define THREAD_MODE
+
+#ifdef THREAD_MODE
+#include <linux/kthread.h>
+struct task_struct *thread;
+#else
+static struct timer_list exp_timer;	/*timer setting */
+#endif
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+static int32_t (*tmu_hal_get_qos_m_local)(struct net_device *dev,
+					  dp_subif_t *subif_id,
+					  s32 queue_id,
+					  struct tmu_hal_qos_stats *qos_mib,
+					  u32 flag);
+static int32_t (*tmu_hal_get_csum_ol_m_local)(
+	struct tmu_hal_qos_stats *csum_mib, uint32_t flag);
+static int32_t (*tmu_hal_clear_qos_m_local)(struct net_device *dev,
+					    dp_subif_t *subif,
+					    s32 queue_id,
+					    uint32_t flag);
+static int32_t (*tmu_hal_clear_csum_ol_m_local)(uint32_t flag);
+static int32_t (*mpe_hal_get_netif_m_local)(struct net_device *dev,
+					    dp_subif_t *subif_id,
+					    struct mpe_hal_if_stats *mpe_mib,
+					    uint32_t flag);
+static int32_t (*mpe_hal_clear_if_m_local)(struct net_device *dev,
+					   dp_subif_t *subif_id,
+					   uint32_t flag);
+#endif
+
+/*internal API: update local net mib counters periodically */
+static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag);
+static int update_vap_mib_lower_lvl(dp_subif_t *subif, u32 flag);
+
+/* ----- API implementation ------- */
+static u64 wraparound(u64 curr, u64 last, u32 size)
+{
+#define WRAPAROUND_MAX_32 0xFFFFFFFF
+
+	if ((size > 4) || /*for 8 bytes(64bit mib),no need to do wraparound*/
+	    (curr >= last))
+		return curr - last;
+	PR_INFO("Wraparound happen:\n");
+	PR_INFO("  current mib: 0x%x\n", curr);
+	PR_INFO("  last    mib: 0x%x\n", last);
+	return ((u64)WRAPAROUND_MAX_32) + (u64)curr - last;
+}
+
+static int port_mib_wraparound(u32 ep, struct mibs_low_lvl_port *curr,
+			       struct mibs_low_lvl_port *last)
+{
+/* RMON_PORT_WRAP: c-current, l-last x-size in bytes */
+#define RMON_PORT_WRAP(c, l, x) wraparound((c)->(x), (l)->(x), sizeof((l)->(x)))
+	GSW_RMON_Port_cnt_t *curr_tmp;
+	GSW_RMON_Port_cnt_t *last_tmp;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	int i;
+#endif
+
+	if (unlikely(ep >= PMAC_MAX_NUM))
+		return -1;
+	if (ep < PAMC_LAN_MAX_NUM) {
+		curr_tmp = &curr->l;
+		last_tmp = &last->l;
+	} else {
+		curr_tmp = &curr->r;
+		last_tmp = &last->r;
+	}
+	/*First handle common RMON mib */
+	//spin_lock_bh(&dp_mib_lock);
+	aggregate_mib[ep].curr.rx_good_bytes +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodBytes);
+	aggregate_mib[ep].curr.rx_bad_bytes +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxBadBytes);
+	aggregate_mib[ep].curr.rx_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodPkts);
+	aggregate_mib[ep].curr.rx_drop_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxDroppedPkts);
+	aggregate_mib[ep].curr.rx_fcs_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFCSErrorPkts);
+	aggregate_mib[ep].curr.rx_undersize_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeGoodPkts);
+	aggregate_mib[ep].curr.rx_oversize_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeGoodPkts);
+	aggregate_mib[ep].curr.rx_undersize_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeErrorPkts);
+	aggregate_mib[ep].curr.rx_oversize_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeErrorPkts);
+	aggregate_mib[ep].curr.rx_align_err_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxAlignErrorPkts);
+	aggregate_mib[ep].curr.rx_filter_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFilteredPkts);
+	aggregate_mib[ep].curr.tx_good_bytes +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodBytes);
+	aggregate_mib[ep].curr.tx_good_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodPkts);
+	aggregate_mib[ep].curr.tx_drop_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxDroppedPkts);
+	aggregate_mib[ep].curr.tx_acm_drop_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxAcmDroppedPkts);
+	aggregate_mib[ep].curr.tx_coll_pkts +=
+	    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxCollCount);
+
+	/*pae port 0 is not required by concept, for debugging only*/
+	if (ep == 0) {
+		curr_tmp = &curr->r;
+		last_tmp = &last->r;
+		aggregate_mib_r[0].curr.rx_good_bytes +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodBytes);
+		aggregate_mib_r[0].curr.rx_bad_bytes +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxBadBytes);
+		aggregate_mib_r[0].curr.rx_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxGoodPkts);
+		aggregate_mib_r[0].curr.rx_drop_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxDroppedPkts);
+		aggregate_mib_r[0].curr.rx_fcs_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFCSErrorPkts);
+		aggregate_mib_r[0].curr.rx_undersize_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeGoodPkts);
+		aggregate_mib_r[0].curr.rx_oversize_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeGoodPkts);
+		aggregate_mib_r[0].curr.rx_undersize_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeErrorPkts);
+		aggregate_mib_r[0].curr.rx_oversize_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeErrorPkts);
+		aggregate_mib_r[0].curr.rx_align_err_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxAlignErrorPkts);
+		aggregate_mib_r[0].curr.rx_filter_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFilteredPkts);
+		aggregate_mib_r[0].curr.tx_good_bytes +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodBytes);
+		aggregate_mib_r[0].curr.tx_good_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxGoodPkts);
+		aggregate_mib_r[0].curr.tx_drop_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxDroppedPkts);
+		aggregate_mib_r[0].curr.tx_acm_drop_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxAcmDroppedPkts);
+		aggregate_mib_r[0].curr.tx_coll_pkts +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxCollCount);
+
+		/*save */
+		*last = *curr;
+		//spin_unlock_bh(&dp_mib_lock);
+		return 0;
+	}
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	/*TMU drop counters */
+	for (i = 0; i < MAX_SUBIF_PER_PORT; i++)
+		aggregate_mib[ep].curr.tx_tmu_drop_pkts +=
+			wraparound(curr->tmu_qos[i].dropPkts,
+				   last->tmu_qos[i].dropPkts,
+				   sizeof(last->tmu_qos[i].dropPkts));
+	aggregate_mib[ep].curr.tx_mpe_drop_pkts +=
+		wraparound(curr->mpe.dropPkts, last->mpe.dropPkts,
+			   sizeof(last->mpe.dropPkts));
+	aggregate_mib[ep].curr.tx_tmu_csum_offload_pkts +=
+		wraparound(curr->tmu_chksum.deqPkts,
+			   last->tmu_chksum.deqPkts,
+			   sizeof(last->tmu_chksum.deqPkts));
+	aggregate_mib[ep].curr.tx_tmu_csum_offload_bytes +=
+		wraparound(curr->tmu_chksum.deqBytes,
+			   last->tmu_chksum.deqBytes,
+			   sizeof(last->tmu_chksum.deqBytes));
+#endif
+	if (ep < PAMC_LAN_MAX_NUM) {
+		/*speical handling for eth0_x: */
+		/*   get drop cnt from its pae's mapped port,*/
+		/*   Don't save whole last as *last = *curr */
+		curr_tmp = &curr->r;
+		last_tmp = &last->r;
+		aggregate_mib[ep].curr.rx_drop_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxDroppedPkts);
+		aggregate_mib[ep].curr.tx_drop_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxDroppedPkts);
+		aggregate_mib[ep].curr.tx_coll_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nTxCollCount);
+
+		aggregate_mib[ep].curr.rx_fcs_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxFCSErrorPkts);
+		aggregate_mib[ep].curr.rx_undersize_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxUnderSizeErrorPkts);
+		aggregate_mib[ep].curr.rx_oversize_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxOversizeErrorPkts);
+		aggregate_mib[ep].curr.rx_align_err_pkts_pae +=
+		    RMON_PORT_WRAP(curr_tmp, last_tmp, nRxAlignErrorPkts);
+
+	} else if (ep == WAN_EP) {	/*redirect mib */
+		aggregate_mib[ep].curr.rx_disc_pkts_redir +=
+		    wraparound(curr->redir.nRxDiscPktsCount,
+			       last->redir.nRxDiscPktsCount,
+			       sizeof(last->redir.nRxDiscPktsCount));
+		aggregate_mib[ep].curr.tx_disc_pkts_redir +=
+		    wraparound(curr->redir.nTxDiscPktsCount,
+			       last->redir.nTxDiscPktsCount,
+			       sizeof(last->redir.nTxDiscPktsCount));
+		aggregate_mib[ep].curr.tx_pkts_redir +=
+		    wraparound(curr->redir.nTxPktsCount,
+			       last->redir.nTxPktsCount,
+			       sizeof(last->redir.nTxPktsCount));
+		aggregate_mib[ep].curr.tx_bytes_redir +=
+		    wraparound(curr->redir.nTxBytesCount,
+			       last->redir.nTxBytesCount,
+			       sizeof(last->redir.nTxBytesCount));
+	}
+	/*save */
+	*last = *curr;
+	//spin_unlock_bh(&dp_mib_lock);
+	return 0;
+}
+
+static int vap_mib_wraparound(dp_subif_t *subif,
+			      struct mibs_low_lvl_vap *curr,
+			      struct mibs_low_lvl_vap *last)
+{
+#define VAP_RMON_WRAP_ITF(c, l, x) do { \
+	wrapar((c)->gsw_if.x, (l)->gsw_if.x, sizeof((l)->gsw_if.x)) \
+} while (0)
+#define VAP_RMON_WRAP_TMU(c, l, x) do { \
+	wrapar((c)->tmu_qos.x, (l)->tmu_qos.x, sizeof((l)->tmu_qos.x)) \
+} while (0)
+#define VAP_RMON_WRAP_MPE(c, l, x) do { \
+	wrapar((c)->mpe.x, (l)->mpe.x, sizeof((l)->mpe.x)) \
+} while (0)
+#define VAP_RMON_WRAP_DRV(c, l, x) do { \
+	wrapar((c)->drv.x, (l)->drv.x, sizeof((l)->drv.x)) \
+} while (0)
+
+	int ep = subif->port_id;
+	int vap = GET_VAP(subif->subif,
+			  PORT_INFO(0, subif->port_id, vap_offset),
+			  PORT_INFO(0, subif->port_id, vap_mask));
+	if ((ep <= 0) ||
+	    (ep >= PMAC_MAX_NUM))
+		return -1;
+	//spin_lock_bh(&dp_mib_lock);
+	aggregate_mib[ep].curr_vap[vap].rx_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nRxPktsCount);
+	aggregate_mib[ep].curr_vap[vap].rx_disc_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nRxDiscPktsCount);
+	aggregate_mib[ep].curr_vap[vap].rx_disc_pkts_drv +=
+	    VAP_RMON_WRAP_ITF(curr, last, nRxDiscPktsCount);
+
+	aggregate_mib[ep].curr_vap[vap].tx_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nTxPktsCount);
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_itf +=
+	    VAP_RMON_WRAP_ITF(curr, last, nTxDiscPktsCount);
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_tmu +=
+	    VAP_RMON_WRAP_TMU(curr, last, dropPkts);
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_mpe +=
+	    VAP_RMON_WRAP_MPE(curr, last, dropPkts);
+#endif
+	aggregate_mib[ep].curr_vap[vap].tx_disc_pkts_drv +=
+	    VAP_RMON_WRAP_DRV(curr, last, tx_drop_pkts);
+	/*save */
+	*last = *curr;
+	//spin_unlock_bh(&dp_mib_lock);
+	return 0;
+}
+
+static int get_gsw_port_rmon(u32 ep, char *gsw_drv_name,
+			     GSW_RMON_Port_cnt_t *mib)
+{
+	GSW_return_t ret;
+
+	if (!mib) {
+		PR_ERR("why mib pointer is %p\n", mib);
+		return -1;
+	}
+	if (ep >= PMAC_MAX_NUM)
+		return -1;
+	memset(mib, 0, sizeof(*mib));
+	mib->nPortId = ep;
+	ret = gsw_core_api((dp_gsw_cb)dp_port_prop[0].ops[index]->gsw_rmon_ops
+			   .RMON_Port_Get, dp_port_prop[0].ops[index], mib);
+	if (ret) {
+		PR_ERR("GSW_RMON_PORT_GET failed(%d) from %s for port %d\n",
+		       ret, gsw_drv_name, ep);
+		return -1;
+	}
+
+	return 0;
+}
+
+static int get_gsw_redirect_rmon(u32 ep, int index,
+				 GSW_RMON_Redirect_cnt_t *mib)
+{
+	GSW_return_t ret;
+
+	if (!mib) {
+		PR_ERR("why mib pointer is %p\n", mib);
+		return -1;
+	}
+
+	memset(mib, 0, sizeof(*mib));
+	ret = gsw_core_api((dp_gsw_cb)dp_port_prop[0].ops[index]->gsw_rmon_ops
+			   .RMON_Redirect_Get, dp_port_prop[0].ops[index], mib);
+	if (ret) {
+		PR_ERR("GSW_RMON_REDIRECT_GET failed from %s\n",
+		       gsw_drv_name);
+		return -1;
+	}
+
+	return 0;
+}
+
+static int get_gsw_itf_rmon(u32 index, int index,
+			    GSW_RMON_If_cnt_t *mib)
+{
+	GSW_return_t ret;
+
+	if (!mib) {
+		PR_ERR("why mib pointer is %p\n", mib);
+		return -1;
+	}
+	memset(mib, 0, sizeof(*mib));
+	mib->nIfId = index;
+	ret = gsw_core_api((dp_gsw_cb)dp_port_prop[0].ops[index]
+				 ->gsw_rmon_ops.RMON_If_Get,
+				 dp_port_prop[0].ops[index], mib);
+	if (ret) {
+		PR_ERR
+		    ("GSW_RMON_PORT_GET GSW_RMON_IF_GET from %s: index %d\n",
+		     gsw_drv_name, index);
+		return -1;
+	}
+	return 0;
+}
+
+int get_gsw_interface_base(int port_id)
+{
+	struct pmac_port_info *port_info;
+
+	if ((port_id <= 0) || (port_id >= PMAC_MAX_NUM)) {
+		PR_ERR("Wrong subif\n");
+		return -1;
+	}
+
+	port_info = get_port_info(port_id);
+	if (!port_info)
+		return -1;
+	if (!port_info->itf_info)
+		return -1;
+	return (int)port_info->itf_info->start;
+}
+
+/* if ethernet WAN redirect is enabled, return 1,
+ * else return 0
+ */
+int gsw_eth_wan_redirect_status(void)
+{
+	GSW_QoS_queuePort_t q_cfg;
+	int i;
+	GSW_return_t ret;
+	struct core_ops *gsw_handle;
+	#define MAX_CLASS_NUM 16
+
+	gsw_handle = dp_port_prop[inst].ops[1];
+
+	memset(&q_cfg, 0, sizeof(q_cfg));
+	q_cfg.nPortId = WAN_EP;
+	for (i = 0; i <= MAX_CLASS_NUM; i++) {
+		q_cfg.nTrafficClassId = i;
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_qos_ops
+				   .QoS_QueuePortGet, gsw_handle, &q_cfg);
+		if (ret) {
+			PR_ERR("%s failed(%d) from %s for port %d\n",
+			       "GSW_QOS_QUEUE_PORT_GET",
+			       ret, GSWIP_R, WAN_EP);
+			return -1;
+		}
+		if (q_cfg.nRedirectPortId == 0)
+			return 1;
+	}
+
+	return 0;
+}
+
+/*Note:
+ *Update mib counter for physical port only
+ *flag so far no much use only
+ */
+static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag)
+{
+	GSW_return_t ret;
+	struct mibs_low_lvl_port *curr;
+	dp_subif_t tmp;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	int update_flag, i;
+	struct pmac_port_info *port;
+#endif
+
+	/*update struct pmac_port_info[subif->ep].net_mib */
+	if (!subif ||
+	    (subif->port_id < 0) ||
+	    (subif->port_id >= PMAC_MAX_NUM)) {
+		if (!subif)
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				 "%s error:NULL subif\n",
+				 "update_port_mib_lower_lvl");
+		else
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				 "%s wrong port_id %d\n",
+				 "update_port_mib_lower_lvl",
+				 subif->port_id);
+		return -1;
+	}
+	curr = kmalloc(sizeof(*curr), GFP_KERNEL);
+	if (!curr)
+		return -1;
+	memset(curr, 0, sizeof(*curr));
+	tmp = *subif;
+	if (tmp.port_id  == 0) {
+		/*not required by concept, just for debugging purpose*/
+		ret = get_gsw_port_rmon(tmp.port_id, GSWIP_L,
+					&curr->l);
+		if (ret)	/*workaroud otherwise wrongly wrapround */
+			curr->l = last[tmp.port_id].l;
+		ret = get_gsw_port_rmon(tmp.port_id, GSWIP_R,
+					&curr->r);
+		if (ret)	/*workaroud otherwise wrongly wrapround */
+			curr->r = last[tmp.port_id].r;
+		goto HANDLE_WRAPWROUND;
+	} else if (tmp.port_id < PAMC_LAN_MAX_NUM) { /* For port_id: 1 ~ 6 */
+		ret =
+		    get_gsw_port_rmon(tmp.port_id, GSWIP_L,
+				      &curr->l);
+		if (ret)	/*workaroud otherwise wrongly wrapround */
+			curr->l = last[tmp.port_id].l;
+	}
+	/*common to all: pae mib still needs for eth0_x */
+	ret = get_gsw_port_rmon(tmp.port_id, GSWIP_R, &curr->r);
+	if (ret)/*workaroud */
+		curr->r = last[tmp.port_id].r;
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	/* collect all mib per VAP for TMU and MPE MIB */
+	tmu_hal_get_qos_m_local = tmu_hal_get_qos_mib_hook_fn;
+	port = get_port_info(tmp.port_id);
+	if (tmu_hal_get_qos_m_local &&
+	    port && port->status) { /*get all VAP's TMU MIB*/
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				 "tmu_hal_get_qos_m_local: %d/%d\n",
+				 tmp.port_id, tmp.subif);
+			if (!port->subif_info[i].flags) {
+				ret = -1;
+			} else {
+				tmp.subif = SET_VAP(i, port->vap_offset,
+						    port->vap_mask);
+				ret = tmu_hal_get_qos_m_local(NULL,
+							      &tmp, -1,
+							      &curr->
+								tmu_qos[i],
+							      0);
+			}
+			if (ret) /*workaround */
+				memcpy(&curr->tmu_qos[i],
+				       &last[tmp.port_id].tmu_qos[i],
+				       sizeof(curr->tmu_qos[i]));
+		}
+	} else
+		memcpy(&curr->tmu_qos, &last[tmp.port_id].tmu_qos,
+		       sizeof(curr->tmu_qos));
+	tmp = *subif;
+	mpe_hal_get_netif_m_local = mpe_hal_get_netif_mib_hook_fn;
+	update_flag = 0;
+	if (mpe_hal_get_netif_m_local) {
+		ret = mpe_hal_get_netif_m_local(NULL, &tmp,
+						&curr->mpe, 0);
+		if (!ret)
+			update_flag  = 1; /*succeed */
+	}
+	if (!update_flag)
+		memcpy(&curr->mpe, &last[tmp.port_id].mpe,
+		       sizeof(curr->mpe));
+#endif
+
+	/*get redirect mib for eth1 only */
+	if (tmp.port_id == WAN_EP) {
+		ret =
+		    get_gsw_redirect_rmon(tmp.port_id, GSWIP_R,
+					  &curr->redir);
+		if (ret)	/*workaroud */
+			curr->redir = last[tmp.port_id].redir;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+		tmu_hal_get_csum_ol_m_local =
+			tmu_hal_get_csum_ol_mib_hook_fn;
+		update_flag = 0;
+		if (tmu_hal_get_csum_ol_m_local) {
+			ret = tmu_hal_get_csum_ol_m_local(&curr->tmu_chksum, 0);
+			if (!ret)
+				update_flag = 1;
+		}
+		if (!update_flag)
+			memcpy(&curr->tmu_chksum, &last[tmp.port_id].tmu_chksum,
+			       sizeof(curr->tmu_chksum));
+#endif
+	}
+	/*get drv mib */
+	ret = dp_get_drv_mib(subif, &curr->drv, 0);
+	if (ret)	/*workaroud */
+		curr->drv = last[tmp.port_id].drv;
+HANDLE_WRAPWROUND:
+	ret =
+	    port_mib_wraparound(tmp.port_id, curr, &last[tmp.port_id]);
+	kfree(curr);
+	return ret;
+}
+
+static void mib_wraparound_timer_poll(unsigned long data)
+{
+	int i;
+	dp_subif_t subif;
+#define START_PORT_ID 0
+	/*start from port 1, not 0 since 0 is no device registered*/
+	static int port = START_PORT_ID;
+
+	subif.port_id = port;
+	subif.subif = 0;
+	/* update physical port mib only */
+	update_port_mib_lower_lvl(&subif, 0);
+	/* update vap if necessary */
+	if (port) {
+		for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+			subif.subif = SET_VAP(i,
+					      PORT_INFO(0, port, vap_offset),
+					      PORT_INFO(0, port, vap_mask));
+			/* update sub-interface/vap mib only */
+			if (update_vap_mib_lower_lvl(&subif, 0))
+				break;
+		}
+	}
+	port++;
+	if (port == PMAC_MAX_NUM)
+		port = START_PORT_ID;
+
+#ifndef THREAD_MODE
+	exp_timer.expires = jiffies + poll_interval;
+	add_timer(&exp_timer);
+#endif
+}
+
+static int update_vap_mib_lower_lvl(dp_subif_t *subif, u32 flag)
+{
+	int ret;
+	u8 vap;
+	int itf_index;
+	int itf_base;
+	struct mibs_low_lvl_vap *curr;
+	int port_id;
+
+	/*update struct pmac_port_info[subif->ep].net_mib */
+	if (!subif || (subif->port_id <= 0) || (subif->port_id >= PMAC_MAX_NUM))
+		return -1;
+
+	curr = kmalloc(sizeof(*curr), GFP_KERNEL);
+	if (!curr)
+		return -1;
+	memset(curr, 0, sizeof(*curr));
+	port_id = subif->port_id;
+	vap = GET_VAP(subif->subif,
+		      PORT_INFO(0, subif->port_id, vap_offset),
+		      PORT_INFO(0, subif->port_id, vap_mask));
+	/* get gsw PAE interface mib counter */
+	itf_base = get_gsw_interface_base(port_id);
+	if (itf_base < 0) {
+		ret = -1;
+		DP_DEBUG(DP_DBG_FLAG_MIB, "wrong itf_base(%d) for port %d\n",
+			 itf_base, port_id);
+		goto EXIT;
+	}
+	itf_index = itf_base + vap;
+	if (itf_index >= MAX_RMON_ITF) {
+		ret = -1;
+		PR_ERR("wrong itf_index(%d) for port %d\n", itf_index,
+		       port_id);
+		goto EXIT;
+	}
+	ret = get_gsw_itf_rmon(itf_index, GSWIP_R, &curr->gsw_if);
+	if (ret) {
+		curr->gsw_if = last_vap[port_id][vap].gsw_if;
+		PR_ERR("get_gsw_itf_rmon failed for port/vap(%d/%d)", port_id,
+		       vap);
+	}
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	/*get TMU mib */
+	tmu_hal_get_qos_m_local = tmu_hal_get_qos_mib_hook_fn;
+	if (!tmu_hal_get_qos_m_local) {
+		curr->tmu_qos = last_vap[port_id][vap].tmu_qos;
+	} else {
+		ret = tmu_hal_get_qos_m_local(NULL, subif, -1,
+					      &curr->tmu_qos, 0);
+		if (ret) {
+			curr->tmu_qos = last_vap[port_id][vap].tmu_qos;
+			PR_ERR("%s failed for port.vap(%d.%d):%d\n",
+			       "tmu_hal_get_qos_mib_hook_fn",
+			       port_id, vap, ret);
+		}
+	}
+	/*get MPE mib */
+	mpe_hal_get_netif_m_local = mpe_hal_get_netif_mib_hook_fn;
+	if (!mpe_hal_get_netif_m_local) {
+		curr->mpe = last_vap[port_id][vap].mpe;
+	} else {
+		ret = mpe_hal_get_netif_m_local(NULL,
+						subif,
+						&curr->mpe,
+						0);
+		if (ret) {
+			curr->mpe = last_vap[port_id][vap].mpe;
+			PR_ERR("%s failed for port.vap(%d.%d):%d\n",
+			       "mpe_hal_get_netif_mib_hook_fn",
+			       port_id, vap, ret);
+		}
+	}
+#endif
+	/*get driver mib */
+	ret = dp_get_drv_mib(subif, &curr->drv, DP_F_STATS_SUBIF);
+	if (ret)	/*workaroud */
+		curr->drv = last_vap[port_id][vap].drv;
+
+	ret = vap_mib_wraparound(subif, curr, &last_vap[port_id][vap]);
+EXIT:
+	kfree(curr);
+
+	return ret;
+}
+
+int dp_reset_sys_mib(u32 flag)
+{
+	dp_clear_netif_stats(NULL, NULL, 0);
+	return 0;
+}
+
+void proc_mib_timer_read(struct seq_file *s)
+{
+	seq_printf(s, "\nMib timer interval is %u sec\n",
+		   (unsigned int)poll_interval / HZ);
+}
+
+ssize_t proc_mib_timer_write(struct file *file, const char *buf, size_t count,
+			     loff_t *ppos)
+{
+	int len, num;
+	char str[64];
+	char *param_list[2];
+#define MIN_POLL_TIME 2
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	poll_interval = dp_atoi(param_list[0]);
+
+	if (poll_interval < MIN_POLL_TIME)
+		poll_interval = MIN_POLL_TIME;
+
+	poll_interval *= HZ;
+#ifndef THREAD_MODE
+	mod_timer(&exp_timer, jiffies + poll_interval);
+#endif
+	PR_INFO("new poll_interval=%u sec\n",
+		(unsigned int)poll_interval / HZ);
+	return count;
+}
+
+static unsigned int proc_mib_port_start_id = 1;
+static unsigned int proc_mib_port_end_id = PMAC_MAX_NUM - 1;
+int proc_mib_inside_dump(struct seq_file *s, int pos)
+{
+	int ret;
+	dp_subif_t subif;
+	struct rtnl_link_stats64 net_mib;
+
+	seq_printf(s, "EP=%d\n", pos);
+	/*l */
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxGoodPkts",
+		   last[pos].l.nRxGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxFCSErrorPkts",
+		   last[pos].l.nRxFCSErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxUnderSizeGoodPkts",
+		   last[pos].l.nRxUnderSizeGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxOversizeGoodPkts",
+		   last[pos].l.nRxOversizeGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxUnderSizeErrorPkts",
+		   last[pos].l.nRxUnderSizeErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxOversizeErrorPkts",
+		   last[pos].l.nRxOversizeErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxAlignErrorPkts",
+		   last[pos].l.nRxAlignErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxDroppedPkts",
+		   last[pos].l.nRxDroppedPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxFilteredPkts",
+		   last[pos].l.nRxFilteredPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nRxGoodPkts",
+		   last[pos].l.nTxGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nTxDroppedPkts",
+		   last[pos].l.nTxDroppedPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.l.nTxCollCount",
+		   last[pos].l.nTxCollCount);
+	/*r */
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxGoodPkts",
+		   last[pos].r.nRxGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxFCSErrorPkts",
+		   last[pos].r.nRxFCSErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxUnderSizeGoodPkts",
+		   last[pos].r.nRxUnderSizeGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxOversizeGoodPkts",
+		   last[pos].r.nRxOversizeGoodPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxUnderSizeErrorPkts",
+		   last[pos].r.nRxUnderSizeErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxOversizeErrorPkts",
+		   last[pos].r.nRxOversizeErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxAlignErrorPkts",
+		   last[pos].r.nRxAlignErrorPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxDroppedPkts",
+		   last[pos].r.nRxDroppedPkts);
+	seq_printf(s, "  %-45s=%40u\n", "last.r.nRxFilteredPkts",
+		   last[pos].r.nRxFilteredPkts);
+	/*redirct */
+	seq_printf(s, "  %-45s=%40u\n", "last.redir.nRxPktsCount",
+		   last[pos].redir.nRxPktsCount);
+	seq_printf(s, "  %-45s=%40u\n", "last.redir.nRxDiscPktsCount",
+		   last[pos].redir.nRxDiscPktsCount);
+	seq_printf(s, "  %-45s=%40u\n", "last.redir.nTxPktsCount",
+		   last[pos].redir.nTxPktsCount);
+	seq_printf(s, "  %-45s=%40u\n", "last.redir.nTxDiscPktsCount",
+		   last[pos].redir.nTxDiscPktsCount);
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	/*checksum */
+	seq_printf(s, "  %-45s=%40llu\n", "last.tmu_chksum.deqPkts",
+		   last[pos].tmu_chksum.deqPkts);
+	seq_printf(s, "  %-45s=%40llu\n", "last.tmu_chksum.deqBytes",
+		   last[pos].tmu_chksum.deqBytes);
+#endif
+	/*mib array */
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_good_pkts",
+		   aggregate_mib[pos].curr.rx_good_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_drop_pkts_pae",
+		   aggregate_mib[pos].curr.rx_drop_pkts_pae);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_disc_pkts_redir",
+		   aggregate_mib[pos].curr.rx_disc_pkts_redir);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_drop_pkts",
+		   aggregate_mib[pos].curr.rx_drop_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_drop_pkts_pae",
+		   aggregate_mib[pos].curr.rx_drop_pkts_pae);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_disc_pkts_redir",
+		   aggregate_mib[pos].curr.rx_disc_pkts_redir);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_fcs_err_pkts",
+		   aggregate_mib[pos].curr.rx_fcs_err_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_undersize_good_pkts",
+		   aggregate_mib[pos].curr.rx_undersize_good_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_oversize_good_pkts",
+		   aggregate_mib[pos].curr.rx_oversize_good_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_undersize_err_pkts",
+		   aggregate_mib[pos].curr.rx_undersize_err_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_oversize_err_pkts",
+		   aggregate_mib[pos].curr.rx_oversize_err_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_align_err_pkts",
+		   aggregate_mib[pos].curr.rx_align_err_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.rx_filter_pkts",
+		   aggregate_mib[pos].curr.rx_filter_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_good_pkts",
+		   aggregate_mib[pos].curr.tx_good_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drop_pkts",
+		   aggregate_mib[pos].curr.tx_drop_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drop_pkts_pae",
+		   aggregate_mib[pos].curr.tx_drop_pkts_pae);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_acm_drop_pkts",
+		   aggregate_mib[pos].curr.tx_acm_drop_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_acm_drop_pkts_pae",
+		   aggregate_mib[pos].curr.tx_acm_drop_pkts_pae);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_disc_pkts_redir",
+		   aggregate_mib[pos].curr.tx_disc_pkts_redir);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_coll_pkts",
+		   aggregate_mib[pos].curr.tx_coll_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_coll_pkts_pae",
+		   aggregate_mib[pos].curr.tx_coll_pkts_pae);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_tmu_drop_pkts",
+		   aggregate_mib[pos].curr.tx_tmu_drop_pkts);
+	seq_printf(s, "  %-45s=%40llu\n",
+		   "a_mib.curr.tx_tmu_csum_offload_bytes",
+		   aggregate_mib[pos].curr.tx_tmu_csum_offload_bytes);
+	seq_printf(s, "  %-45s=%40llu\n",
+		   "a_mib.curr.tx_tmu_csum_offload_pkts",
+		   aggregate_mib[pos].curr.tx_tmu_csum_offload_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drv_drop_pkts",
+		   aggregate_mib[pos].curr.tx_drv_drop_pkts);
+	seq_printf(s, "  %-45s=%40llu\n", "a_mib.curr.tx_drv_error_pkts",
+		   aggregate_mib[pos].curr.tx_drv_error_pkts);
+	subif.port_id = pos;
+	subif.subif = 0;
+
+	if (dp_get_port_vap_mib_30(&subif, NULL, &net_mib, 0)) {
+		seq_puts(s, "dp_get_port_vap_mib_30 failed\n");
+		goto EXIT;
+	}
+
+	seq_printf(s, "  %-45s=%40llu\n", "aggregated rx_packets",
+		   net_mib.rx_packets);
+	seq_printf(s, "  %-45s=%40llu\n", "aggregated rx_dropped",
+		   net_mib.rx_dropped);
+	seq_printf(s, "  %-45s=%40llu\n", "aggregated tx_packets",
+		   net_mib.tx_packets);
+	seq_printf(s, "  %-45s=%40llu\n", "aggregated tx_dropped",
+		   net_mib.tx_dropped);
+	if (seq_has_overflowed(s)) /*buffer over flow and don't increase pos */
+		return pos;
+
+ EXIT:
+
+	if ((pos >= PMAC_MAX_NUM - 1) || (pos >= proc_mib_port_end_id))
+		return -1;	/*loop finished */
+
+	pos++;
+	return pos;
+}
+
+int proc_mib_inside_start(void)
+{
+	return proc_mib_port_start_id;
+}
+
+ssize_t proc_mib_inside_write(struct file *file, const char *buf,
+			      size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	char *s[2] = { 0 };
+	unsigned int num[2] = { -1 };
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	if (dp_split_buffer(str, s, 2) < 2)
+		goto help;
+
+	if (s[0] && strlen(s[0]))
+		num[0] = dp_atoi(s[0]);
+
+	if (s[1] && strlen(s[1]))
+		num[1] = dp_atoi(s[1]);
+
+	set_start_end_id(num[0], num[1], PMAC_MAX_NUM - 1, PMAC_MAX_NUM - 1,
+			 0, PMAC_MAX_NUM - 1, &proc_mib_port_start_id,
+			 &proc_mib_port_end_id);
+	PR_INFO("proc_mib_port_start_id=%u, proc_mib_port_end_id=%u\n",
+		proc_mib_port_start_id, proc_mib_port_end_id);
+	return count;
+
+ help:
+	PR_INFO("ussage echo start_id end_id > /proc/dp/mib_inside\n");
+	PR_INFO("       then display the selected port info via cat %s\n",
+		"/proc/dp/mib_inside");
+	return count;
+}
+
+/*Note:
+ *if (flag & DP_F_STATS_SUBIF), get sub-interface/vap mib only
+ *otherwise, get physical port's mib
+ */
+int dp_get_port_vap_mib_30(dp_subif_t *subif, void *priv,
+			   struct rtnl_link_stats64 *net_mib, u32 flag)
+{
+	dp_subif_t tmp_subif;
+	unsigned int port_id, vap;
+	struct pmac_port_info *port_info;
+
+	if (!subif || (subif->port_id < 0) ||
+	    (subif->port_id >= PMAC_MAX_NUM) ||
+	    !net_mib)
+		return -1;
+	spin_lock_bh(&dp_mib_lock);
+	port_id = subif->port_id;
+	vap = GET_VAP(subif->subif,
+		      PORT_INFO(0, subif->port_id, vap_offset),
+		      PORT_INFO(0, subif->port_id, vap_mask));
+	port_info = get_port_info(port_id);
+	memset(net_mib, 0, sizeof(*net_mib));
+
+	if ((flag & DP_F_STATS_SUBIF)) {	/*only sub-interface/VAP's
+						 *mib mib only
+						 */
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "%s for port.vap(%u.%u) with flag=0x%x\n",
+			 "dp_get_port_vap_mib_30",
+			 subif->port_id, vap, flag);
+		if (update_vap_mib_lower_lvl(subif, flag))
+			PR_ERR("%s failed for port %d VAP=%d\n",
+			       "update_vap_mib_lower_lvl",
+			       port_id, subif->subif);
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr_vap[vap].rx_disc_pkts_itf +
+		    aggregate_mib[port_id].curr_vap[vap].rx_disc_pkts_drv;
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr_vap[vap].rx_pkts_itf -
+		    net_mib->rx_dropped;
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_itf +
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_tmu +
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_mpe +
+		    aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_drv;
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr_vap[vap].tx_pkts_itf;
+		spin_unlock_bh(&dp_mib_lock);
+		return 0;
+	}
+
+	/*Get physical port's MIB only */
+	DP_DEBUG(DP_DBG_FLAG_MIB,
+		 "dp_get_port_vap_mib_30 for physical port %u w/ flag=0x%x\n",
+		 port_id, flag);
+	tmp_subif.port_id = port_id;
+	tmp_subif.subif = 0;/*for dp_get_drv_mib to get all mib of all VAPs */
+
+	if (update_port_mib_lower_lvl(&tmp_subif, 0))
+		PR_ERR
+		    ("update_port_mib_lower_lvl failed for port %d VAP=%d\n",
+		     tmp_subif.port_id, tmp_subif.subif);
+	if (port_id == 0) { /*not required by concept, for debugging only */
+		struct mibs_port *aggregate_cpu;
+
+		if (flag & DP_F_STATS_PAE_CPU)/*pae cpu*/
+			aggregate_cpu = &aggregate_mib_r[0].curr;
+		else /*gsw-l cpu */
+			aggregate_cpu = &aggregate_mib[0].curr;
+		net_mib->tx_errors =
+		    aggregate_cpu->tx_coll_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_coll_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_cpu->tx_coll_pkts);
+		net_mib->tx_dropped =
+		    aggregate_cpu->tx_drop_pkts +
+		    aggregate_cpu->tx_acm_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_cpu->tx_drop_pkts,
+			 aggregate_cpu->tx_drv_drop_pkts);
+
+		net_mib->tx_packets = aggregate_cpu->tx_good_pkts +
+			net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) + tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_cpu->tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_cpu->tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_pkts(%llu)\n", port_id,
+			 net_mib->tx_bytes,
+			 aggregate_cpu->tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_cpu->rx_drop_pkts +
+		    aggregate_cpu->rx_filter_pkts +
+		    aggregate_cpu->rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + aggregate_cpu->rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_cpu->rx_drop_pkts,
+			 aggregate_cpu->rx_filter_pkts,
+			 aggregate_cpu->rx_drv_drop_pkts);
+
+		net_mib->rx_errors =
+		    aggregate_cpu->rx_fcs_err_pkts +
+		    aggregate_cpu->rx_undersize_good_pkts +
+		    aggregate_cpu->rx_undersize_err_pkts +
+		    aggregate_cpu->rx_oversize_good_pkts +
+		    aggregate_cpu->rx_oversize_err_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_good_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_good_pkts(%llu) + rx_oversize_err_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_cpu->rx_fcs_err_pkts,
+			 aggregate_cpu->rx_undersize_good_pkts,
+			 aggregate_cpu->rx_undersize_err_pkts,
+			 aggregate_cpu->rx_oversize_good_pkts,
+			 aggregate_cpu->rx_oversize_err_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_cpu->rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_cpu->rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_cpu->rx_good_bytes +
+		    aggregate_cpu->rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_cpu->rx_good_bytes,
+			 aggregate_cpu->rx_bad_bytes);
+	} else if (port_id == WAN_EP) {
+		/*tx mib */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts);
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_disc_pkts_redir +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_disc_pkts_redir(%llu) + tx_tmu_drop_pkts(%llu) + tx_mpe_drop_pkts(%llu) + tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_disc_pkts_redir,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+			aggregate_mib[port_id].curr.tx_pkts_redir +
+			net_mib->tx_dropped -
+			aggregate_mib[port_id].curr.tx_tmu_csum_offload_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_pkts_redir(%llu) + tx_dropped(%llu) - tx_tmu_csum_offload_pkts(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_pkts_redir,
+			 net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_tmu_csum_offload_pkts);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_bytes_redir -
+			aggregate_mib[port_id].curr.tx_tmu_csum_offload_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_bytes_redir(%llu) - tx_tmu_csum_offload_bytes(%llu)\n",
+			 port_id,
+			 net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_bytes_redir,
+			 aggregate_mib[port_id].curr.tx_tmu_csum_offload_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts +
+		 * nRxOverSizeErrorPkts + nRxAlignErrorPkts.
+		 */
+		net_mib->rx_errors =
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts(%llu) + rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr.rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	} else if (port_id < PAMC_LAN_MAX_NUM) {
+		/*tx mib */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_coll_pkts +
+		    aggregate_mib[port_id].curr.tx_coll_pkts_pae +
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_coll_pkts(%llu) + tx_coll_pkts_pae(%llu) + tx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_coll_pkts,
+			 aggregate_mib[port_id].curr.tx_coll_pkts_pae,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts);
+
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_acm_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drop_pkts_pae +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu) + tx_drop_pkts_pae(%llu) + tx_tmu_drop_pkts(%llu) + tx_tmu_drop_pkts(%llu)+ tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_acm_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drop_pkts_pae,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr.tx_good_pkts +
+		    net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) + tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_bytes(%llu)\n",
+			 port_id, net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drop_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drop_pkts_pae(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drop_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts +
+		 * nRxOverSizeErrorPkts + nRxAlignErrorPkts
+		 */
+		net_mib->rx_errors =
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts +
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts(%llu) + rx_fcs_err_pkts_pae(%llu) + rx_undersize_err_pkts_pae(%llu) + rx_oversize_err_pkts_pae(%llu) + rx_align_err_pkts_pae(%llu)+  rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr.rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	} else if (!(port_info->alloc_flags &
+		   DP_F_FAST_DSL)) {	/*WIFI/LTE Directpath */
+		/*tx mib */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts +
+		    aggregate_mib[port_id].curr.tx_coll_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_drv_error_pkts(%llu) + tx_coll_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts,
+			 aggregate_mib[port_id].curr.tx_coll_pkts);
+
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_acm_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu) + tx_tmu_drop_pkts(%llu) + tx_mpe_drop_pkts(%llu) + tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_acm_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr.tx_good_pkts +
+		    net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) + tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_bytes(%llu)\n",
+			 port_id, net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts +
+		 * nRxOverSizeErrorPkts + nRxAlignErrorPkts
+		 */
+		net_mib->rx_errors =
+			aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+			aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+			aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+			aggregate_mib[port_id].curr.rx_align_err_pkts +
+			aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts(%llu)  + rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+			aggregate_mib[port_id].curr.rx_good_pkts +
+			net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	} else {		/*DSL */
+		/*Here datapath follow PTM algo. For ATM it
+		 * should be handled by VRX518 directly
+		 */
+		net_mib->tx_errors =
+		    aggregate_mib[port_id].curr.tx_drv_error_pkts +
+		    aggregate_mib[port_id].curr.tx_coll_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_errors(%llu)=tx_drv_error_pkts(%llu) + tx_coll_pkts(%llu)\n",
+			 port_id, net_mib->tx_errors,
+			 aggregate_mib[port_id].curr.tx_drv_error_pkts,
+			 aggregate_mib[port_id].curr.tx_coll_pkts);
+
+		net_mib->tx_dropped =
+		    aggregate_mib[port_id].curr.tx_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_acm_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts +
+		    aggregate_mib[port_id].curr.tx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_dropped(%llu)=tx_drop_pkts(%llu) + tx_acm_drop_pkts(%llu) + tx_tmu_drop_pkts(%llu) + tx_mpe_drop_pkts(%llu) +tx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->tx_dropped,
+			 aggregate_mib[port_id].curr.tx_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_acm_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_tmu_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_mpe_drop_pkts,
+			 aggregate_mib[port_id].curr.tx_drv_drop_pkts);
+
+		net_mib->tx_packets =
+		    aggregate_mib[port_id].curr.tx_good_pkts +
+		    net_mib->tx_dropped + net_mib->tx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_packets(%llu)=tx_good_pkts(%llu) + tx_dropped(%llu) tx_errors(%llu)\n",
+			 port_id, net_mib->tx_packets,
+			 aggregate_mib[port_id].curr.tx_good_pkts,
+			 net_mib->tx_dropped, net_mib->tx_errors);
+
+		net_mib->tx_bytes = aggregate_mib[port_id].curr.tx_good_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: tx_bytes(%llu)=tx_good_bytes(%llu)\n",
+			 port_id, net_mib->tx_bytes,
+			 aggregate_mib[port_id].curr.tx_good_bytes);
+
+		/*rx mib */
+		net_mib->rx_dropped =
+		    aggregate_mib[port_id].curr.rx_drop_pkts +
+		    aggregate_mib[port_id].curr.rx_filter_pkts +
+		    aggregate_mib[port_id].curr.rx_drv_drop_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_dropped(%llu)=rx_drop_pkts(%llu) + rx_filter_pkts(%llu) + rx_drv_drop_pkts(%llu)\n",
+			 port_id, net_mib->rx_dropped,
+			 aggregate_mib[port_id].curr.rx_drop_pkts,
+			 aggregate_mib[port_id].curr.rx_filter_pkts,
+			 aggregate_mib[port_id].curr.rx_drv_drop_pkts);
+
+		/*ErrPktsCount = nRxFCSErrorPkts + nRxUnderSizeErrorPkts +
+		 * nRxOverSizeErrorPkts + nRxAlignErrorPkts
+		 */
+		net_mib->rx_errors =
+		    aggregate_mib[port_id].curr.rx_fcs_err_pkts +
+		    aggregate_mib[port_id].curr.rx_undersize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_oversize_err_pkts +
+		    aggregate_mib[port_id].curr.rx_align_err_pkts_pae +
+		    aggregate_mib[port_id].curr.rx_drv_error_pkts;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_errors(%llu)=rx_fcs_err_pkts(%llu) + rx_undersize_err_pkts(%llu) + rx_oversize_err_pkts(%llu) + rx_align_err_pkts_pae(%llu) + rx_drv_error_pkts(%llu)\n",
+			 port_id, net_mib->rx_errors,
+			 aggregate_mib[port_id].curr.rx_fcs_err_pkts,
+			 aggregate_mib[port_id].curr.rx_undersize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_oversize_err_pkts,
+			 aggregate_mib[port_id].curr.rx_align_err_pkts_pae,
+			 aggregate_mib[port_id].curr.rx_drv_error_pkts);
+
+		net_mib->rx_packets =
+		    aggregate_mib[port_id].curr.rx_good_pkts +
+		    net_mib->rx_dropped + net_mib->rx_errors;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_packets(%llu)=rx_good_pkts(%llu) + rx_dropped(%llu) + rx_errors(%llu)\n",
+			 port_id, net_mib->rx_packets,
+			 aggregate_mib[port_id].curr.rx_good_pkts,
+			 net_mib->rx_dropped, net_mib->rx_errors);
+
+		net_mib->rx_bytes =
+		    aggregate_mib[port_id].curr.rx_good_bytes +
+		    aggregate_mib[port_id].curr.rx_bad_bytes;
+		DP_DEBUG(DP_DBG_FLAG_MIB_ALGO,
+			 "%02d: rx_bytes(%llu)=rx_good_bytes(%llu) + rx_bad_bytes(%llu)\n",
+			 port_id, net_mib->rx_bytes,
+			 aggregate_mib[port_id].curr.rx_good_bytes,
+			 aggregate_mib[port_id].curr.rx_bad_bytes);
+	}
+	spin_unlock_bh(&dp_mib_lock);
+	return 0;
+}
+
+/*Clear GSW Interface MIB: only for sub interface/vap only  */
+int clear_gsw_itf_mib(dp_subif_t *subif, u32 flag)
+{
+	int start, end;
+	GSW_RMON_clear_t rmon;
+	int i;
+	struct pmac_port_info *port_info;
+	struct core_ops *gsw_handle;
+
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	if (!(flag & DP_F_STATS_SUBIF))
+		return 0;
+	if (!subif) { /* clear all */
+		start = 0;
+		end = MAX_RMON_ITF;
+	} else if ((subif->port_id < 0) || (subif->port_id >= PMAC_MAX_NUM)) {
+		DP_DEBUG(DP_DBG_FLAG_MIB, "wrong port_id %d\n",
+			 subif->port_id);
+		return -1;
+	}
+
+	if (subif) {
+		port_info = get_port_info(subif->port_id);
+		if (!port_info || !port_info->itf_info)
+			return 0;
+		start = port_info->itf_info->start +
+			GET_VAP(subif->subif,
+				PORT_INFO(0, subif->port_id, vap_offset),
+				PORT_INFO(0, subif->port_id, vap_mask));
+		end = start + 1;
+	}
+	rmon.eRmonType = GSW_RMON_IF_TYPE;
+	for (i = start; i < end; i++) {
+		rmon.nRmonId = i;
+		if (rmon.nRmonId >= MAX_RMON_ITF) {
+			PR_ERR("Why Port[%d]'s interface ID %d so big\n",
+			       subif ? subif->port_id : -1,
+			       rmon.nRmonId);
+			return -1;
+		}
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_rmon_ops.RMON_Clear,
+			     gsw_handle, &rmon);
+	}
+	return 0;
+}
+
+int dp_clear_netif_mib_30(dp_subif_t *subif, void *priv, u32 flag)
+{
+	unsigned int port_id, vap;
+	GSW_RMON_clear_t rmon;
+	int i;
+	dp_subif_t tmp_subif;
+	struct core_ops *gsw_l, *gsw_r;
+
+	gsw_l = dp_port_prop[inst].ops[GSWIP_L];
+	gsw_r = dp_port_prop[inst].ops[GSWIP_R];
+
+	if (!subif) { /*clear all */
+		spin_lock_bh(&dp_mib_lock);
+		gsw_mib_reset_30(0, 0);
+		gsw_mib_reset_30(1, 0);
+		tmu_reset_mib_all(flag);
+		dp_clear_all_mib_inside(flag);
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+		tmu_hal_clear_qos_m_local =
+			tmu_hal_clear_qos_mib_hook_fn;
+		if (tmu_hal_clear_qos_m_local)
+			tmu_hal_clear_qos_m_local(NULL, NULL, -1, 0);
+		mpe_hal_clear_if_m_local =
+			mpe_hal_clear_if_mib_hook_fn;
+		if (mpe_hal_clear_if_m_local)
+			mpe_hal_clear_if_m_local(NULL, NULL, 0);
+		tmu_hal_clear_csum_ol_m_local =
+			tmu_hal_clear_csum_ol_mib_hook_fn;
+		if (tmu_hal_clear_csum_ol_m_local)
+			tmu_hal_clear_csum_ol_m_local(0);
+#endif
+		memset(aggregate_mib, 0, sizeof(aggregate_mib));
+		memset(aggregate_mib_r, 0, sizeof(aggregate_mib_r));
+		memset(&last, 0, sizeof(last));
+		memset(&last_vap, 0, sizeof(last_vap));
+		spin_unlock_bh(&dp_mib_lock);
+		return 0;
+	}
+
+	if ((subif->port_id <= 0) ||
+	    subif->port_id >= PMAC_MAX_NUM)
+		return -1;
+
+	port_id = subif->port_id;
+	vap = GET_VAP(subif->subif,
+		      PORT_INFO(0, port_id, vap_offset),
+		      PORT_INFO(0, port_id, vap_mask));
+	if ((flag & DP_F_STATS_SUBIF)) {
+		spin_lock_bh(&dp_mib_lock);
+		/*clear the specific subif mib counter */
+		clear_gsw_itf_mib(subif, flag);
+		dp_clear_mib(subif, 0);
+
+		/*workaround since this VAP's mib is cleared*/
+		DP_DEBUG(DP_DBG_FLAG_MIB, "Clear aggregate_mib: %d/%d\n",
+			 port_id, vap);
+		if (aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_tmu <=
+		    aggregate_mib[port_id].curr.tx_tmu_drop_pkts)
+			aggregate_mib[port_id].curr.tx_tmu_drop_pkts -=
+			 aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_tmu;
+		if (aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_mpe <=
+		    aggregate_mib[port_id].curr.tx_mpe_drop_pkts)
+			aggregate_mib[port_id].curr.tx_mpe_drop_pkts -=
+			aggregate_mib[port_id].curr_vap[vap].tx_disc_pkts_mpe;
+		memset(&aggregate_mib[port_id].curr_vap[vap], 0,
+		       sizeof(aggregate_mib[port_id].curr_vap[vap]));
+		memset(&last_vap[port_id][vap], 0,
+		       sizeof(last_vap[port_id][vap]));
+		/*how about last[] & last_vap[]*/
+		spin_unlock_bh(&dp_mib_lock);
+		return 0;
+	}
+	spin_lock_bh(&dp_mib_lock);
+	/*Clear port based RMON mib */
+	DP_DEBUG(DP_DBG_FLAG_MIB,
+		 "dp_clear_netif_mib port %u mib flag=0x%x\n", port_id, flag);
+
+	/*First we delete all its VAP mib counter first since TMU/MPE port mib
+	 * counter is based on its VAP's
+	 */
+	tmp_subif = *subif;
+	for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+		DP_DEBUG(DP_DBG_FLAG_MIB, "dp_clear_netif_mib: %d/%d\n",
+			 tmp_subif.port_id, i);
+		tmp_subif.subif =
+			SET_VAP(i,
+				PORT_INFO(0, tmp_subif.port_id, vap_offset),
+				PORT_INFO(0, tmp_subif.port_id, vap_mask));
+		dp_clear_netif_mib_30(&tmp_subif, NULL, DP_F_STATS_SUBIF);
+	}
+
+	memset(&aggregate_mib[port_id], 0, sizeof(aggregate_mib[port_id]));
+	memset(&last[port_id], 0, sizeof(last[port_id]));
+
+	if (port_id == WAN_EP) {
+		/*reset GSWIP-R rmon counters */
+		rmon.eRmonType = GSW_RMON_PORT_TYPE;
+		rmon.nRmonId = port_id;
+		gsw_core_api((dp_gsw_cb)gsw_r->gsw_rmon_ops.RMON_Clear,
+			     gsw_r, &rmon);
+
+		/*reset GSWIP-R redirect counters */
+		rmon.eRmonType = GSW_RMON_REDIRECT_TYPE;
+		rmon.nRmonId = 0;
+		gsw_core_api((dp_gsw_cb)gsw_r->gsw_rmon_ops.RMON_Clear,
+			     gsw_r, &rmon);
+
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+		tmu_hal_clear_csum_ol_m_local =
+			tmu_hal_clear_csum_ol_mib_hook_fn;
+		if (tmu_hal_clear_csum_ol_m_local)
+			tmu_hal_clear_csum_ol_m_local(0);
+#endif
+		/*how about last[] & last_vap[] */
+	} else if (port_id < PAMC_LAN_MAX_NUM) {
+		/*reset GSWIP-L/R rmon counters */
+		rmon.eRmonType = GSW_RMON_PORT_TYPE;
+		rmon.nRmonId = port_id;
+		gsw_core_api((dp_gsw_cb)gsw_l->gsw_rmon_ops.RMON_Clear,
+			     gsw_r, &rmon);
+		gsw_core_api((dp_gsw_cb)gsw_r->gsw_rmon_ops.RMON_Clear,
+			     gsw_r, &rmon);
+	} else {		/*port 7 ~ 14 */
+		rmon.eRmonType = GSW_RMON_PORT_TYPE;
+		rmon.nRmonId = port_id;
+		gsw_core_api((dp_gsw_cb)gsw_r->gsw_rmon_ops.RMON_Clear,
+			     gsw_r, &rmon);
+	}
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	tmu_hal_clear_qos_m_local = tmu_hal_clear_qos_mib_hook_fn;
+	if (tmu_hal_clear_qos_m_local)
+		tmu_hal_clear_qos_m_local(NULL, subif, -1, flag);
+	mpe_hal_clear_if_m_local =
+		mpe_hal_clear_if_m_local;
+	if (mpe_hal_clear_if_m_local)
+		mpe_hal_clear_if_m_local(NULL, subif, flag);
+#endif
+
+	/*reset datapath's all vap mib */
+	subif->subif = -1;
+	dp_clear_mib(subif, 0);
+
+	/*reset GSW interface mib */
+	subif->subif = -1;
+	clear_gsw_itf_mib(subif, 0);
+	memset(&last[port_id], 0, sizeof(last[port_id]));
+	spin_unlock_bh(&dp_mib_lock);
+	return 0;
+}
+
+int proc_mib_port_start(void)
+{
+	return 0;
+}
+
+int proc_mib_port_dump(struct seq_file *s, int pos)
+{
+	int i = 0;
+	dp_subif_t subif;
+	struct rtnl_link_stats64 stats_mib = {0};
+
+	if (pos == 0) {
+		memset(&subif, 0, sizeof(subif));
+		seq_printf(s, "%-12s %20s %20s %20s %20s\n", "PORT",
+			   "Tx_Pkts/", "Tx_Bytes/", "Tx_Drop_Pkts/",
+			   "Tx_Err_Pkts/");
+		seq_printf(s, "%-12s %20s %20s %20s %20s\n", "    ",
+			   "Rx_Pkts", "Rx_Bytes", "Rx_Drop_Pkts",
+			   "Rx_Err_Pkts");
+		seq_puts(s, "-------------------------------------------------------------------------------------------------------\n");
+	}
+
+	i = pos;
+	subif.port_id = i;
+	if (dp_get_port_vap_mib_30(&subif, NULL, &stats_mib, 0) == 0) {
+		if (pos == 0)
+			seq_printf(s, "%-7d(L  ) %20llu %20llu %20llu %20llu\n",
+				   subif.port_id,
+				   stats_mib.tx_packets,
+				   stats_mib.tx_bytes,
+				   stats_mib.tx_dropped,
+				   stats_mib.tx_errors);
+		else
+			seq_printf(s, "%-12d %20llu %20llu %20llu %20llu\n",
+				   subif.port_id,
+				   stats_mib.tx_packets,
+				   stats_mib.tx_bytes,
+				   stats_mib.tx_dropped,
+				   stats_mib.tx_errors);
+		seq_printf(s, "             %20llu %20llu %20llu %20llu\n",
+			   stats_mib.rx_packets,
+			   stats_mib.rx_bytes,
+			   stats_mib.rx_dropped,
+			   stats_mib.rx_errors);
+		seq_puts(s, "\n");
+	}
+
+	if ((pos == 0) &&
+	    (dp_get_port_vap_mib_30(&subif, NULL, &stats_mib,
+	    DP_F_STATS_PAE_CPU) == 0)) {
+		seq_printf(s, "%-7d(pae) %20llu %20llu %20llu %20llu\n",
+			   subif.port_id,
+			   stats_mib.tx_packets,
+			   stats_mib.tx_bytes,
+			   stats_mib.tx_dropped,
+			   stats_mib.tx_errors);
+		seq_printf(s, "             %20llu %20llu %20llu %20llu\n",
+			   stats_mib.rx_packets,
+			   stats_mib.rx_bytes,
+			   stats_mib.rx_dropped,
+			   stats_mib.rx_errors);
+		seq_puts(s, "\n");
+	}
+
+	pos++;
+
+	if (pos > (PMAC_MAX_NUM - 1)) {
+		pos = -1;	/*end of the loop */
+		/* check GSWIP whether redirect enabled or not */
+		if (!gsw_eth_wan_redirect_status())
+			seq_puts(s, "Note: Ethernet WAN redirect is not enabled. Its MIB algo not work\n");
+	}
+
+	return pos;
+}
+
+ssize_t proc_mib_port_write(struct file *file, const char *buf, size_t count,
+			    loff_t *ppos)
+{
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+	int len;
+	char str[64];
+	int i, num, res;
+	char *param_list[10];
+	struct pmac_port_info *port;
+	dp_subif_t tmp;
+	static struct tmu_hal_qos_stats qos_stats;
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+	memset(&qos_stats, 0, sizeof(qos_stats));
+	if (dp_strncmpi(param_list[0], "qos_mib" ,strlen("qos_mib")) == 0) {
+		s32 port_list[] = {15, 2, 3, 4, 5, 7, 8};
+		int k;
+
+		tmu_hal_get_qos_m_local =
+			tmu_hal_get_qos_mib_hook_fn;
+		if (!tmu_hal_get_qos_m_local) {
+			PR_INFO("tmu_hal_get_qos_mib_hook_fn NULL\n");
+			return count;
+		}
+		for (k = 0; k < ARRAY_SIZE(port_list); k++) {
+			tmp.port_id = port_list[k];
+			port = get_port_info(tmp.port_id);
+			if (!port)
+				continue;
+			for (i = 0; i < MAX_SUBIF_PER_PORT; i++) {
+				if (!port->subif_info[i].flags)
+					continue;
+				tmp.subif = SET_VAP(i, port->vap_offset,
+						    port->vap_mask);
+				res = tmu_hal_get_qos_m_local(NULL,
+							      &tmp,
+							      -1,
+							      &qos_stats,
+							      0);
+				if (res) {
+					PR_INFO("%s failed for p[%d]\n",
+						"tmu_hal_get_qos_mib_hook_fn",
+						tmp.port_id);
+					continue;
+				}
+				PR_INFO("%s[%d/%d]:drop_pkts=%llu bytes=%llu\n",
+					"qos_mib", tmp.port_id,
+					GET_VAP(tmp.subif, port->vap_offset,
+						port->vap_mask),
+					qos_stats.dropPkts,
+					qos_stats.dropBytes);
+				PR_INFO("%s[%d/%d]:enqPkts=%llu Bytes=%llu\n",
+					"qos_mib", tmp.port_id,
+					GET_VAP(tmp.subif, port->vap_offset,
+						port->vap_mask),
+				       qos_stats.enqPkts,
+				       qos_stats.enqBytes);
+				PR_INFO("%s[%d/%d]:deqPkts=%llu Bytes=%llu\n",
+					"qos_mib", tmp.port_id,
+					GET_VAP(tmp.subif, port->vap_offset,
+						port->vap_mask),
+					qos_stats.deqPkts,
+					qos_stats.deqBytes);
+			}
+			PR_INFO("\n");
+		}
+	} else if (dp_strncmpi(param_list[0], "csum_mib" ,strlen("csum_mib")) == 0) {
+		tmu_hal_get_csum_ol_m_local =
+			tmu_hal_get_csum_ol_mib_hook_fn;
+		if (!tmu_hal_get_csum_ol_m_local) {
+			PR_INFO("tmu_hal_get_csum_ol_mib_hook_fn NULL\n");
+			return count;
+		}
+		res = tmu_hal_get_csum_ol_m_local(&qos_stats, 0);
+		if (res)
+			PR_INFO("tmu_hal_get_csum_ol_mib_hook_fn failed\n");
+		else
+			PR_INFO("csum_mib: deqPkts=%llu  deqBytes=%llu\n",
+				qos_stats.deqPkts,
+				qos_stats.deqBytes);
+
+	} else if (dp_strncmpi(param_list[0], "qos_mib_clear", strlen("qos_mib_clear")) == 0) {
+		tmu_hal_clear_qos_m_local =
+			tmu_hal_clear_qos_mib_hook_fn;
+		if (!tmu_hal_clear_qos_m_local) {
+			PR_INFO("tmu_hal_clear_qos_m_local NULL ?\n");
+			return count;
+		}
+		res = tmu_hal_clear_qos_m_local(NULL, NULL, -1, 0);
+		if (res)
+			PR_INFO("tmu_hal_clear_qos_m_local failed\n");
+		else
+			PR_INFO("%s done\n",
+				"tmu_hal_clear_qos_m_local(NULL, NULL, -1, 0)");
+
+	} else if (dp_strncmpi(param_list[0], "csum_mib_clear", strlen("csum_mib_clear")) == 0) {
+		tmu_hal_clear_csum_ol_m_local =
+			tmu_hal_clear_csum_ol_mib_hook_fn;
+		if (!tmu_hal_clear_csum_ol_m_local) {
+			PR_INFO("tmu_hal_clear_csum_ol_mib_hook_fn NULL\n");
+			return count;
+		}
+		res = tmu_hal_clear_csum_ol_m_local(0);
+		if (res)
+			PR_INFO("tmu_hal_clear_csum_ol_mib_hook_fn failed\n");
+		else
+			PR_INFO("tmu_hal_clear_csum_ol_mib_hook_fn(0) done\n");
+
+	} else {
+		goto help;
+	}
+#else
+	return count;
+#endif
+	return count;
+#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+help:
+	PR_INFO("usage:\n");
+	PR_INFO("  test qos_mib  api:      echo qos_mib        > %s\n",
+		"/proc/dp/mib_port");
+	PR_INFO("  test csum_mib api       echo csum_mib       > %s\n",
+		"/proc/dp/mib_port\n");
+	PR_INFO("  test cear_qos_mib  api  echo qos_mib_clear  > %s\n",
+		"/proc/dp/mib_port");
+	PR_INFO("  test csum_mib_clear api echo csum_mib_clear > %s\n",
+		"/proc/dp/mib_port");
+
+	return count;
+#endif
+}
+
+int proc_mib_vap_dump(struct seq_file *s, int pos)
+{
+	int j = 0;
+	int ret = 0, f_newline = 0;
+	dp_subif_t subif;
+	struct rtnl_link_stats64 stats_mib;
+	int itf_base;
+	struct pmac_port_info *port;
+
+	if ((pos > (PMAC_MAX_NUM - 1)) || (pos > proc_mib_vap_end_id)) {
+		pos = -1;	/*end of the loop */
+		return pos;
+	}
+
+	if (pos == proc_mib_vap_start_id) {
+		memset(&subif, 0, sizeof(dp_subif_t));
+		memset(&stats_mib, 0, sizeof(stats_mib));
+		seq_printf(s, "%5s/%3s %5s %22s %22s %22s %22s\n", "Port",
+			   "VAP", "IfID", "Rx_PKTS", "Tx_PKTS",
+			   "Rx_DROP_PKTS", "Tx_DROP_PKTS\n");
+	}
+	port = get_port_info(pos);
+
+	if (!port || !port->status)		/*not allocated yet*/
+		goto EXIT;
+
+	for (j = 0; j <= (MAX_SUBIF_PER_PORT - 1); j++) {
+		subif.port_id = pos;
+		subif.subif = SET_VAP(j,
+				      PORT_INFO(0, pos, vap_offset),
+				      PORT_INFO(0, pos, vap_mask));
+		itf_base = get_gsw_interface_base(pos);
+		if (itf_base < 0)	/*no GSW itf assigned*/
+			continue;
+		if (!port->subif_info[j].flags)	/*not registered yet*/
+			continue;
+		if (dp_get_port_vap_mib_30
+		    (&subif, NULL, &stats_mib,
+		     DP_F_STATS_SUBIF) == 0) {
+			seq_printf(s,
+				   "%5d/%03d %5d %22llu %22llu %22llu %22llu\n",
+				   subif.port_id, j, itf_base + j,
+				   stats_mib.rx_packets, stats_mib.tx_packets,
+				   stats_mib.rx_dropped,
+				   stats_mib.tx_dropped);
+			seq_puts(s, "\n");
+			f_newline = 1;
+		} else
+			seq_printf(s,
+				   "port_vap_mib failed for port/vap %d/%d\n",
+				   pos, j);
+	}
+	if (f_newline)
+		seq_puts(s, "\n");
+
+	/*buffer over flow and don't increase pos */
+	if (seq_has_overflowed(s))
+		return pos;
+
+ EXIT:
+	pos++;
+	return pos;
+}
+
+int proc_mib_vap_start(void)
+{
+	return proc_mib_vap_start_id;
+}
+
+ssize_t proc_mib_vap_write(struct file *file, const char *buf, size_t count,
+			   loff_t *ppos)
+{
+	int len;
+	char str[64];
+	char *param_list[2] = { 0 };
+	unsigned int num[2] = { -1 };
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	if (dp_split_buffer(str, param_list, ARRAY_SIZE(param_list)) < 2)
+		goto help;
+
+	if (param_list[0] && strlen(param_list[0]))
+		num[0] = dp_atoi(param_list[0]);
+
+	if (param_list[1] && strlen(param_list[1]))
+		num[1] = dp_atoi(param_list[1]);
+
+	set_start_end_id(num[0], num[1], MAX_SUBIF_PER_PORT - 1,
+			 MAX_SUBIF_PER_PORT - 1, 0, -1,
+			 &proc_mib_vap_start_id, &proc_mib_vap_end_id);
+	PR_INFO("proc_mib_vap_start_id=%d, proc_mib_vap_end_id=%d\n",
+		proc_mib_vap_start_id, proc_mib_vap_end_id);
+	return count;
+
+ help:
+	PR_INFO("usage: echo start_id end_id > /proc/dp/mib_vap\n");
+	return count;
+}
+
+#ifdef THREAD_MODE
+int mib_wraparound_thread(void *data)
+{
+	while (1) {
+		if (poll_interval)
+			mib_wraparound_timer_poll(0);
+		msleep(poll_interval / HZ * 1000 / PMAC_MAX_NUM / 2);
+		DP_DEBUG(DP_DBG_FLAG_MIB, "mib_wraparound_thread\n");
+	}
+}
+#endif
+
+int set_gsw_itf(u8 ep, u8 ena, int start)
+{
+	GSW_portCfg_t port_cfg;
+	struct core_ops *gsw_r;
+
+	gsw_r = dp_port_prop[inst].ops[GSWIP_R];
+
+	if (ep >= PMAC_MAX_NUM)
+		return -1;
+
+	/*get this ports itf base */
+	port_cfg.nPortId = ep;
+	if (gsw_core_api((dp_gsw_cb)gsw_r->gsw_common_ops.PortCfgGet,
+			 gsw_r, &port_cfg)) {
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "Why gsw_core_api return failure: GSW_PORT_CFG_GET for port_id=%d\n",
+			 port_cfg.nPortId);
+		return -1;
+	}
+	port_cfg.nIfCountStartIdx = start;
+	port_cfg.bIfCounters = ena ? 1 : 0;
+	if (gsw_core_api((dp_gsw_cb)gsw_r->gsw_common_ops.PortCfgSet,
+			 gsw_r, &port_cfg)) {
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "Why gsw_core_api return failure: GSW_PORT_CFG_SET for port_id=%d\n",
+			 port_cfg.nPortId);
+		return -1;
+	}
+
+	return 0;
+}
+
+struct gsw_itf *get_free_itf(u8 ep, u32 flag)
+{
+	int i;
+	int free_id = -1;
+
+	if (ep >= PMAC_MAX_NUM)
+		return NULL;
+
+	for (i = 0; i < ARRAY_SIZE(itf_assign); i++) {
+		if (ep == itf_assign[i].ep) {
+			DP_DEBUG(DP_DBG_FLAG_MIB,
+				 "Found the free gsw itf for itf_assign[i]=%d\n",
+				 i);
+			set_gsw_itf(ep, 1, itf_assign[i].start);
+			return &itf_assign[i];
+		}
+		if ((itf_assign[i].ep == (u8)-1) && (free_id == -1))
+			free_id = i;
+	}
+	if (free_id != -1) {
+		i = free_id;
+		DP_DEBUG(DP_DBG_FLAG_MIB,
+			 "Found the free gsw itf for itf_assign[i]=%d\n",
+			 i);
+		itf_assign[i].ep = ep;
+		set_gsw_itf(ep, 1, itf_assign[i].start);
+		return &itf_assign[i];
+	}
+
+	return NULL;
+}
+
+int reset_gsw_itf(u8 ep)
+{
+	int i;
+
+	if (ep >= PMAC_MAX_NUM)
+		return -1;
+
+	/* only matched the fixed assignment one */
+	for (i = 0; i < ARRAY_SIZE(itf_assign); i++)
+		if (itf_assign[i].ep == ep)
+			break;
+	if (i >= ARRAY_SIZE(itf_assign)) {
+		set_gsw_itf(ep, 0, 0);
+	} else if (itf_assign[i].fixed) {
+		set_gsw_itf(ep, 1, itf_assign[i].start);
+	} else {
+		set_gsw_itf(ep, 0, 0);
+		itf_assign[i].ep = -1;
+	}
+
+	return 0;
+}
+
+int dp_mib_init(u32 flag)
+{
+	spin_lock_init(&dp_mib_lock);
+	memset(&aggregate_mib, 0, sizeof(aggregate_mib));
+	memset(&last, 0, sizeof(last));
+	memset(&last_vap, 0, sizeof(last_vap));
+
+#ifdef THREAD_MODE
+	thread = kthread_run(mib_wraparound_thread, 0, "dp_mib");
+#else
+	init_timer_on_stack(&exp_timer);
+	exp_timer.expires = jiffies + poll_interval;
+	exp_timer.data = 0;
+	exp_timer.function = mib_wraparound_timer_poll;
+	add_timer(&exp_timer);
+	PR_INFO("dp_mib_init done\n");
+#endif
+	return 0;
+}
+
+void dp_mib_exit(void)
+{
+#ifdef THREAD_MODE
+	if (thread)
+		kthread_stop(thread);
+#else
+	del_timer(&exp_timer);
+#endif
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.h b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.h
new file mode 100644
index 000000000000..dc4dc4e81350
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.h
@@ -0,0 +1,20 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#ifndef DATAPATH_MIB_H
+#define DATAPATH_MIB_H
+
+int dp_reset_mib(u32 flag);
+int set_gsw_itf(u8 ep, u8 ena, int start);
+struct gsw_itf *get_free_itf(u8 ep, u32 flag);
+int reset_gsw_itf(u8 ep);
+int dp_get_port_vap_mib_30(dp_subif_t *subif, void *priv,
+			   struct rtnl_link_stats64 *net_mib, u32 flag);
+
+#endif
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c
new file mode 100644
index 000000000000..8c03e4601c63
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c
@@ -0,0 +1,680 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/version.h>
+#include <linux/if_ether.h>
+#include <linux/ethtool.h>
+#include <linux/proc_fs.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/clk.h>
+#include <linux/if_ether.h>
+#include <linux/if_vlan.h>
+
+#include <linux/clk.h>
+#include <linux/ip.h>
+#include <net/ip.h>
+
+#include <lantiq.h>
+#include <lantiq_soc.h>
+#include <net/lantiq_cbm_api.h>
+#define DATAPATH_HAL_LAYER   /*must put before include datapath_api.h in
+			      *order to avoid include another platform's
+			      *DMA descriptor and pmac header files
+			      */
+#include <net/lantiq_cbm_api.h>
+#include <net/datapath_api.h>
+#include <net/datapath_api_gswip30.h>
+#include "../datapath.h"
+#include "datapath_proc.h"
+#include "datapath_misc.h"
+#include "datapath_mib.h"
+
+#ifdef CONFIG_LTQ_TMU
+#include <net/drv_tmu_ll.h>
+#endif
+
+static void init_dma_desc_mask(void)
+{
+	/*mask 0: to remove the bit, 1 -- keep the bit */
+	dma_rx_desc_mask1.all = 0xFFFFFFFF;
+	dma_rx_desc_mask3.all = 0xFFFFFFFF;
+	dma_rx_desc_mask3.field.own = 0;
+	dma_rx_desc_mask3.field.c = 0;
+	dma_rx_desc_mask3.field.sop = 0;
+	dma_rx_desc_mask3.field.eop = 0;
+	dma_rx_desc_mask3.field.dic = 0;
+	dma_rx_desc_mask3.field.byte_offset = 0;
+	dma_rx_desc_mask1.field.dec = 0;
+	dma_rx_desc_mask1.field.enc = 0;
+	dma_rx_desc_mask1.field.mpe2 = 0;
+	dma_rx_desc_mask1.field.mpe1 = 0;
+	/*mask to keep some value via 1
+	 *set by top application all others set to 0
+	 */
+	dma_tx_desc_mask0.all = 0;
+	dma_tx_desc_mask1.all = 0;
+	dma_tx_desc_mask0.field.flow_id = 0xFF;
+	dma_tx_desc_mask0.field.dest_sub_if_id = 0x7FFF;
+	dma_tx_desc_mask1.field.mpe1 = 0x1;
+	dma_tx_desc_mask1.field.color = 0x3;
+	dma_tx_desc_mask1.field.ep = 0xF;
+}
+
+static void init_dma_pmac_template(int portid, u32 flags)
+{
+	int i;
+	struct pmac_port_info2 *dp_info = &dp_port_info2[0][portid];
+
+	/*Note:
+	 * final tx_dma0 = (tx_dma0 & dma0_mask_template) | dma0_template
+	 * final tx_dma1 = (tx_dma1 & dma1_mask_template) | dma1_template
+	 * final tx_pmac = pmac_template
+	 */
+	memset(dp_info->pmac_template, 0, sizeof(dp_info->pmac_template));
+	memset(dp_info->dma0_template, 0, sizeof(dp_info->dma0_template));
+	memset(dp_info->dma1_template, 0, sizeof(dp_info->dma1_template));
+	for (i = 0; i < MAX_TEMPLATE; i++) {
+		dp_info->dma0_mask_template[i].all = 0xFFFFFFFF;
+		dp_info->dma1_mask_template[i].all = 0xFFFFFFFF;
+	}
+
+	if (flags & DP_F_FAST_ETH_LAN) { /*always with pmac*/
+		/*always with pmac */
+		for (i = 0; i < MAX_TEMPLATE; i++) {
+			dp_info->pmac_template[i].port_map_en = 1;
+			dp_info->pmac_template[i].sppid = PMAC_CPU_ID;
+			dp_info->pmac_template[i].redirect = 0;
+			dp_info->pmac_template[i].class_en = 1;
+			SET_PMAC_PORTMAP(&dp_info->pmac_template[i], portid);
+		}
+		/*for checksum for pmac_template[1]*/
+		dp_info->pmac_template[TEMPL_CHECKSUM].tcp_chksum = 1;
+	} else if (flags & DP_F_FAST_ETH_WAN) {/*always with pmac*/
+		/*always with pmac */
+		for (i = 0; i < MAX_TEMPLATE; i++) {
+			dp_info->pmac_template[i].port_map_en = 1;
+			dp_info->pmac_template[i].sppid = PMAC_CPU_ID;
+			dp_info->pmac_template[i].redirect = 1;
+			dp_info->pmac_template[i].class_en = 1;
+			SET_PMAC_PORTMAP(&dp_info->pmac_template[i], portid);
+		}
+		/*for checksum for pmac_template[1]*/
+		dp_info->pmac_template[TEMPL_CHECKSUM].tcp_chksum = 1;
+	} else if (flags & DP_F_FAST_WLAN) {
+		/*someties with pma
+		 *normal fast_wlan without pmac
+		 *So no need to configure pmac_tmplate[0]
+		 */
+		/*fast_wlan with checksum support */
+		dp_info->pmac_template[TEMPL_CHECKSUM].port_map_en = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].sppid = portid;
+		dp_info->pmac_template[TEMPL_CHECKSUM].redirect = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].tcp_chksum = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_CHECKSUM],
+				 portid);
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.enc = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.dec = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.mpe2 = 1;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.mpe2 = 0;
+	} else if (flags & DP_F_DIRECTLINK) { /*always with pmac*/
+		/*normal dirctpath without checksum support
+		 *but with pmac to Switch for accelerate
+		 */
+		dp_info->pmac_template[TEMPL_NORMAL].port_map_en = 0;
+		dp_info->pmac_template[TEMPL_NORMAL].sppid = portid;
+		dp_info->pmac_template[TEMPL_NORMAL].redirect = 0;
+		dp_info->pmac_template[TEMPL_NORMAL].port_map = 0xff;
+		dp_info->pmac_template[TEMPL_NORMAL].port_map2 = 0xff;
+		dp_info->pmac_template[TEMPL_NORMAL].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_NORMAL], portid);
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.enc = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.dec = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.mpe2 = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.mpe2 = 0;
+
+		/*dirctpath with checksum support */
+		dp_info->pmac_template[TEMPL_CHECKSUM].port_map_en = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].sppid = portid;
+		dp_info->pmac_template[TEMPL_CHECKSUM].redirect = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].tcp_chksum = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_CHECKSUM],
+				 portid);
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.enc = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.dec = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.mpe2 = 1;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.mpe2 = 0;
+
+		/*dirctpath w/o checksum support but send packet to MPE DL FW*/
+		dp_info->pmac_template[TEMPL_OTHERS].port_map_en = 1;
+		dp_info->pmac_template[TEMPL_OTHERS].sppid = portid;
+		dp_info->pmac_template[TEMPL_OTHERS].redirect = 1;
+		dp_info->pmac_template[TEMPL_OTHERS].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_OTHERS], portid);
+#if defined(CONFIG_ACCL_11AC_CS2) || defined(CONFIG_ACCL_11AC_CS2_MODULE)
+		/* CPU traffic to PAE via cbm to apply PCE rule */
+		dp_info->dma1_template[TEMPL_OTHERS].field.enc = 1;
+		dp_info->dma1_template[TEMPL_OTHERS].field.dec = 1;
+		dp_info->dma1_template[TEMPL_OTHERS].field.mpe2 = 0;
+		dp_info->dma1_mask_template[TEMPL_OTHERS].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_OTHERS].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_OTHERS].field.mpe2 = 0;
+#endif
+	} else if (flags & DP_F_FAST_DSL) {
+		/* For normal single DSL upstream, there is no pmac at all*/
+		dp_info->dma1_template[TEMPL_NORMAL].field.dec = 1;
+		dp_info->dma1_template[TEMPL_NORMAL].field.mpe2 = 1;
+		dp_info->dma1_mask_template[TEMPL_NORMAL].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_NORMAL].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_NORMAL].field.mpe2 = 0;
+
+		/*DSL  with checksum support */
+		dp_info->pmac_template[TEMPL_CHECKSUM].port_map_en = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].sppid = portid;
+		dp_info->pmac_template[TEMPL_CHECKSUM].redirect = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].tcp_chksum = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_CHECKSUM],
+				 portid);
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.enc = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.dec = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.mpe2 = 1;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.mpe2 = 0;
+
+		/*Bonding DSL  FCS Support via GSWIP */
+		dp_info->pmac_template[TEMPL_OTHERS].port_map_en = 1;
+		dp_info->pmac_template[TEMPL_OTHERS].sppid = portid;
+		dp_info->pmac_template[TEMPL_OTHERS].redirect = 1;
+		/*dp_info->pmac_template[TEMPL_OTHERS].tcp_chksum = 1; */
+		dp_info->pmac_template[TEMPL_OTHERS].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_CHECKSUM],
+				 portid);
+		dp_info->dma1_template[TEMPL_OTHERS].field.enc = 1;
+		dp_info->dma1_template[TEMPL_OTHERS].field.dec = 1;
+		dp_info->dma1_template[TEMPL_OTHERS].field.mpe2 = 1;
+		dp_info->dma1_mask_template[TEMPL_OTHERS].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_OTHERS].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_OTHERS].field.mpe2 = 0;
+	} else /*if(flags & DP_F_DIRECT ) */{/*always with pmac*/
+		/*normal dirctpath without checksum support */
+		dp_info->pmac_template[TEMPL_NORMAL].port_map_en = 0;
+		dp_info->pmac_template[TEMPL_NORMAL].sppid = portid;
+		dp_info->pmac_template[TEMPL_NORMAL].redirect = 0;
+		dp_info->pmac_template[TEMPL_NORMAL].port_map = 0xff;
+		dp_info->pmac_template[TEMPL_NORMAL].port_map2 = 0xff;
+		dp_info->pmac_template[TEMPL_NORMAL].class_en = 1;
+		dp_info->dma1_template[TEMPL_NORMAL].field.enc = 1;
+		dp_info->dma1_template[TEMPL_NORMAL].field.dec = 1;
+		dp_info->dma1_template[TEMPL_NORMAL].field.mpe2 = 0;
+		dp_info->dma1_mask_template[TEMPL_NORMAL].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_NORMAL].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_NORMAL].field.mpe2 = 0;
+
+		/*dirctpath with checksum support */
+		dp_info->pmac_template[TEMPL_CHECKSUM].port_map_en = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].sppid = PMAC_CPU_ID;
+		dp_info->pmac_template[TEMPL_CHECKSUM].redirect = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].tcp_chksum = 1;
+		dp_info->pmac_template[TEMPL_CHECKSUM].class_en = 1;
+		SET_PMAC_PORTMAP(&dp_info->pmac_template[TEMPL_CHECKSUM],
+				 portid);
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.enc = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.dec = 1;
+		dp_info->dma1_template[TEMPL_CHECKSUM].field.mpe2 = 1;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.enc = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.dec = 0;
+		dp_info->dma1_mask_template[TEMPL_CHECKSUM].field.mpe2 = 0;
+	}
+}
+
+static void dump_rx_dma_desc(struct dma_rx_desc_0 *desc_0,
+			     struct dma_rx_desc_1 *desc_1,
+			     struct dma_rx_desc_2 *desc_2,
+			     struct dma_rx_desc_3 *desc_3)
+{
+	if (!desc_0 || !desc_1 || !desc_2 || !desc_3) {
+		PR_ERR("rx desc_0/1/2/3 NULL\n");
+		return;
+	}
+	PR_INFO(" DMA Descripotr:D0=0x%08x D1=0x%08x D2=0x%08x D3=0x%08x\n",
+		*(u32 *)desc_0, *(u32 *)desc_1,
+		*(u32 *)desc_2, *(u32 *)desc_3);
+	PR_INFO("  DW0:%s=%d tunl_id=%d flow_id=%d eth_type=%d subif=0x%04x\n",
+		"resv0", desc_0->field.resv0,
+		desc_0->field.tunnel_id,
+		desc_0->field.flow_id, desc_0->field.eth_type,
+		desc_0->field.dest_sub_if_id);
+	PR_INFO("  DW1:sess=%d tcp_err=%d nat=%d dec=%d enc=%d mpe2/1=%d/%d\n",
+		desc_1->field.session_id, desc_1->field.tcp_err,
+		desc_1->field.nat, desc_1->field.dec, desc_1->field.enc,
+		desc_1->field.mpe2, desc_1->field.mpe1);
+	PR_INFO("      color=%02d ep=%02d resv1=%d classid=%02d\n",
+		desc_1->field.color, desc_1->field.ep, desc_1->field.resv1,
+		desc_1->field.classid);
+	PR_INFO("  DW2:data_ptr=0x%08x\n", desc_2->field.data_ptr);
+	PR_INFO("  DW3:own=%d c=%d sop=%d eop=%d dic=%d pdu_type=%d\n",
+		desc_3->field.own, desc_3->field.c, desc_3->field.sop,
+		desc_3->field.eop, desc_3->field.dic, desc_3->field.pdu_type);
+	PR_INFO("      offset=%d atm_q=%d mpoa_pt=%d mpoa_mode=%d len=%d\n",
+		desc_3->field.byte_offset, desc_3->field.qid,
+		desc_3->field.mpoa_pt, desc_3->field.mpoa_mode,
+		desc_3->field.data_len);
+}
+
+static void dump_tx_dma_desc(struct dma_tx_desc_0 *desc_0,
+			     struct dma_tx_desc_1 *desc_1,
+			     struct dma_tx_desc_2 *desc_2,
+			     struct dma_tx_desc_3 *desc_3)
+{
+	int lookup;
+
+	if (!desc_0 || !desc_1 || !desc_2 || !desc_3) {
+		PR_ERR("tx desc_0/1/2/3 NULL\n");
+		return;
+	}
+	PR_INFO(" DMA Descripotr:D0=0x%08x D1=0x%08x D2=0x%08x D3=0x%08x\n",
+		*(u32 *)desc_0, *(u32 *)desc_1,
+		*(u32 *)desc_2, *(u32 *)desc_3);
+	PR_INFO("  DW0:%s=%d tunl_id=%d flow_id=%d eth_type=%d subif=0x%04x\n",
+		"resv0", desc_0->field.resv0,
+		desc_0->field.tunnel_id,
+		desc_0->field.flow_id, desc_0->field.eth_type,
+		desc_0->field.dest_sub_if_id);
+	PR_INFO("  DW1:sess=%d tcp_err=%d nat=%d dec=%d enc=%d mpe2/1=%d/%d\n",
+		desc_1->field.session_id, desc_1->field.tcp_err,
+		desc_1->field.nat, desc_1->field.dec, desc_1->field.enc,
+		desc_1->field.mpe2, desc_1->field.mpe1);
+	PR_INFO("  color=%02d ep=%02d resv1=%d classid=%02d\n",
+		desc_1->field.color, desc_1->field.ep, desc_1->field.resv1,
+		desc_1->field.classid);
+	PR_INFO("  DW2:data_ptr=0x%08x\n", desc_2->field.data_ptr);
+	PR_INFO("  DW3:own=%d c=%d sop=%d eop=%d dic=%d pdu_type=%d\n",
+		desc_3->field.own, desc_3->field.c, desc_3->field.sop,
+		desc_3->field.eop, desc_3->field.dic, desc_3->field.pdu_type);
+	PR_INFO("  offset=%d atm_qid=%d mpoa_pt=%d mpoa_mode=%d len=%d\n",
+		desc_3->field.byte_offset, desc_3->field.qid,
+		desc_3->field.mpoa_pt, desc_3->field.mpoa_mode,
+		desc_3->field.data_len);
+	lookup =
+	    ((desc_0->field.flow_id >> 6) << 12) | ((desc_1->field.
+						     dec) << 11) | ((desc_1->
+								     field.
+								     enc) <<
+								    10) |
+	    ((desc_1->field.mpe2) << 9) | ((desc_1->field.
+					    mpe1) << 8) | ((desc_1->field.
+							    ep) << 4) |
+	    ((desc_1->field.classid) << 0);
+	PR_INFO("  lookup index=0x%x qid=%d\n", lookup,
+		get_lookup_qid_via_index(lookup));
+}
+
+static void dump_rx_pmac(struct pmac_rx_hdr *pmac)
+{
+	int i, l;
+	unsigned char *p = (char *)pmac;
+	unsigned char buf[100];
+
+	if (!pmac) {
+		PR_ERR(" pmac NULL ??\n");
+		return;
+	}
+
+	l = sprintf(buf, "PMAC at 0x%p: ", p);
+	for (i = 0; i < 8; i++)
+		l += sprintf(buf + l, "0x%02x ", p[i]);
+	l += sprintf(buf + l, "\n");
+	PR_INFO("%s", buf);
+
+	/*byte 0 */
+	PR_INFO("  byte 0:res=%d ver_done=%d ip_offset=%d\n", pmac->res1,
+		pmac->ver_done, pmac->ip_offset);
+	/*byte 1 */
+	PR_INFO("  byte 1:tcp_h_offset=%d tcp_type=%d\n", pmac->tcp_h_offset,
+		pmac->tcp_type);
+	/*byte 2 */
+	PR_INFO("  byte 2:ppid=%d class=%d\n", pmac->sppid, pmac->class);
+	/*byte 3 */
+	PR_INFO("  byte 3:res=%d pkt_type=%d\n", pmac->res2, pmac->pkt_type);
+	/*byte 4 */
+	PR_INFO("  byte 4:res=%d redirect=%d res2=%d src_sub_inf_id=%d\n",
+		pmac->res3, pmac->redirect, pmac->res4, pmac->src_sub_inf_id);
+	/*byte 5 */
+	PR_INFO("  byte 5:src_sub_inf_id2=%d\n", pmac->src_sub_inf_id2);
+	/*byte 6 */
+	PR_INFO("  byte 6:port_map=%d\n", pmac->port_map);
+	/*byte 7 */
+	PR_INFO("  byte 7:port_map2=%d\n", pmac->port_map2);
+}
+
+static void dump_tx_pmac(struct pmac_tx_hdr *pmac)
+{
+	int i, l;
+	unsigned char *p = (char *)pmac;
+	unsigned char buf[100];
+
+	if (!pmac) {
+		PR_ERR("dump_tx_pmac pmac NULL ??\n");
+		return;
+	}
+
+	l = sprintf(buf, "PMAC at 0x%p: ", p);
+	for (i = 0; i < 8; i++)
+		l += sprintf(buf + l, "0x%02x ", p[i]);
+	sprintf(buf + l, "\n");
+	PR_INFO("%s", buf);
+	/*byte 0 */
+	PR_INFO("  byte 0:tcp_chksum=%d res=%d ip_offset=%d\n",
+		pmac->tcp_chksum, pmac->res1, pmac->ip_offset);
+	/*byte 1 */
+	PR_INFO("  byte 1:tcp_h_offset=%d tcp_type=%d\n", pmac->tcp_h_offset,
+		pmac->tcp_type);
+	/*byte 2 */
+	PR_INFO("  byte 2:ppid=%d res=%d\n", pmac->sppid, pmac->res);
+	/*byte 3 */
+	PR_INFO("  byte 3:%s=%d %s=%d/%d time_dis=%d class_en=%d pkt_type=%d\n",
+		"map_en", pmac->port_map_en,
+		"res", pmac->res2, pmac->res3,
+		pmac->time_dis, pmac->class_en,
+		pmac->pkt_type);
+	/*byte 4 */
+	PR_INFO("  byte 4:fcs_ins_dis=%d redirect=%d time_stmp=%d subif=%d\n",
+		pmac->fcs_ins_dis, pmac->redirect, pmac->time_stmp,
+		pmac->src_sub_inf_id);
+	/*byte 5 */
+	PR_INFO("  byte 5:src_sub_inf_id2=%d\n", pmac->src_sub_inf_id2);
+	/*byte 6 */
+	PR_INFO("  byte 6:port_map=%d\n", pmac->port_map);
+	/*byte 7 */
+	PR_INFO("  byte 7:port_map2=%d\n", pmac->port_map2);
+}
+
+static void mib_init(u32 flag)
+{
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	dp_mib_init(0);
+#endif
+	gsw_mib_reset_30(0, 0); /* GSW L */
+	gsw_mib_reset_30(1, 0); /* GSW R */
+	cbm_counter_mode_set(0, 1); /*enqueue to byte */
+	cbm_counter_mode_set(1, 1); /*dequeue to byte */
+}
+
+void dp_sys_mib_reset_30(u32 flag)
+{
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	dp_reset_sys_mib(0);
+#else
+	gsw_mib_reset_30(0, 0); /* GSW L */
+	gsw_mib_reset_30(1, 0); /* GSW R */
+	dp_clear_all_mib_inside(0);
+#ifdef CONFIG_LTQ_TMU
+	tmu_reset_mib_all(flag);
+#endif
+#endif
+}
+
+static int dp_platform_set(int inst, u32 flag)
+{
+	if (!inst)/*only inst zero need DMA descriptor */
+		init_dma_desc_mask();
+
+	if (!dp_port_prop[inst].ops[0] ||
+	    !dp_port_prop[inst].ops[1]) {
+		PR_ERR("Why gswip handle zero?\n");
+		return -1;
+	}
+		if (!inst)
+			dp_sub_proc_install_30();
+	if (!inst)
+		mib_init(0);
+	dp_get_gsw_parser_30(NULL, NULL, NULL, NULL);
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+	if (!inst)
+		dp_coc_cpufreq_init();
+#endif
+
+	return 0;
+}
+
+static int port_platform_set(int inst, u8 ep, struct dp_port_data *data,
+			     u32 flags)
+{
+	int idx, i;
+	struct pmac_port_info *port_info = &dp_port_info[inst][ep];
+
+	dp_port_info[inst][ep].ctp_max = MAX_SUBIF_PER_PORT;
+	dp_port_info[inst][ep].vap_offset = 8;
+	dp_port_info[inst][ep].vap_mask = 0xF;
+	idx = port_info->deq_port_base;
+	for (i = 0; i < port_info->deq_port_num; i++)
+		dp_deq_port_tbl[inst][i + idx].dp_port = ep;
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	if (flags & DP_F_DEREGISTER) {
+		reset_gsw_itf(ep);
+		return 0;
+	}
+
+	dp_port_info[inst][ep].itf_info = get_free_itf(ep, flags);
+	return 0;
+#else
+	return 0;
+#endif
+}
+
+static int supported_logic_dev(int inst, struct net_device *dev,
+			       char *subif_name)
+{
+	return is_vlan_dev(dev);
+}
+
+static int subif_hw_set(int inst, int portid, int subif_ix,
+			struct subif_platform_data *data, u32 flags)
+{
+	int deq_port_idx = 0, cqe_deq;
+	struct pmac_port_info *port_info;
+
+	if (!data || !data->subif_data) {
+		PR_ERR("data NULL or subif_data NULL\n");
+		return -1;
+	}
+	port_info = &dp_port_info[inst][portid];
+	if (data->subif_data)
+		deq_port_idx = data->subif_data->deq_port_idx;
+	if (port_info->deq_port_num < deq_port_idx + 1) {
+		PR_ERR("Wrong deq_port_idx(%d), should < %d\n",
+		       deq_port_idx, port_info->deq_port_num);
+		return -1;
+	}
+	cqe_deq = port_info->deq_port_base + deq_port_idx;
+	port_info->subif_info[subif_ix].cqm_deq_port = cqe_deq;
+	dp_deq_port_tbl[inst][cqe_deq].ref_cnt++;
+	DP_DEBUG(DP_DBG_FLAG_REG, "cbm[%d].ref_cnt=%d\n",
+		 cqe_deq,
+		 dp_deq_port_tbl[inst][cqe_deq].ref_cnt);
+	return 0;
+}
+
+static int subif_hw_reset(int inst, int portid, int subif_ix,
+			  struct subif_platform_data *data, u32 flags)
+{
+	int deq_port_idx = 0, cqe_deq;
+	struct pmac_port_info *port_info;
+
+	if (!data || !data->subif_data) {
+		PR_ERR("data NULL or subif_data NULL\n");
+		return -1;
+	}
+	port_info = &dp_port_info[inst][portid];
+	if (data->subif_data)
+		deq_port_idx = data->subif_data->deq_port_idx;
+	if (port_info->deq_port_num < deq_port_idx + 1) {
+		PR_ERR("Wrong deq_port_idx(%d), should < %d\n",
+		       deq_port_idx, port_info->deq_port_num);
+		return -1;
+	}
+	cqe_deq = port_info->deq_port_base + deq_port_idx;
+	if (!dp_deq_port_tbl[inst][cqe_deq].ref_cnt) {
+		PR_ERR("Wrong cbm[%d].ref_cnt=%d\n",
+		       cqe_deq,
+		       dp_deq_port_tbl[inst][cqe_deq].ref_cnt);
+		return -1;
+	}
+	dp_deq_port_tbl[inst][cqe_deq].ref_cnt--;
+	DP_DEBUG(DP_DBG_FLAG_REG, "cbm[%d].ref_cnt=%d\n",
+		 cqe_deq,
+		 dp_deq_port_tbl[inst][cqe_deq].ref_cnt);
+	return 0;
+}
+
+static int subif_platform_set(int inst, int portid, int subif_ix,
+			      struct subif_platform_data *data, u32 flags)
+{
+	if (flags & DP_F_DEREGISTER)
+		return subif_hw_reset(inst, portid, subif_ix, data, flags);
+	return subif_hw_set(inst, portid, subif_ix, data, flags);
+}
+
+static int subif_platform_set_unexplicit(int inst, int port_id,
+					 struct logic_dev *dev,
+					 u32 flag)
+{
+	return 0;
+}
+
+static int not_valid_rx_ep(int ep)
+{
+	return (((ep >= 1) && (ep <= 6)) || (ep >= 15));
+}
+
+static void set_pmac_subif(struct pmac_tx_hdr *pmac, int32_t subif)
+{
+	pmac->src_sub_inf_id2 = subif & 0xff;
+	pmac->src_sub_inf_id =  (subif >> 8) & 0x1f;
+}
+
+static void update_port_vap(int inst, u32 *ep, int *vap,
+			    struct sk_buff *skb,
+			    struct pmac_rx_hdr *pmac, char *decryp)
+{
+	*ep = pmac->sppid; /*get the port_id from pmac's sppid */
+	if (dp_port_info[inst][*ep].alloc_flags & DP_F_LOOPBACK) {
+		*ep = GET_VAP((u32)pmac->src_sub_inf_id2 +
+			(u32)(pmac->src_sub_inf_id << 8),
+			PORT_INFO(inst, *ep, vap_offset),
+			PORT_INFO(inst, *ep, vap_mask));
+		*vap = 0;
+		*decryp = 1;
+	} else
+		*vap = GET_VAP((u32)pmac->src_sub_inf_id2 +
+			(u32)(pmac->src_sub_inf_id << 8),
+			PORT_INFO(inst, *ep, vap_offset),
+			PORT_INFO(inst, *ep, vap_mask));
+}
+
+static void get_dma_pmac_templ(int index, struct pmac_tx_hdr *pmac,
+			       struct dma_tx_desc_0 *desc_0,
+			       struct dma_tx_desc_1 *desc_1,
+			       struct pmac_port_info2 *dp_info)
+{
+	if (likely(pmac))
+		memcpy(pmac, &dp_info->pmac_template[index], sizeof(*pmac));
+	desc_1->all = (desc_1->all & dp_info->dma1_mask_template[index].all) |
+				dp_info->dma1_template[index].all;
+}
+
+static int check_csum_cap(void)
+{
+	return 1;
+}
+
+static int get_itf_start_end(struct gsw_itf *itf_info, u16 *start, u16 *end)
+{
+	if (!itf_info)
+		return -1;
+	if (start)
+		*start = itf_info->start;
+	if (end)
+		*end = itf_info->end;
+
+	return 0;
+}
+
+int register_dp_cap_gswip30(int flag)
+{
+	struct dp_hw_cap cap;
+
+	memset(&cap, 0, sizeof(cap));
+	cap.info.type = GSWIP30_TYPE;
+	cap.info.ver = GSWIP30_VER;
+	cap.info.dp_platform_set = dp_platform_set;
+	cap.info.port_platform_set = port_platform_set;
+	cap.info.subif_platform_set_unexplicit = subif_platform_set_unexplicit;
+	cap.info.proc_print_ctp_bp_info = NULL;
+	cap.info.init_dma_pmac_template = init_dma_pmac_template;
+	//dp.info.port_platform_set_unexplicit = port_platform_set_unexplicit;
+	cap.info.subif_platform_set = subif_platform_set;
+	cap.info.init_dma_pmac_template = init_dma_pmac_template;
+	cap.info.not_valid_rx_ep = not_valid_rx_ep;
+	cap.info.set_pmac_subif = set_pmac_subif;
+	cap.info.update_port_vap = update_port_vap;
+	cap.info.check_csum_cap = check_csum_cap;
+	cap.info.get_dma_pmac_templ = get_dma_pmac_templ;
+	cap.info.get_itf_start_end = get_itf_start_end;
+	cap.info.dump_rx_dma_desc = dump_rx_dma_desc;
+	cap.info.dump_tx_dma_desc = dump_tx_dma_desc;
+	cap.info.dump_rx_pmac = dump_rx_pmac;
+	cap.info.dump_tx_pmac = dump_tx_pmac;
+	cap.info.supported_logic_dev = supported_logic_dev;
+	cap.info.dp_pmac_set = dp_pmac_set_30;
+	cap.info.dp_set_gsw_parser = dp_set_gsw_parser_30;
+	cap.info.dp_get_gsw_parser = dp_get_gsw_parser_30;
+#ifdef CONFIG_LTQ_DATAPATH_HAL_GSWIP30_MIB
+	cap.info.dp_get_port_vap_mib = dp_get_port_vap_mib_30;
+	cap.info.dp_clear_netif_mib = dp_clear_netif_mib_30;
+#endif
+	cap.info.cap.tx_hw_chksum = 1;
+	cap.info.cap.rx_hw_chksum = 1;
+	cap.info.cap.hw_tso = 1;
+	cap.info.cap.hw_gso = 1;
+	strncpy(cap.info.cap.qos_eng_name, "TMU",
+		sizeof(cap.info.cap.qos_eng_name));
+	strncpy(cap.info.cap.pkt_eng_name, "PAE/MPE",
+		sizeof(cap.info.cap.pkt_eng_name));
+	cap.info.cap.max_num_queues = 128;
+	cap.info.cap.max_num_scheds = 128;
+	cap.info.cap.max_num_deq_ports = 24;
+	cap.info.cap.max_num_qos_ports = 24;
+	cap.info.cap.max_num_dp_ports = PMAC_MAX_NUM;
+	cap.info.cap.max_num_subif_per_port = 16;
+	cap.info.cap.max_num_subif = 256;
+	cap.info.cap.max_num_bridge_port = 0;
+
+	if (register_dp_hw_cap(&cap, flag)) {
+		PR_ERR("Why register_dp_hw_cap fail\n");
+		return -1;
+	}
+
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h
new file mode 100644
index 000000000000..4387956b4542
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h
@@ -0,0 +1,82 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#ifndef DATAPATH_MISC30_H
+#define DATAPATH_MISC30_H
+
+#define PMAC_MAX_NUM  16
+#define PAMC_LAN_MAX_NUM 7
+#define VAP_OFFSET 8
+#define VAP_MASK  0xF
+#define VAP_DSL_OFFSET 3
+#define NEW_CBM_API 1
+
+#define GSWIP_L 0
+#define GSWIP_R 1
+#define MAX_SUBIF_PER_PORT 16
+#define PMAC_SIZE 8
+
+struct gsw_itf {
+	u8 ep; /*-1 means no assigned yet for dynamic case */
+	u8 fixed; /*fixed (1) or dynamically allocate (0)*/
+	u16 start;
+	u16 end;
+	u16 n;
+};
+
+#define SET_PMAC_PORTMAP(pmac, port_id) do { \
+	if ((port_id) <= 7) \
+		(pmac)->port_map2 = 1 << (port_id); \
+	else \
+		(pmac)->port_map = (1 << (port_id - 8)); } \
+	while (0)
+
+#define SET_PMAC_SUBIF(pmac, subif) do { \
+	(pmac)->src_sub_inf_id2 = (subif) & 0xff; \
+	(pmac)->src_sub_inf_id =  ((subif) >> 8) & 0x1f; } \
+	while (0)
+
+int dp_sub_proc_install_30(void);
+void dp_sys_mib_reset_30(u32 flag);
+int dp_set_gsw_parser_30(u8 flag, u8 cpu, u8 mpe1, u8 mpe2, u8 mpe3);
+int dp_get_gsw_parser_30(u8 *cpu, u8 *mpe1, u8 *mpe2, u8 *mpe3);
+int gsw_mib_reset_30(int dev, u32 flag);
+int dp_pmac_set_30(int inst, u32 port, dp_pmac_cfg_t *pmac_cfg);
+
+static inline GSW_return_t gsw_core_api(dp_gsw_cb func,
+					void *ops, void *param)
+{
+	#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+		if (dp_dbg_flag & DP_DBG_FLAG_GSWIP_API)
+			print_symbol_name((unsigned long)func);
+	#endif
+	return func(ops, param);
+}
+
+static inline char *parser_flag_str(u8 f)
+{
+	if (f == DP_PARSER_F_DISABLE)
+		return "No Parser";
+	else if (f == DP_PARSER_F_HDR_ENABLE)
+		return "Parser Flag only";
+	else if (f == DP_PARSER_F_HDR_OFFSETS_ENABLE)
+		return "Parser Full";
+	else
+		return "Reserved";
+}
+
+ssize_t proc_get_qid_via_index(struct file *file, const char *buf,
+			       size_t count, loff_t *ppos);
+int lookup_dump30(struct seq_file *s, int pos);
+int lookup_start30(void);
+ssize_t proc_get_qid_via_index30(struct file *file, const char *buf,
+				 size_t count, loff_t *ppos);
+
+#endif
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_proc.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_proc.c
new file mode 100644
index 000000000000..1ab90ba865f9
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_proc.c
@@ -0,0 +1,3385 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+#include <linux/module.h>
+#include <net/datapath_proc_api.h>	/*for proc api*/
+#include <net/datapath_api.h>
+#include <net/drv_tmu_ll.h>
+#include <linux/list.h>
+#include <net/lantiq_cbm_api.h>
+#include "../../cqm/grx500/reg/fsqm.h" /* hardcoded path*/
+
+#include <linux/list.h>
+
+#include "../datapath.h"
+#include "datapath_misc.h"
+
+#define PROC_PARSER "parser"
+#define PROC_RMON_PORTS  "rmon"
+#define PROC_MIB_TIMER "mib_timer"
+#define PROC_MIB_INSIDE "mib_inside"
+#define PROC_MIBPORT "mib_port"
+#define PROC_CHECKSUM "checksum"
+#define PROC_MIBVAP "mib_vap"
+#define PROC_COMMON_CMD "cmd"
+#define PROC_COC "coc"
+#define PROC_CBM_BUF_TEST   "cbm_buf"
+#define PROC_PCE  "pce"
+#define PROC_ROUTE  "route"
+#define PROC_PMAC  "pmac"
+#define PROC_EP "ep"	/*EP/port ID info */
+#define PROC_DPORT "dport"	/*TMU dequeue port info */
+#define DP_PROC_CBMLOOKUP "lookup"
+
+#define MAX_GSW_L_PMAC_PORT  7
+#define MAX_GSW_R_PMAC_PORT  16
+static GSW_RMON_Port_cnt_t gsw_l_rmon_mib[MAX_GSW_L_PMAC_PORT];
+static GSW_RMON_Port_cnt_t gsw_r_rmon_mib[MAX_GSW_R_PMAC_PORT];
+static GSW_RMON_Redirect_cnt_t gswr_rmon_redirect;
+
+enum RMON_MIB_TYPE {
+	RX_GOOD_PKTS = 0,
+	RX_FILTER_PKTS,
+	RX_DROP_PKTS,
+	RX_OTHERS,
+
+	TX_GOOD_PKTS,
+	TX_ACM_PKTS,
+	TX_DROP_PKTS,
+	TX_OTHERS,
+
+	REDIRECT_MIB,
+	DP_DRV_MIB,
+
+	/*last entry */
+	RMON_MAX
+};
+
+static char f_q_mib_title_proc;
+static int tmp_inst;
+
+#define RMON_DASH_LINE 130
+static void print_dash_line(struct seq_file *s)
+{
+	char buf[RMON_DASH_LINE + 4];
+
+	memset(buf, '-', RMON_DASH_LINE);
+	sprintf(buf + RMON_DASH_LINE, "\n");
+	seq_puts(s, buf);
+}
+
+#define GSW_PORT_RMON_PRINT(title, var)  do { \
+	seq_printf(s, \
+		   "%-14s%10s %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title, "L(0-6)", \
+		   gsw_l_rmon_mib[0].var, gsw_l_rmon_mib[1].var, \
+		   gsw_l_rmon_mib[2].var, gsw_l_rmon_mib[3].var, \
+		   gsw_l_rmon_mib[4].var, gsw_l_rmon_mib[5].var, \
+		   gsw_l_rmon_mib[6].var); \
+	seq_printf(s, \
+		   "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title, "R(0-6,15)", \
+		   gsw_r_rmon_mib[0].var, gsw_r_rmon_mib[1].var, \
+		   gsw_r_rmon_mib[2].var, gsw_r_rmon_mib[3].var, \
+		   gsw_r_rmon_mib[4].var, gsw_r_rmon_mib[5].var, \
+		   gsw_r_rmon_mib[6].var, gsw_r_rmon_mib[15].var); \
+	seq_printf(s, \
+		   "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title, "R(7-14)", \
+		   gsw_r_rmon_mib[7].var, gsw_r_rmon_mib[8].var, \
+		   gsw_r_rmon_mib[9].var, gsw_r_rmon_mib[10].var, \
+		   gsw_r_rmon_mib[11].var, gsw_r_rmon_mib[12].var, \
+		   gsw_r_rmon_mib[13].var, gsw_r_rmon_mib[14].var); \
+	print_dash_line(s); \
+} while (0)
+
+static void proc_checksum_read(struct seq_file *s);
+static void proc_parser_read(struct seq_file *s);
+static ssize_t proc_parser_write(struct file *, const char *, size_t,
+				 loff_t *);
+static ssize_t proc_checksum_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos);
+static ssize_t proc_cbm_buf_write(struct file *file, const char *buf,
+				  size_t count, loff_t *ppos);
+static void proc_cbm_buf_read(struct seq_file *s);
+static int proc_gsw_pce_dump(struct seq_file *s, int pos);
+static int proc_gsw_pce_start(void);
+static ssize_t proc_gsw_route_write(struct file *file, const char *buf,
+				    size_t count, loff_t *ppos);
+static ssize_t proc_gsw_pmac_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos);
+static int proc_ep_dump(struct seq_file *s, int pos);
+static ssize_t ep_port_write(struct file *, const char *, size_t, loff_t *);
+static int proc_dport_dump(struct seq_file *s, int pos);
+static int proc_gsw_route_dump(struct seq_file *seq, int pos);
+static int rmon_display_tmu_mib = 1;
+static int rmon_display_port_full;
+
+#ifndef CONFIG_LTQ_TMU
+void tmu_qoct_read(const u32 qid,
+		   u32 *wq,
+		   u32 *qrth, u32 *qocc, u32 *qavg)
+{
+}
+
+void tmu_qdct_read(const u32 qid, u32 *qdc)
+{
+}
+
+char *get_dma_flags_str(u32 epn, char *buf, int buf_len)
+{
+	return NULL;
+}
+
+void tmu_equeue_link_get(const u32 qid, struct tmu_equeue_link *link)
+{
+}
+
+u32 get_enq_counter(u32 index)
+{
+	return 0;
+}
+
+u32 get_deq_counter(u32 index)
+{
+	return 0;
+}
+
+#endif
+
+static void proc_parser_read(struct seq_file *s)
+{
+	s8 cpu, mpe1, mpe2, mpe3;
+
+	dp_get_gsw_parser_30(&cpu, &mpe1, &mpe2, &mpe3);
+	seq_printf(s, "cpu : %s with parser size =%d bytes\n",
+		   parser_flag_str(cpu), parser_size_via_index(0));
+	seq_printf(s, "mpe1: %s with parser size =%d bytes\n",
+		   parser_flag_str(mpe1), parser_size_via_index(1));
+	seq_printf(s, "mpe2: %s with parser size =%d bytes\n",
+		   parser_flag_str(mpe2), parser_size_via_index(2));
+	seq_printf(s, "mpe3: %s with parser size =%d bytes\n",
+		   parser_flag_str(mpe3), parser_size_via_index(3));
+}
+
+static ssize_t proc_parser_write(struct file *file, const char *buf,
+				 size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num, i;
+	char *param_list[20];
+	s8 cpu = 0, mpe1 = 0, mpe2 = 0, mpe3 = 0, flag = 0;
+	static int pce_rule_id;
+	static GSW_PCE_rule_t pce;
+	int inst = 0;
+	struct core_ops *gsw_handle;
+
+	memset(&pce, 0, sizeof(pce));
+	gsw_handle = dp_port_prop[inst].ops[GSWIP_R];
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (dp_strncmpi(param_list[0], "enable", strlen("enable")) == 0) {
+		for (i = 1; i < num; i++) {
+			if (dp_strncmpi(param_list[i], "cpu", strlen("cpu")) == 0) {
+				flag |= 0x1;
+				cpu = 2;
+			}
+
+			if (dp_strncmpi(param_list[i], "mpe1", strlen("mpe1")) == 0) {
+				flag |= 0x2;
+				mpe1 = 2;
+			}
+
+			if (dp_strncmpi(param_list[i], "mpe2", strlen("mpe2")) == 0) {
+				flag |= 0x4;
+				mpe2 = 2;
+			}
+
+			if (dp_strncmpi(param_list[i], "mpe3", strlen("mpe3")) == 0) {
+				flag |= 0x8;
+				mpe3 = 2;
+			}
+		}
+
+		if (!flag) {
+			flag = 0x1 | 0x2 | 0x4 | 0x8;
+			cpu = 2;
+			mpe1 = 2;
+			mpe2 = 2;
+			mpe3 = 2;
+		}
+
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "flag=0x%x mpe3/2/1/cpu=%d/%d/%d/%d\n", flag, mpe3,
+			 mpe2, mpe1, cpu);
+		dp_set_gsw_parser_30(flag, cpu, mpe1, mpe2, mpe3);
+	} else if (dp_strncmpi(param_list[0], "disable", strlen("disable")) == 0) {
+		for (i = 1; i < num; i++) {
+			if (dp_strncmpi(param_list[i], "cpu", strlen("cpu")) == 0) {
+				flag |= 0x1;
+				cpu = 0;
+			}
+
+			if (dp_strncmpi(param_list[i], "mpe1", strlen("mpe1")) == 0) {
+				flag |= 0x2;
+				mpe1 = 0;
+			}
+
+			if (dp_strncmpi(param_list[i], "mpe2", strlen("mpe2")) == 0) {
+				flag |= 0x4;
+				mpe2 = 0;
+			}
+
+			if (dp_strncmpi(param_list[i], "mpe3", strlen("mpe3")) == 0) {
+				flag |= 0x8;
+				mpe3 = 0;
+			}
+		}
+
+		if (!flag) {
+			flag = 0x1 | 0x2 | 0x4 | 0x8;
+			cpu = 0;
+			mpe1 = 0;
+			mpe2 = 0;
+			mpe3 = 0;
+		}
+
+		DP_DEBUG(DP_DBG_FLAG_DBG,
+			 "flag=0x%x mpe3/2/1/cpu=%d/%d/%d/%d\n", flag, mpe3,
+			 mpe2, mpe1, cpu);
+		dp_set_gsw_parser_30(flag, cpu, mpe1, mpe2, mpe3);
+	} else if (dp_strncmpi(param_list[0], "refresh", strlen("refresh")) == 0) {
+		dp_get_gsw_parser_30(NULL, NULL, NULL, NULL);
+		PR_INFO("value:cpu=%d mpe1=%d mpe2=%d mpe3=%d\n", pinfo[0].v,
+			pinfo[1].v, pinfo[2].v, pinfo[3].v);
+		PR_INFO("size :cpu=%d mpe1=%d mpe2=%d mpe3=%d\n",
+			pinfo[0].size, pinfo[1].size, pinfo[2].size,
+			pinfo[3].size);
+		return count;
+	} else if (dp_strncmpi(param_list[0], "mark", strlen("mark")) == 0) {
+		int flag = dp_atoi(param_list[1]);
+
+		if (flag < 0)
+			flag = 0;
+		else if (flag > 3)
+			flag = 3;
+		PR_INFO("eProcessPath_Action set to %d\n", flag);
+		/*: All packets set to same mpe flag as specified */
+		memset(&pce, 0, sizeof(pce));
+		pce.pattern.nIndex = pce_rule_id;
+		pce.pattern.bEnable = 1;
+
+		pce.pattern.bParserFlagMSB_Enable = 1;
+		pce.pattern.nParserFlagMSB_Mask = 0xffff;
+		pce.pattern.bParserFlagLSB_Enable = 1;
+		pce.pattern.nParserFlagLSB_Mask = 0xffff;
+		pce.pattern.nDstIP_Mask = 0xffffffff;
+		pce.pattern.bDstIP_Exclude = 0;
+
+		pce.action.bRtDstPortMaskCmp_Action = 1;
+		pce.action.bRtSrcPortMaskCmp_Action = 1;
+		pce.action.bRtDstIpMaskCmp_Action = 1;
+		pce.action.bRtSrcIpMaskCmp_Action = 1;
+
+		pce.action.bRoutExtId_Action = 1;
+		pce.action.nRoutExtId = 0; /*RT_EXTID_UDP; */
+		pce.action.bRtAccelEna_Action = 1;
+		pce.action.bRtCtrlEna_Action = 1;
+		pce.action.eProcessPath_Action = flag;
+		pce.action.bRMON_Action = 1;
+		pce.action.nRMON_Id = 0;	/*RMON_UDP_CNTR; */
+
+		if (gsw_core_api((dp_gsw_cb)gsw_handle->gsw_tflow_ops
+				 .TFLOW_PceRuleWrite, gsw_handle, &pce)) {
+			PR_ERR("PCE rule add fail for GSW_PCE_RULE_WRITE\n");
+			return count;
+		}
+
+	} else if (dp_strncmpi(param_list[0], "unmark", strlen("unmark")) == 0) {
+		/*: All packets set to same mpe flag as specified */
+		memset(&pce, 0, sizeof(pce));
+		pce.pattern.nIndex = pce_rule_id;
+		pce.pattern.bEnable = 0;
+		if (gsw_core_api((dp_gsw_cb)gsw_handle->gsw_tflow_ops
+				 .TFLOW_PceRuleWrite, gsw_handle, &pce)) {
+			PR_ERR("PCE rule add fail for GSW_PCE_RULE_WRITE\n");
+			return count;
+		}
+	} else {
+		PR_INFO("Usage: echo %s > parser\n",
+			"<enable/disable> [cpu] [mpe1] [mpe2] [mpe3]");
+		PR_INFO("Usage: echo <refresh> parser\n");
+
+		PR_INFO("Usage: echo %s > parser\n",
+			" mark eProcessPath_Action_value(0~3)");
+		PR_INFO("Usage: echo unmark > parser\n");
+		return count;
+	}
+
+	return count;
+}
+
+#define GSW_PORT_RMON64_PRINT(title, var)  do { \
+	seq_printf(s, "%-14s%10s %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title "(H)", "L(0-6)", \
+		   high_10dec(gsw_l_rmon_mib[0].var), \
+		   high_10dec(gsw_l_rmon_mib[1].var), \
+		   high_10dec(gsw_l_rmon_mib[2].var),  \
+		   high_10dec(gsw_l_rmon_mib[3].var), \
+		   high_10dec(gsw_l_rmon_mib[4].var),  \
+		   high_10dec(gsw_l_rmon_mib[5].var), \
+		   high_10dec(gsw_l_rmon_mib[6].var)); \
+	seq_printf(s, "%-14s%10s %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title "(L)", "L(0-6)", \
+		   low_10dec(gsw_l_rmon_mib[0].var), \
+		   low_10dec(gsw_l_rmon_mib[1].var), \
+		   low_10dec(gsw_l_rmon_mib[2].var), \
+		   low_10dec(gsw_l_rmon_mib[3].var), \
+		   low_10dec(gsw_l_rmon_mib[4].var), \
+		   low_10dec(gsw_l_rmon_mib[5].var), \
+		   low_10dec(gsw_l_rmon_mib[6].var)); \
+	seq_printf(s, "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title "(H)", "R(0-6,15)", \
+		   high_10dec(gsw_r_rmon_mib[0].var), \
+		   high_10dec(gsw_r_rmon_mib[1].var), \
+		   high_10dec(gsw_r_rmon_mib[2].var), \
+		   high_10dec(gsw_r_rmon_mib[3].var), \
+		   high_10dec(gsw_r_rmon_mib[4].var), \
+		   high_10dec(gsw_r_rmon_mib[5].var), \
+		   high_10dec(gsw_r_rmon_mib[6].var), \
+		   high_10dec(gsw_r_rmon_mib[15].var)); \
+	seq_printf(s, "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title "(L)", "R(0-6,15)", \
+		   low_10dec(gsw_r_rmon_mib[0].var), \
+		   low_10dec(gsw_r_rmon_mib[1].var), \
+		   low_10dec(gsw_r_rmon_mib[2].var), \
+		   low_10dec(gsw_r_rmon_mib[3].var), \
+		   low_10dec(gsw_r_rmon_mib[4].var), \
+		   low_10dec(gsw_r_rmon_mib[5].var), \
+		   low_10dec(gsw_r_rmon_mib[6].var), \
+		   low_10dec(gsw_r_rmon_mib[15].var)); \
+	seq_printf(s, "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title "(H)", "R(7-14)", \
+		   high_10dec(gsw_r_rmon_mib[7].var), \
+		   high_10dec(gsw_r_rmon_mib[8].var), \
+		   high_10dec(gsw_r_rmon_mib[9].var),  \
+		   high_10dec(gsw_r_rmon_mib[10].var), \
+		   high_10dec(gsw_r_rmon_mib[11].var), \
+		   high_10dec(gsw_r_rmon_mib[12].var), \
+		   high_10dec(gsw_r_rmon_mib[13].var), \
+		   high_10dec(gsw_r_rmon_mib[14].var)); \
+	seq_printf(s, \
+		   "%-14s%10s %12u %12u %12u %12u %12u %12u %12u %12u\n", \
+		   title "(L)", "R(7-14)", \
+		   low_10dec(gsw_r_rmon_mib[7].var), \
+		   low_10dec(gsw_r_rmon_mib[8].var), \
+		   low_10dec(gsw_r_rmon_mib[9].var), \
+		   low_10dec(gsw_r_rmon_mib[10].var), \
+		   low_10dec(gsw_r_rmon_mib[11].var), \
+		   low_10dec(gsw_r_rmon_mib[12].var), \
+		   low_10dec(gsw_r_rmon_mib[13].var), \
+		   low_10dec(gsw_r_rmon_mib[14].var)); \
+	print_dash_line(s); \
+	} while (0)
+
+typedef int (*ingress_pmac_set_callback_t) (dp_pmac_cfg_t *pmac_cfg,
+					    u32 value);
+typedef int (*egress_pmac_set_callback_t) (dp_pmac_cfg_t *pmac_cfg,
+					   u32 value);
+struct ingress_pmac_entry {
+	char *name;
+	ingress_pmac_set_callback_t ingress_callback;
+};
+
+struct egress_pmac_entry {
+	char *name;
+	egress_pmac_set_callback_t egress_callback;
+};
+
+static int ingress_err_disc_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.err_disc = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_ERR_DISC;
+	return 0;
+}
+
+static int ingress_pmac_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.pmac = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PRESENT;
+	return 0;
+}
+
+static int ingress_pmac_pmap_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_pmap = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMAP;
+	return 0;
+}
+
+static int ingress_pmac_en_pmap_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_en_pmap = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMAPENA;
+	return 0;
+}
+
+static int ingress_pmac_tc_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_tc = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_CLASS;
+	return 0;
+}
+
+static int ingress_pmac_en_tc_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_en_tc = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_CLASSENA;
+	return 0;
+}
+
+static int ingress_pmac_subifid_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_subifid = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_SUBIF;
+	return 0;
+}
+
+static int ingress_pmac_srcport_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->ig_pmac.def_pmac_src_port = value;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_SPID;
+	return 0;
+}
+
+static int ingress_pmac_hdr1_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[0] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR1;
+	return 0;
+}
+
+static int ingress_pmac_hdr2_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[1] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR2;
+	return 0;
+}
+
+static int ingress_pmac_hdr3_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[2] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR3;
+	return 0;
+}
+
+static int ingress_pmac_hdr4_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[3] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR4;
+	return 0;
+}
+
+static int ingress_pmac_hdr5_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[4] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR5;
+	return 0;
+}
+
+static int ingress_pmac_hdr6_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[5] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR6;
+	return 0;
+}
+
+static int ingress_pmac_hdr7_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[6] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR7;
+	return 0;
+}
+
+static int ingress_pmac_hdr8_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	u8 hdr;
+
+	hdr = (u8)value;
+	pmac_cfg->ig_pmac.def_pmac_hdr[7] = hdr;
+	pmac_cfg->ig_pmac_flags = IG_PMAC_F_PMACHDR8;
+	return 0;
+}
+
+static int egress_fcs_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.fcs = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_FCS;
+	return 0;
+}
+
+static int egress_l2hdr_bytes_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.num_l2hdr_bytes_rm = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_L2HDR_RM;
+	return 0;
+}
+
+static int egress_rx_dma_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.rx_dma_chan = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RXID;
+	return 0;
+}
+
+static int egress_pmac_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.pmac = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_PMAC;
+	return 0;
+}
+
+static int egress_res_dw_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.res_dw1 = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RESDW1;
+	return 0;
+}
+
+static int egress_res1_dw_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.res1_dw0 = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RES1DW0;
+	return 0;
+}
+
+static int egress_res2_dw_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.res2_dw0 = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_RES2DW0;
+	return 0;
+}
+
+static int egress_tc_ena_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.tc_enable = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_TCENA;
+	return 0;
+}
+
+static int egress_dec_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.dec_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_DECFLG;
+	return 0;
+}
+
+static int egress_enc_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.enc_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_ENCFLG;
+	return 0;
+}
+
+static int egress_mpe1_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.mpe1_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_MPE1FLG;
+	return 0;
+}
+
+static int egress_mpe2_flag_set(dp_pmac_cfg_t *pmac_cfg, u32 value)
+{
+	pmac_cfg->eg_pmac.mpe2_flag = value;
+	pmac_cfg->eg_pmac_flags = EG_PMAC_F_MPE2FLG;
+	return 0;
+}
+
+static struct ingress_pmac_entry ingress_entries[] = {
+	{"errdisc", ingress_err_disc_set},
+	{"pmac", ingress_pmac_set},
+	{"pmac_pmap", ingress_pmac_pmap_set},
+	{"pmac_en_pmap", ingress_pmac_en_pmap_set},
+	{"pmac_tc", ingress_pmac_tc_set},
+	{"pmac_en_tc", ingress_pmac_en_tc_set},
+	{"pmac_subifid", ingress_pmac_subifid_set},
+	{"pmac_srcport", ingress_pmac_srcport_set},
+	{"pmac_hdr1", ingress_pmac_hdr1_set},
+	{"pmac_hdr2", ingress_pmac_hdr2_set},
+	{"pmac_hdr3", ingress_pmac_hdr3_set},
+	{"pmac_hdr4", ingress_pmac_hdr4_set},
+	{"pmac_hdr5", ingress_pmac_hdr5_set},
+	{"pmac_hdr6", ingress_pmac_hdr6_set},
+	{"pmac_hdr7", ingress_pmac_hdr7_set},
+	{"pmac_hdr8", ingress_pmac_hdr8_set},
+	{NULL, NULL}
+};
+
+static struct egress_pmac_entry egress_entries[] = {
+	{"rx_dmachan", egress_rx_dma_set},
+	{"rm_l2hdr", egress_l2hdr_bytes_set},
+	{"fcs", egress_fcs_set},
+	{"pmac", egress_pmac_set},
+	{"res_dw1", egress_res_dw_set},
+	{"res1_dw0", egress_res1_dw_set},
+	{"res2_dw0", egress_res2_dw_set},
+	{"tc_enable", egress_tc_ena_set},
+	{"dec_flag", egress_dec_flag_set},
+	{"enc_flag", egress_enc_flag_set},
+	{"mpe1_flag", egress_mpe1_flag_set},
+	{"mpe2_flag", egress_mpe2_flag_set},
+	{NULL, NULL}
+};
+
+static int proc_gsw_port_rmon_dump(struct seq_file *s, int pos)
+{
+	int i;
+	int ret = 0;
+	struct core_ops *gsw_handle;
+	char flag_buf[20];
+
+	if (pos == 0) {
+		memset(gsw_r_rmon_mib, 0, sizeof(gsw_r_rmon_mib));
+		memset(gsw_l_rmon_mib, 0, sizeof(gsw_l_rmon_mib));
+
+		/*read gswip-r rmon counter */
+		gsw_handle = dp_port_prop[0].ops[GSWIP_R];
+
+		for (i = 0; i < ARRAY_SIZE(gsw_r_rmon_mib); i++) {
+			gsw_r_rmon_mib[i].nPortId = i;
+			ret = gsw_core_api((dp_gsw_cb)gsw_handle
+					   ->gsw_rmon_ops.RMON_Port_Get,
+					   gsw_handle, &gsw_r_rmon_mib[i]);
+
+			if (ret != GSW_statusOk) {
+				PR_ERR("RMON_PORT_GET fail for Port %d\n", i);
+				return -1;
+			}
+		}
+
+		/*read pmac rmon redirect mib */
+		memset(&gswr_rmon_redirect, 0, sizeof(gswr_rmon_redirect));
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle
+				   ->gsw_rmon_ops.RMON_Redirect_Get, gsw_handle,
+				   &gswr_rmon_redirect);
+
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_RMON_REDIRECT_GET fail for Port %d\n", i);
+			return -1;
+		}
+
+		/*read gswip-l rmon counter */
+		gsw_handle = dp_port_prop[0].ops[GSWIP_L];
+		for (i = 0; i < ARRAY_SIZE(gsw_l_rmon_mib); i++) {
+			gsw_l_rmon_mib[i].nPortId = i;
+			ret = gsw_core_api((dp_gsw_cb)gsw_handle
+					   ->gsw_rmon_ops.RMON_Port_Get,
+					   gsw_handle,
+					   &gsw_l_rmon_mib[i]);
+			if (ret != GSW_statusOk) {
+				PR_ERR("RMON_PORT_GET fail for Port %d\n", i);
+				return -1;
+			}
+		}
+
+		seq_printf(s, "%-24s %12u %12u %12u %12u %12u %12u %12u\n",
+			   "GSWIP-L", 0, 1, 2, 3, 4, 5, 6);
+		seq_printf(s, "%-24s %12u %12u %12u %12u %12u %12u %12u %12u\n",
+			   "GSWIP-R(Fixed)", 0, 1, 2, 3, 4, 5, 6, 15);
+		seq_printf(s, "%-24s %12u %12u %12u %12u %12u %12u %12u %12u\n",
+			   "GSWIP-R(Dynamic)", 7, 8, 9, 10, 11, 12, 13, 14);
+		print_dash_line(s);
+	}
+	if (pos == RX_GOOD_PKTS) {
+		GSW_PORT_RMON_PRINT("RX_Good", nRxGoodPkts);
+	} else if (pos == RX_FILTER_PKTS) {
+		GSW_PORT_RMON_PRINT("RX_FILTER", nRxFilteredPkts);
+	} else if (pos == RX_DROP_PKTS) {
+		GSW_PORT_RMON_PRINT("RX_DROP", nRxDroppedPkts);
+	} else if (pos == RX_OTHERS) {
+		if (!rmon_display_port_full)
+			goto NEXT;
+
+		GSW_PORT_RMON_PRINT("RX_UNICAST", nRxUnicastPkts);
+		GSW_PORT_RMON_PRINT("RX_BROADCAST", nRxBroadcastPkts);
+		GSW_PORT_RMON_PRINT("RX_MULTICAST", nRxMulticastPkts);
+		GSW_PORT_RMON_PRINT("RX_FCS_ERR", nRxFCSErrorPkts);
+		GSW_PORT_RMON_PRINT("RX_UNDER_GOOD",
+				    nRxUnderSizeGoodPkts);
+		GSW_PORT_RMON_PRINT("RX_OVER_GOOD", nRxOversizeGoodPkts);
+		GSW_PORT_RMON_PRINT("RX_UNDER_ERR",
+				    nRxUnderSizeErrorPkts);
+		GSW_PORT_RMON_PRINT("RX_OVER_ERR", nRxOversizeErrorPkts);
+		GSW_PORT_RMON_PRINT("RX_ALIGN_ERR", nRxAlignErrorPkts);
+		GSW_PORT_RMON_PRINT("RX_64B", nRx64BytePkts);
+		GSW_PORT_RMON_PRINT("RX_127B", nRx127BytePkts);
+		GSW_PORT_RMON_PRINT("RX_255B", nRx255BytePkts);
+		GSW_PORT_RMON_PRINT("RX_511B", nRx511BytePkts);
+		GSW_PORT_RMON_PRINT("RX_1023B", nRx1023BytePkts);
+		GSW_PORT_RMON_PRINT("RX_MAXB", nRxMaxBytePkts);
+		GSW_PORT_RMON64_PRINT("RX_BAD_b", nRxBadBytes);
+	} else if (pos == TX_GOOD_PKTS) {
+		GSW_PORT_RMON_PRINT("TX_Good", nTxGoodPkts);
+	} else if (pos == TX_ACM_PKTS) {
+		GSW_PORT_RMON_PRINT("TX_ACM_DROP", nTxAcmDroppedPkts);
+	} else if (pos == TX_DROP_PKTS) {
+		GSW_PORT_RMON_PRINT("TX_Drop", nTxDroppedPkts);
+	} else if (pos == TX_OTHERS) {
+		if (!rmon_display_port_full)
+			goto NEXT;
+
+		GSW_PORT_RMON_PRINT("TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON_PRINT("TX_BROADAST", nTxBroadcastPkts);
+		GSW_PORT_RMON_PRINT("TX_MULTICAST", nTxMulticastPkts);
+		GSW_PORT_RMON_PRINT("TX_SINGLE_COLL",
+				    nTxSingleCollCount);
+		GSW_PORT_RMON_PRINT("TX_MULT_COLL", nTxMultCollCount);
+		GSW_PORT_RMON_PRINT("TX_LATE_COLL", nTxLateCollCount);
+		GSW_PORT_RMON_PRINT("TX_EXCESS_COLL",
+				    nTxExcessCollCount);
+		GSW_PORT_RMON_PRINT("TX_COLL", nTxCollCount);
+		GSW_PORT_RMON_PRINT("TX_PAUSET", nTxPauseCount);
+		GSW_PORT_RMON_PRINT("TX_64B", nTx64BytePkts);
+		GSW_PORT_RMON_PRINT("TX_127B", nTx127BytePkts);
+		GSW_PORT_RMON_PRINT("TX_255B", nTx255BytePkts);
+		GSW_PORT_RMON_PRINT("TX_511B", nTx511BytePkts);
+		GSW_PORT_RMON_PRINT("TX_1023B", nTx1023BytePkts);
+		GSW_PORT_RMON_PRINT("TX_MAX_B", nTxMaxBytePkts);
+		GSW_PORT_RMON_PRINT("TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON_PRINT("TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON_PRINT("TX_UNICAST", nTxUnicastPkts);
+		GSW_PORT_RMON64_PRINT("TX_GOOD_b", nTxGoodBytes);
+
+	} else if (pos == REDIRECT_MIB) {
+		/*GSWIP-R PMAC Redirect conter */
+		seq_printf(s, "%-24s %12s %12s %12s %12s\n",
+			   "GSW-R Redirect", "Rx_Pkts", "Tx_Pkts",
+			   "Rx_DropsPkts", "Tx_DropsPkts");
+
+		seq_printf(s, "%-24s %12d %12d %12d %12d\n", "",
+			   gswr_rmon_redirect.nRxPktsCount,
+			   gswr_rmon_redirect.nTxPktsCount,
+			   gswr_rmon_redirect.nRxDiscPktsCount,
+			   gswr_rmon_redirect.nTxDiscPktsCount);
+		print_dash_line(s);
+	} else if (pos == DP_DRV_MIB) {
+		u64 eth0_rx = 0, eth0_tx = 0;
+		u64 eth1_rx = 0, eth1_tx = 0;
+		u64 dsl_rx = 0, dsl_tx = 0;
+		u64 other_rx = 0, other_tx = 0;
+		int i, j;
+		struct pmac_port_info *port;
+
+		for (i = 1; i < PMAC_MAX_NUM; i++) {
+			port = get_port_info(tmp_inst, i);
+
+			if (!port)
+				continue;
+
+			if (i < 6) {
+				for (j = 0; j < 16; j++) {
+					eth0_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_rxif_pkt);
+					eth0_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_txif_pkt);
+					eth0_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_cbm_pkt);
+					eth0_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_tso_pkt);
+				}
+			} else if (i == 15) {
+				for (j = 0; j < 16; j++) {
+					eth1_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_rxif_pkt);
+					eth1_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_txif_pkt);
+					eth1_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_cbm_pkt);
+					eth1_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_tso_pkt);
+				}
+			} else if (port->alloc_flags & DP_F_FAST_DSL) {
+				for (j = 0; j < 16; j++) {
+					dsl_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_rxif_pkt);
+					dsl_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_txif_pkt);
+					dsl_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_cbm_pkt);
+					dsl_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_tso_pkt);
+				}
+			} else {
+				for (j = 0; j < 16; j++) {
+					other_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_rxif_pkt);
+					other_rx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    rx_fn_txif_pkt);
+					other_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_cbm_pkt);
+					other_tx +=
+					    STATS_GET(port->subif_info[j].mib.
+					    tx_tso_pkt);
+				}
+			}
+		}
+
+		seq_printf(s, "%-15s %22s %22s %22s %22s\n", "DP Drv Mib",
+			   "ETH_LAN", "ETH_WAN", "DSL", "Others");
+
+		seq_printf(s, "%15s %22llu %22llu %22llu %22llu\n",
+			   "Rx_Pkts", eth0_rx, eth1_rx, dsl_rx, other_rx);
+		seq_printf(s, "%15s %22llu %22llu %22llu %22llu\n",
+			   "Tx_Pkts", eth0_tx, eth1_tx, dsl_tx, other_tx);
+		print_dash_line(s);
+	} else if ((pos >= RMON_MAX) &&
+		   (pos < (RMON_MAX + EGRESS_QUEUE_ID_MAX))) {
+		u32 qdc[4], enq_c, deq_c, index;
+		u32 wq, qrth, qocc, qavg;
+		struct tmu_equeue_link equeue_link;
+		char *flag_s;
+
+		if (!rmon_display_tmu_mib)
+			goto NEXT;
+
+		index = pos - RMON_MAX;
+		enq_c = get_enq_counter(index);
+		deq_c = get_deq_counter(index);
+		tmu_qdct_read(index, qdc);
+		tmu_qoct_read(index, &wq, &qrth, &qocc, &qavg);
+		tmu_equeue_link_get(index, &equeue_link);
+		flag_s =
+		    get_dma_flags_str(equeue_link.epn, flag_buf,
+				      sizeof(flag_buf));
+
+		if ((enq_c || deq_c || (qdc[0] + qdc[1] + qdc[2] + qdc[3])) ||
+		    qocc || qavg) {
+			if (!f_q_mib_title_proc) {
+				seq_printf(s, "%-15s %10s %10s %10s (%10s %10s %10s %10s) %10s %10s %10s\n",
+					   "TMU MIB     QID", "enq",
+					   "deq", "drop", "No-Color",
+					   "Green", "Yellow", "Red",
+					   "qocc", "qavg", "  DMA  Flag");
+				f_q_mib_title_proc = 1;
+			}
+
+			seq_printf(s, "%15d %10u %10u %10u (%10u %10u %10u %10u) %10u %10u %10s\n",
+				   index, enq_c, deq_c,
+				   (qdc[0] + qdc[1] + qdc[2] + qdc[3]),
+				   qdc[0], qdc[1], qdc[2], qdc[3], qocc,
+				   (qavg >> 8), flag_s ? flag_s : "");
+
+		} else {
+			goto NEXT;
+		}
+	} else {
+		goto NEXT;
+	}
+NEXT:
+	pos++;
+
+	if (pos - RMON_MAX + 1 >= EGRESS_QUEUE_ID_MAX)
+		return -1;
+
+	return pos;
+}
+
+static int proc_gsw_rmon_port_start(void)
+{
+	f_q_mib_title_proc = 0;
+	tmp_inst = 0;
+	return 0;
+}
+
+static ssize_t proc_gsw_rmon_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num;
+	char *param_list[10];
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (num < 1)
+		goto help;
+
+	if (dp_strncmpi(param_list[0], "clear", strlen("clear")) == 0 ||
+	    dp_strncmpi(param_list[0], "c", 1) == 0 ||
+	    dp_strncmpi(param_list[0], "rest", strlen("rest")) == 0 ||
+	    dp_strncmpi(param_list[0], "r", 1) == 0) {
+		dp_sys_mib_reset_30(0);
+		goto EXIT_OK;
+	}
+
+	if (dp_strncmpi(param_list[0], "TMU", strlen("TMU")) == 0) {
+		if (dp_strncmpi(param_list[1], "on", 2) == 0) {
+			rmon_display_tmu_mib = 1;
+			goto EXIT_OK;
+		} else if (dp_strncmpi(param_list[1], "off", 3) == 0) {
+			rmon_display_tmu_mib = 0;
+			goto EXIT_OK;
+		}
+	}
+
+	if (dp_strncmpi(param_list[0], "RMON", strlen("RMON")) == 0) {
+		if (dp_strncmpi(param_list[1], "Full", strlen("Full")) == 0) {
+			rmon_display_port_full = 1;
+			goto EXIT_OK;
+		} else if (dp_strncmpi(param_list[1], "Basic", strlen("Basic")) == 0) {
+			rmon_display_port_full = 0;
+			goto EXIT_OK;
+		}
+	}
+
+	/*unknown command */
+	goto help;
+
+EXIT_OK:
+	return count;
+
+help:
+	PR_INFO("usage: echo clear > /proc/dp/rmon\n");
+	PR_INFO("usage: echo TMU on > /proc/dp/rmon\n");
+	PR_INFO("usage: echo TMU off > /proc/dp/rmon\n");
+	PR_INFO("usage: echo RMON Full > /proc/dp/rmon\n");
+	PR_INFO("usage: echo RMON Basic > /proc/dp/rmon\n");
+	return count;
+}
+
+static void dp_send_packet(u8 *pdata, int len, char *devname, u32 flag)
+{
+	struct sk_buff *skb;
+	dp_subif_t subif = { 0 };
+
+	skb = cbm_alloc_skb(len + 8, GFP_ATOMIC);
+
+	if (unlikely(!skb)) {
+		PR_ERR("allocate cbm buffer fail\n");
+		return;
+	}
+
+	skb->DW0 = 0;
+	skb->DW1 = 0;
+	skb->DW2 = 0;
+	skb->DW3 = 0;
+	memcpy(skb->data, pdata, len);
+	skb->len = 0;
+	skb_put(skb, len);
+	skb->dev = dev_get_by_name(&init_net, devname);
+
+	if (dp_get_netif_subifid(skb->dev, skb, NULL, skb->data, &subif, 0)) {
+		PR_ERR("dp_get_netif_subifid failed for %s\n",
+		       skb->dev->name);
+		dev_kfree_skb_any(skb);
+		return;
+	}
+
+	((struct dma_tx_desc_1 *)&skb->DW1)->field.ep = subif.port_id;
+	((struct dma_tx_desc_0 *)&skb->DW0)->field.dest_sub_if_id =
+		subif.subif;
+
+	dp_xmit(skb->dev, &subif, skb, skb->len, flag);
+}
+
+static u8 ipv4_plain_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x3E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x11, /*ip hdr*/
+	0x3A, 0x56, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x2A, 0x7A, 0x41, 0x00, 0x00, /*udp hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00
+};
+
+static u8 ipv4_plain_tcp[1514] = {
+	0x00, 0x01, 0x01, 0x01, 0x01, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x3E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x06, /*ip hdr*/
+	0x3A, 0x61, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03, /*tcp hdr*/
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0x9F, 0xD9, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, /*data */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00
+};
+
+static u8 ipv6_plain_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x3E, 0x11, 0xFF, 0x20, 0x00, /*ip hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x3E, 0xBB, 0x6F, 0x00, 0x00, /*udp hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00
+};
+
+static u8 ipv6_plain_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x46, 0x06, 0xFF, 0x20, 0x00, /*ip hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03, /*tcp hdr*/
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0xE1, 0x13, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, /*data */
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 ipv6_extensions_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x8E, 0x00, 0xFF, 0x20, 0x00, /*ip hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x3C, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00,	/*next extension:hop */
+	0x2B, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00,	/*next extension:Dst */
+	0x11, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,	/*next extension:Rout*/
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x76, 0xBA, 0xFF, 0x00, 0x00,/*udp hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 ipv6_extensions_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x8E, 0x00, 0xFF, 0x20, 0x00,/*ip hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x3C, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00, /*next extension:hop */
+	0x2B, 0x00, 0x01, 0x04, 0x00, 0x00, 0x00, 0x00, /*next extension:dst*/
+	0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, /*next extension:Rout*/
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,/*tcp hdr*/
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0xE0, 0xE3, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 rd6_ip4_ip6_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x6E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x29,/*ip4 hdr */
+	0x3A, 0x0E, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x32, 0x11, 0xFF, 0x20, 0x00,/*ip6 hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x32, 0xBB, 0x87, 0x00, 0x00,/*udp hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 rd6_ip4_ip6_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x08, 0x00,		/*type */
+	0x45, 0x00, 0x00, 0x6E, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x29, /*ip4 hdr*/
+	0x3A, 0x0E, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x32, 0x06, 0xFF, 0x20, 0x00, /*ip6 hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03, /*tcp hdr*/
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0xE1, 0x27, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 dslite_ip6_ip4_udp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x46, 0x04, 0xFF, 0x20, 0x00, /*ip6 hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x45, 0x00, 0x00, 0x46, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x11, /*ip4 hdr*/
+	0x3A, 0x4E, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x00, 0x00, 0x00, 0x32, 0x7A, 0x31, 0x00, 0x00, /*udp hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static u8 dslite_ip6_ip4_tcp[] = {
+	0x00, 0x00, 0x01, 0x00, 0x00, 0x01,	/*mac */
+	0x00, 0x10, 0x94, 0x00, 0x00, 0x02,
+	0x86, 0xDD,		/*type */
+	0x60, 0x00, 0x00, 0x00, 0x00, 0x46, 0x04, 0xFF, 0x20, 0x00,/*ip6 hdr*/
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x02, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
+	0x45, 0x00, 0x00, 0x46, 0x00, 0x00, 0x00, 0x00, 0xFF, 0x06,/*ip4 hdr*/
+	0x3A, 0x59, 0xC0, 0x55, 0x01, 0x02, 0xC0, 0x00, 0x00, 0x01,
+	0x04, 0x00, 0x04, 0x00, 0x00, 0x01, 0xE2, 0x40, 0x00, 0x03,/*tcp hdr*/
+	0x94, 0x47, 0x50, 0x10, 0x10, 0x00, 0x9F, 0xD1, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
+	0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00
+};
+
+static int checksm_mode = 2;
+void proc_checksum_read(struct seq_file *s)
+{
+	char *devname = "eth0_4";
+
+	if (!checksm_mode) {
+		seq_printf(s,
+			   "\nsend pmac checksum ipv4_plain_udp new via %s\n",
+			   devname);
+		dp_send_packet(ipv4_plain_udp, sizeof(ipv4_plain_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum ipv4_plain_tcp new via %s\n",
+			   devname);
+		dp_send_packet(ipv4_plain_tcp, sizeof(ipv4_plain_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum ipv6_plain_udp new via %s\n",
+			   devname);
+		dp_send_packet(ipv6_plain_udp, sizeof(ipv6_plain_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum ipv6_plain_tcp new via %s\n",
+			   devname);
+		dp_send_packet(ipv6_plain_tcp, sizeof(ipv6_plain_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum ipv6_extensions_udp new via %s\n",
+			   devname);
+		dp_send_packet(ipv6_extensions_udp,
+			       sizeof(ipv6_extensions_udp), devname,
+			       DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum ipv6_extensions_tcp via %s\n",
+			   devname);
+		dp_send_packet(ipv6_extensions_tcp,
+			       sizeof(ipv6_extensions_tcp), devname,
+			       DP_TX_CAL_CHKSUM);
+
+		seq_printf(s, "\nsend pmac checksum rd6_ip4_ip6_udp via %s\n",
+			   devname);
+		dp_send_packet(rd6_ip4_ip6_udp, sizeof(rd6_ip4_ip6_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s, "\nsend pmac checksum rd6_ip4_ip6_tcp via %s\n",
+			   devname);
+		dp_send_packet(rd6_ip4_ip6_tcp, sizeof(rd6_ip4_ip6_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum dslite_ip6_ip4_udp via %s\n",
+			   devname);
+		dp_send_packet(dslite_ip6_ip4_udp, sizeof(dslite_ip6_ip4_udp),
+			       devname, DP_TX_CAL_CHKSUM);
+
+		seq_printf(s,
+			   "\nsend pmac checksum dslite_ip6_ip4_tcp via %s\n",
+			   devname);
+		dp_send_packet(dslite_ip6_ip4_tcp, sizeof(dslite_ip6_ip4_tcp),
+			       devname, DP_TX_CAL_CHKSUM);
+	} else if (checksm_mode == 1) {
+#define MOD_V  32
+		int offset = 14 /*mac */ + 20 /*ip */ + 20 /*tcp */;
+#define IP_LEN_OFFSET 16
+		int i;
+		int numbytes = jiffies % 1515;
+
+		if (numbytes < 64)
+			numbytes = 64;
+		else if (numbytes >= 1514)
+			numbytes = 1514;
+
+		for (i = 0; i < sizeof(ipv4_plain_tcp) - offset; i++) {
+			if (i < (numbytes - offset))
+				ipv4_plain_tcp[offset + i] = (i % MOD_V) + 1;
+			else
+				ipv4_plain_tcp[offset + i] = 0;
+		}
+		*(unsigned short *)&ipv4_plain_tcp[IP_LEN_OFFSET] =
+		    numbytes - 14 /*MAC HDR */;
+
+		dp_send_packet(ipv4_plain_tcp, numbytes, devname,
+			       DP_TX_CAL_CHKSUM);
+	} else if (checksm_mode == 2) {
+#define MOD_V  32
+		int offset = 14 /*mac */  + 20 /*ip */  + 20 /*tcp */;
+		int i;
+		int numbytes = offset + 2 /*2 bytes payload */;
+
+		for (i = 0; i < sizeof(ipv4_plain_tcp) - offset; i++) {
+			if (i < (numbytes - offset))
+				ipv4_plain_tcp[offset + i] = (i % MOD_V) + 1;
+			else
+				ipv4_plain_tcp[offset + i] = 0;
+		}
+		*(unsigned short *)&ipv4_plain_tcp[IP_LEN_OFFSET] =
+		    numbytes - 14 /*MAC HDR */;
+		dp_send_packet(ipv4_plain_tcp, numbytes, devname,
+			       DP_TX_CAL_CHKSUM);
+	}
+}
+
+static ssize_t proc_checksum_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num;
+	char *param_list[2];
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if ((dp_strncmpi(param_list[0], "help", strlen("help")) == 0) ||
+	    (dp_strncmpi(param_list[0], "h", 1) == 0)) {
+		goto help;
+	} else {
+		checksm_mode = dp_atoi(param_list[0]);
+	}
+
+	PR_INFO("new checksm_mode=%d\n", checksm_mode);
+	return count;
+
+help:
+	PR_INFO("checksm_mode usage: current value=%d\n", checksm_mode);
+	PR_INFO(" 0: common protocol test with HW checksum\n");
+	PR_INFO(" 1: TCP random size with HW checksum\n");
+	PR_INFO(" 2: 2 Bytes TCP packet with HW checksum\n");
+	PR_INFO(" others: not supported value\n");
+
+	return count;
+}
+
+static int proc_dport_dump(struct seq_file *s, int pos)
+{
+	int i;
+	cbm_dq_port_res_t res;
+	u32 flag = 0;
+
+	memset(&res, 0, sizeof(cbm_dq_port_res_t));
+	if (cbm_dequeue_port_resources_get(pos, &res, flag) == 0) {
+		seq_printf(s, "Dequeue port=%d free_base=0x%x\n", pos,
+			   (u32)res.cbm_buf_free_base);
+
+		for (i = 0; i < res.num_deq_ports; i++) {
+			seq_printf(s,
+				   "%d:deq_port_base=0x%x num_desc=%d port = %d tx chan %d\n",
+				   i, (u32)res.deq_info[i].cbm_dq_port_base,
+				   res.deq_info[i].num_desc,
+				   res.deq_info[i].port_no,
+				   res.deq_info[i].dma_tx_chan);
+		}
+
+		kfree(res.deq_info);
+	}
+
+	pos++;
+
+	if (pos >= PMAC_MAX_NUM)
+		pos = -1;	/*end of the loop */
+
+	return pos;
+}
+
+struct dp_skb_info {
+	struct list_head list;
+	struct sk_buff *skb;
+};
+
+static int cbm_skb_num;	/* for cbm buffer testing purpose */
+static struct dp_skb_info skb_list;
+#define get_val(val, mask, offset) (((val) & (mask)) >> (offset))
+static int cbm_get_free_buf(int fsqm_index, u32 *free_num, u32 *head,
+			    u32 *tail)
+{
+	unsigned char *base;
+
+	if (!fsqm_index)
+		base = (unsigned char *)(FSQM0_MODULE_BASE + 0xa0000000);
+	else
+		base = (unsigned char *)(FSQM1_MODULE_BASE + 0xa0000000);
+	if (free_num)
+		*free_num =
+		    get_val(*(u32 *)(base + OFSC), OFSC_FSC_MASK,
+			    OFSC_FSC_POS);
+	if (head)
+		*head =
+		    get_val(*(u32 *)(base + OFSQ), OFSQ_HEAD_MASK,
+			    OFSQ_HEAD_POS);
+	if (tail)
+		*tail =
+		    get_val(*(u32 *)(base + OFSQ), OFSQ_TAIL_MASK,
+			    OFSQ_TAIL_POS);
+
+	return 0;
+}
+
+static void proc_cbm_buf_read(struct seq_file *s)
+{
+	u32 free_fsqm_num[2], fsqm_head[2], fsqm_tail[2];
+	int i;
+
+	for (i = 0; i < 2; i++)
+		cbm_get_free_buf(i, &free_fsqm_num[i], &fsqm_head[i],
+				 &fsqm_tail[i]);
+	for (i = 0; i < 2; i++)
+		seq_printf(s,
+			   "FSQM%d: free buffer-%04d, head-%04d, tail-%04d\n",
+			   i, free_fsqm_num[i], fsqm_head[i], fsqm_tail[i]);
+	if (cbm_skb_num)
+		seq_printf(s,
+			   "Overall %d CBM buffer allocated for test only!\n",
+			   cbm_skb_num);
+	seq_printf(s,
+		   "Note: %s: echo help > /proc/dp/%s\n",
+		   "use echo to display other commands",
+		   PROC_CBM_BUF_TEST);
+}
+
+static ssize_t proc_cbm_buf_write(struct file *file, const char *buf,
+				  size_t count, loff_t *ppos)
+{
+	int len;
+	char str[64];
+	char *param_list[2] = { 0 };
+	unsigned int num;
+	struct dp_skb_info *tmp = NULL;
+	u32 free_fsqm_num[2], fsqm_head[2], fsqm_tail[2], *check_list;
+	int i;
+	u32 idx, buf_ptr, val, head, tail, bits;
+	const u32 fsqm_buf_len[] = {9216, 1024};
+	void __iomem *base;
+
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	if (dp_split_buffer(str, param_list, ARRAY_SIZE(param_list)) < 2)
+		goto help;
+	if (!cbm_skb_num)
+		INIT_LIST_HEAD(&skb_list.list);
+	if (list_empty(&skb_list.list) && (cbm_skb_num != 0)) {
+		PR_ERR("%s but recorded value of cbm_skb_num=%d\n",
+		       "Why skb_list is empty",
+		       cbm_skb_num);
+		goto exit;
+	}
+	if (cbm_skb_num < 0) {
+		PR_ERR("Why cbm_skb_num(%d) less than zero\n", cbm_skb_num);
+		goto exit;
+	}
+	num = dp_atoi(param_list[1]);
+	if (dp_strncmpi(param_list[0], "alloc", strlen("alloc")) == 0) {
+		if (num == 0)
+			goto exit;
+			do {
+				tmp = kmalloc(sizeof(*tmp),
+					      GFP_KERNEL);
+				if (!tmp)
+					goto exit;
+				INIT_LIST_HEAD(&tmp->list);
+				tmp->skb = cbm_alloc_skb(1000, 0);
+				if (!tmp->skb) {
+					kfree(tmp);
+					goto exit;
+				}
+				DP_DEBUG(DP_DBG_FLAG_CBM_BUF,
+					 "%s: %p (node=%p buffer=%p)\n",
+					 "cbm_alloc_skb ok",
+					 tmp->skb, &tmp->list, tmp);
+				list_add(&tmp->list, &skb_list.list);
+				num--;
+				cbm_skb_num++;
+			} while (num);
+	} else if (dp_strncmpi(param_list[0], "free", strlen("free")) == 0) {
+		struct list_head *pos, *n;
+		struct dp_skb_info *p;
+
+		if (cbm_skb_num == 0 || num == 0)
+			goto exit;
+		list_for_each_safe(pos, n, &skb_list.list) {
+			p = list_entry(pos, struct dp_skb_info, list);
+			if (p->skb) {
+				if (!check_ptr_validation
+				    ((uint32_t)p->skb->data))
+					PR_ERR("%s %p(node=%p buffer=%p) %s\n",
+					       "Wrong Free skb",
+					       p->skb, pos, p,
+					       "not CBM bffer");
+				else
+					DP_DEBUG(DP_DBG_FLAG_CBM_BUF,
+						 "%s %p(node=%p buffer=%p)\n",
+						 "Free skb",
+						 p->skb, pos, p);
+				dev_kfree_skb(p->skb);
+
+				p->skb = NULL;
+			} else {
+				PR_ERR("why p->skb NULL ???\n");
+			}
+			list_del(pos);
+			kfree(p);
+			num--;
+			cbm_skb_num--;
+			if (!num)
+				break;
+		}
+	} else if (dp_strncmpi(param_list[0], "check", strlen("check")) == 0) {
+		int good = 1;
+
+		idx = dp_atoi(param_list[1]);
+		if (idx >= 2) {
+			PR_INFO("FSQM idx must be 0 or 1\n");
+			return count;
+		}
+		num = idx;
+		PR_INFO("\%s!\n",
+			"nCBM link list check can only work with NO traffic");
+		check_list = kmalloc(fsqm_buf_len[idx] >> 3, GFP_KERNEL);
+		if (!check_list) {
+			PR_ERR("Failed to allocate check list buffer\n");
+			return count;
+		}
+		memset(check_list, 0, fsqm_buf_len[idx] >> 3);
+		if (idx == 0) /* Fixme: Hardcoded mapping address */
+			base = (void __iomem *)FSQM0_MODULE_BASE + 0xa0000000;
+		else
+			base = (void __iomem *)FSQM1_MODULE_BASE + 0xa0000000;
+		val = readl(base + OFSQ);
+		head = val & 0x7FFF;
+		tail = (val >> 16) & 0x7FFF;
+		PR_INFO("FSQM Head: 0x%x, Tail: 0x%x\n", head, tail);
+		for (i = 0, buf_ptr = head;
+			i < fsqm_buf_len[num] && buf_ptr != tail;
+			i++) {
+			idx = buf_ptr / 32;
+			bits = buf_ptr % 32;
+			if (!(check_list[idx] & BIT(bits))) {
+				check_list[idx] |= BIT(bits);
+			} else {
+				PR_INFO("FSQM[%d] ERROR: PTR:[0x%4x] dupcate\n",
+					num, buf_ptr);
+				good = 0;
+			}
+			buf_ptr = readl(base + RAM + (buf_ptr << 2));
+		}
+		PR_INFO("%s: 0x%x, free buffer cnt in CBM OFSC REG: 0x%x--%s\n",
+			"Total freed buffers in link list",
+			i + 1, readl(base + OFSC),
+			good ? "In Good State" : "In Wrong State");
+		kfree(check_list);
+		return count;
+	}
+
+	goto help;
+exit:
+	for (i = 0; i < 2; i++)
+		cbm_get_free_buf(i, &free_fsqm_num[i], &fsqm_head[i],
+				 &fsqm_tail[i]);
+	if (cbm_skb_num)
+		PR_INFO("Overall %d CBM buffer allocated for testing purpose\n",
+			cbm_skb_num);
+	else
+		PR_INFO("All buffer already returned to CBM\n");
+	for (i = 0; i < 2; i++)
+		PR_INFO("FSQM%d: free buffer-%04d, head-%04d, tail-%04d\n", i,
+			free_fsqm_num[i], fsqm_head[i], fsqm_tail[i]);
+	return count;
+
+help:
+	PR_INFO("usage: echo alloc [cbm buffer num] > /proc/dp/%s\n",
+		PROC_CBM_BUF_TEST);
+	PR_INFO("usage: echo free  [cbm buffer num] > /proc/dp/%s\n",
+		PROC_CBM_BUF_TEST);
+	PR_INFO("Check CBM buffer list:echo check <fqsm_idx> > /proc/dp/%s\n",
+		PROC_CBM_BUF_TEST);
+	return count;
+}
+
+static int proc_gsw_pce_dump(struct seq_file *s, int pos)
+{
+	struct core_ops *gsw_handle;
+	GSW_PCE_rule_t *rule;
+	int i;
+	GSW_return_t ret;
+
+	rule = kmalloc(sizeof(GSW_PCE_rule_t) + 1,
+		       GFP_KERNEL);
+	if (!rule) {
+		pos = -1;
+		return pos;
+	}
+
+	/*read gswip-r rmon counter */
+	gsw_handle = dp_port_prop[0].ops[1];
+	rule->pattern.nIndex = pos;
+	ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_tflow_ops
+			   .TFLOW_PceRuleRead, gsw_handle, rule);
+	if (ret != GSW_statusOk) {
+		pos = -1;
+		return pos;
+	}
+	if (!rule->pattern.bEnable)
+		goto EXIT;
+
+	seq_printf(s, "Pattern[%d]:-----\n", rule->pattern.nIndex);
+	if (rule->pattern.bPortIdEnable) {
+		seq_printf(s, "  bPortIdEnable           =   %d\n",
+			   rule->pattern.bPortIdEnable);
+		seq_printf(s, "  nPortId                 =   %d\n",
+			   rule->pattern.nPortId);
+		seq_printf(s, "  bPortId_Exclude         =   %d\n",
+			   rule->pattern.bPortId_Exclude);
+	}
+	if (rule->pattern.bSubIfIdEnable) {
+		seq_printf(s, "  bSubIfIdEnable          =   %d\n",
+			   rule->pattern.bSubIfIdEnable);
+		seq_printf(s, "  nSubIfId                =   %d\n",
+			   rule->pattern.nSubIfId);
+		seq_printf(s, "  bSubIfId_Exclude        =   %d\n",
+			   rule->pattern.bSubIfId_Exclude);
+	}
+	if (rule->pattern.bDSCP_Enable) {
+		seq_printf(s, "  bDSCP_Enable            =   %d\n",
+			   rule->pattern.bDSCP_Enable);
+		seq_printf(s, "  nDSCP                   =   %d\n",
+			   rule->pattern.nDSCP);
+		seq_printf(s, "  bDSCP_Exclude           =   %d\n",
+			   rule->pattern.bDSCP_Exclude);
+	}
+	if (rule->pattern.bInner_DSCP_Enable) {
+		seq_printf(s, "  bInner_DSCP_Enable      =   %d\n",
+			   rule->pattern.bInner_DSCP_Enable);
+		seq_printf(s, "  nInnerDSCP              =   %d\n",
+			   rule->pattern.nInnerDSCP);
+		seq_printf(s, "  bInnerDSCP_Exclude      =   %d\n",
+			   rule->pattern.bInnerDSCP_Exclude);
+	}
+	if (rule->pattern.bPCP_Enable) {
+		seq_printf(s, "  bPCP_Enable             =   %d\n",
+			   rule->pattern.bPCP_Enable);
+		seq_printf(s, "  nPCP                    =   %d\n",
+			   rule->pattern.nPCP);
+		seq_printf(s, "  bCTAG_PCP_DEI_Exclude   =   %d\n",
+			   rule->pattern.bCTAG_PCP_DEI_Exclude);
+	}
+	if (rule->pattern.bSTAG_PCP_DEI_Enable) {
+		seq_printf(s, "  bSTAG_PCP_DEI_Enable    =   %d\n",
+			   rule->pattern.bSTAG_PCP_DEI_Enable);
+		seq_printf(s, "  nSTAG_PCP_DEI           =   %d\n",
+			   rule->pattern.nSTAG_PCP_DEI);
+		seq_printf(s, "  bSTAG_PCP_DEI_Exclude   =   %d\n",
+			   rule->pattern.bSTAG_PCP_DEI_Exclude);
+	}
+	if (rule->pattern.bPktLngEnable) {
+		seq_printf(s, "  bPktLngEnable           =   %d\n",
+			   rule->pattern.bPktLngEnable);
+		seq_printf(s, "  nPktLng                 =   %d\n",
+			   rule->pattern.nPktLng);
+		seq_printf(s, "  nPktLngRange            =   %d\n",
+			   rule->pattern.nPktLngRange);
+		seq_printf(s, "  bPktLng_Exclude         =   %d\n",
+			   rule->pattern.bPktLng_Exclude);
+	}
+	if (rule->pattern.bMAC_DstEnable) {
+		seq_printf(s, "  bMAC_DstEnable          =   %d\n",
+			   rule->pattern.bMAC_DstEnable);
+		seq_printf(s,
+			   "  nMAC_Dst                =   %02x:%2x:%2x:%2x:%2x:%2x\n",
+			   rule->pattern.nMAC_Dst[0],
+			   rule->pattern.nMAC_Dst[1],
+			   rule->pattern.nMAC_Dst[2],
+			   rule->pattern.nMAC_Dst[3],
+			   rule->pattern.nMAC_Dst[4],
+			   rule->pattern.nMAC_Dst[5]);
+		seq_printf(s, "  nMAC_DstMask            =   %x\n",
+			   rule->pattern.nMAC_DstMask);
+		seq_printf(s, "  bDstMAC_Exclude         =   %d\n",
+			   rule->pattern.bDstMAC_Exclude);
+	}
+	if (rule->pattern.bMAC_SrcEnable) {
+		seq_printf(s, "  bMAC_SrcEnable          =   %d\n",
+			   rule->pattern.bMAC_SrcEnable);
+		seq_printf(s,
+			   "  nMAC_Src                =   %02x:%2x:%2x:%2x:%2x:%2x\n",
+			   rule->pattern.nMAC_Src[0],
+			   rule->pattern.nMAC_Src[1],
+			   rule->pattern.nMAC_Src[2],
+			   rule->pattern.nMAC_Src[3],
+			   rule->pattern.nMAC_Src[4],
+			   rule->pattern.nMAC_Src[5]);
+		seq_printf(s, "  nMAC_SrcMask            =   %x\n",
+			   rule->pattern.nMAC_SrcMask);
+		seq_printf(s, "  bSrcMAC_Exclude         =   %d\n",
+			   rule->pattern.bSrcMAC_Exclude);
+	}
+	if (rule->pattern.bAppDataMSB_Enable) {
+		seq_printf(s, "  bAppDataMSB_Enable      =   %d\n",
+			   rule->pattern.bAppDataMSB_Enable);
+		seq_printf(s, "  nAppDataMSB             =   %x\n",
+			   rule->pattern.nAppDataMSB);
+		seq_printf(s, "  bAppMaskRangeMSB_Select =   %d\n",
+			   rule->pattern.bAppMaskRangeMSB_Select);
+		seq_printf(s, "  nAppMaskRangeMSB        =   %x\n",
+			   rule->pattern.nAppMaskRangeMSB);
+		seq_printf(s, "  bAppMSB_Exclude         =   %d\n",
+			   rule->pattern.bAppMSB_Exclude);
+	}
+	if (rule->pattern.bAppDataLSB_Enable) {
+		seq_printf(s, "  bAppDataLSB_Enable      =   %d\n",
+			   rule->pattern.bAppDataLSB_Enable);
+		seq_printf(s, "  nAppDataLSB             =   %x\n",
+			   rule->pattern.nAppDataLSB);
+		seq_printf(s, "  bAppMaskRangeLSB_Select =   %d\n",
+			   rule->pattern.bAppMaskRangeLSB_Select);
+		seq_printf(s, "  nAppMaskRangeLSB        =   %x\n",
+			   rule->pattern.nAppMaskRangeLSB);
+		seq_printf(s, "  bAppLSB_Exclude         =   %d\n",
+			   rule->pattern.bAppLSB_Exclude);
+	}
+	if (rule->pattern.eDstIP_Select) {
+		seq_printf(s, "  eDstIP_Select           =   %d\n",
+			   rule->pattern.eDstIP_Select);
+		seq_printf(s, "  nDstIP                  =   %08x ",
+			   rule->pattern.nDstIP.nIPv4);
+		if (rule->pattern.eDstIP_Select == 2)
+			for (i = 2; i < 8; i++)
+				seq_printf(s, "%04x ",
+					   rule->pattern.nDstIP.nIPv6[i]);
+		seq_puts(s, "\n");
+		seq_printf(s, "  nDstIP_Mask             =   %x\n",
+			   rule->pattern.nDstIP_Mask);
+		seq_printf(s, "  bDstIP_Exclude          =   %d\n",
+			   rule->pattern.bDstIP_Exclude);
+	}
+	if (rule->pattern.eInnerDstIP_Select) {
+		seq_printf(s, "  eInnerDstIP_Select      =   %d\n",
+			   rule->pattern.eInnerDstIP_Select);
+		seq_printf(s, "  nInnerDstIP             =   %x\n",
+			   rule->pattern.nInnerDstIP.nIPv4);
+		seq_printf(s, "  nInnerDstIP_Mask        =   %x\n",
+			   rule->pattern.nInnerDstIP_Mask);
+		seq_printf(s, "  bInnerDstIP_Exclude     =   %d\n",
+			   rule->pattern.bInnerDstIP_Exclude);
+	}
+	if (rule->pattern.eSrcIP_Select) {
+		seq_printf(s, "  eSrcIP_Select           =   %d\n",
+			   rule->pattern.eSrcIP_Select);
+		seq_printf(s, "  nSrcIP                  =   %x\n",
+			   rule->pattern.nSrcIP.nIPv4);
+		seq_printf(s, "  nSrcIP_Mask             =   %x\n",
+			   rule->pattern.nSrcIP_Mask);
+		seq_printf(s, "  bSrcIP_Exclude          =   %d\n",
+			   rule->pattern.bSrcIP_Exclude);
+	}
+	if (rule->pattern.eInnerSrcIP_Select) {
+		seq_printf(s, "  eInnerSrcIP_Select      =   %d\n",
+			   rule->pattern.eInnerSrcIP_Select);
+		seq_printf(s, "  nInnerSrcIP             =   %x\n",
+			   rule->pattern.nInnerSrcIP.nIPv4);
+		seq_printf(s, "  nInnerSrcIP_Mask        =   %x\n",
+			   rule->pattern.nInnerSrcIP_Mask);
+		seq_printf(s, "  bInnerSrcIP_Exclude     =   %d\n",
+			   rule->pattern.bInnerSrcIP_Exclude);
+	}
+	if (rule->pattern.bEtherTypeEnable) {
+		seq_printf(s, "  bEtherTypeEnable        =   %d\n",
+			   rule->pattern.bEtherTypeEnable);
+		seq_printf(s, "  nEtherType              =   %x\n",
+			   rule->pattern.nEtherType);
+		seq_printf(s, "  nEtherTypeMask          =   %x\n",
+			   rule->pattern.nEtherTypeMask);
+		seq_printf(s, "  bEtherType_Exclude      =   %d\n",
+			   rule->pattern.bEtherType_Exclude);
+	}
+	if (rule->pattern.bProtocolEnable) {
+		seq_printf(s, "  bProtocolEnable         =   %d\n",
+			   rule->pattern.bProtocolEnable);
+		seq_printf(s, "  nProtocol               =   %x\n",
+			   rule->pattern.nProtocol);
+		seq_printf(s, "  nProtocolMask           =   %x\n",
+			   rule->pattern.nProtocolMask);
+		seq_printf(s, "  bProtocol_Exclude       =   %d\n",
+			   rule->pattern.bProtocol_Exclude);
+	}
+	if (rule->pattern.bInnerProtocolEnable) {
+		seq_printf(s, "  bInnerProtocolEnable    =   %d\n",
+			   rule->pattern.bInnerProtocolEnable);
+		seq_printf(s, "  nInnerProtocol          =   %x\n",
+			   rule->pattern.nInnerProtocol);
+		seq_printf(s, "  nInnerProtocolMask      =   %x\n",
+			   rule->pattern.nInnerProtocolMask);
+		seq_printf(s, "  bInnerProtocol_Exclude  =   %d\n",
+			   rule->pattern.bInnerProtocol_Exclude);
+	}
+	if (rule->pattern.bSessionIdEnable) {
+		seq_printf(s, "  bSessionIdEnable        =   %d\n",
+			   rule->pattern.bSessionIdEnable);
+		seq_printf(s, "  nSessionId              =   %x\n",
+			   rule->pattern.nSessionId);
+		seq_printf(s, "  bSessionId_Exclude      =   %d\n",
+			   rule->pattern.bSessionId_Exclude);
+	}
+	if (rule->pattern.bPPP_ProtocolEnable) {
+		seq_printf(s, "  bPPP_ProtocolEnable     =   %d\n",
+			   rule->pattern.bPPP_ProtocolEnable);
+		seq_printf(s, "  nPPP_Protocol           =   %x\n",
+			   rule->pattern.nPPP_Protocol);
+		seq_printf(s, "  nPPP_ProtocolMask       =   %x\n",
+			   rule->pattern.nPPP_ProtocolMask);
+		seq_printf(s, "  bPPP_Protocol_Exclude   =   %d\n",
+			   rule->pattern.bPPP_Protocol_Exclude);
+	}
+	if (rule->pattern.bVid) {
+		seq_printf(s, "  bVid                    =   %d\n",
+			   rule->pattern.bVid);
+		seq_printf(s, "  nVid                    =   %d\n",
+			   rule->pattern.nVid);
+		seq_printf(s, "  bVid_Exclude            =   %d\n",
+			   rule->pattern.bVid_Exclude);
+	}
+	if (rule->pattern.bSLAN_Vid) {
+		seq_printf(s, "  bSLAN_Vid               =    %d\n",
+			   rule->pattern.bSLAN_Vid);
+		seq_printf(s, "  nSLAN_Vid               =    %d\n",
+			   rule->pattern.nSLAN_Vid);
+		seq_printf(s, "  bSLANVid_Exclude        =    %d\n",
+			   rule->pattern.bSLANVid_Exclude);
+	}
+	if (rule->pattern.bPayload1_SrcEnable) {
+		seq_printf(s, "  bPayload1_SrcEnable     =   %d\n",
+			   rule->pattern.bPayload1_SrcEnable);
+		seq_printf(s, "  nPayload1               =   %x\n",
+			   rule->pattern.nPayload1);
+		seq_printf(s, "  nPayload1_Mask          =   %x\n",
+			   rule->pattern.nPayload1_Mask);
+		seq_printf(s, "  bPayload1_Exclude       =   %d\n",
+			   rule->pattern.bPayload1_Exclude);
+	}
+	if (rule->pattern.bPayload2_SrcEnable) {
+		seq_printf(s, "  bPayload2_SrcEnable     =   %d\n",
+			   rule->pattern.bPayload2_SrcEnable);
+		seq_printf(s, "  nPayload2               =   %x\n",
+			   rule->pattern.nPayload2);
+		seq_printf(s, "  nPayload2_Mask          =   %x\n",
+			   rule->pattern.nPayload2_Mask);
+		seq_printf(s, "  bPayload2_Exclude       =   %d\n",
+			   rule->pattern.bPayload2_Exclude);
+	}
+	if (rule->pattern.bParserFlagLSB_Enable) {
+		seq_printf(s, "  bParserFlagLSB_Enable   =   %d\n",
+			   rule->pattern.bParserFlagLSB_Enable);
+		seq_printf(s, "  nParserFlagLSB          =   %x\n",
+			   rule->pattern.nParserFlagLSB);
+		seq_printf(s, "  nParserFlagLSB_Mask     =   %x\n",
+			   rule->pattern.nParserFlagLSB_Mask);
+		seq_printf(s, "  bParserFlagLSB_Exclude  =   %d\n",
+			   rule->pattern.bParserFlagLSB_Exclude);
+	}
+	if (rule->pattern.bParserFlagMSB_Enable) {
+		seq_printf(s, "  bParserFlagMSB_Enable   =   %d\n",
+			   rule->pattern.bParserFlagMSB_Enable);
+		seq_printf(s, "  nParserFlagMSB          =   %x\n",
+			   rule->pattern.nParserFlagMSB);
+		seq_printf(s, "  nParserFlagMSB_Mask     =   %x\n",
+			   rule->pattern.nParserFlagMSB_Mask);
+		seq_printf(s, "  bParserFlagMSB_Exclude  =   %d\n",
+			   rule->pattern.bParserFlagMSB_Exclude);
+	}
+
+	seq_puts(s, "Action:\n");
+	if (rule->action.eTrafficClassAction) {
+		seq_printf(s, "  eTrafficClassAction      =   %d\n",
+			   rule->action.eTrafficClassAction);
+		seq_printf(s, "  nTrafficClassAlternate   =   %d\n",
+			   rule->action.nTrafficClassAlternate);
+	}
+	if (rule->action.eSnoopingTypeAction)
+		seq_printf(s, "  eSnoopingTypeAction      =   %d\n",
+			   rule->action.eSnoopingTypeAction);
+	if (rule->action.eLearningAction)
+		seq_printf(s, "  eLearningAction          =   %d\n",
+			   rule->action.eLearningAction);
+	if (rule->action.eIrqAction)
+		seq_printf(s, "  eIrqAction               =   %d\n",
+			   rule->action.eIrqAction);
+	if (rule->action.eCrossStateAction)
+		seq_printf(s, "  eCrossStateAction        =   %d\n",
+			   rule->action.eCrossStateAction);
+	if (rule->action.eCritFrameAction)
+		seq_printf(s, "  eCritFrameAction         =   %d\n",
+			   rule->action.eCritFrameAction);
+	if (rule->action.eTimestampAction) {
+		seq_printf(s, "  eTimestampAction         =   %d\n",
+			   rule->action.eTimestampAction);
+	}
+	if (rule->action.ePortMapAction) {
+		seq_printf(s, "  ePortMapAction           =   %d\n",
+			   rule->action.ePortMapAction);
+		seq_printf(s, "  nForwardSubIfId          =   %d\n",
+			   rule->action.nForwardSubIfId);
+	}
+	if (rule->action.bRemarkAction)
+		seq_printf(s, "  bRemarkAction            =   %d\n",
+			   rule->action.bRemarkAction);
+	if (rule->action.bRemarkPCP)
+		seq_printf(s, "  bRemarkPCP               =   %d\n",
+			   rule->action.bRemarkPCP);
+	if (rule->action.bRemarkSTAG_PCP)
+		seq_printf(s, "  bRemarkSTAG_PCP          =   %d\n",
+			   rule->action.bRemarkSTAG_PCP);
+	if (rule->action.bRemarkSTAG_DEI)
+		seq_printf(s, "  bRemarkSTAG_DEI          =   %d\n",
+			   rule->action.bRemarkSTAG_DEI);
+	if (rule->action.bRemarkDSCP)
+		seq_printf(s, "  bRemarkDSCP              =   %d\n",
+			   rule->action.bRemarkDSCP);
+	if (rule->action.bRemarkClass) {
+		seq_printf(s, "  bRemarkClass             =   %d\n",
+			   rule->action.bRemarkClass);
+	}
+	if (rule->action.eMeterAction) {
+		seq_printf(s, "  eMeterAction             =   %d\n",
+			   rule->action.eMeterAction);
+		seq_printf(s, "  nMeterId                 =   %d\n",
+			   rule->action.nMeterId);
+	}
+	if (rule->action.bRMON_Action) {
+		seq_printf(s, "  bRMON_Action             =   %d\n",
+			   rule->action.bRMON_Action);
+		seq_printf(s, "  nRMON_Id                 =   %d\n",
+			   rule->action.nRMON_Id);
+	}
+	if (rule->action.eVLAN_Action) {
+		seq_printf(s, "  eVLAN_Action             =   %d\n",
+			   rule->action.eVLAN_Action);
+		seq_printf(s, "  nVLAN_Id                 =   %d\n",
+			   rule->action.nVLAN_Id);
+	}
+	if (rule->action.eSVLAN_Action) {
+		seq_printf(s, "  eSVLAN_Action            =   %d\n",
+			   rule->action.eSVLAN_Action);
+		seq_printf(s, "  nSVLAN_Id                =   %d\n",
+			   rule->action.nSVLAN_Id);
+	}
+	if (rule->action.eVLAN_CrossAction)
+		seq_printf(s, "  eVLAN_CrossAction        =   %d\n",
+			   rule->action.eVLAN_CrossAction);
+	if (rule->action.nFId)
+		seq_printf(s, "  nFId                     =   %d\n",
+			   rule->action.nFId);
+	if (rule->action.bPortBitMapMuxControl)
+		seq_printf(s, "  bPortBitMapMuxControl    =   %d\n",
+			   rule->action.bPortBitMapMuxControl);
+	if (rule->action.bPortTrunkAction)
+		seq_printf(s, "  bPortTrunkAction         =   %d\n",
+			   rule->action.bPortTrunkAction);
+	if (rule->action.bPortLinkSelection)
+		seq_printf(s, "  bPortLinkSelection       =   %d\n",
+			   rule->action.bPortLinkSelection);
+	if (rule->action.bCVLAN_Ignore_Control)
+		seq_printf(s, "  bCVLAN_Ignore_Control    =   %d\n",
+			   rule->action.bCVLAN_Ignore_Control);
+	if (rule->action.bFlowID_Action) {
+		seq_printf(s, "  bFlowID_Action           =   %d\n",
+			   rule->action.bFlowID_Action);
+		seq_printf(s, "  nFlowID                  =   %d\n",
+			   rule->action.nFlowID);
+	}
+	if (rule->action.bRoutExtId_Action) {
+		seq_printf(s, "  bRoutExtId_Action        =   %d\n",
+			   rule->action.bRoutExtId_Action);
+		seq_printf(s, "  nRoutExtId               =   %d\n",
+			   rule->action.nRoutExtId);
+	}
+	if (rule->action.bRtDstPortMaskCmp_Action)
+		seq_printf(s, "  bRtDstPortMaskCmp_Action =   %d\n",
+			   rule->action.bRtDstPortMaskCmp_Action);
+	if (rule->action.bRtSrcPortMaskCmp_Action)
+		seq_printf(s, "  bRtSrcPortMaskCmp_Action =   %d\n",
+			   rule->action.bRtSrcPortMaskCmp_Action);
+	if (rule->action.bRtDstIpMaskCmp_Action)
+		seq_printf(s, "  bRtDstIpMaskCmp_Action   =   %d\n",
+			   rule->action.bRtDstIpMaskCmp_Action);
+	if (rule->action.bRtSrcIpMaskCmp_Action)
+		seq_printf(s, "  bRtSrcIpMaskCmp_Action   =   %d\n",
+			   rule->action.bRtSrcIpMaskCmp_Action);
+	if (rule->action.bRtInnerIPasKey_Action)
+		seq_printf(s, "  bRtInnerIPasKey_Action   =   %d\n",
+			   rule->action.bRtInnerIPasKey_Action);
+	if (rule->action.bRtAccelEna_Action)
+		seq_printf(s, "  bRtAccelEna_Action       =   %d\n",
+			   rule->action.bRtAccelEna_Action);
+	if (rule->action.bRtCtrlEna_Action)
+		seq_printf(s, "  bRtCtrlEna_Action        =   %d\n",
+			   rule->action.bRtCtrlEna_Action);
+	if (rule->action.eProcessPath_Action)
+		seq_printf(s, "  eProcessPath_Action      =   %d\n",
+			   rule->action.eProcessPath_Action);
+	if (rule->action.ePortFilterType_Action)
+		seq_printf(s, "  ePortFilterType_Action   =   %d\n",
+			   rule->action.ePortFilterType_Action);
+	seq_puts(s, "\n");
+ EXIT:
+	kfree(rule);
+	pos++;
+
+	return pos;
+}
+
+static int proc_gsw_pce_start(void)
+{
+	return 0;
+}
+
+static char *get_pae_ip_type(int type)
+{
+	if (type == GSW_RT_IP_V4)
+		return "IPV4";
+	if (type == GSW_RT_IP_V6)
+		return "IPV6";
+	return "Unknown";
+}
+
+static char *get_pae_tunnel_type(int type)
+{
+	if (type == GSW_ROUTE_TUNL_NULL)
+		return "NULL";
+	if (type == GSW_ROUTE_TUNL_6RD)
+		return "6RD";
+	if (type == GSW_ROUTE_TUNL_DSLITE)
+		return "Dslite";
+	if (type == GSW_ROUTE_TUNL_L2TP)
+		return "L2TP";
+	if (type == GSW_ROUTE_TUNL_IPSEC)
+		return "IPSEC";
+	return "Unknown";
+}
+
+static char *get_pae_ext_type(int type)
+{
+	if (type == 100)
+		return "UDP";
+	if (type == 0)
+		return "TCP";
+	return "Unknown";
+}
+
+static char *get_pae_dir_type(int type)
+{
+	if (type == GSW_ROUTE_DIRECTION_DNSTREAM)
+		return "DownStream";
+	if (type == GSW_ROUTE_DIRECTION_UPSTREAM)
+		return "UpStream";
+	return "Unknown";
+}
+
+static char *pae_pppoe_mode_s(int type)
+{
+	if (type == 0)
+		return "Transparent";
+	if (type == GSW_ROUTE_DIRECTION_UPSTREAM)
+		return "Termination";
+	return "Unknown";
+}
+
+static char *pae_rout_mode_s(int type)
+{
+	if (type == GSW_ROUTE_MODE_NULL)
+		return "NULL";
+	if (type == GSW_ROUTE_MODE_ROUTING)
+		return "Basic Routing";
+	if (type == GSW_ROUTE_MODE_NAT)
+		return "NAT";
+	if (type == GSW_ROUTE_MODE_NAPT)
+		return "NAPT";
+	return "Unknown";
+}
+
+static char *get_pae_out_dscp_type(int type)
+{
+	if (type == GSW_ROUTE_OUT_DSCP_NULL)
+		return "No Outer DSCP Marking";
+	if (type == GSW_ROUTE_OUT_DSCP_INNER)
+		return "Outer DSCP from Inner IP header";
+	if (type == GSW_ROUTE_OUT_DSCP_SESSION)
+		return "Outer DSCP from Session action";
+	return "Unknown";
+}
+
+/* For proc only, no protection */
+
+static char *get_pae_port_list(u32 port)
+{
+	int i, k;
+	static char list[PMAC_MAX_NUM * 2 + 1];
+
+	k = 0;
+	list[0] = 0;
+	for (i = 0; i < PMAC_MAX_NUM; i++) {
+		if (port & (1 << i)) {
+			if (k)
+				sprintf(list + strlen(list), "/");
+			sprintf(list + strlen(list), "%d", i);
+			k++;
+		}
+	}
+	return list;
+}
+
+/* return 0 -- ok */
+static int dp_route_dump_seq(struct seq_file *seq, GSW_ROUTE_Entry_t *rt_entry)
+{
+	seq_printf(seq, "Index[%04d] Hash=%u: %s(%u)\n",
+		   rt_entry->nRtIndex, rt_entry->nHashVal,
+		   (rt_entry->routeEntry.pattern.bValid ==
+			   LTQ_TRUE) ? "Valid" : "Not Valid",
+		   rt_entry->routeEntry.pattern.bValid);
+	seq_puts(seq, " Compare:\n");
+	seq_printf(seq, "   IP Type         = %d (%s)\n",
+		   rt_entry->routeEntry.pattern.eIpType,
+		   get_pae_ip_type(rt_entry->routeEntry.pattern.eIpType));
+	if (rt_entry->routeEntry.action.eIpType == GSW_RT_IP_V6)
+		seq_printf(seq, "   Src IP          = %pI6\n",
+			   rt_entry->routeEntry.pattern.nSrcIP.nIPv6);
+	else
+		seq_printf(seq, "   Src IP          = %pI4\n",
+			   &rt_entry->routeEntry.pattern.nSrcIP.nIPv4);
+
+	if (rt_entry->routeEntry.pattern.eIpType == GSW_RT_IP_V6)
+		seq_printf(seq, "   Dest IP         = %pI6\n",
+			   rt_entry->routeEntry.pattern.nDstIP.nIPv6);
+	else
+		seq_printf(seq, "   Dest IP         = %pI4\n",
+			   &rt_entry->routeEntry.pattern.nDstIP.nIPv4);
+
+	seq_printf(seq, "   Src Port        = %d\n",
+		   rt_entry->routeEntry.pattern.nSrcPort);
+	seq_printf(seq, "   Dest Port       = %d\n",
+		   rt_entry->routeEntry.pattern.nDstPort);
+	seq_printf(seq, "   Extn Id         = %d (%s)\n",
+		   rt_entry->routeEntry.pattern.nRoutExtId,
+		   get_pae_ext_type(rt_entry->routeEntry.pattern.
+					   nRoutExtId));
+	seq_puts(seq, " Action:\n");
+	seq_printf(seq, "   Dst PMAC List   = 0x%0x (%s)\n",
+		   rt_entry->routeEntry.action.nDstPortMap,
+		   get_pae_port_list(rt_entry->routeEntry.action.
+					    nDstPortMap));
+	seq_printf(seq, "   Subif           = 0x%0x\n",
+		   rt_entry->routeEntry.action.nDstSubIfId);
+	seq_printf(seq, "   IP Type         = %d (%s)\n",
+		   rt_entry->routeEntry.action.eIpType,
+		   get_pae_ip_type(rt_entry->routeEntry.action.eIpType));
+	if (rt_entry->routeEntry.action.eIpType == GSW_RT_IP_V6)
+		seq_printf(seq, "   NAT IP          = %pI6\n",
+			   rt_entry->routeEntry.action.nNATIPaddr.
+				  nIPv6);
+	else
+		seq_printf(seq, "   NAT IP          = %pI4\n",
+			   &rt_entry->routeEntry.action.nNATIPaddr.
+				  nIPv4);
+	seq_printf(seq, "   NAT Port        = %d\n",
+		   rt_entry->routeEntry.action.nTcpUdpPort);
+	seq_printf(seq, "   MTU             = %d\n",
+		   rt_entry->routeEntry.action.nMTUvalue);
+	seq_printf(seq, "   Src MAC         = %pM (%s)\n",
+		   rt_entry->routeEntry.action.nSrcMAC,
+		   rt_entry->routeEntry.action.
+			  bMAC_SrcEnable ? "Enabled" : "Disabled");
+	seq_printf(seq, "   Dst MAC         = %pM (%s)\n",
+		   rt_entry->routeEntry.action.nDstMAC,
+		   rt_entry->routeEntry.action.
+			  bMAC_DstEnable ? "Enabled" : "Disabled");
+	seq_printf(seq, "   PPPoE Mode      = %u (%s)\n",
+		   rt_entry->routeEntry.action.bPPPoEmode,
+		   pae_pppoe_mode_s(rt_entry->routeEntry.action.
+						  bPPPoEmode));
+	seq_printf(seq, "   PPPoE SessID    = %u\n",
+		   rt_entry->routeEntry.action.nPPPoESessId);
+	seq_printf(seq, "   Dir             = %u (%s)\n",
+		   rt_entry->routeEntry.action.eSessDirection,
+		   get_pae_dir_type(rt_entry->routeEntry.action.
+					   eSessDirection));
+	seq_printf(seq, "   Class           = %u (%s)\n",
+		   rt_entry->routeEntry.action.nTrafficClass,
+		   rt_entry->routeEntry.action.
+			  bTCremarking ? "Enabled" : "Disabled");
+	seq_printf(seq, "   Routing Mode    = %u (%s)\n",
+		   rt_entry->routeEntry.action.eSessRoutingMode,
+		   pae_rout_mode_s(rt_entry->routeEntry.action.
+			  eSessRoutingMode));
+	seq_printf(seq, "   Tunnel Type     = %u (%s: %s\n",
+		   rt_entry->routeEntry.action.eTunType,
+		   get_pae_tunnel_type(rt_entry->routeEntry.action.
+					      eTunType),
+		   rt_entry->routeEntry.action.
+			  bTunnel_Enable ? "Enabled" : "Disabled");
+	seq_printf(seq, "   Tunnel Index    = %u\n",
+		   rt_entry->routeEntry.action.nTunnelIndex);
+	seq_printf(seq, "   MeterID         = %u (%s)\n",
+		   rt_entry->routeEntry.action.nMeterId,
+		   rt_entry->routeEntry.action.
+			  bMeterAssign ? "Enabled" : "Disabled");
+	seq_printf(seq, "   TTL  Decrease   = %u (%s)\n",
+		   rt_entry->routeEntry.action.bTTLDecrement,
+		   rt_entry->routeEntry.action.
+			  bTTLDecrement ? "Enabled" : "Disabled");
+	seq_printf(seq, "   OutDSCP         = %u (%s)\n",
+		   rt_entry->routeEntry.action.eOutDSCPAction,
+		   get_pae_out_dscp_type(rt_entry->routeEntry.
+			action.eOutDSCPAction));
+	seq_printf(seq, "   InDSCP          = %u (%s)\n",
+		   rt_entry->routeEntry.action.bInnerDSCPRemark,
+		   rt_entry->routeEntry.action.
+		   bInnerDSCPRemark ? "Enabled" : "Disabled");
+	seq_printf(seq, "   DSCP            = %u\n",
+		   rt_entry->routeEntry.action.nDSCP);
+	seq_printf(seq, "   RTP             = %s (seq=%u roll=%u)\n",
+		   rt_entry->routeEntry.action.
+			  bRTPMeasEna ? "Enabled" : "Disabled",
+		   rt_entry->routeEntry.action.nRTPSeqNumber,
+		   rt_entry->routeEntry.action.nRTPSessionPktCnt);
+	seq_printf(seq, "   FID             = %u\n",
+		   rt_entry->routeEntry.action.nFID);
+	seq_printf(seq, "   Flow ID         = %u\n",
+		   rt_entry->routeEntry.action.nFlowId);
+	seq_printf(seq, "   Hit Status      = %u\n",
+		   rt_entry->routeEntry.action.bHitStatus);
+	seq_printf(seq, "   Session Counters= %u\n",
+		   rt_entry->routeEntry.action.nSessionCtrs);
+	seq_puts(seq, "\n");
+	return 0;
+}
+
+static int dp_route_dump_pr(GSW_ROUTE_Entry_t *rt_entry)
+{
+	PR_INFO("Index[%04d] Hash=%u: %s(%u)\n",
+		rt_entry->nRtIndex, rt_entry->nHashVal,
+		(rt_entry->routeEntry.pattern.bValid == LTQ_TRUE) ?
+		"Valid" : "Not Valid",
+		rt_entry->routeEntry.pattern.bValid);
+	PR_INFO(" Compare:\n");
+	PR_INFO("   IP Type         = %d (%s)\n",
+		rt_entry->routeEntry.pattern.eIpType,
+		get_pae_ip_type(rt_entry->routeEntry.pattern.eIpType));
+	if (rt_entry->routeEntry.action.eIpType == GSW_RT_IP_V6)
+		PR_INFO("   Src IP          = %pI6\n",
+			rt_entry->routeEntry.pattern.nSrcIP.nIPv6);
+	else
+		PR_INFO("   Src IP          = %pI4\n",
+			&rt_entry->routeEntry.pattern.nSrcIP.nIPv4);
+
+	if (rt_entry->routeEntry.pattern.eIpType == GSW_RT_IP_V6)
+		PR_INFO("   Dest IP         = %pI6\n",
+			rt_entry->routeEntry.pattern.nDstIP.nIPv6);
+	else
+		PR_INFO("   Dest IP         = %pI4\n",
+			&rt_entry->routeEntry.pattern.nDstIP.nIPv4);
+
+	PR_INFO("   Src Port        = %d\n",
+		rt_entry->routeEntry.pattern.nSrcPort);
+	PR_INFO("   Dest Port       = %d\n",
+		rt_entry->routeEntry.pattern.nDstPort);
+	PR_INFO("   Extn Id         = %d (%s)\n",
+		rt_entry->routeEntry.pattern.nRoutExtId,
+		get_pae_ext_type(rt_entry->routeEntry.pattern.nRoutExtId));
+	PR_INFO(" Action:\n");
+	PR_INFO("   Dst PMAC List   = 0x%0x (%s)\n",
+		rt_entry->routeEntry.action.nDstPortMap,
+		get_pae_port_list(rt_entry->routeEntry.action.nDstPortMap));
+	PR_INFO("   Subif           = 0x%0x\n",
+		rt_entry->routeEntry.action.nDstSubIfId);
+	PR_INFO("   IP Type         = %d (%s)\n",
+		rt_entry->routeEntry.action.eIpType,
+		get_pae_ip_type(rt_entry->routeEntry.action.eIpType));
+	if (rt_entry->routeEntry.action.eIpType == GSW_RT_IP_V6)
+		PR_INFO("   NAT IP          = %pI6\n",
+			rt_entry->routeEntry.action.nNATIPaddr.nIPv6);
+	else
+		PR_INFO("   NAT IP          = %pI4\n",
+			&rt_entry->routeEntry.action.nNATIPaddr.nIPv4);
+	PR_INFO("   NAT Port        = %d\n",
+		rt_entry->routeEntry.action.nTcpUdpPort);
+	PR_INFO("   MTU             = %d\n",
+		rt_entry->routeEntry.action.nMTUvalue);
+	PR_INFO("   Src MAC         = %pM (%s)\n",
+		rt_entry->routeEntry.action.nSrcMAC,
+		rt_entry->routeEntry.action.bMAC_SrcEnable ?
+		"Enabled" : "Disabled");
+	PR_INFO("   Dst MAC         = %pM (%s)\n",
+		rt_entry->routeEntry.action.nDstMAC,
+		rt_entry->routeEntry.action.bMAC_DstEnable ?
+		"Enabled" : "Disabled");
+	PR_INFO("   PPPoE Mode      = %u (%s)\n",
+		rt_entry->routeEntry.action.bPPPoEmode,
+		pae_pppoe_mode_s(rt_entry->routeEntry.action.bPPPoEmode));
+	PR_INFO("   PPPoE SessID    = %u\n",
+		rt_entry->routeEntry.action.nPPPoESessId);
+	PR_INFO("   Dir             = %u (%s)\n",
+		rt_entry->routeEntry.action.eSessDirection,
+		get_pae_dir_type(rt_entry->routeEntry.action.eSessDirection));
+	PR_INFO("   Class           = %u (%s)\n",
+		rt_entry->routeEntry.action.nTrafficClass,
+		rt_entry->routeEntry.action.bTCremarking ?
+		"Enabled" : "Disabled");
+	PR_INFO("   Routing Mode    = %u (%s)\n",
+		rt_entry->routeEntry.action.eSessRoutingMode,
+		pae_rout_mode_s(rt_entry->routeEntry.action.eSessRoutingMode));
+	PR_INFO("   Tunnel Type     = %u (%s: %s\n",
+		rt_entry->routeEntry.action.eTunType,
+		get_pae_tunnel_type(rt_entry->routeEntry.action.eTunType),
+		rt_entry->routeEntry.action.bTunnel_Enable ?
+		"Enabled" : "Disabled");
+	PR_INFO("   Tunnel Index    = %u\n",
+		rt_entry->routeEntry.action.nTunnelIndex);
+	PR_INFO("   MeterID         = %u (%s)\n",
+		rt_entry->routeEntry.action.nMeterId,
+		rt_entry->routeEntry.action.
+		bMeterAssign ? "Enabled" : "Disabled");
+	PR_INFO("   TTL  Decrease   = %u (%s)\n",
+		rt_entry->routeEntry.action.bTTLDecrement,
+		rt_entry->routeEntry.action.
+		bTTLDecrement ? "Enabled" : "Disabled");
+	PR_INFO("   OutDSCP         = %u (%s)\n",
+		rt_entry->routeEntry.action.eOutDSCPAction,
+		get_pae_out_dscp_type(rt_entry->routeEntry.
+	       action.eOutDSCPAction));
+	PR_INFO("   InDSCP          = %u (%s)\n",
+		rt_entry->routeEntry.action.bInnerDSCPRemark,
+		rt_entry->routeEntry.action.
+	       bInnerDSCPRemark ? "Enabled" : "Disabled");
+	PR_INFO("   DSCP            = %u\n",
+		rt_entry->routeEntry.action.nDSCP);
+	PR_INFO("   RTP             = %s (seq=%u roll=%u)\n",
+		rt_entry->routeEntry.action.bRTPMeasEna ? "Enable" : "Disable",
+		rt_entry->routeEntry.action.nRTPSeqNumber,
+		rt_entry->routeEntry.action.nRTPSessionPktCnt);
+	PR_INFO("   FID             = %u\n",
+		rt_entry->routeEntry.action.nFID);
+	PR_INFO("   Flow ID         = %u\n",
+		rt_entry->routeEntry.action.nFlowId);
+	PR_INFO("   Hit Status      = %u\n",
+		rt_entry->routeEntry.action.bHitStatus);
+	PR_INFO("   Session Counters= %u\n",
+		rt_entry->routeEntry.action.nSessionCtrs);
+	PR_INFO("\n");
+	return 0;
+}
+
+ssize_t proc_gsw_route_write(struct file *file, const char *buf,
+			     size_t count, loff_t *ppos)
+{
+	u16 len, i, tmp, start_param;
+	GSW_return_t ret = 0;
+	char *str = NULL;
+	char *param_list[30 * 2];
+	unsigned int num;
+	GSW_ROUTE_Entry_t *rt_entry;
+	struct core_ops *gsw_handle;
+	u8 dscp_f = 0;
+
+	gsw_handle = dp_port_prop[0].ops[1];
+	str = kmalloc(count + 1, GFP_KERNEL);
+	if (!str)
+		return count;
+	rt_entry = kmalloc(sizeof(GSW_ROUTE_Entry_t) + 1,
+			   GFP_KERNEL);
+	if (!rt_entry) {
+		kfree(str);
+		return count;
+	}
+
+	len = count;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if (num < 2) {
+		PR_INFO("parameter %d not enough. count=%d\n", num, count);
+		goto help;
+	}
+	if (dp_strncmpi(param_list[0], "help", strlen("help")) == 0)	/* help */
+		goto help;
+
+	/* delete an entry */
+	if (dp_strncmpi(param_list[0], "del", strlen("del")) == 0) {
+		rt_entry->nRtIndex = dp_atoi(param_list[1]);
+		DP_DEBUG(DP_DBG_FLAG_PAE, "Delete pae entry %d\n",
+			 rt_entry->nRtIndex);
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pae_ops
+				   .ROUTE_SessionEntryDel, gsw_handle,
+				   rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		kfree(str);
+		kfree(rt_entry);
+		return count;
+	}
+
+	/* dump an entry */
+	if (dp_strncmpi(param_list[0], "dump", strlen("dump")) == 0) {
+		rt_entry->nRtIndex = dp_atoi(param_list[1]);
+		DP_DEBUG(DP_DBG_FLAG_PAE, "Dump pae entry %d\n",
+			 rt_entry->nRtIndex);
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pae_ops
+				   .ROUTE_SessionEntryRead, gsw_handle,
+				   rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		dp_route_dump_pr(rt_entry);
+		kfree(str);
+		kfree(rt_entry);
+		return count;
+	}
+
+	/* Modify an entry */
+	if (dp_strncmpi(param_list[0], "modify", strlen("modify")) == 0) {
+		rt_entry->nRtIndex = dp_atoi(param_list[1]);
+		/*read back before delete and add it new */
+		DP_DEBUG(DP_DBG_FLAG_PAE, "Dump pae entry %d\n",
+			 rt_entry->nRtIndex);
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pae_ops
+				   .ROUTE_SessionEntryRead, gsw_handle,
+				   rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pae_ops
+				   .ROUTE_SessionEntryDel, gsw_handle,
+				   rt_entry);
+		if (ret != GSW_statusOk) {
+			PR_ERR("GSW_ROUTE_ENTRY_DELETE returned failure\n");
+			goto exit;
+		}
+		rt_entry->nHashVal = -1; /*since GSWAPI no modify support,
+					  *here switch to add command
+					  */
+		start_param = 2;
+		goto ADD_MODIFY_BOTH;
+	}
+
+	/* add a new entry */
+	if (dp_strncmpi(param_list[0], "add", strlen("add")) != 0) {
+		PR_INFO("wrong command: %s\n", param_list[0]);
+		goto help;
+	}
+	memset(rt_entry, 0, sizeof(*rt_entry));
+	rt_entry->nHashVal = -1;
+	rt_entry->bPrio = 1;
+	rt_entry->routeEntry.action.nMTUvalue = 1501;
+	rt_entry->routeEntry.pattern.bValid = LTQ_TRUE;
+	start_param = 1;
+ ADD_MODIFY_BOTH:
+	for (i = start_param; i < num; i += 2) {
+		/*compare table */
+		if (dp_strncmpi(param_list[i], "SrcIP", strlen("SrcIP")) == 0) {
+			tmp =
+			    pton(param_list[i + 1],
+				 &rt_entry->routeEntry.pattern.nSrcIP);
+			if (tmp == 4)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V4;
+			else if (tmp == 6)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V6;
+			else {
+				PR_INFO("Wong IP format for SrcIP\n");
+				goto exit;
+			}
+		} else if (dp_strncmpi(param_list[i], "DstIP", strlen("DstIP")) == 0) {
+			tmp =
+			    pton(param_list[i + 1],
+				 &rt_entry->routeEntry.pattern.nDstIP);
+			if (tmp == 4)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V4;
+			else if (tmp == 6)
+				rt_entry->routeEntry.pattern.eIpType =
+				    GSW_RT_IP_V6;
+			else {
+				PR_INFO("Wong IP format for DstIP\n");
+				goto exit;
+			}
+		} else if (dp_strncmpi(param_list[i], "SrcPort", strlen("SrcPort")) == 0)
+			rt_entry->routeEntry.pattern.nSrcPort =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "DstPort", strlen("DstPort")) == 0)
+			rt_entry->routeEntry.pattern.nDstPort =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "ExtId", strlen("ExtId")) == 0)
+			rt_entry->routeEntry.pattern.nRoutExtId =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "SrcMac", strlen("SrcMac")) == 0) {
+			rt_entry->routeEntry.action.bMAC_SrcEnable = 1;
+			mac_stob(param_list[i + 1],
+				 rt_entry->routeEntry.action.nSrcMAC);
+
+			if (rt_entry->routeEntry.action.eSessRoutingMode <
+			    GSW_ROUTE_MODE_ROUTING) /*normally only
+						     *routing mode will
+						     *change mac
+						     */
+				rt_entry->routeEntry.action.eSessRoutingMode =
+				    GSW_ROUTE_MODE_ROUTING;
+		} /*below is all actions */
+		else if (dp_strncmpi(param_list[i], "DstMac", strlen("DstMac")) == 0) {
+			rt_entry->routeEntry.action.bMAC_DstEnable = 1;
+			mac_stob(param_list[i + 1],
+				 rt_entry->routeEntry.action.nDstMAC);
+
+			if (rt_entry->routeEntry.action.eSessRoutingMode <
+			    GSW_ROUTE_MODE_ROUTING) /*normally only routing
+						     *mode will change mac
+						     */
+				rt_entry->routeEntry.action.eSessRoutingMode =
+				    GSW_ROUTE_MODE_ROUTING;
+		} else if (dp_strncmpi(param_list[i], "NatIP", strlen("NatIP")) == 0) {
+			tmp =
+			    pton(param_list[i + 1],
+				 &rt_entry->routeEntry.action.nNATIPaddr);
+			if (tmp == 4)
+				rt_entry->routeEntry.action.eIpType =
+				    GSW_RT_IP_V4;
+			else if (tmp == 6)
+				rt_entry->routeEntry.action.eIpType =
+				    GSW_RT_IP_V6;
+			else {
+				PR_INFO("Wong IP format for NatIP\n");
+				goto exit;
+			}
+			if (rt_entry->routeEntry.action.eSessRoutingMode <
+			    GSW_ROUTE_MODE_NAT)
+				rt_entry->routeEntry.action.eSessRoutingMode =
+				GSW_ROUTE_MODE_NAT;	/* NAT */
+		} else if (dp_strncmpi(param_list[i], "NatPort", strlen("NatPort")) == 0) {
+			rt_entry->routeEntry.action.nTcpUdpPort =
+			    dp_atoi(param_list[i + 1]);
+			if (rt_entry->routeEntry.action.eSessRoutingMode <
+			    GSW_ROUTE_MODE_NAPT)
+				rt_entry->routeEntry.action.eSessRoutingMode =
+				GSW_ROUTE_MODE_NAPT;/* NAPT */
+		} else if (dp_strncmpi(param_list[i], "MTU", strlen("MTU")) == 0)
+			rt_entry->routeEntry.action.nMTUvalue =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "PPPoEmode", strlen("PPPoEmode")) == 0)
+			rt_entry->routeEntry.action.bPPPoEmode =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "PPPoEId", strlen("PPPoEId")) == 0)
+			rt_entry->routeEntry.action.nPPPoESessId =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "TunType", strlen("TunType")) == 0) {
+			rt_entry->routeEntry.action.bTunnel_Enable = 1;
+			rt_entry->routeEntry.action.eTunType =
+			    dp_atoi(param_list[i + 1]);
+		} else if (dp_strncmpi(param_list[i], "TunIndex", strlen("TunIndex")) == 0) {
+			rt_entry->routeEntry.action.bTunnel_Enable = 1;
+			rt_entry->routeEntry.action.eTunType =
+			    dp_atoi(param_list[i + 1]);
+
+		} else if (dp_strncmpi(param_list[i], "MeterId", strlen("MeterId")) == 0) {
+			rt_entry->routeEntry.action.bMeterAssign = 1;
+			rt_entry->routeEntry.action.nMeterId =
+			    dp_atoi(param_list[i + 1]);
+
+		} else if (dp_strncmpi(param_list[i], "FID", strlen("FID")) == 0)
+			rt_entry->routeEntry.action.nFID =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "FlowId", strlen("FlowId")) == 0)
+			rt_entry->routeEntry.action.nFlowId =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "OutDscp", strlen("OutDscp")) == 0)
+			rt_entry->routeEntry.action.eOutDSCPAction =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "InDscp", strlen("InDscp")) == 0)
+			rt_entry->routeEntry.action.bInnerDSCPRemark =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "Dscp", strlen("Dscp")) == 0) {
+			rt_entry->routeEntry.action.nDSCP =
+			    dp_atoi(param_list[i + 1]);
+			dscp_f = 1;
+		} else if (dp_strncmpi(param_list[i], "class", strlen("class")) == 0) {
+			rt_entry->routeEntry.action.bTCremarking = 1;
+			rt_entry->routeEntry.action.nTrafficClass =
+			    dp_atoi(param_list[i + 1]);
+		} else if (dp_strncmpi(param_list[i], "ttl", strlen("ttl")) == 0)
+			rt_entry->routeEntry.action.bTTLDecrement =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "dir", strlen("dir")) == 0)
+			rt_entry->routeEntry.action.eSessDirection =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "DstPmac", strlen("DstPmac")) == 0)
+			rt_entry->routeEntry.action.nDstPortMap =
+			    dp_atoi(param_list[i + 1]);
+		else if (dp_strncmpi(param_list[i], "Subif", strlen("Subif")) == 0)
+			rt_entry->routeEntry.action.nDstSubIfId =
+			    dp_atoi(param_list[i + 1]);
+		else {
+			PR_INFO("wrong parameter[%d]: %s\n", i, param_list[i]);
+			goto exit;
+		}
+
+		if (!rt_entry->routeEntry.action.bTTLDecrement &&
+		    (rt_entry->routeEntry.action.eSessRoutingMode >
+		     GSW_ROUTE_MODE_NULL))
+			rt_entry->routeEntry.action.bTTLDecrement = 1;
+
+		/* if key in dscp but no inner/outer dscp action enabled,
+		 * then auto enable indscp action
+		 */
+		if (dscp_f &&
+		    !rt_entry->routeEntry.action.eOutDSCPAction &&
+		    !rt_entry->routeEntry.action.bInnerDSCPRemark)
+			rt_entry->routeEntry.action.bInnerDSCPRemark = 1;
+		/*nSessionCtrs ??*/
+	}
+	ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pae_ops
+				   .ROUTE_SessionEntryAdd, gsw_handle,
+				   rt_entry);
+	if (ret < GSW_statusOk) {
+		PR_ERR("GSW_ROUTE_ENTRY_ADD returned failure\n");
+		goto exit;
+	}
+	DP_DEBUG(DP_DBG_FLAG_PAE, "pae entry %d updated\n",
+		 rt_entry->nRtIndex);
+
+	dp_route_dump_pr(rt_entry);
+
+ exit:
+	kfree(str);
+	kfree(rt_entry);
+	return count;
+
+ help:
+	PR_INFO("usage:\n");
+	PR_INFO("  echo del	<entry-index> > /prooc/dp/%s\n",
+		PROC_ROUTE);
+	PR_INFO("  echo show <entry-index> > /prooc/dp/%s\n",
+		PROC_ROUTE);
+	PR_INFO("  echo add %s %s\n",
+		"[SrcIP] [IP-value] [DstIP] [IP-value] [SrcPort] [Port-value]",
+		"[DstPort] [Port-value] [ExtId] [ExtId-value]");
+	PR_INFO("           %s [NatIP] [IP-value] [NatPort] [Port-value]\n",
+		"[dir] [dir-value] [SrcMAC] [MAC-value] [DstMAC] [MAC-value]");
+	PR_INFO("           %s [PPPoEId-value] [TunType] [Tunnel-value]\n",
+		"[MTU] [MTU-value] [PPPoEmode] [PPPoEmode-value] [PPPoEId]");
+	PR_INFO("           %s [FID] [FID-value] [FlowId] [FlowId-value]\n",
+		"[TunIndex] [Tunnel-index-value] [MeterId] [MeterId-value]");
+	PR_INFO("           %s [OutDscp-value] [class] [class-value]\n",
+		"[InDscp] [InDscp-value] [Dscp] [Dscp-value] [OutDscp]");
+	PR_INFO("           [DstPmac] [DstPmac-value] [Subif] [Subif-value]\n");
+	PR_INFO("		> /prooc/dp/%s\n", PROC_ROUTE);
+	PR_INFO("  echo modify <entry-index> %s > /prooc/dp/%s\n",
+		"[followed by paramers as add command]",
+		PROC_ROUTE);
+
+	PR_INFO(" Take note:\n");
+	PR_INFO("     Only MAC address learned session is accelerated by HW\n");
+	PR_INFO("     After modify entry, its entry index maybe changed\n");
+	PR_INFO("     ExtId: %d(%s)/%d(%s)\n", 0, get_pae_ext_type(0), 100,
+		get_pae_ext_type(100));
+	PR_INFO("     Dir: %d(%s)/%d(%s)\n", GSW_ROUTE_DIRECTION_DNSTREAM,
+		get_pae_dir_type(GSW_ROUTE_DIRECTION_DNSTREAM),
+		GSW_ROUTE_DIRECTION_UPSTREAM,
+		get_pae_dir_type(GSW_ROUTE_DIRECTION_UPSTREAM));
+	PR_INFO("     OutDscp: %d(%s)/%d(%s)/%d(%s)\n",
+		GSW_ROUTE_OUT_DSCP_NULL,
+		get_pae_dir_type(GSW_ROUTE_OUT_DSCP_NULL),
+		GSW_ROUTE_OUT_DSCP_INNER,
+		get_pae_out_dscp_type(GSW_ROUTE_OUT_DSCP_INNER),
+		GSW_ROUTE_OUT_DSCP_SESSION,
+		get_pae_out_dscp_type(GSW_ROUTE_OUT_DSCP_SESSION));
+	PR_INFO("     Tunnel: %d(%s)/%d(%s)/%d(%s)/%d(%s)/%d(%s)\n",
+		GSW_ROUTE_TUNL_NULL, get_pae_tunnel_type(GSW_ROUTE_TUNL_NULL),
+		GSW_ROUTE_TUNL_6RD, get_pae_tunnel_type(GSW_ROUTE_TUNL_6RD),
+		GSW_ROUTE_TUNL_DSLITE,
+		get_pae_tunnel_type(GSW_ROUTE_TUNL_DSLITE),
+		GSW_ROUTE_TUNL_L2TP, get_pae_tunnel_type(GSW_ROUTE_TUNL_L2TP),
+		GSW_ROUTE_TUNL_IPSEC,
+		get_pae_tunnel_type(GSW_ROUTE_TUNL_IPSEC));
+	PR_INFO("     PPPoEmode: %d(%s)/%d(%s)\n", 0,
+		pae_pppoe_mode_s(0), 1, pae_pppoe_mode_s(1));
+	PR_INFO("     TTL/Route Mode/IPV4/6 auto handled inside the proc\n");
+	PR_INFO("     DstPmac:bit 0 for pmac port 0, 1 for pmac port 1....\n");
+	PR_INFO("     Subif(ATM bit format): %s\n",
+		"ATM-QID[6:3] Mpoa_pt[2] Mpoa_mode[1:0]");
+	PR_INFO("     ext(up)  : echo add %s %s %s %s %s > /proc/dp/%s\n",
+		"SrcIP 192.168.1.100 DstIP 192.168.0.100",
+		"SrcPort 1024 DstPort 1024 ExtId 100",
+		"SrcMac 11:11:11:11:11:11 DstMac 11:11:11:11:11:22",
+		"NatIP 192.168.0.1   NatPort 3000 MTU 1500",
+		"DstPmac 0x8000 subif 0 dir 1",
+		PROC_ROUTE);
+	PR_INFO("     ext(down): echo add %s %s %s %s %s > /proc/dp/%s\n",
+		"SrcIP 192.168.0.100 DstIP 192.168.0.1",
+		"SrcPort 1024 DstPort 3000 ExtId 100",
+		"SrcMac 11:11:11:11:11:33 DstMac 11:11:11:11:11:44",
+		"NatIP 192.168.1.100",
+		"NatPort 1024 MTU 1500 DstPmac 0x2 subif 0 dir 0",
+		PROC_ROUTE);
+
+	goto exit;
+}
+
+int proc_gsw_route_dump(struct seq_file *seq, int pos)
+{
+	struct core_ops *gsw_handle;
+	GSW_ROUTE_Entry_t *rt_entry;
+	GSW_return_t  ret = 0;
+
+	rt_entry = kmalloc(sizeof(GSW_ROUTE_Entry_t) + 1,
+			   GFP_KERNEL);
+	if (!rt_entry)
+		return -1;
+	/* read gswip-r rmon counter */
+	gsw_handle = dp_port_prop[0].ops[1];
+	memset(rt_entry, 0, sizeof(*rt_entry));
+	rt_entry->nRtIndex = pos;
+	ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pae_ops
+			   .ROUTE_SessionEntryRead, gsw_handle, rt_entry);
+	if (ret != GSW_statusOk) {
+		PR_ERR("GSW_ROUTE_ENTRY_READ returned Failure for index=%d\n",
+		       rt_entry->nRtIndex);
+		pos = -1;
+		kfree(rt_entry);
+		return pos;
+	}
+	if (rt_entry->routeEntry.pattern.bValid != LTQ_TRUE)
+		goto EXIT;
+
+	if (dp_route_dump_seq(seq, rt_entry))
+		return pos;	/*need report*/
+
+ EXIT:
+	pos++;
+	kfree(rt_entry);
+	if (pos >= 4096) /*GSWIP API does not check the maximum
+			  *entry and it will hang
+			  */
+		pos = -1;
+	return pos;
+}
+
+#define PMAC_EG_SET(x, y) (pmac.eg.x = dp_atoi(y))
+#define PMAC_IG_SET(x, y) (pmac.ig.x = dp_atoi(y))
+
+static int set_pmac_ig_v(char *p, char *tail, GSW_PMAC_Ig_Cfg_t *ig)
+{
+	char *tmp;
+	int k;
+
+	for (k = 0; k < 8; k++) {
+		if (k < (8 - 1)) {
+			tmp = strstr(p, ":");
+			if (!tmp ||
+			    ((u32)tmp >= (u32)tail)) {
+				PR_INFO("%s: should be like %s\n",
+					"Wrong format",
+					"xx:xx:xx:xx:xx:xx:xx:xx");
+				return -1;
+			}
+			*tmp = 0; /*replace:with zero*/
+		}
+		ig->defPmacHdr[k] = dp_atoi(p);
+
+		p = tmp + 1; /* move to next value */
+	}
+	return 0;
+}
+
+static ssize_t proc_gsw_pmac_write(struct file *file, const char *buf,
+				   size_t count, loff_t *ppos)
+{
+	u16 len, i, k, start_param;
+	GSW_return_t ret = 0;
+	char *str = NULL;
+	char *param_list[20 * 2];
+	unsigned int num;
+	union {
+		GSW_PMAC_Eg_Cfg_t eg;
+		GSW_PMAC_Ig_Cfg_t ig;
+	} pmac;
+	#define MAX_GSWIP_CALSS 15
+	#define MAX_GSWIP_FLOW  3
+	struct core_ops *gsw_handle;
+	int class_s = 0, class_e = MAX_GSWIP_CALSS;
+	int flow_s = 0, flow_e = MAX_GSWIP_FLOW;
+
+	str = kmalloc(count + 1, GFP_KERNEL);
+	if (!str)
+		return count;
+	len = count;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+	if ((num < 2) || (num >= ARRAY_SIZE(param_list))) {
+		PR_INFO("parameter %d not enough/more. count=%d\n", num, count);
+		goto help;
+	}
+	if (dp_strncmpi(param_list[0], "help", strlen("help")) == 0)	/* help */
+		goto help;
+	/* set pmac */
+	if (dp_strncmpi(param_list[0], "set", strlen("set")) != 0) {
+		PR_INFO("wrong command: %s\n", param_list[0]);
+		goto help;
+	}
+	if (dp_strncmpi(param_list[1], "L", 1) == 0) {
+		gsw_handle = dp_port_prop[0].ops[GSWIP_L];
+	} else if (dp_strncmpi(param_list[1], "R", 1) == 0) {
+		gsw_handle = dp_port_prop[0].ops[GSWIP_R];
+	} else {
+		PR_INFO("wrong param:should provide L/R\n");
+		goto exit;
+	}
+	memset(&pmac, 0, sizeof(pmac));
+	start_param = 3;
+
+	if (dp_strncmpi(param_list[start_param - 1], "EG", 2) == 0) {
+		/*ingress pmac */
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops
+				   .Pmac_Eg_CfgGet, gsw_handle, &pmac);
+		for (i = start_param; i < num; i += 2) {
+			if (dp_strncmpi(param_list[i], "Class", strlen("Class")) == 0) {
+				char *p = param_list[i + 1];
+
+				char *tail = p + strlen(p);
+				char *tmp;
+
+				tmp = strstr(p, ":");
+				if (!tmp || (tmp >= tail)) {
+					PR_INFO("%s: should be like xx:xx\n",
+						"Wrong format for Class");
+					goto exit;
+				}
+				*tmp = 0;
+				class_s = dp_atoi(p);
+				class_e = dp_atoi(tmp + 1);
+			} else if (dp_strncmpi(param_list[i], "FlowID", strlen("FlowID")) == 0) {
+				char *p = param_list[i + 1];
+				char *tail = p + strlen(p);
+				char *tmp;
+
+				tmp = strstr(p, ":");
+				if (!tmp || (tmp >= tail)) {
+					PR_INFO("%s:should be like xx:xx\n",
+						"Wrong format for FlowID");
+					goto exit;
+				}
+				*tmp = 0;
+				flow_s = dp_atoi(p);
+				flow_e = dp_atoi(tmp + 1);
+			} else if (dp_strncmpi(param_list[i], "DestPort", strlen("DestPort")) == 0) {
+				PMAC_EG_SET(nDestPortId, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i], "RxDmaCH", strlen("RxDmaCH")) == 0) {
+				PMAC_EG_SET(nRxDmaChanId, param_list[i + 1]);
+			}
+#ifdef xxxxx
+			/*below global flag cannot be editted here*/
+			else if (dp_strncmpi(param_list[i], "MPE1", strlen("MPE1")) == 0)
+				PMAC_EG_SET(bMpe1Flag, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "MPE2", strlen("MPE2")) == 0)
+				PMAC_EG_SET(bMpe2Flag, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "DEC", strlen("DEC")) == 0)
+				PMAC_EG_SET(bDecFlag, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "ENC", strlen("ENC")) == 0)
+				PMAC_EG_SET(bEncFlag, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "ProcFlag", strlen("ProcFlag")) == 0)
+				PMAC_EG_SET(bProcFlagsSelect,
+					    param_list[i + 1]);
+#endif
+			else if (dp_strncmpi(param_list[i], "RemL2Hdr", strlen("RemL2Hdr")) == 0)
+				PMAC_EG_SET(bRemL2Hdr, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "RemNum", strlen("RemNum")) == 0)
+				PMAC_EG_SET(numBytesRem, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "FCS", strlen("FCS")) == 0)
+				PMAC_EG_SET(bFcsEna, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "PmacEna", strlen("PmacEna")) == 0)
+				PMAC_EG_SET(bPmacEna, param_list[i + 1]);
+			else if (dp_strncmpi(param_list[i], "TcEnable", strlen("TcEnable")) == 0)
+				PMAC_EG_SET(bTCEnable, param_list[i + 1]);
+			else {
+				PR_INFO("wrong parameter[%d]: %s\n",
+					i, param_list[i]);
+				goto exit;
+			}
+		}
+		if (class_e > MAX_GSWIP_CALSS)
+			class_e = MAX_GSWIP_CALSS;
+		if (flow_e > MAX_GSWIP_FLOW)
+			flow_e = MAX_GSWIP_FLOW;
+		if (class_s > class_e) {
+			PR_INFO("wrong param:class_s=%d should < class_e=%d\n",
+				class_s, class_e);
+			goto exit;
+		}
+		if (flow_s > flow_e) {
+			PR_INFO("wrong param:flow_s=%d should < flow_e=%d\n",
+				flow_s, flow_e);
+			goto exit;
+		}
+		PR_INFO("Set EG PMAC for class %d:%d flow %d:%d\n",
+			class_s, class_e, flow_s, flow_e);
+		for (i = class_s; i <= class_e; i++) {
+			for (k = flow_s; k <= flow_e; k++) {
+				pmac.eg.nTrafficClass = i;
+				/*Note: bProcFlagsSelect zero,
+				 *just nTrafficClass,
+				 *else use MPE1/2/ENC/DEC flag instead
+				 */
+				pmac.eg.bMpe1Flag = (pmac.eg.nTrafficClass >>
+					0) & 1;
+				pmac.eg.bMpe2Flag = (pmac.eg.nTrafficClass >>
+					1) & 1;
+				pmac.eg.bEncFlag = (pmac.eg.nTrafficClass >>
+					2) & 1;
+				pmac.eg.bDecFlag = (pmac.eg.nTrafficClass >>
+					3) & 1;
+				pmac.eg.nFlowIDMsb = k;
+				ret = gsw_core_api((dp_gsw_cb)gsw_handle->
+						   gsw_pmac_ops.Pmac_Eg_CfgSet,
+						   gsw_handle, &pmac);
+			}
+		}
+		if (ret < GSW_statusOk) {
+			PR_ERR("GSW_PMAC_EG_CFG_SET returned failure\n");
+			goto exit;
+		}
+	} else if (dp_strncmpi(param_list[start_param - 1], "IG", 2) == 0) {
+		/*ingress pmac1 */
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops
+				   .Pmac_Ig_CfgGet, gsw_handle, &pmac);
+		for (i = start_param; i < num; i += 2) {
+			if (dp_strncmpi(param_list[i], "TxDmaCH", strlen("TxDmaCH")) == 0) {
+				PMAC_IG_SET(nTxDmaChanId, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i], "ErrDrop", strlen("ErrDrop")) == 0) {
+				PMAC_IG_SET(bErrPktsDisc, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					      "ClassEna", strlen("ClassEna")) == 0) {
+				PMAC_IG_SET(bClassEna, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					      "ClassDefault", strlen("ClassDefault")) == 0) {
+				PMAC_IG_SET(bClassDefault, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i], "PmacEna", strlen("PmacEna")) == 0) {
+				PMAC_IG_SET(bPmapEna, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					      "PmacDefault", strlen("PmacDefault")) == 0) {
+				PMAC_IG_SET(bPmapDefault, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					      "SubIdDefault", strlen("SubIdDefault")) == 0) {
+				 /*changed from bSubIdDefault in GSWIP3.1 */
+				//PMAC_IG_SET(bSubIdDefault, param_list[i + 1]);
+				PMAC_IG_SET(eSubId, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					      "SpIdDefault", strlen("SpIdDefault")) == 0) {
+				PMAC_IG_SET(bSpIdDefault, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					      "PmacPresent", strlen("PmacPresent")) == 0) {
+				PMAC_IG_SET(bPmacPresent, param_list[i + 1]);
+			} else if (dp_strncmpi(param_list[i],
+					    "DefaultPmacHdr", strlen("DefaultPmacHdr")) == 0) {
+				char *p = param_list[i + 1];
+				char *tail = p + strlen(p);
+
+				if (set_pmac_ig_v(p, tail, &pmac.ig))
+					goto exit;
+			} else {
+				PR_INFO("wrong parameter[%d]: %s\n", i,
+					param_list[i]);
+				goto exit;
+			}
+		}
+		ret = gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops
+				   .Pmac_Ig_CfgSet, gsw_handle, &pmac);
+		if (ret < GSW_statusOk) {
+			PR_ERR("GSW_PMAC_IG_CFG_SET returned failure\n");
+			goto exit;
+		}
+	} else if (dp_strncmpi(param_list[start_param - 1], "reset", strlen("reset")) == 0) {
+		GSW_reset_t reset;
+
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_common_ops.Reset,
+			     gsw_handle, &reset);
+	} else {
+		PR_INFO("wrong parameter not supported: %s\n",
+			param_list[start_param - 1]);
+		goto exit;
+	}
+exit:
+	kfree(str);
+	return count;
+
+help:
+	PR_INFO("usage:\n");
+	PR_INFO("  echo set <L/R> EG\n");
+	PR_INFO("    [DestPort] [Dst-PMAC-Port-value]\n");
+	PR_INFO("    [Class] [Class-start:end](0~15)\n");
+	PR_INFO("    [FlowID] [FlowID-start:end](0~3)\n");
+	PR_INFO("\n");
+	PR_INFO("    [PmacEna] [Enable PMAC HDR (1) or not(0)]\n");
+	PR_INFO("    [RxDmaCH] [RxDmaCH-value]\n");
+	PR_INFO("    [TcEnable] [TcEnable-value(0/1)] [FCS] [FCS-value(0/1]\n");
+	PR_INFO("    %s [RemL2Hdr-value(0/1)] [RemNum] [RemNum-value]\n",
+		"[RemL2Hdr]");
+	PR_INFO("     > /prooc/dp/%s\n", PROC_PMAC);
+	PR_INFO("  echo set <L/R> IG [TxDmaCH] [TX-DMA-CH-value]\n");
+	PR_INFO("\n");
+	PR_INFO("    [ErrDrop] [Error-Drop-value(0/1)]\n");
+	PR_INFO("    %s PMAC header(1) or incoming PMAC header(0)]\n",
+		"[ClassEna] [Class Enable info from default");
+	PR_INFO("    %s %s %s\n",
+		"[ClassDefault]",
+		"[Class Default info from default PMAC header(1)",
+		"or incoming PMAC header(0)]");
+	PR_INFO("    %s %s %s\n",
+		"[PmacEna]",
+		"[Port Map Enable info from default PMAC header(1)",
+		"or incoming PMAC header(0)]");
+	PR_INFO("    %s %s or incoming PMAC header(0)]\n",
+		"[PmacDefault]",
+		"[Port Map info from default PMAC header(1)");
+	PR_INFO("    %s %s or in packet descriptor (0)]\n",
+		"[SubIdDefault]",
+		"[Sub_Interface Id Info from default PMAC header(1)");
+	PR_INFO("    %s %s or incoming PMAC header (False)]\n",
+		"[SpIdDefault]",
+		"[Source port id from default PMAC header(1)");
+	PR_INFO("    %s %s or not (0)]\n",
+		"[PmacPresent]",
+		"[Packet PMAC header is present (1)");
+	PR_INFO("    %s [Default PMAC HDR(8 bytes: xx:xx:xx:xx:xx:xx:xx:xx]\n",
+		"[DefaultPmacHdr]");
+	PR_INFO("     > /prooc/dp/%s\n", PROC_PMAC);
+	PR_INFO("  echo set <0/1> reset\n");
+	PR_INFO("  ext1: echo %s %s %s %s > /proc/dp/pmac\n",
+		"set R IG TxDmaCH 1 ErrDrop 0 PmacDefault 0 PmacEna 0",
+		"ClassEna 1 ClassDefault 1 SubIdDefault 1 SpIdDefault 1",
+		"PmacPresent 0",
+		"DefaultPmacHdr 0x11:0x22:0x33:0x44:0x55:0x66:0x77:0x88");
+	PR_INFO("  ext2: %s %s > /proc/dp/pmac\n",
+		"echo set R EG DestPort 15 class 0:15 FlowID 0:3",
+		"RxDmaCH 4 TcEnable 1 RemL2Hdr 1 RemNum 8 PmacEna 0 FCS 1");
+	goto exit;
+}
+
+static int proc_gsw_pmac_start(void)
+{
+	return 0;
+}
+
+static int proc_gsw_pmac_dump(struct seq_file *s, int pos)
+{
+	GSW_PMAC_Ig_Cfg_t igCfg;
+	GSW_PMAC_Eg_Cfg_t egCfg;
+	struct core_ops *gsw_handle;
+	u8 i = 0, j = 0;
+
+	/* Do the GSW-L configuration */
+	gsw_handle = dp_port_prop[0].ops[0];
+	seq_puts(s, "\nGSWIP PMAC0 Ingress PMAC Configure\n");
+	seq_printf(s, "%15s %15s %15s %15s %15s %15s %15s %15s %15s %15s\n",
+		   "nTxDmaChanId", "bErrPktsDisc", "bPmapDefault", "bPmapEna",
+		   "bClassDefault", "bClassEna", "bSubIdDefault",
+		   "bSpIdDefault", "bPmacPresent", "defPmacHdr");
+	for (i = 0; i <= 15; i++) {
+		memset(&igCfg, 0x00, sizeof(igCfg));
+		igCfg.nPmacId = 0;
+		igCfg.nTxDmaChanId = i;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops.Pmac_Ig_CfgGet,
+			     gsw_handle, &igCfg);
+		seq_printf(s, "%15d %15d %15d %15d %15d %15d %15d %15d %15d ",
+			   igCfg.nTxDmaChanId, igCfg.bErrPktsDisc,
+			   igCfg.bPmapDefault, igCfg.bPmapEna,
+			   igCfg.bClassDefault, igCfg.bClassEna,
+			   igCfg.eSubId, igCfg.bSpIdDefault,
+			   igCfg.bPmacPresent);
+		for (j = 0; j < 8; j++)
+			seq_printf(s, "%02x", igCfg.defPmacHdr[j]);
+		seq_puts(s, "\n");
+	}
+
+	seq_puts(s, "GSWIP PMAC0 Egress PMAC Configure\n");
+	for (i = 0; i <= 3; i++) {
+		memset(&egCfg, 0x00, sizeof(egCfg));
+		egCfg.nPmacId = 0;
+		egCfg.nDestPortId	= i;
+		egCfg.nTrafficClass	= 0;
+		egCfg.nFlowIDMsb	= 0;
+		egCfg.bDecFlag		= 0;
+		egCfg.bEncFlag		= 0;
+		egCfg.bMpe1Flag		= 0;
+		egCfg.bMpe2Flag		= 0;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops.Pmac_Eg_CfgGet,
+			     gsw_handle, &egCfg);
+		seq_printf(s, " nRxDmaChanId  = %d\n", egCfg.nRxDmaChanId);
+		seq_printf(s, " bRemL2Hdr     = %d\n", egCfg.bRemL2Hdr);
+		seq_printf(s, " numBytesRem   = %d\n", egCfg.numBytesRem);
+		seq_printf(s, " bFcsEna       = %d\n", egCfg.bFcsEna);
+		seq_printf(s, " bPmacEna      = %d\n", egCfg.bPmacEna);
+		seq_printf(s, " nResDW1       = %d\n", egCfg.nResDW1);
+		seq_printf(s, " nRes1DW0      = %d\n", egCfg.nRes1DW0);
+		seq_printf(s, " nRes2DW0      = %d\n", egCfg.nRes2DW0);
+		seq_printf(s, " nDestPortId   = %d\n", egCfg.nDestPortId);
+		seq_printf(s, " nTrafficClass = %d\n", egCfg.nTrafficClass);
+		seq_printf(s, " nFlowIDMsb    = %d\n", egCfg.nFlowIDMsb);
+		seq_printf(s, " bDecFlag      = %d\n", egCfg.bDecFlag);
+		seq_printf(s, " bEncFlag      = %d\n", egCfg.bEncFlag);
+		seq_printf(s, " bMpe1Flag     = %d\n", egCfg.bMpe1Flag);
+		seq_printf(s, " bMpe2Flag     = %d\n", egCfg.bMpe2Flag);
+		seq_puts(s, "\n");
+	}
+
+	seq_puts(s, "\n\nGSWIP PMAC Ingress PMAC Configure\n");
+		seq_printf(s, "\n%15s %15s %15s %15s %15s %15s %15s %15s %15s %15s\n",
+			   "nTxDmaChanId", "bErrPktsDisc", "bPmapDefault",
+			   "bPmapEna", "bClassDefault", "bClassEna",
+			   "bSubIdDefault", "bSpIdDefault", "bPmacPresent",
+			   "defPmacHdr");
+	for (i = 0; i <= 15; i++) {
+		memset(&igCfg, 0x00, sizeof(igCfg));
+		igCfg.nPmacId = 1;
+		igCfg.nTxDmaChanId = i;
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops.Pmac_Ig_CfgGet,
+			     gsw_handle, &igCfg);
+		seq_printf(s, "%15d %15d %15d %15d %15d %15d %15d %15d %15d ",
+			   igCfg.nTxDmaChanId, igCfg.bErrPktsDisc,
+			   igCfg.bPmapDefault, igCfg.bPmapEna,
+			   igCfg.bClassDefault, igCfg.bClassEna,
+			   igCfg.eSubId, igCfg.bSpIdDefault,
+			   igCfg.bPmacPresent);
+		for (j = 0; j < 8; j++)
+			seq_printf(s, "%02x", igCfg.defPmacHdr[j]);
+		seq_puts(s, "\n");
+	}
+	seq_puts(s, "\n\n\nGSWIP-R Egress PMAC Configure\n");
+	for (i = 0; i <= 15; i++) {
+		memset(&egCfg, 0x00, sizeof(egCfg));
+		egCfg.nPmacId = 1;
+		egCfg.nDestPortId	= i;
+		egCfg.nTrafficClass	= 0;
+		egCfg.nFlowIDMsb	= 0;
+		egCfg.bDecFlag		= 0;
+		egCfg.bEncFlag		= 0;
+		egCfg.bMpe1Flag		= 0;
+		egCfg.bMpe2Flag		= 0;
+
+		gsw_core_api((dp_gsw_cb)gsw_handle->gsw_pmac_ops.Pmac_Eg_CfgGet,
+			     gsw_handle, &egCfg);
+
+		seq_printf(s, " nRxDmaChanId  = %d\n", egCfg.nRxDmaChanId);
+		seq_printf(s, " bRemL2Hdr     = %d\n", egCfg.bRemL2Hdr);
+		seq_printf(s, " numBytesRem   = %d\n", egCfg.numBytesRem);
+		seq_printf(s, " bFcsEna       = %d\n", egCfg.bFcsEna);
+		seq_printf(s, " bPmacEna      = %d\n", egCfg.bPmacEna);
+		seq_printf(s, " nResDW1       = %d\n", egCfg.nResDW1);
+		seq_printf(s, " nRes1DW0      = %d\n", egCfg.nRes1DW0);
+		seq_printf(s, " nRes2DW0      = %d\n", egCfg.nRes2DW0);
+		seq_printf(s, " nDestPortId   = %d\n", egCfg.nDestPortId);
+		seq_printf(s, " nTrafficClass = %d\n", egCfg.nTrafficClass);
+		seq_printf(s, " nFlowIDMsb    = %d\n", egCfg.nFlowIDMsb);
+		seq_printf(s, " bDecFlag      = %d\n", egCfg.bDecFlag);
+		seq_printf(s, " bEncFlag      = %d\n", egCfg.bEncFlag);
+		seq_printf(s, " bMpe1Flag     = %d\n", egCfg.bMpe1Flag);
+		seq_printf(s, " bMpe2Flag     = %d\n", egCfg.bMpe2Flag);
+		seq_puts(s, "\n");
+	}
+	if (!seq_has_overflowed(s))
+		pos++;
+	if (pos == 1)
+		return -1;
+
+	return pos;
+}
+
+int proc_ep_dump(struct seq_file *s, int pos)
+{
+#if defined(NEW_CBM_API) && NEW_CBM_API
+	u32 num;
+	cbm_tmu_res_t *res = NULL;
+	u32 flag = 0;
+	int i;
+	struct pmac_port_info *port = get_port_info(0, pos);
+
+	if (cbm_dp_port_resources_get
+	    (&pos, &num, &res, port ? port->alloc_flags : flag) == 0) {
+		for (i = 0; i < num; i++) {
+			seq_printf(s, "ep=%d tmu_port=%d queue=%d sid=%d\n",
+				   pos, res[i].tmu_port, res[i].tmu_q,
+				   res[i].tmu_sched);
+		}
+
+		kfree(res);
+	}
+#endif
+	pos++;
+
+	if (pos >= PMAC_MAX_NUM)
+		pos = -1;	/*end of the loop */
+
+	return pos;
+}
+
+static void pmac_eg_cfg(char *param_list[], int num, dp_pmac_cfg_t *pmac_cfg)
+{
+	int i, j;
+	u32 value;
+
+	for (i = 2; i < num; i += 2) {
+		for (j = 0; j < ARRAY_SIZE(egress_entries); j++) {
+			if (dp_strncmpi(param_list[i],
+				       egress_entries[j].name, strlen(egress_entries[j].name)))
+				continue;
+			if (dp_strncmpi(egress_entries[j].name,
+				       "rm_l2hdr", strlen("rm_l2hdr")) == 0) {
+				if (dp_atoi(param_list[i + 1]) > 0) {
+					pmac_cfg->eg_pmac.rm_l2hdr = 1;
+					value = dp_atoi(param_list[i + 1]);
+					egress_entries[j].
+					   egress_callback(pmac_cfg,
+							   value);
+					PR_INFO("egress pmac ep %s config ok\n",
+						egress_entries
+					     [j].name);
+					break;
+				}
+				pmac_cfg->eg_pmac.rm_l2hdr =
+				    dp_atoi(param_list[i + 1]);
+			} else {
+				value = dp_atoi(param_list[i + 1]);
+				egress_entries[j].
+				    egress_callback(pmac_cfg,
+						    value);
+				PR_INFO("egress pmac ep %s configu ok\n",
+					egress_entries[j].name);
+				break;
+			}
+		}
+	}
+}
+
+ssize_t ep_port_write(struct file *file, const char *buf, size_t count,
+		      loff_t *ppos)
+{
+	int len;
+	char str[64];
+	int num, i, j, ret;
+	u32 value;
+	u32 port;
+	char *param_list[10];
+	dp_pmac_cfg_t pmac_cfg;
+	int inst = 0;
+
+	memset(&pmac_cfg, 0, sizeof(dp_pmac_cfg_t));
+	len = (sizeof(str) > count) ? count : sizeof(str) - 1;
+	len -= copy_from_user(str, buf, len);
+	str[len] = 0;
+	num = dp_split_buffer(str, param_list, ARRAY_SIZE(param_list));
+
+	if (dp_strncmpi(param_list[0], "ingress", strlen("ingress")) == 0) {
+		port = dp_atoi(param_list[1]);
+
+		for (i = 2; i < num; i += 2) {
+			for (j = 0; j < ARRAY_SIZE(ingress_entries); j++) {
+				if (dp_strncmpi
+				    (param_list[i],
+				     ingress_entries[j].name, strlen(ingress_entries[j].name)) == 0) {
+					value = dp_atoi(param_list[i + 1]);
+					ingress_entries[j].
+					    ingress_callback(&pmac_cfg,
+							     value);
+					PR_INFO("ingress pmac ep %s configed\n",
+						ingress_entries[j].name);
+					break;
+				}
+			}
+		}
+
+		ret = dp_pmac_set_30(inst, port, &pmac_cfg);
+
+		if (ret != 0) {
+			PR_ERR("pmac set configuration failed\n");
+			return -1;
+		}
+	} else if (dp_strncmpi(param_list[0], "egress", 6) == 0) {
+		port = dp_atoi(param_list[1]);
+
+		pmac_eg_cfg(param_list, num, &pmac_cfg);
+		ret = dp_pmac_set_30(inst, port, &pmac_cfg);
+
+		if (ret != 0) {
+			PR_ERR("pmac set configuration failed\n");
+			return -1;
+		}
+	} else {
+		PR_INFO("wrong command\n");
+		goto help;
+	}
+
+	return count;
+help:
+	PR_INFO("echo ingress/egress [ep_port] %s > /proc/dp/ep\n",
+		"['ingress/egress fields'] [value]");
+	PR_INFO("(eg) echo ingress 1 pmac 1 > /proc/dp/ep\n");
+	PR_INFO("(eg) echo egress 1 rm_l2hdr 2 > /proc/dp/ep\n");
+	PR_INFO("echo %s ['errdisc/pmac/pmac_pmap/pmac_en_pmap/pmac_tc",
+		"ingress [ep_port] ");
+	PR_INFO("                         %s > /proc/dp/ep\n",
+		"/pmac_en_tc/pmac_subifid/pmac_srcport'] [value]");
+	PR_INFO("echo  %s %s> /proc/dp/ep\n",
+		"egress [ep_port]",
+		"['rx_dmachan/fcs/pmac/res_dw1/res1_dw0/res2_dw0] [value]");
+	PR_INFO("echo egress [ep_port] ['rm_l2hdr'] [value] > /proc/dp/ep\n");
+	return count;
+}
+
+static struct dp_proc_entry dp_proc_entries[] = {
+	/*name single_callback_t multi_callback_t/_start write_callback_t */
+	{PROC_PARSER, proc_parser_read, NULL, NULL, proc_parser_write},
+	{PROC_RMON_PORTS, NULL, proc_gsw_port_rmon_dump,
+	 proc_gsw_rmon_port_start, proc_gsw_rmon_write},
+	{PROC_CHECKSUM, proc_checksum_read, NULL, NULL,
+		proc_checksum_write},
+#ifdef CONFIG_LTQ_DATAPATH_MIB
+	{PROC_MIB_TIMER, proc_mib_timer_read, NULL, NULL,
+		proc_mib_timer_write},
+	{PROC_MIB_INSIDE, NULL, proc_mib_inside_dump,
+		proc_mib_inside_start, proc_mib_inside_write},
+	{PROC_MIBPORT, NULL, proc_mib_port_dump,
+		proc_mib_port_start, proc_mib_port_write},
+	{PROC_MIBVAP, NULL, proc_mib_vap_dump, proc_mib_vap_start,
+		proc_mib_vap_write},
+#endif
+#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+	{PROC_COC, proc_coc_read, NULL, NULL, proc_coc_write},
+#endif
+	{PROC_CBM_BUF_TEST, proc_cbm_buf_read, NULL, NULL,
+	 proc_cbm_buf_write},
+	{PROC_EP, NULL, proc_ep_dump, NULL, ep_port_write},
+	{PROC_PCE, NULL, proc_gsw_pce_dump, proc_gsw_pce_start, NULL},
+	{PROC_ROUTE, NULL, proc_gsw_route_dump, NULL, proc_gsw_route_write},
+	{PROC_DPORT, NULL, proc_dport_dump, NULL, NULL},
+	{PROC_PMAC, NULL, proc_gsw_pmac_dump, proc_gsw_pmac_start,
+	 proc_gsw_pmac_write},
+	{DP_PROC_CBMLOOKUP, NULL, lookup_dump30, lookup_start30,
+	 proc_get_qid_via_index30},
+	/*the last place holder */
+	{NULL, NULL, NULL, NULL, NULL}
+};
+
+int dp_sub_proc_install_30(void)
+{
+	int i;
+
+	if (!dp_proc_node) {
+		PR_INFO("dp_sub_proc_install failed\n");
+		return 0;
+	}
+
+	for (i = 0; i < ARRAY_SIZE(dp_proc_entries); i++)
+		dp_proc_entry_create(dp_proc_node, &dp_proc_entries[i]);
+	PR_INFO("dp_sub_proc_install ok\n");
+	return 0;
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_proc.h b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_proc.h
new file mode 100644
index 000000000000..550ef07bea67
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_proc.h
@@ -0,0 +1,8 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
diff --git a/include/net/datapath_api_gswip30.h b/include/net/datapath_api_gswip30.h
new file mode 100644
index 000000000000..ebe263af99ff
--- /dev/null
+++ b/include/net/datapath_api_gswip30.h
@@ -0,0 +1,425 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#ifndef DATAPATH_API_GRX500_H
+#define DATAPATH_API_GRX500_H
+
+#ifdef CONFIG_LITTLE_ENDIAN
+struct dma_rx_desc_0 {
+	/* DWORD 0 */
+	union {
+		struct {
+			u32 dest_sub_if_id:15;
+			u32 eth_type:2;
+			u32 flow_id:8;
+			u32 tunnel_id:4;
+			u32 resv0:3;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_rx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			u32 classid:4;
+			u32 resv1:4;
+			u32 ep:4;
+			u32 color:2;
+			u32 mpe1:1;
+			u32 mpe2:1;
+			u32 enc:1;
+			u32 dec:1;
+			u32 nat:1;
+			u32 tcp_err:1;
+			u32 session_id:12;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_rx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			u32 data_ptr;
+		} __packed field;
+		u32 all;
+	};
+
+} __packed;
+
+struct dma_rx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			u32 data_len:16;
+			u32 mpoa_mode:2;
+			u32 mpoa_pt:1;
+			u32 qid:4;
+			u32 byte_offset:3;
+			u32 pdu_type:1;
+			u32 dic:1;
+			u32 eop:1;
+			u32 sop:1;
+			u32 c:1;
+			u32 own:1;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_0 {
+	/* DWORD 0 */
+	union {
+		struct {
+			u32 dest_sub_if_id:15;
+			u32 eth_type:2;
+			u32 flow_id:8;
+			u32 tunnel_id:4;
+			u32 resv0:3;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			u32 classid:4;
+			u32 resv1:4;
+			u32 ep:4;
+			u32 color:2;
+			u32 mpe1:1;
+			u32 mpe2:1;
+			u32 enc:1;
+			u32 dec:1;
+			u32 nat:1;
+			u32 tcp_err:1;
+			u32 session_id:12;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			u32 data_ptr;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			u32 data_len:16;
+			u32 mpoa_mode:2;
+			u32 mpoa_pt:1;
+			u32 qid:4;
+			u32 byte_offset:3;
+			u32 pdu_type:1;
+			u32 dic:1;
+			u32 eop:1;
+			u32 sop:1;
+			u32 c:1;
+			u32 own:1;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+#else				/*big endian */
+
+struct dma_rx_desc_0 {
+	/* DWORD 0 */
+	union {
+		struct {
+			u32 resv0:3;
+			u32 tunnel_id:4;
+			u32 flow_id:8;
+			u32 eth_type:2;
+			u32 dest_sub_if_id:15;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_rx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			u32 session_id:12;
+			u32 tcp_err:1;
+			u32 nat:1;
+			u32 dec:1;
+			u32 enc:1;
+			u32 mpe2:1;
+			u32 mpe1:1;
+			u32 color:2;
+			u32 ep:4;
+			u32 resv1:4;
+			u32 classid:4;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_rx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			u32 data_ptr;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_rx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			u32 own:1;
+			u32 c:1;
+			u32 sop:1;
+			u32 eop:1;
+			u32 dic:1;
+			u32 pdu_type:1;
+			u32 byte_offset:3;
+			u32 qid:4;
+			u32 mpoa_pt:1;
+			u32 mpoa_mode:2;
+			u32 data_len:16;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_0 {
+	union {
+		struct {
+			/* DWORD 0 */
+			u32 resv0:3;
+			u32 tunnel_id:4;
+			u32 flow_id:8;
+			u32 eth_type:2;
+			u32 dest_sub_if_id:15;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_1 {
+	/* DWORD 1 */
+	union {
+		struct {
+			u32 session_id:12;
+			u32 tcp_err:1;
+			u32 nat:1;
+			u32 dec:1;
+			u32 enc:1;
+			u32 mpe2:1;
+			u32 mpe1:1;
+			u32 color:2;
+			u32 ep:4;
+			u32 resv1:4;
+			u32 classid:4;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_2 {
+	/*DWORD 2 */
+	union {
+		struct {
+			u32 data_ptr;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+struct dma_tx_desc_3 {
+	/*DWORD 3 */
+	union {
+		struct {
+			u32 own:1;
+			u32 c:1;
+			u32 sop:1;
+			u32 eop:1;
+			u32 dic:1;
+			u32 pdu_type:1;
+			u32 byte_offset:3;
+			u32 qid:4;
+			u32 mpoa_pt:1;
+			u32 mpoa_mode:2;
+			u32 data_len:16;
+		} __packed field;
+		u32 all;
+	};
+} __packed;
+
+#endif
+#ifdef CONFIG_CPU_BIG_ENDIAN
+/*Note:pmac normally not DWORD aligned. Most time 2 bytes aligment */
+struct pmac_rx_hdr {
+	/*byte 0 */
+	u8 res1:1;
+	u8 ver_done:1;
+	u8 ip_offset:6;
+
+	/*byte 1 */
+	u8 tcp_h_offset:5;
+	u8 tcp_type:3;
+
+	/*byte 2 */
+	u8 sppid:4;
+	u8 class:4;
+
+	/*byte 3 */
+	u8 res2:6;
+	u8 pkt_type:2;
+
+	/*byte 4 */
+	u8 res3:1;
+	u8 redirect:1;
+	u8 res4:1;
+	u8 src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+
+	/*byte 5 */
+	u8 src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	u8 port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	u8 port_map2:8;	/*low:port map */
+} __packed;
+
+struct pmac_tx_hdr {
+	/*byte 0 */
+	u8 tcp_chksum:1;
+	u8 res1:1;
+	u8 ip_offset:6;
+
+	/*byte 1 */
+	u8 tcp_h_offset:5;
+	u8 tcp_type:3;
+
+	/*byte 2 */
+	u8 sppid:4;
+	u8 res:4;
+
+	/*byte 3 */
+	u8 port_map_en:1;
+	u8 res2:1;
+	u8 time_dis:1;
+	u8 class_en:1;
+	u8 res3:2;
+	u8 pkt_type:2;
+
+	/*byte 4 */
+	u8 fcs_ins_dis:1;
+	u8 redirect:1;
+	u8 time_stmp:1;
+	u8 src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+
+	/*byte 5 */
+	u8 src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	u8 port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	u8 port_map2:8;	/*low:port map */
+} __packed;
+
+#else
+
+/*Note:pmac normally not DWORD aligned. Most time 2 bytes aligment */
+struct pmac_rx_hdr {
+	/*byte 0 */
+	u8 ip_offset:6;
+	u8 ver_done:1;
+	u8 res1:1;
+
+	/*byte 1 */
+	u8 tcp_type:3;
+	u8 tcp_h_offset:5;
+
+	/*byte 2 */
+	u8 class:4;
+	u8 sppid:4;
+
+	/*byte 3 */
+	u8 pkt_type:2; /* refer to PMAC_TCP_TYPE */
+	u8 res2:6;
+
+	/*byte 4 */
+	u8 src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+	u8 res4:1;
+	u8 redirect:1;
+	u8 res3:1;
+
+	/*byte 5 */
+	u8 src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	u8 port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	u8 port_map2:8;	/*low:port map */
+} __packed;
+
+struct pmac_tx_hdr {
+	/*byte 0 */
+	u8 ip_offset:6;
+	u8 res1:1;
+	u8 tcp_chksum:1;
+
+	/*byte 1 */
+	u8 tcp_type:3;
+	u8 tcp_h_offset:5;
+
+	/*byte 2 */
+	u8 res:4;
+	u8 sppid:4;
+
+	/*byte 3 */
+	u8 pkt_type:2; /* refer to PMAC_TCP_TYPE */
+	u8 res3:2;
+	u8 class_en:1;
+	u8 time_dis:1;
+	u8 res2:1;
+	u8 port_map_en:1;
+
+	/*byte 4 */
+	u8 src_sub_inf_id:5;	/*high:mc:1 + vap:4 */
+	u8 time_stmp:1;
+	u8 redirect:1;
+	u8 fcs_ins_dis:1;
+
+	/*byte 5 */
+	u8 src_sub_inf_id2:8;	/*low:mc:1 + vap:4 */
+
+	/*byte 6 */
+	u8 port_map:8;	/*high:port map */
+
+	/*byte 7 */
+	u8 port_map2:8;	/*low:port map */
+} __packed;
+
+#endif
+
+#endif

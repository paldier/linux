From 638fea553561a9103455d08f98bc15c99e5b7e76 Mon Sep 17 00:00:00 2001
From: Rekha Eswaran <rekha.eswaran@intel.com>
Date: Tue, 9 Apr 2019 16:28:38 +0800
Subject: [PATCH] DRVLIB_SW-2162 - Datapath changes from lgmdev x64 to master
 branch

---
 drivers/net/ethernet/lantiq/datapath/Kconfig       |  81 ++
 drivers/net/ethernet/lantiq/datapath/Makefile      |   4 +-
 drivers/net/ethernet/lantiq/datapath/datapath.h    | 146 +++-
 .../net/ethernet/lantiq/datapath/datapath_api.c    | 952 +++------------------
 .../ethernet/lantiq/datapath/datapath_instance.c   |  48 +-
 .../ethernet/lantiq/datapath/datapath_instance.h   |   7 +-
 .../net/ethernet/lantiq/datapath/datapath_ioctl.c  |   8 +-
 .../net/ethernet/lantiq/datapath/datapath_ioctl.h  |   3 +-
 .../lantiq/datapath/datapath_logical_dev.c         |  11 +-
 .../net/ethernet/lantiq/datapath/datapath_misc.c   | 155 +++-
 .../ethernet/lantiq/datapath/datapath_notifier.c   |   2 +-
 .../lantiq/datapath/datapath_platform_dev.c        |   5 +-
 .../net/ethernet/lantiq/datapath/datapath_proc.c   | 285 +++++-
 .../ethernet/lantiq/datapath/datapath_proc_api.c   |   2 +-
 .../ethernet/lantiq/datapath/datapath_proc_qos.c   |   2 +-
 .../net/ethernet/lantiq/datapath/datapath_qos.c    |  15 +-
 .../net/ethernet/lantiq/datapath/datapath_soc.c    |  35 +-
 .../net/ethernet/lantiq/datapath/datapath_swdev.c  |  19 +-
 .../net/ethernet/lantiq/datapath/datapath_swdev.h  |   1 -
 .../net/ethernet/lantiq/datapath/gswip30/Kconfig   |  11 +-
 .../net/ethernet/lantiq/datapath/gswip30/Makefile  |  11 +-
 .../lantiq/datapath/gswip30/datapath_gswip.c       |   3 +-
 .../lantiq/datapath/gswip30/datapath_lookup_proc.c |   4 +-
 .../lantiq/datapath/gswip30/datapath_mib.c         |  22 +-
 .../lantiq/datapath/gswip30/datapath_misc.c        |  44 +-
 .../lantiq/datapath/gswip30/datapath_misc.h        |   3 +
 .../ethernet/lantiq/datapath/gswip30/datapath_rx.c | 334 ++++++++
 .../ethernet/lantiq/datapath/gswip30/datapath_tx.c | 437 ++++++++++
 .../net/ethernet/lantiq/datapath/gswip31/Kconfig   |  10 +-
 .../net/ethernet/lantiq/datapath/gswip31/Makefile  |  23 +-
 .../lantiq/datapath/gswip31/datapath_coc.c         |   3 +-
 .../lantiq/datapath/gswip31/datapath_gswip.c       |  11 +-
 .../datapath/gswip31/datapath_gswip_simulate.c     |   1 -
 .../lantiq/datapath/gswip31/datapath_lookup_proc.c |   2 -
 .../lantiq/datapath/gswip31/datapath_mib.c         |   2 -
 .../lantiq/datapath/gswip31/datapath_misc.c        |  66 +-
 .../lantiq/datapath/gswip31/datapath_misc.h        |  18 +-
 .../lantiq/datapath/gswip31/datapath_ppv4.c        |  16 +-
 .../lantiq/datapath/gswip31/datapath_ppv4.h        |   4 +-
 .../lantiq/datapath/gswip31/datapath_ppv4_api.c    |   1 -
 .../lantiq/datapath/gswip31/datapath_proc.c        |   2 +-
 .../ethernet/lantiq/datapath/gswip31/datapath_rx.c | 342 ++++++++
 .../datapath/gswip31/datapath_tc_asym_vlan.c       |  11 -
 .../ethernet/lantiq/datapath/gswip31/datapath_tx.c | 437 ++++++++++
 include/net/datapath_api.h                         | 723 ++++++++++++----
 include/net/datapath_api_qos.h                     |  21 +
 include/net/datapath_api_umt.h                     | 121 +++
 include/net/datapath_inst.h                        |  18 +-
 include/net/datapath_proc_api.h                    |  10 +-
 include/net/lantiq_cbm_api.h                       |   7 +
 50 files changed, 3175 insertions(+), 1324 deletions(-)

diff --git a/drivers/net/ethernet/lantiq/datapath/Kconfig b/drivers/net/ethernet/lantiq/datapath/Kconfig
index 99f7162effde..9f6625048ac1 100644
--- a/drivers/net/ethernet/lantiq/datapath/Kconfig
+++ b/drivers/net/ethernet/lantiq/datapath/Kconfig
@@ -12,6 +12,7 @@ menuconfig LTQ_DATAPATH
 	  Take note: All devices need to register to datapath Lib first
 
 if LTQ_DATAPATH
+
 config LTQ_DATAPATH_ACA_CSUM_WORKAROUND
 	bool "ACA Checksum Workaround"
 	default n
@@ -143,6 +144,86 @@ config LTQ_DATAPATH_CPUFREQ
 	---help---
 	  It is to support DFS(COC) in Datapath
 
+config INTEL_DATAPATH
+	bool
+	depends on LTQ_DATAPATH
+	default y
+
+config INTEL_DATAPATH_ACA_CSUM_WORKAROUND
+	bool
+	default y
+	depends on SOC_GRX500 && INTEL_DATAPATH && LTQ_DATAPATH_ACA_CSUM_WORKAROUND
+
+config INTEL_DATAPATH_MANUAL_PARSE
+	bool
+	default y
+	depends on INTEL_DATAPATH && LTQ_DATAPATH_MANUAL_PARSE
+
+config INTEL_DATAPATH_COPY_LINEAR_BUF_ONLY
+	bool
+	default y
+	depends on INTEL_DATAPATH && LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+
+config INTEL_DATAPATH_DBG
+	bool
+	default y
+	depends on INTEL_DATAPATH && LTQ_DATAPATH_DBG
+
+config INTEL_DATAPATH_DBG_PROTOCOL_PARSE
+	bool
+	default y
+	depends on INTEL_DATAPATH_DBG && LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+
+config INTEL_DATAPATH_EXTRA_DEBUG
+	bool
+	default y
+	depends on  INTEL_DATAPATH_DBG && LTQ_DATAPATH_EXTRA_DEBUG
+
+config INTEL_DATAPATH_SWDEV_TEST
+	bool
+	default y
+	depends on  INTEL_DATAPATH_DBG && INTEL_DATAPATH_SWITCHDEV && LTQ_DATAPATH_SWDEV_TEST
+
+config INTEL_DATAPATH_SKB
+	bool
+	default y
+	depends on  INTEL_DATAPATH && LTQ_DATAPATH_SKB
+
+config INTEL_DATAPATH_MPE_FASTHOOK_TEST
+	bool
+	default y
+	depends on  INTEL_DATAPATH_SKB && LTQ_DATAPATH_MPE_FASTHOOK_TEST
+
+config INTEL_DATAPATH_ETH_OAM
+	bool
+	default y
+	depends on  INTEL_DATAPATH_SKB && LTQ_DATAPATH_ETH_OAM
+
+config INTEL_DATAPATH_SWITCHDEV
+	bool
+	default y
+	depends on  INTEL_DATAPATH && LTQ_DATAPATH_SWITCHDEV
+
+config INTEL_DATAPATH_PTP1588
+	bool
+	default y
+	depends on  INTEL_DATAPATH && LTQ_DATAPATH_PTP1588
+
+config INTEL_DATAPATH_PTP1588_SW_WORKAROUND
+	bool
+	default y
+        depends on  INTEL_DATAPATH && INTEL_DATAPATH_PTP1588 && LTQ_DATAPATH_PTP1588_SW_WORKAROUND
+
+config INTEL_DATAPATH_DDR_SIMULATE_GSWIP31
+	bool
+	default y
+	depends on INTEL_DATAPATH && LTQ_DATAPATH_DDR_SIMULATE_GSWIP31
+
+config INTEL_DATAPATH_CPUFREQ
+	bool
+	default y
+	depends on INTEL_DATAPATH && CPU_FREQ && LTQ_DATAPATH_CPUFREQ
+
 source "drivers/net/ethernet/lantiq/datapath/gswip31/Kconfig"
 source "drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig"
 endif
diff --git a/drivers/net/ethernet/lantiq/datapath/Makefile b/drivers/net/ethernet/lantiq/datapath/Makefile
index 44ed059a5c04..6d7719c1d77a 100644
--- a/drivers/net/ethernet/lantiq/datapath/Makefile
+++ b/drivers/net/ethernet/lantiq/datapath/Makefile
@@ -1,9 +1,9 @@
 obj-$(CONFIG_LTQ_DATAPATH) = datapath_api.o datapath_proc_api.o datapath_proc.o  datapath_misc.o datapath_notifier.o datapath_logical_dev.o datapath_instance.o datapath_platform_dev.o datapath_soc.o datapath_qos.o datapath_proc_qos.o
 
-ifneq ($(CONFIG_LTQ_DATAPATH_HAL_GSWIP31),)
+ifneq ($(CONFIG_INTEL_DATAPATH_HAL_GSWIP31),)
 obj-$(CONFIG_LTQ_DATAPATH) += gswip31/
 endif
-ifneq ($(CONFIG_LTQ_DATAPATH_HAL_GSWIP30),)
+ifneq ($(CONFIG_INTEL_DATAPATH_HAL_GSWIP30),)
 obj-$(CONFIG_LTQ_DATAPATH) += gswip30/
 endif
 
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath.h b/drivers/net/ethernet/lantiq/datapath/datapath.h
index 918c2f6ed5d7..76c10e2c0ac7 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath.h
+++ b/drivers/net/ethernet/lantiq/datapath/datapath.h
@@ -10,37 +10,46 @@
 #ifndef DATAPATH_H
 #define DATAPATH_H
 
-#include <linux/klogging.h>
 #include <linux/skbuff.h>	/*skb */
 #include <linux/types.h>
 #include <linux/netdevice.h>
 #include <linux/platform_device.h>
-#include <net/lantiq_cbm_api.h>
-#include <linux/dma/lantiq_dmax.h>
 #include <linux/atomic.h>
+#include <linux/version.h>
+#include <net/ppa/qos_mgr_tc_hook.h>
+//#include "../cqm/cqm_common.h"
 
-//#define CONFIG_LTQ_DATAPATH_DUMMY_QOS
+//#define CONFIG_INTEL_DATAPATH_DUMMY_QOS
 //#define DUMMY_PPV4_QOS_API_OLD
-
+#define dp_vlan_dev_priv vlan_dev_priv
 #ifdef DUMMY_PPV4_QOS_API_OLD
 /*TODO:currently need to include both header file */
 #include <net/pp_qos_drv_slim.h>
-#include <net/pp_qos_drv.h>
+#include <linux/pp_qos_api.h>
 #else
-#include <net/pp_qos_drv.h>
+	#if LINUX_VERSION_CODE < KERNEL_VERSION(4,19,0)
+		#include <net/pp_qos_drv.h>
+	#else
+		#include <linux/pp_qos_api.h>
+	#endif
+#endif
+#if IS_ENABLED(CONFIG_INTEL_CBM_SKB) || \
+	LINUX_VERSION_CODE < KERNEL_VERSION(4,19,0)
+	#define DP_SKB_HACK
 #endif
 #include <net/datapath_api_qos.h>
-#ifdef CONFIG_NET_SWITCHDEV
+#if IS_ENABLED(CONFIG_NET_SWITCHDEV)
 #include <net/switchdev.h>
 #endif
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 #include "datapath_swdev.h"
 #endif
 #include <net/datapath_inst.h>
 
-#define MAX_SUBIFS 256
+#define MAX_SUBIFS 256  /* Max subif per DPID */
 #define MAX_DP_PORTS  16
 #define PMAC_SIZE 8
+#define PMAC_SIZE_GSW32	16
 #define PMAC_CPU_ID  0
 #define DP_MAX_BP_NUM 128
 #define DP_MAX_QUEUE_NUM 256
@@ -49,15 +58,21 @@
 
 #ifdef LOGF_KLOG_ERROR
 #define PR_ERR  LOGF_KLOG_ERROR
+#define DP_ERR  LOGF_KLOG_ERROR
+
 #else
 #define PR_ERR printk
+#define DP_ERR printk
 #endif
 
 #ifdef LOGF_KLOG_INFO
 #undef PR_INFO
-#define PR_INFO LOGF_KLOG_INFO
+#define PR_INFO LOGF_KLOG_ERROR
+#define DP_INFO LOGF_KLOG_ERROR
+
 #else
 #undef PR_INFO
+#define DP_INFO printk
 #define PR_INFO printk
 #endif
 
@@ -99,7 +114,7 @@
 	PR_ERR(fmt, ##arg); \
 } while (0)
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 #define DP_DEBUG(flags, fmt, arg...)  do { \
 	if (unlikely((dp_dbg_flag & (flags)) && \
 		     (((dp_print_num_en) && \
@@ -115,13 +130,13 @@
 
 #else
 #define DP_DEBUG(flags, fmt, arg...)
-#endif				/* end of CONFIG_LTQ_DATAPATH_DBG */
+#endif				/* end of CONFIG_INTEL_DATAPATH_DBG */
 
 #define IFNAMSIZ 16
 #define DP_MAX_HW_CAP 4
 
 #if (!IS_ENABLED(CONFIG_PRX300_CQM))
-#define DP_SPIN_LOCK 
+#define DP_SPIN_LOCK
 #endif
 #ifdef DP_SPIN_LOCK
 #define DP_DEFINE_LOCK(lock) DEFINE_SPINLOCK(lock)
@@ -342,7 +357,7 @@ enum DP_DBG_FLAG {
 	DP_DBG_ENUM_OR_STRING(DP_DBG_FLAG_MAX, "")\
 }
 
-enum QOS_FLAG {
+enum {
 	NODE_LINK_ADD = 0, /*add a link node */
 	NODE_LINK_GET,     /*get a link node */
 	NODE_LINK_EN_GET,  /*Get link status: enable/disable */
@@ -368,6 +383,7 @@ enum QOS_FLAG {
 	QUEUE_MAP_SET,     /*set lookup entries to the specified qid*/
 	NODE_CHILDREN_GET, /*get direct children list of node*/
 	QOS_LEVEL_GET,     /* get Max Scheduler level for Node */
+	QOS_Q_LOGIC,       /* get logical queue ID based on physical queue ID */
 	QOS_GLOBAL_CFG_GET, /* get global qos config info */
 };
 
@@ -394,7 +410,7 @@ struct logic_dev {
 /*! Sub interface detail information */
 struct dp_subif_info {
 	s32 flags;
-	u32 subif:15;
+	u32 subif;
 	struct net_device *netif; /*! pointer to  net_device */
 	char device_name[IFNAMSIZ]; /*! devide name, like wlan0, */
 	struct dev_mib mib; /*! mib */
@@ -402,11 +418,7 @@ struct dp_subif_info {
 	u16 bp; /*bridge port */
 	u16 fid; /* switch bridge id */
 	struct list_head logic_dev; /*unexplicit logical dev*/
-	struct net_device_ops *old_dev_ops;
-	struct net_device_ops new_dev_ops;
-#ifdef CONFIG_NET_SWITCHDEV
-	struct switchdev_ops *old_swdev_ops;
-	struct switchdev_ops new_swdev_ops;
+#if IS_ENABLED(CONFIG_NET_SWITCHDEV)
 	void *swdev_priv; /*to store ext vlan info*/
 #endif
 	s16 qid;    /* physical queue id */
@@ -418,10 +430,29 @@ struct dp_subif_info {
 	u32 subif_flag; /* To store original flag from caller during
 			 * dp_register_subif
 			 */
-	atomic_t rx_flag; /* To enable/disable DP rx */
 	u16 mac_learn_dis; /* To store mac learning capability of subif from
 			    * caller during dp_register_subif
 			    */
+	atomic_t rx_flag; /* To enable/disable DP rx */
+	atomic_t f_dfl_sess[DP_DFL_SESS_NUM]; /*! flag to indicate whether
+					       *  dfl_eg_sess valid or
+					       *  not
+					       */
+	u32 dfl_sess[DP_DFL_SESS_NUM]; /*! default CPU egress session ID
+					* Valid only if f_dfl_eg_sess is set
+					* one sesson per class[4 bits]
+					*/
+	u16 max_pkt_size;
+	u16 headroom_size;
+	u16 tailroom_size;
+	u16 min_pkt_len;
+#define DP_POLICY_PER_PORT 4
+	u16 policy_base;
+	u8 policy_num;
+	u16 pool_map; /* pool map: bit 0: POOL SIZE 0, bit 1: POOL_SIZE_1 and so on */
+	u8  pkt_only_en;
+	u8  seg_en;
+	u16 gpid;
 };
 
 struct vlan_info {
@@ -435,7 +466,7 @@ struct vlan_info {
 enum DP_TEMP_DMA_PMAC {
 	TEMPL_NORMAL = 0,
 	TEMPL_CHECKSUM,
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 	TEMPL_PTP,
 #endif
 	TEMPL_OTHERS,
@@ -455,7 +486,6 @@ struct pmac_port_info {
 	u32 dev_port;
 	u32 num_subif;
 	s32 port_id;
-	struct dp_subif_info subif_info[MAX_SUBIFS];
 	atomic_t tx_err_drop;
 	atomic_t rx_err_drop;
 	struct gsw_itf *itf_info;  /*point to switch interface configuration */
@@ -470,23 +500,37 @@ struct pmac_port_info {
 	u32 dma_chan; /*associated dma tx CH,-1 means no DMA CH*/
 	u32 tx_pkt_credit;  /*PP port tx bytes credit */
 	u32 tx_b_credit;  /*PP port tx bytes credit */
-	u32 tx_ring_addr;  /*PP port ring address. should follow HW definition*/
+	void *tx_ring_addr;  /*PP port ring address (physical address) */
+	void *tx_ring_addr_push;  /*PP port ring address. should follow HW definition*/
 	u32 tx_ring_size; /*PP ring size */
 	u32 tx_ring_offset;  /*PP: next tx_ring_addr=
 			      *   current tx_ring_addr + tx_ring_offset
 			      */
-	u32 lct_idx; /* LCT subif register flag */
+	u16 gpid_base; /* gpid base
+			* For CPU/DPDK:
+			*   alloc it in dp_platform_set
+			*   config it in dp_platform_set
+			* For peripheral device
+			*   alloc it at dp_alloc_port via gpid_port_assign
+			*   config it at dp_register_subif
+			*/
+	u16 gpid_num; /* reserved nubmer of continuous of gpid */
+	u16 gpid_spl;  /* special GPID:
+			* alloc it at dp_alloc_port
+			* config it at dp_register_dev for policy setting
+			*/
+	u16 policy_base; /* policy base */
+	u8 policy_num;   /* policy number */
+	u16 pool_map; /* pool map: bit 0: POOL SIZE 0, bit 1: POOL_SIZE_1 and so on */
 	u32 num_dma_chan; /*For G.INT it's 8 or 16, for other 1*/
+	u32 lct_idx; /* LCT subif register flag */
 	u32 dma_ch_base; /*! Base entry index of dp_dma_chan_tbl */
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 	u32 f_ptp:1; /* PTP1588 support enablement */
 #endif
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	u32 swdev_en; /* switchdev enable/disable flag for port */
 #endif
-};
-
-struct pmac_port_info2 {
 	/*only valid for 1st dp instanace which need dp_xmit/dp_rx*/
 	/*[0] for non-checksum case,
 	 *[1] for checksum offload
@@ -499,6 +543,11 @@ struct pmac_port_info2 {
 	struct dma_tx_desc_0 dma0_mask_template[MAX_TEMPLATE];
 	struct dma_tx_desc_1 dma1_template[MAX_TEMPLATE];
 	struct dma_tx_desc_1 dma1_mask_template[MAX_TEMPLATE];
+	struct dma_tx_desc_3 dma3_template[MAX_TEMPLATE];
+	struct dma_tx_desc_3 dma3_mask_template[MAX_TEMPLATE];
+	/* These members must be end. */
+	u32 tail;
+	struct dp_subif_info *subif_info;
 };
 
 /*bridge port with pmapper supported dev structure */
@@ -525,7 +574,7 @@ struct q_info {
 };
 
 /*scheduler struct */
-struct sched_info {
+struct dp_sched_info {
 	int flag;  /*0-FREE, 1-Used*/
 	int ref_cnt; /*subif_counter*/
 	int cqm_dequeue_port; /*CQM dequeue port */
@@ -539,7 +588,8 @@ struct cqm_port_info {
 	int f_first_qid : 1; /*0 not valid */
 	u32 ref_cnt; /*reference counter: the number of CTP attached to it*/
 	u32 tx_pkt_credit;  /*PP port tx bytes credit */
-	u32 tx_ring_addr;  /*PP port ring address. should follow HW definition*/
+	void *tx_ring_addr;  /*PP port ring address. should follow HW definition*/
+	void *tx_ring_addr_push;  /*PP port ring address. should follow HW definition*/
 	u32 tx_ring_size; /*PP port ring size */
 	int qos_port; /*qos port id*/
 	int first_qid; /*in order to auto sharing queue, 1st queue allocated by
@@ -644,7 +694,7 @@ struct dp_tc_vlan_info {
 	int inst;  /*DP instance */
 };
 
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#ifdef CONFIG_INTEL_DATAPATH_CPUFREQ
 enum CPUFREQ_FLAG {
 	PRE_CHANGE = 0,		/*! Cpufreq transition prechange */
 	POST_CHANGE,		/*! Cpufreq transition postchange */
@@ -654,21 +704,23 @@ enum CPUFREQ_FLAG {
 
 /*port 0 is reserved*/
 extern int dp_inst_num;
+extern int dp_print_len;
 extern struct inst_property dp_port_prop[DP_MAX_INST];
-extern struct pmac_port_info dp_port_info[DP_MAX_INST][MAX_DP_PORTS];
-extern struct pmac_port_info2 dp_port_info2[DP_MAX_INST][MAX_DP_PORTS];
+extern struct pmac_port_info *dp_port_info[DP_MAX_INST];
 extern struct q_info dp_q_tbl[DP_MAX_INST][DP_MAX_QUEUE_NUM];
-extern struct sched_info dp_sched_tbl[DP_MAX_INST][DP_MAX_SCHED_NUM];
+extern struct dp_sched_info dp_sched_tbl[DP_MAX_INST][DP_MAX_SCHED_NUM];
 extern struct cqm_port_info dp_deq_port_tbl[DP_MAX_INST][DP_MAX_CQM_DEQ];
 extern struct bp_pmapper_dev dp_bp_dev_tbl[DP_MAX_INST][DP_MAX_BP_NUM];
 extern struct dma_chan_info *dp_dma_chan_tbl[DP_MAX_INST];
-
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
 extern u32 dp_dbg_flag;
 extern unsigned int dp_dbg_err;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 extern unsigned int dp_max_print_num;
 extern unsigned int dp_print_num_en;
 #endif
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+extern int aca_portid;
+#endif
 
 int dp_loop_eth_dev_init(struct dentry *parent);
 void dp_loop_eth_dev_exit(void);
@@ -688,6 +740,7 @@ enum TEST_MODE {
 
 extern u32 dp_rx_test_mode;
 extern struct dma_rx_desc_1 dma_rx_desc_mask1;
+extern struct dma_rx_desc_2 dma_rx_desc_mask2;
 extern struct dma_rx_desc_3 dma_rx_desc_mask3;
 extern struct dma_rx_desc_0 dma_tx_desc_mask0;
 extern struct dma_rx_desc_1 dma_tx_desc_mask1;
@@ -763,7 +816,7 @@ void set_dp_dbg_flag(uint32_t flags);
 uint32_t get_dp_dbg_flag(void);
 void dp_dump_raw_data(char *buf, int len, char *prefix_str);
 
-#ifdef CONFIG_LTQ_TOE_DRIVER
+#if IS_ENABLED(CONFIG_LTQ_TOE_DRIVER)
 /*! @brief  ltq_tso_xmit
  *@param[in] skb  pointer to packet buffer like sk_buff
  *@param[in] hdr  point to packet header, like pmac header
@@ -787,10 +840,19 @@ int dp_request_inst(struct dp_inst_info *info, u32 flag);
 int register_dp_cap(u32 flag);
 typedef GSW_return_t(*dp_gsw_cb)(void *, void *);
 int bp_pmapper_dev_get(int inst, struct net_device *dev);
+extern int dp_init_ok;
+void set_chksum(struct pmac_tx_hdr *pmac, u32 tcp_type,
+		u32 ip_offset, int ip_off_hw_adjust, u32 tcp_h_offset);
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,13,0)
 extern int32_t (*qos_mgr_hook_setup_tc)(struct net_device *dev, u32 handle,
 					__be16 protocol,
 					struct tc_to_netdev *tc);
+#else
+extern int32_t (*qos_mgr_hook_setup_tc)(struct net_device *dev,
+					enum tc_setup_type type,
+					void *type_data);
+#endif
 
 #define DP_SUBIF_LIST_HASH_SHIFT 8
 #define DP_SUBIF_LIST_HASH_BIT_LENGTH 10
@@ -813,9 +875,13 @@ struct dp_subif_cache *dp_subif_lookup_safe(struct hlist_head *head,
 					    struct net_device *dev,
 					    void *data);
 int dp_subif_list_init(void);
+int parser_enabled(int ep, struct dma_rx_desc_1 *desc_1);
+int dp_lan_wan_bridging(int port_id, struct sk_buff *skb);
 u32 get_dma_chan_idx(int inst, int num_dma_chan);
 u32 alloc_dma_chan_tbl(int inst);
 void free_dma_chan_tbl(int inst);
+u32 alloc_dp_port_subif_info(int inst);
+void free_dp_port_subif_info(int inst);
 u32 dp_subif_hash(struct net_device *dev);
 int32_t dp_get_netif_subifid_priv(struct net_device *netif,
 				  struct sk_buff *skb, void *subif_data,
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_api.c b/drivers/net/ethernet/lantiq/datapath/datapath_api.c
index dcbf9fdaf0b0..d31ee9ba01ab 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_api.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_api.c
@@ -22,25 +22,19 @@
 #include <linux/clk.h>
 #include <linux/ip.h>
 #include <net/ip.h>
-#include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
-#include <net/datapath_api_skb.h>
 #include "datapath.h"
 #include "datapath_instance.h"
 #include "datapath_swdev_api.h"
 
-#if IS_ENABLED(CONFIG_PPA_API_SW_FASTPATH)
-#include <net/ppa/ppa_api.h>
-#endif
-
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 unsigned int dp_max_print_num = -1, dp_print_num_en = 0;
 #endif
 
 GSW_API_HANDLE gswr_r;
 u32    dp_rx_test_mode = DP_RX_MODE_NORMAL;
 struct dma_rx_desc_1 dma_rx_desc_mask1;
+struct dma_rx_desc_2 dma_rx_desc_mask2;
 struct dma_rx_desc_3 dma_rx_desc_mask3;
 struct dma_rx_desc_0 dma_tx_desc_mask0;
 struct dma_rx_desc_1 dma_tx_desc_mask1;
@@ -50,20 +44,6 @@ u32 dp_pkt_size_check;
 u32 dp_dbg_flag;
 EXPORT_SYMBOL(dp_dbg_flag);
 
-#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
-u32 ltq_mpe_eanble;
-EXPORT_SYMBOL(ltq_mpe_eanble);
-
-int (*ltq_mpe_fasthook_free_fn)(struct sk_buff *) = NULL;
-EXPORT_SYMBOL(ltq_mpe_fasthook_free_fn);
-
-int (*ltq_mpe_fasthook_tx_fn)(struct sk_buff *, u32, void *) = NULL;
-EXPORT_SYMBOL(ltq_mpe_fasthook_tx_fn);
-
-int (*ltq_mpe_fasthook_rx_fn)(struct sk_buff *, u32, void *) = NULL;
-EXPORT_SYMBOL(ltq_mpe_fasthook_rx_fn);
-#endif	/*CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST */
-
 #undef DP_DBG_ENUM_OR_STRING
 #define DP_DBG_ENUM_OR_STRING(name, short_name) short_name
 char *dp_dbg_flag_str[] = DP_DBG_FLAG_LIST;
@@ -89,18 +69,17 @@ char *dp_port_status_str[] = {
 };
 
 static int try_walkaround;
-static int dp_init_ok;
+int dp_init_ok;
 DP_DEFINE_LOCK(dp_lock);
 unsigned int dp_dbg_err = 1; /*print error */
-static int32_t dp_rx_one_skb(struct sk_buff *skb, uint32_t flags);
+EXPORT_SYMBOL(dp_dbg_err);
+
 /*port 0 is reserved and never assigned to any one */
 int dp_inst_num;
 /* Keep per DP instance information here */
 struct inst_property dp_port_prop[DP_MAX_INST];
 /* Keep all subif information per instance/LPID/subif */
-struct pmac_port_info dp_port_info[DP_MAX_INST][MAX_DP_PORTS];
-/* Keep all default DMA descriptor mask/bit per instance/LPID */
-struct pmac_port_info2 dp_port_info2[DP_MAX_INST][MAX_DP_PORTS];
+struct pmac_port_info *dp_port_info[DP_MAX_INST];
 
 /* bp_mapper_dev[] is mainly for PON case
  * Only if multiple gem port are attached to same bridge port,
@@ -113,7 +92,7 @@ struct bp_pmapper_dev dp_bp_dev_tbl[DP_MAX_INST][DP_MAX_BP_NUM];
 struct q_info dp_q_tbl[DP_MAX_INST][DP_MAX_QUEUE_NUM];
 /* sched_tbl[] is mainly for the sched created/used during dp_register_subif_ext
  */
-struct sched_info dp_sched_tbl[DP_MAX_INST][DP_MAX_SCHED_NUM];
+struct dp_sched_info dp_sched_tbl[DP_MAX_INST][DP_MAX_SCHED_NUM];
 /* dp_deq_port_tbl[] is to record cqm dequeue port info
  */
 struct cqm_port_info dp_deq_port_tbl[DP_MAX_INST][DP_MAX_CQM_DEQ];
@@ -122,11 +101,12 @@ struct cqm_port_info dp_deq_port_tbl[DP_MAX_INST][DP_MAX_CQM_DEQ];
 struct dma_chan_info *dp_dma_chan_tbl[DP_MAX_INST];
 
 struct parser_info pinfo[4];
-static int print_len;
-#ifdef CONFIG_LTQ_DATAPATH_ACA_CSUM_WORKAROUND
+int dp_print_len;
+
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
 static struct module aca_owner;
 static struct net_device aca_dev;
-static int aca_portid = -1;
+int aca_portid = -1;
 #endif
 
 char *get_dp_port_type_str(int k)
@@ -157,7 +137,7 @@ int get_dp_port_status_str_size(void)
 int parser_size_via_index(u8 index)
 {
 	if (index >= ARRAY_SIZE(pinfo)) {
-		PR_ERR("Wrong index=%d, it should less than %d\n", index,
+		PR_ERR("Wrong index=%d, it should less than %zu\n", index,
 		       ARRAY_SIZE(pinfo));
 		return 0;
 	}
@@ -165,17 +145,22 @@ int parser_size_via_index(u8 index)
 	return pinfo[index].size;
 }
 
-static inline int parser_enabled(int ep, struct dma_rx_desc_1 *desc_1)
+int parser_enabled(int ep, struct dma_rx_desc_1 *desc_1)
 {
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
 	if (!desc_1) {
 		PR_ERR("NULL desc_1 is not allowed\n");
 		return 0;
 	}
 #endif
+
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SIMULATE_GSWIP32) || \
+	IS_ENABLED(CONFIG_X86_INTEL_LGM)
+#else
 	if (!ep)
 		return pinfo[(desc_1->field.mpe2 << 1) +
 			desc_1->field.mpe1].size;
+#endif
 	return 0;
 }
 
@@ -354,7 +339,6 @@ static int32_t dp_alloc_port_private(int inst,
 				     u32 flags)
 {
 	int i;
-	u16 dma_ch_base;
 	struct cbm_dp_alloc_data cbm_data = {0};
 
 	if (!owner) {
@@ -370,7 +354,7 @@ static int32_t dp_alloc_port_private(int inst,
 		return DP_FAILURE;
 	}
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	if (unlikely(dp_dbg_flag & DP_DBG_FLAG_REG)) {
 		DP_DEBUG(DP_DBG_FLAG_REG, "Flags=");
 		for (i = 0; i < ARRAY_SIZE(dp_port_type_str); i++)
@@ -396,8 +380,9 @@ static int32_t dp_alloc_port_private(int inst,
 		dp_inst_insert_mod(owner, port_id, inst, 0);
 		DP_DEBUG(DP_DBG_FLAG_REG, "de-alloc port %d\n", port_id);
 		DP_CB(inst, port_platform_set)(inst, port_id, data, flags);
+		/* Only clear those fields we need to clear */
 		memset(&dp_port_info[inst][port_id], 0,
-		       sizeof(dp_port_info[inst][port_id]));
+		       offsetof(struct pmac_port_info, tail));
 		return DP_SUCCESS;
 	}
 	if (port_id) { /*with specified port_id */
@@ -424,9 +409,15 @@ static int32_t dp_alloc_port_private(int inst,
 		       owner->name, dev_port);
 		return DP_FAILURE;
 	}
+	DP_DEBUG(DP_DBG_FLAG_REG,
+		 "cbm alloc dpport:%d deq:%d dmachan=0x%x deq_num:%d\n",
+		 cbm_data.dp_port, cbm_data.deq_port, cbm_data.dma_chan,
+		 cbm_data.deq_port_num);
+	
 	port_id = cbm_data.dp_port;
+	/* Only clear those fields we need to clear */
 	memset(&dp_port_info[inst][port_id], 0,
-	       sizeof(dp_port_info[inst][port_id]));
+	       offsetof(struct pmac_port_info, tail));
 	/*save info from caller */
 	dp_port_info[inst][port_id].owner = owner;
 	dp_port_info[inst][port_id].dev = dev;
@@ -438,49 +429,52 @@ static int32_t dp_alloc_port_private(int inst,
 	dp_port_info[inst][port_id].port_id = cbm_data.dp_port;
 	dp_port_info[inst][port_id].deq_port_base = cbm_data.deq_port;
 	dp_port_info[inst][port_id].deq_port_num = cbm_data.deq_port_num;
+	DP_DEBUG(DP_DBG_FLAG_REG,
+		 "cbm alloc dp_port:%d deq:%d deq_num:%d\n",
+		 cbm_data.dp_port, cbm_data.deq_port, cbm_data.deq_port_num);
+
 	dp_port_info[inst][port_id].num_dma_chan = cbm_data.num_dma_chan;
-	/*save info to port data*/
-	data->deq_port_base = dp_port_info[inst][port_id].deq_port_base;
-	data->deq_num = dp_port_info[inst][port_id].deq_port_num;
+#if 1  /* TODO: Hardcorded currently, later need to align with CQM */
+	dp_port_info[inst][port_id].policy_base = 0;
+	dp_port_info[inst][port_id].policy_num = 4;
+#endif
 	if (cbm_data.num_dma_chan) {
+		u16 dma_ch_base;
+
 		dma_ch_base = get_dma_chan_idx(inst, cbm_data.num_dma_chan);
 		if (dma_ch_base == DP_FAILURE) {
-			PR_ERR("Failed get_dma_chan_idx!!\n");
+			DP_ERR("Failed get_dma_chan_idx!!\n");
 			cbm_dp_port_dealloc(owner, dev_port, port_id, &cbm_data,
 					    flags | DP_F_DEREGISTER);
+			/* Only clear those fields we need to clear */
 			memset(&dp_port_info[inst][port_id], 0,
-			       sizeof(dp_port_info[inst][port_id]));
+			       offsetof(struct pmac_port_info, tail));
 			return DP_FAILURE;
 		}
 		dp_port_info[inst][port_id].dma_ch_base = dma_ch_base;
 	}
-	DP_DEBUG(DP_DBG_FLAG_REG,
-		 "cbm alloc dp_port:%d deq:%d deq_num:%d no_dma_chan:%d\n",
-		 cbm_data.dp_port, cbm_data.deq_port, cbm_data.deq_port_num,
-		 cbm_data.num_dma_chan);
+	/*save info to port data*/
+	data->deq_port_base = dp_port_info[inst][port_id].deq_port_base;
+	data->deq_num = dp_port_info[inst][port_id].deq_port_num;
 	if (cbm_data.flags & CBM_PORT_DMA_CHAN_SET)
 		dp_port_info[inst][port_id].dma_chan = cbm_data.dma_chan;
 	if (cbm_data.flags & CBM_PORT_PKT_CRDT_SET)
 		dp_port_info[inst][port_id].tx_pkt_credit =
 				cbm_data.tx_pkt_credit;
 	if (cbm_data.flags & CBM_PORT_BYTE_CRDT_SET)
-	dp_port_info[inst][port_id].tx_b_credit = cbm_data.tx_b_credit;
-	if (cbm_data.flags & CBM_PORT_RING_ADDR_SET)
-	dp_port_info[inst][port_id].tx_ring_addr = cbm_data.tx_ring_addr;
+		dp_port_info[inst][port_id].tx_b_credit = cbm_data.tx_b_credit;
+	if (cbm_data.flags & CBM_PORT_RING_ADDR_SET) {
+		dp_port_info[inst][port_id].tx_ring_addr = cbm_data.tx_ring_addr;
+		dp_port_info[inst][port_id].tx_ring_addr_push = cbm_data.tx_ring_addr_txpush;
+	}
 	if (cbm_data.flags & CBM_PORT_RING_SIZE_SET)
 	dp_port_info[inst][port_id].tx_ring_size = cbm_data.tx_ring_size;
 	if (cbm_data.flags & CBM_PORT_RING_OFFSET_SET)
 		dp_port_info[inst][port_id].tx_ring_offset =
 				cbm_data.tx_ring_offset;
-
-	DP_DEBUG(DP_DBG_FLAG_DBG, "cid=%d pid=%d nid=%d\n",
-		 _DMA_CONTROLLER(cbm_data.dma_chan),
-		 _DMA_PORT(cbm_data.dma_chan),
-		 _DMA_CHANNEL(cbm_data.dma_chan));
-
-	if ((cbm_data.num_dma_chan) && (cbm_data.num_dma_chan >
-		cbm_data.deq_port_num)) {
-		PR_ERR("ERROR: deq_port_num=%d  not equal to num_dma_chan=%d\n",
+	if((cbm_data.num_dma_chan > 1) && (cbm_data.deq_port_num !=
+	   cbm_data.num_dma_chan)) {
+		PR_ERR("ERROR:deq_port_num=%d not equal to num_dma_chan=%d\n",
 		       cbm_data.deq_port_num, cbm_data.num_dma_chan);
 		return DP_FAILURE;
 	}
@@ -491,8 +485,9 @@ static int32_t dp_alloc_port_private(int inst,
 		       port_id, owner ? owner->name : "");
 		cbm_dp_port_dealloc(owner, dev_port, port_id, &cbm_data,
 				    flags | DP_F_DEREGISTER);
+		/* Only clear those fields we need to clear */
 		memset(&dp_port_info[inst][port_id], 0,
-		       sizeof(dp_port_info[inst][port_id]));
+		       offsetof(struct pmac_port_info, tail));
 		return DP_FAILURE;
 	}
 	if (pmac_cfg)
@@ -597,6 +592,7 @@ int32_t dp_register_subif_private(int inst, struct module *owner,
 		cqm_deq_port = port_info->subif_info[i].cqm_deq_port;
 		dma_ch_offset =
 			dp_deq_port_tbl[inst][cqm_deq_port].dma_ch_offset;
+
 		port_info->subif_info[i].flags = 1;
 		port_info->subif_info[i].netif = dev;
 		port_info->port_id = port_id;
@@ -642,15 +638,15 @@ int32_t dp_register_subif_private(int inst, struct module *owner,
 			dma_ch_ref = atomic_read(&(dp_dma_chan_tbl[inst] +
 						 dma_ch_offset)->ref_cnt);
 			/* PPA Directpath/LitePath don't have DMA CH */
-			if (dma_ch_ref == 1 && !(port_info->alloc_flags &
-			    DP_F_DIRECT) && (cbm_data.num_dma_chan))
+			if (dma_ch_ref == 1 &&
+			    !(port_info->alloc_flags & DP_F_DIRECT))
 				cbm_data.dma_chnl_init = 1; /*to enable DMA*/
-			DP_DEBUG(DP_DBG_FLAG_REG, "%s:%s%d %s%d %s%d %s%d\n",
+			DP_DEBUG(DP_DBG_FLAG_REG, "%s:%s%d %s%d %s%d  %s%d\n",
 				 "cbm_dp_enable",
 				 "dp_port=", port_id,
 				 "deq_port=", cbm_data.deq_port,
 				 "dma_chnl_init=", cbm_data.dma_chnl_init,
-				 "tx_dma_chan: (ref=%d)",
+				 "tx_dma_chan ref=%d\n",
 				 dma_ch_ref);
 			if (cbm_dp_enable(owner, port_id, &cbm_data, 0,
 					  port_info->alloc_flags)) {
@@ -763,9 +759,6 @@ int32_t dp_deregister_subif_private(int inst, struct module *owner,
 		port_info->status = PORT_DEV_REGISTERED;
 
 	if (!dp_deq_port_tbl[inst][cqm_port].ref_cnt) {
-		u32 dma_ch_ref;
-		u32 dma_ch_offset;
-
 		/*delete all queues which may created by PPA or other apps*/
 		struct dp_node_alloc port_node;
 
@@ -778,11 +771,8 @@ int32_t dp_deregister_subif_private(int inst, struct module *owner,
 		cbm_data.dp_inst = inst;
 		cbm_data.cbm_inst = dp_port_prop[inst].cbm_inst;
 		cbm_data.deq_port = cqm_port;
-		dma_ch_offset = dp_deq_port_tbl[inst][cqm_port].dma_ch_offset;
-		dma_ch_ref = atomic_read(&(dp_dma_chan_tbl[inst] +
-					 dma_ch_offset)->ref_cnt);
 		/* PPA Directpath/LitePath don't have DMA CH */
-		if (dma_ch_ref == 0 && !(port_info->alloc_flags & DP_F_DIRECT))
+		if (!(port_info->alloc_flags & DP_F_DIRECT))
 			cbm_data.dma_chnl_init = 1; /*to disable DMA */
 		if (cbm_dp_enable(owner, port_id, &cbm_data,
 				  CBM_PORT_F_DISABLE, port_info->alloc_flags)) {
@@ -867,7 +857,7 @@ int32_t dp_alloc_port_ext(int inst, struct module *owner,
 	if (inst) /* only inst zero need ACA workaround */
 		return res;
 
-#ifdef CONFIG_LTQ_DATAPATH_ACA_CSUM_WORKAROUND
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
 	/*For VRX518, it will always carry DP_F_FAST_WLAN flag for
 	 * ACA HW resource purpose in CBM
 	 */
@@ -924,8 +914,10 @@ int32_t dp_register_dev_ext(int inst, struct module *owner, uint32_t port_id,
 {
 	int res = DP_FAILURE;
 	struct pmac_port_info *port_info;
+#if 0
+	struct cbm_dp_alloc_complete_data cbm_data = {0};
+#endif
 	struct dp_dev_data tmp_data = {0};
-
 	if (unlikely(!dp_init_ok)) {
 		PR_ERR("dp_register_dev failed for datapath not init yet\n");
 		return DP_FAILURE;
@@ -968,7 +960,13 @@ int32_t dp_register_dev_ext(int inst, struct module *owner, uint32_t port_id,
 		return res;
 	}
 
+#if 0
 	/*register a device */
+	if (cbm_dp_port_alloc_complete(owner, port_info->dev,
+		port_info->dev_port, port_id, &cbm_data, flags)) {
+		;
+	}
+#endif
 	if (port_info->status != PORT_ALLOCATED) {
 		DP_DEBUG(DP_DBG_FLAG_REG,
 			 "No de-register for %s for unknown status:%d\n",
@@ -977,7 +975,7 @@ int32_t dp_register_dev_ext(int inst, struct module *owner, uint32_t port_id,
 	}
 
 	if (port_info->owner != owner) {
-		DP_DEBUG(DP_DBG_FLAG_REG, "No matched owner(%s):%p->%p\n",
+		DP_DEBUG(DP_DBG_FLAG_REG, "No matched owner(%s):%px->%px\n",
 			 owner->name, owner, port_info->owner);
 		DP_LIB_UNLOCK(&dp_lock);
 		return res;
@@ -1058,7 +1056,7 @@ int32_t dp_register_subif_ext(int inst, struct module *owner,
 
 	if (((!dev) && !(port_info->alloc_flags & DP_F_FAST_DSL)) ||
 	    !subif_name) {
-		DP_DEBUG(DP_DBG_FLAG_REG, "Wrong dev=%p, subif_name=%p\n",
+		DP_DEBUG(DP_DBG_FLAG_REG, "Wrong dev=%px, subif_name=%px\n",
 			 dev, subif_name);
 		return DP_FAILURE;
 	}
@@ -1067,7 +1065,7 @@ int32_t dp_register_subif_ext(int inst, struct module *owner,
 	DP_LIB_LOCK(&dp_lock);
 	if (port_info->owner != owner) {
 		DP_DEBUG(DP_DBG_FLAG_REG,
-			 "Unregister subif fail:Not matching:%p(%s)->%p(%s)\n",
+			 "Unregister subif fail:Not matching:%px(%s)->%px(%s)\n",
 			 owner, owner->name, port_info->owner,
 			 port_info->owner->name);
 		DP_LIB_UNLOCK(&dp_lock);
@@ -1086,9 +1084,10 @@ int32_t dp_register_subif_ext(int inst, struct module *owner,
 					  subif_id, data, flags);
 	if (!(flags & DP_F_SUBIF_LOGICAL))
 		subifid_fn_t = port_info->cb.get_subifid_fn;
+	
 	subif_id_sync = kmalloc(sizeof(*subif_id_sync) * 2, GFP_KERNEL);
 	if (!subif_id_sync) {
-		PR_ERR("Failed to alloc %d bytes\n",
+		PR_ERR("Failed to alloc %zu bytes\n",
 		       sizeof(*subif_id_sync) * 2);
 		return DP_FAILURE;
 	}
@@ -1195,31 +1194,32 @@ int32_t dp_get_netif_subifid_priv(struct net_device *netif, struct sk_buff *skb,
 	u16 *subifs = NULL;
 	u32 *subif_flag = NULL;
 	struct logic_dev *tmp = NULL;
+	u16 gpid = 0;
 
 	subifs = kmalloc(sizeof(*subifs) * DP_MAX_CTP_PER_DEV,
 			 GFP_ATOMIC);
 	if (!subifs) {
-		PR_ERR("Failed to alloc %d bytes\n",
+		PR_ERR("Failed to alloc %zu bytes\n",
 		       sizeof(*subifs) * DP_MAX_CTP_PER_DEV);
 		return res;
 	}
 	subif_flag = kmalloc(sizeof(*subif_flag) * DP_MAX_CTP_PER_DEV,
 			     GFP_ATOMIC);
 	if (!subif_flag) {
-		PR_ERR("Failed to alloc %d bytes\n",
+		PR_ERR("Failed to alloc %zu bytes\n",
 		       sizeof(*subif_flag) * DP_MAX_CTP_PER_DEV);
 		kfree(subifs);
 		return res;
 	}
 	if (!netif && !subif_data) {
 		DP_DEBUG(DP_DBG_FLAG_REG,
-			 "dp_get_netif_subifid failed: netif=%p subif_data=%p\n",
+			 "dp_get_netif_subifid failed: netif=%px subif_data=%px\n",
 			 netif, subif_data);
 		goto EXIT;
 	}
 	if (!subif) {
 		DP_DEBUG(DP_DBG_FLAG_REG,
-			 "dp_get_netif_subifid failed:subif=%p\n", subif);
+			 "dp_get_netif_subifid failed:subif=%px\n", subif);
 		goto EXIT;
 	}
 	if (!netif && subif_data)
@@ -1264,6 +1264,8 @@ int32_t dp_get_netif_subifid_priv(struct net_device *netif, struct sk_buff *skb,
 							subif_flag);
 				bport = PORT_SUBIF(inst, k, i, bp);
 				subif->flag_bp = 0;
+				gpid = PORT_SUBIF(inst, k, i, gpid);
+				subif->def_qid = PORT_SUBIF(inst, k, i, qid);
 				num++;
 				break;
 			}
@@ -1290,6 +1292,9 @@ int32_t dp_get_netif_subifid_priv(struct net_device *netif, struct sk_buff *skb,
 					 */
 					subifs[num] = PORT_SUBIF(inst, k, i,
 								 subif);
+					gpid = PORT_SUBIF(inst, k, i, gpid);
+					subif->def_qid = PORT_SUBIF(inst, k, i,
+							     qid);
 					subif_flag[num] = PORT_SUBIF(inst, k, i,
 								subif_flag);
 					if (dp_port_info[inst][k].subif_info[i].
@@ -1320,6 +1325,10 @@ int32_t dp_get_netif_subifid_priv(struct net_device *netif, struct sk_buff *skb,
 					subif->inst = inst;
 					subif->port_id = k;
 					subif->bport = tmp->bp;
+					subif->gpid = dp_port_info[inst][k].
+					    subif_info[i].gpid;
+					subif->def_qid = dp_port_info[inst][k].
+					    subif_info[i].qid;
 					res = 0;
 					/*note: logical device no callback */
 					goto EXIT;
@@ -1333,7 +1342,7 @@ int32_t dp_get_netif_subifid_priv(struct net_device *netif, struct sk_buff *skb,
 	if (port_id < 0) {
 		if (subif_data)
 			DP_DEBUG(DP_DBG_FLAG_DBG,
-				 "dp_get_netif_subifid failed with subif_data %p\n",
+				 "dp_get_netif_subifid failed with subif_data %px\n",
 				 subif_data);
 		else /*netif must should be valid */
 			DP_DEBUG(DP_DBG_FLAG_DBG,
@@ -1345,6 +1354,7 @@ int32_t dp_get_netif_subifid_priv(struct net_device *netif, struct sk_buff *skb,
 	subif->inst = inst;
 	subif->port_id = port_id;
 	subif->bport = bport;
+	subif->gpid = gpid;
 	subif->alloc_flag = dp_port_info[inst][port_id].alloc_flags;
 	subif->subif_num = num;
 	for (i = 0; i < num; i++) {
@@ -1728,7 +1738,7 @@ int dp_set_pmapper(struct net_device *dev, struct dp_pmapper *mapper, u32 flag)
 	}
 	map = kmalloc(sizeof(*map), GFP_ATOMIC);
 	if (!map) {
-		PR_ERR("Failed for kmalloc: %d bytes\n", sizeof(*map));
+		PR_ERR("Failed for kmalloc: %zu bytes\n", sizeof(*map));
 		return DP_FAILURE;
 	}
 	memcpy(map, mapper, sizeof(*map));
@@ -1828,6 +1838,7 @@ int32_t dp_rx(struct sk_buff *skb, uint32_t flags)
 {
 	struct sk_buff *next;
 	int res = -1;
+	int inst = 0;
 
 	if (unlikely(!dp_init_ok)) {
 		while (skb) {
@@ -1841,7 +1852,7 @@ int32_t dp_rx(struct sk_buff *skb, uint32_t flags)
 	while (skb) {
 		next = skb->next;
 		skb->next = 0;
-		res = dp_rx_one_skb(skb, flags);
+		res = dp_port_prop[inst].info.dp_rx(skb, flags);
 		skb = next;
 	}
 
@@ -1890,423 +1901,7 @@ int dp_lan_wan_bridging(int port_id, struct sk_buff *skb)
 	return DP_SUCCESS;
 }
 
-static void rx_dbg(u32 f, struct sk_buff *skb, struct dma_rx_desc_0 *desc0,
-		   struct dma_rx_desc_1 *desc1, struct dma_rx_desc_2 *desc2,
-		   struct dma_rx_desc_3 *desc3, unsigned char *parser,
-		   struct pmac_rx_hdr *pmac, int paser_exist)
-{
-	int inst = 0;
-
-	DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
-		 "\ndp_rx:skb->data=%p Loc=%x offset=%d skb->len=%d\n",
-		 skb->data, desc2->field.data_ptr,
-		 desc3->field.byte_offset, skb->len);
-	if ((f) & DP_DBG_FLAG_DUMP_RX_DATA)
-		dp_dump_raw_data(skb->data,
-				 (skb->len >
-				  (print_len)) ? skb->len : (print_len),
-				 "Original Data");
-	DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "parse hdr size = %d\n",
-		 paser_exist);
-	if ((f) & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
-		dp_port_prop[inst].info.dump_rx_dma_desc(desc0, (desc1),
-			desc2, desc3);
-	if (paser_exist && (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_PASER))
-		dump_parser_flag(parser);
-	if ((f) & DP_DBG_FLAG_DUMP_RX_PMAC)
-		dp_port_prop[inst].info.dump_rx_pmac(pmac);
-}
-
-#define PRINT_INTERVAL  (5 * HZ) /* 5 seconds */
-unsigned long dp_err_interval = PRINT_INTERVAL;
-static void rx_dbg_zero_port(struct sk_buff *skb, struct dma_rx_desc_0 *desc0,
-			     struct dma_rx_desc_1 *desc1,
-			     struct dma_rx_desc_2 *desc2,
-			     struct dma_rx_desc_3 *desc3,
-			     unsigned char *parser,
-			     struct pmac_rx_hdr *pmac, int paser_exist,
-			     u32 ep, u32 port_id, int vap)
-{
-	int inst = 0;
-	static unsigned long last;
-
-	if (!dp_dbg_err) /*bypass dump */
-		return;
-	if (time_before(jiffies, last + dp_err_interval))
-		/* not print in order to keep console not busy */
-		return;
-	last = jiffies;
-	DP_DEBUG(-1, "%s=%d vap=%d\n",
-		 (ep) ? "ep" : "port_id", port_id, vap);
-	PR_ERR("\nDrop for ep and source port id both zero ??\n");
-	dp_port_prop[inst].info.dump_rx_dma_desc(desc0, desc1, desc2, desc3);
-
-	if (paser_exist)
-		dump_parser_flag(parser);
-	if (pmac)
-		dp_port_prop[inst].info.dump_rx_pmac(pmac);
-	dp_dump_raw_data((char *)(skb->data),
-			 (skb->len >
-			  print_len) ? skb->len : print_len,
-			 "Recv Data");
-}
-
-/* clone skb to send one copy to lct dev for multicast/broadcast
- * otherwise for unicast send only to lct device
- * return 0 - Caller will not proceed handling i.e. for unicast do rx only for
- *	      LCT port
- *	  1 - Caller continue to handle rx for other device
- */
-static int dp_handle_lct(struct pmac_port_info *dp_port,
-			 struct sk_buff *skb, dp_rx_fn_t rx_fn)
-{
-	struct sk_buff *lct_skb;
-	int vap;
-
-	vap = dp_port->lct_idx;
-
-	skb->dev = dp_port->subif_info[vap].netif;
-	if (skb->data[PMAC_SIZE] & 0x1) {
-		/* multicast/broadcast */
-		DP_DEBUG(DP_DBG_FLAG_PAE, "LCT mcast or broadcast\n");
-		if ((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
-			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
-			return 1;
-		}
-		lct_skb = skb_clone(skb, GFP_ATOMIC);
-		if (!lct_skb) {
-			PR_ERR("LCT mcast/bcast skb clone fail\n");
-			return -1;
-		}
-		lct_skb->dev = dp_port->subif_info[vap].netif;
-		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_rxif_pkt);
-		DP_DEBUG(DP_DBG_FLAG_PAE, "pkt sent lct(%s)\n",
-			 lct_skb->dev->name ? lct_skb->dev->name : "NULL");
-		rx_fn(lct_skb->dev, NULL, lct_skb, lct_skb->len);
-		return 1;
-	} else if (memcmp(skb->data + PMAC_SIZE, skb->dev->dev_addr, 6) == 0) {
-		/* unicast */
-		DP_DEBUG(DP_DBG_FLAG_PAE, "LCT unicast\n");
-		DP_DEBUG(DP_DBG_FLAG_PAE, "unicast pkt sent lct(%s)\n",
-			 skb->dev->name ? skb->dev->name : "NULL");
-		if ((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
-			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
-			dev_kfree_skb_any(skb);
-			return 0;
-		}
-		rx_fn(skb->dev, NULL, skb, skb->len);
-		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_rxif_pkt);
-		return 0;
-	}
-	return 1;
-}
-
-#define DP_TS_HDRLEN	10
-
-static inline int32_t dp_rx_one_skb(struct sk_buff *skb, uint32_t flags)
-{
-	int res = DP_SUCCESS;
-	struct dma_rx_desc_0 *desc_0 = (struct dma_rx_desc_0 *)&skb->DW0;
-	struct dma_rx_desc_1 *desc_1 = (struct dma_rx_desc_1 *)&skb->DW1;
-	struct dma_rx_desc_2 *desc_2 = (struct dma_rx_desc_2 *)&skb->DW2;
-	struct dma_rx_desc_3 *desc_3 = (struct dma_rx_desc_3 *)&skb->DW3;
-	struct pmac_rx_hdr *pmac;
-	unsigned char *parser = NULL;
-	int rx_tx_flag = 0;	/*0-rx, 1-tx */
-	u32 ep = desc_1->field.ep;	/* ep: 0 -15 */
-	int vap; /*vap: 0-15 */
-	int paser_exist;
-	u32 port_id = ep; /*same with ep now, later set to sspid if ep is 0 */
-	struct net_device *dev = NULL;
-	dp_rx_fn_t rx_fn;
-	char decryp = 0;
-	u8 inst = 0;
-	struct pmac_port_info *dp_port;
-	struct mac_ops *ops;
-	int ret_lct = 1;
-
-	dp_port = &dp_port_info[inst][0];
-	if (!skb) {
-		PR_ERR("skb NULL\n");
-		return DP_FAILURE;
-	}
-	if (!skb->data) {
-		PR_ERR("skb->data NULL\n");
-		return DP_FAILURE;
-	}
-
-	paser_exist = parser_enabled(port_id, desc_1);
-	if (paser_exist)
-		parser = skb->data;
-	pmac = (struct pmac_rx_hdr *)(skb->data + paser_exist);
-
-	if (unlikely(dp_dbg_flag))
-		rx_dbg(dp_dbg_flag, skb, desc_0, desc_1, desc_2,
-		       desc_3, parser, pmac, paser_exist);
-	if (paser_exist) {
-		skb_pull(skb, paser_exist);	/*remove parser */
-#if IS_ENABLED(CONFIG_PPA_API_SW_FASTPATH)
-		skb->mark |= FLG_PPA_PROCESSED;
-#endif
-	}
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
-	/*Sanity check */
-	if (unlikely(dp_port_prop[inst].info.not_valid_rx_ep(ep))) {
-		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Wrong: why ep=%d??\n", ep);
-		rx_dbg(-1, skb, desc_0, desc_1, desc_2, desc_3,
-		       parser, pmac, paser_exist);
-		goto RX_DROP;
-	}
-	if (unlikely(dp_drop_all_tcp_err && desc_1->field.tcp_err)) {
-		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "\n----dp_rx why tcp_err ???\n");
-		rx_dbg(-1, skb, desc_0, desc_1, desc_2, desc_3, parser,
-		       pmac, paser_exist);
-		goto RX_DROP;
-	}
-#endif
-
-	if (port_id == PMAC_CPU_ID) { /*To CPU and need check src pmac port */
-		dp_port_prop[inst].info.update_port_vap(inst, &port_id, &vap,
-			skb,
-			pmac, &decryp);
-	} else {		/*GSWIP-R already know the destination */
-		rx_tx_flag = 1;
-		vap = GET_VAP(desc_0->field.dest_sub_if_id,
-			      dp_port_info[inst][port_id].vap_offset,
-			      dp_port_info[inst][port_id].vap_mask);
-	}
-	if (unlikely(!port_id)) { /*Normally shouldnot go to here */
-		rx_dbg_zero_port(skb, desc_0, desc_1, desc_2, desc_3, parser,
-				 pmac, paser_exist, ep, port_id, vap);
-		goto RX_DROP;
-	}
-	dp_port = &dp_port_info[inst][port_id];
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
-	if (dp_port->f_ptp) {
-		ops = dp_port_prop[inst].mac_ops[port_id];
-		if (ops)
-			ops->do_rx_hwts(ops, skb);
-	}
-#endif
-	/*PON traffic always have timestamp attached,removing Timestamp */
-	if (dp_port->alloc_flags & (DP_F_GPON | DP_F_EPON)) {
-		/* Stripping of last 10 bytes timestamp */
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
-		if (!dp_port->f_ptp)
-			__pskb_trim(skb, skb->len - DP_TS_HDRLEN);
-#else
-		__pskb_trim(skb, skb->len - DP_TS_HDRLEN);
-#endif
-	}
-
-	rx_fn = dp_port->cb.rx_fn;
-	if (likely(rx_fn && dp_port->status)) {
-		/*Clear some fields as SWAS V3.7 required */
-		//desc_1->all &= dma_rx_desc_mask1.all;
-		desc_3->all &= dma_rx_desc_mask3.all;
-		skb->priority = desc_1->field.classid;
-		skb->dev = dp_port->subif_info[vap].netif;
-		if (((dp_port->alloc_flags & DP_F_FAST_DSL) == 0) && /*non-dsl*/
-			dp_port->subif_info[vap].flags) { /*not de-registered */
-			dev = dp_port->subif_info[vap].netif;
-		}
-		if (decryp) { /*workaround mark for bypass xfrm policy*/
-			desc_1->field.dec = 1;
-			desc_1->field.enc = 1;
-		}
-		if (!dev &&
-		    ((dp_port->alloc_flags & DP_F_FAST_DSL) == 0)) {
-			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
-			goto RX_DROP;
-		}
-
-		if (unlikely(dp_dbg_flag)) {
-			DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "%s=%d vap=%d\n",
-				 (ep) ? "ep" : "port_id", port_id, vap);
-
-			if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DATA) {
-				dp_dump_raw_data(skb->data, PMAC_SIZE,
-						 "pmac to top drv");
-				dp_dump_raw_data(skb->data + PMAC_SIZE,
-						 ((skb->len - PMAC_SIZE) >
-							print_len) ?
-							skb->len - PMAC_SIZE :
-							print_len,
-						 "Data to top drv");
-			}
-			if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
-				dp_port_prop[inst].info.dump_rx_dma_desc(
-					desc_0, desc_1,
-					desc_2, desc_3);
-		}
-#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
-		if (unlikely(ltq_mpe_fasthook_rx_fn))
-			ltq_mpe_fasthook_rx_fn(skb, 1, NULL);	/*with pmac */
-#endif
-		if (unlikely((enum TEST_MODE)dp_rx_test_mode ==
-			DP_RX_MODE_LAN_WAN_BRIDGE)) {
-			/*for datapath performance test only */
-			dp_lan_wan_bridging(port_id, skb);
-			/*return DP_SUCCESS;*/
-		}
-		/*If switch h/w acceleration is enabled,setting of this bit
-		 *avoid forwarding duplicate packets from linux
-		 */
-		#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
-			if (dp_port->subif_info[vap].fid > 0)
-				skb->offload_fwd_mark = 1;
-		#endif
-		if (rx_tx_flag == 0) {
-			if (dp_port->lct_idx > 0)
-				ret_lct = dp_handle_lct(dp_port, skb, rx_fn);
-			if (ret_lct) {
-				if ((STATS_GET(dp_port->subif_info[vap].
-					rx_flag) <= 0) &&
-					((dp_port->alloc_flags & DP_F_FAST_DSL)
-						== 0)) {
-					UP_STATS(dp_port->subif_info[vap].
-							mib.rx_fn_dropped);
-					goto RX_DROP2;
-				}
-				rx_fn(dev, NULL, skb, skb->len);
-				UP_STATS(dp_port->subif_info[vap].mib.
-								rx_fn_rxif_pkt);
-			}
-		} else {
-			if ((STATS_GET(dp_port->subif_info[vap].
-					rx_flag) <= 0) &&
-					((dp_port->alloc_flags & DP_F_FAST_DSL)
-						== 0)) {
-				UP_STATS(dp_port->subif_info[vap].mib.
-						rx_fn_dropped);
-				goto RX_DROP2;
-			}
-			rx_fn(NULL, dev, skb, skb->len);
-			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_txif_pkt);
-		}
-
-		return DP_SUCCESS;
-	}
-
-	if (unlikely(port_id >=
-	    dp_port_prop[inst].info.cap.max_num_dp_ports - 1)) {
-		PR_ERR("Drop for wrong ep or src port id=%u ??\n",
-		       port_id);
-		goto RX_DROP;
-	} else if (unlikely(dp_port->status == PORT_FREE)) {
-		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Drop for port %u free\n",
-			 port_id);
-		goto RX_DROP;
-	} else if (unlikely(!rx_fn)) {
-		DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
-			 "Drop for subif of port %u not registered yet\n",
-			 port_id);
-		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
-		goto RX_DROP2;
-	} else {
-		pr_info("Unknown issue\n");
-	}
-RX_DROP:
-	UP_STATS(dp_port->rx_err_drop);
-RX_DROP2:
-	if (skb)
-		dev_kfree_skb_any(skb);
-	return res;
-}
-
-void dp_xmit_dbg(
-	char *title,
-	struct sk_buff *skb,
-	s32 ep,
-	s32 len,
-	u32 flags,
-	struct pmac_tx_hdr *pmac,
-	dp_subif_t *rx_subif,
-	int need_pmac,
-	int gso,
-	int checksum)
-{
-	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
-		 "%s: dp_xmit:skb->data/len=0x%p/%d data_ptr=%x from port=%d and subitf=%d\n",
-		 title,
-		 skb->data, len,
-		 ((struct dma_tx_desc_2 *)&skb->DW2)->field.data_ptr,
-		 ep, rx_subif->subif);
-	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DATA) {
-		if (pmac) {
-			dp_dump_raw_data((char *)pmac, PMAC_SIZE, "Tx Data");
-			dp_dump_raw_data(skb->data,
-					 (skb->len > print_len) ?
-						skb->len :
-						print_len,
-					 "Tx Data");
-		} else
-			dp_dump_raw_data(skb->data,
-					 (skb->len > print_len) ?
-						skb->len : print_len,
-					 "Tx Data");
-	}
-	DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
-		 "ip_summed=%s(%d) encapsulation=%s\n",
-		 dp_skb_csum_str(skb), skb->ip_summed,
-		 skb->encapsulation ? "Yes" : "No");
-	if (skb->encapsulation)
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
-			 "inner ip start=0x%x(%d), transport=0x%x(%d)\n",
-			 (unsigned int)skb_inner_network_header(skb),
-			 (int)(skb_inner_network_header(skb) -
-			       skb->data),
-			 (unsigned int)
-			 skb_inner_transport_header(skb),
-			 (int)(skb_inner_transport_header(skb) -
-			       skb_inner_network_header(skb)));
-	else
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
-			 "ip start=0x%x(%d), transport=0x%x(%d)\n",
-			 (unsigned int)(unsigned int)
-			 skb_network_header(skb),
-			 (int)(skb_network_header(skb) - skb->data),
-			 (unsigned int)skb_transport_header(skb),
-			 (int)(skb_transport_header(skb) -
-			       skb_network_header(skb)));
-
-	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR)
-		dp_port_prop[0].info.dump_tx_dma_desc(
-				 (struct dma_tx_desc_0 *)&skb->DW0,
-				 (struct dma_tx_desc_1 *)&skb->DW1,
-				 (struct dma_tx_desc_2 *)&skb->DW2,
-				 (struct dma_tx_desc_3 *)&skb->DW3);
-
-	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "flags=0x%x skb->len=%d\n",
-		 flags, skb->len);
-	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
-		 "skb->data=0x%p with pmac hdr size=%u\n", skb->data,
-		 sizeof(struct pmac_tx_hdr));
-	if (need_pmac) { /*insert one pmac header */
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
-			 "need pmac\n");
-		if (pmac && (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR))
-			dp_port_prop[0].info.dump_tx_pmac(pmac);
-	} else {
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "no pmac\n");
-	}
-	if (gso)
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "GSO pkt\n");
-	else
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "Non-GSO pkt\n");
-	if (checksum)
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "Need checksum offload\n");
-	else
-		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "No need checksum offload pkt\n");
-
-	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "\n\n");
-}
-
-#define NO_NEED_PMAC(flags)  ((dp_info->alloc_flags & \
-		(DP_F_FAST_WLAN | DP_F_FAST_DSL)) && \
-		!((flags) & (DP_TX_CAL_CHKSUM | DP_TX_DSL_FCS)))
-
-static void set_chksum(struct pmac_tx_hdr *pmac, u32 tcp_type,
+void set_chksum(struct pmac_tx_hdr *pmac, u32 tcp_type,
 		       u32 ip_offset, int ip_off_hw_adjust,
 		       u32 tcp_h_offset)
 {
@@ -2318,329 +1913,12 @@ static void set_chksum(struct pmac_tx_hdr *pmac, u32 tcp_type,
 int32_t dp_xmit(struct net_device *rx_if, dp_subif_t *rx_subif,
 		struct sk_buff *skb, int32_t len, uint32_t flags)
 {
-	struct dma_tx_desc_0 *desc_0;
-	struct dma_tx_desc_1 *desc_1;
-	struct dma_tx_desc_2 *desc_2;
-	struct dma_tx_desc_3 *desc_3;
-	struct pmac_port_info *dp_info = NULL;
-	struct pmac_port_info2 *dp_info2 = NULL;
-	struct pmac_tx_hdr pmac = {0};
-	u32 ip_offset, tcp_h_offset, tcp_type;
-	char tx_chksum_flag = 0; /*check csum cal can be supported or not */
-	char insert_pmac_f = 1;	/*flag to insert one pmac */
-	int res = DP_SUCCESS;
-	int ep, vap;
-	enum dp_xmit_errors err_ret = 0;
+	int32_t res;
 	int inst = 0;
-	struct cbm_tx_data data;
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
-	struct mac_ops *ops;
-	int rec_id = 0;
-#endif
-
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
-	if (unlikely(!dp_init_ok)) {
-		err_ret = DP_XMIT_ERR_NOT_INIT;
-		goto lbl_err_ret;
-	}
-	if (unlikely(!rx_subif)) {
-		err_ret = DP_XMIT_ERR_NULL_SUBIF;
-		goto lbl_err_ret;
-	}
-	if (unlikely(!skb)) {
-		err_ret = DP_XMIT_ERR_NULL_SKB;
-		goto lbl_err_ret;
-	}
-#endif
-	ep = rx_subif->port_id;
-	if (unlikely(ep >= dp_port_prop[inst].info.cap.max_num_dp_ports)) {
-		err_ret = DP_XMIT_ERR_PORT_TOO_BIG;
-		goto lbl_err_ret;
-	}
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
-	if (unlikely(in_irq())) {
-		err_ret = DP_XMIT_ERR_IN_IRQ;
-		goto lbl_err_ret;
-	}
-#endif
-	dp_info = &dp_port_info[inst][ep];
-	dp_info2 = &dp_port_info2[inst][ep];
-	vap = GET_VAP(rx_subif->subif, dp_info->vap_offset, dp_info->vap_mask);
-	if (unlikely(!rx_if && /*For atm pppoa case, rx_if is NULL now */
-		     !(dp_info->alloc_flags & DP_F_FAST_DSL))) {
-		err_ret = DP_XMIT_ERR_NULL_IF;
-		goto lbl_err_ret;
-	}
-#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
-	if (unlikely(ltq_mpe_fasthook_tx_fn))
-		ltq_mpe_fasthook_tx_fn(skb, 0, NULL);
-#endif
-	if (unlikely(dp_dbg_flag))
-		dp_xmit_dbg("\nOrig", skb, ep, len, flags,
-			    NULL, rx_subif, 0, 0, flags & DP_TX_CAL_CHKSUM);
-
-	/*No PMAC for WAVE500 and DSL by default except bonding case */
-	if (unlikely(NO_NEED_PMAC(dp_info->alloc_flags)))
-		insert_pmac_f = 0;
-
-	/**********************************************
-	 *Must put these 4 lines after INSERT_PMAC
-	 *since INSERT_PMAC will change skb if needed
-	 *********************************************/
-	desc_0 = (struct dma_tx_desc_0 *)&skb->DW0;
-	desc_1 = (struct dma_tx_desc_1 *)&skb->DW1;
-	desc_2 = (struct dma_tx_desc_2 *)&skb->DW2;
-	desc_3 = (struct dma_tx_desc_3 *)&skb->DW3;
-
-	if (flags & DP_TX_CAL_CHKSUM) {
-		int ret_flg;
-
-		if (!dp_port_prop[inst].info.check_csum_cap()) {
-			err_ret = DP_XMIT_ERR_CSM_NO_SUPPORT;
-			goto lbl_err_ret;
-		}
-		ret_flg = get_offset_clear_chksum(skb, &ip_offset,
-						  &tcp_h_offset, &tcp_type);
-		if (likely(ret_flg == 0))
-			/*HW can support checksum offload*/
-			tx_chksum_flag = 1;
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
-		else if (ret_flg == -1)
-			pr_info_once("packet can't do hw checksum\n");
-#endif
-	}
-
-	/*reset all descriptors as SWAS required since SWAS 3.7 */
-	/*As new SWAS 3.7 required, MPE1/Color/FlowID is set by applications */
-	desc_0->all &= dma_tx_desc_mask0.all;
-	desc_1->all &= dma_tx_desc_mask1.all;
-	/*desc_2->all = 0;*/ /*remove since later it will be set properly */
-	if (desc_3->field.dic) {
-		desc_3->all = 0; /*keep DIC bit to support test tool*/
-		desc_3->field.dic = 1;
-	} else {
-		desc_3->all = 0;
-	}
-
-	if (flags & DP_TX_OAM) /* OAM */
-		desc_3->field.pdu_type = 1;
-	desc_1->field.classid = (skb->priority >= 15) ? 15 : skb->priority;
-	desc_2->field.data_ptr = (uint32_t)skb->data;
-
-	/*for ETH LAN/WAN */
-	if (dp_info->alloc_flags & (DP_F_FAST_ETH_LAN | DP_F_FAST_ETH_WAN |
-	    DP_F_GPON | DP_F_EPON | DP_F_GINT)) {
-		/*always with pmac*/
-		if (likely(tx_chksum_flag)) {
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			set_chksum(&pmac, tcp_type, ip_offset,
-				   ip_offset_hw_adjust, tcp_h_offset);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		} else {
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		}
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588_SW_WORKAROUND)
-		if (dp_info->f_ptp)
-#else
-		if (dp_info->f_ptp &&
-		    (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP))
-#endif
-		{	ops = dp_port_prop[inst].mac_ops[dp_info->port_id];
-			if (!ops) {
-				err_ret = DP_XMIT_PTP_ERR;
-				goto lbl_err_ret;
-			}
-			rec_id = ops->do_tx_hwts(ops, skb);
-			if (rec_id < 0) {
-				err_ret = DP_XMIT_PTP_ERR;
-				goto lbl_err_ret;
-			}
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_PTP, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			pmac.record_id_msb = rec_id;
-		}
-#endif
-	} else if (dp_info->alloc_flags & DP_F_FAST_DSL) { /*some with pmac*/
-		if (unlikely(flags & DP_TX_CAL_CHKSUM)) { /* w/ pmac*/
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			set_chksum(&pmac, tcp_type, ip_offset,
-				   ip_offset_hw_adjust, tcp_h_offset);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-#ifdef CONFIG_LTQ_DATAPATH_ACA_CSUM_WORKAROUND
-			if (aca_portid > 0)
-				desc_1->field.ep = aca_portid;
-#endif
-		} else if (flags & DP_TX_DSL_FCS) {/* after checksum check */
-			/* w/ pmac for FCS purpose*/
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_OTHERS, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-			insert_pmac_f = 1;
-#ifdef CONFIG_LTQ_DATAPATH_ACA_CSUM_WORKAROUND
-			if (aca_portid > 0)
-				desc_1->field.ep = aca_portid;
-#endif
-		} else { /*no pmac */
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, NULL,
-							desc_0, desc_1,
-							dp_info2);
-		}
-	} else if (dp_info->alloc_flags & DP_F_FAST_WLAN) {/*some with pmac*/
-		/*normally no pmac. But if need checksum, need pmac*/
-		if (unlikely(tx_chksum_flag)) { /*with pmac*/
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			set_chksum(&pmac, tcp_type, ip_offset,
-				   ip_offset_hw_adjust, tcp_h_offset);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-#ifdef CONFIG_LTQ_DATAPATH_ACA_CSUM_WORKAROUND
-			if (aca_portid > 0)
-				desc_1->field.ep = aca_portid;
-#endif
-		} else { /*no pmac*/
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, NULL,
-							desc_0, desc_1,
-							dp_info2);
-		}
-	} else if (dp_info->alloc_flags & DP_F_DIRECTLINK) { /*always w/ pmac*/
-		if (unlikely(flags & DP_TX_CAL_CHKSUM)) { /* w/ pmac*/
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			set_chksum(&pmac, tcp_type, ip_offset,
-				   ip_offset_hw_adjust, tcp_h_offset);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		} else if (flags & DP_TX_TO_DL_MPEFW) { /*w/ pmac*/
-			/*copy from checksum's pmac template setting,
-			 *but need to reset tcp_chksum in TCP header
-			 */
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_OTHERS, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		} else { /*do like normal directpath with pmac */
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		}
-	} else { /*normal directpath: always w/ pmac */
-		if (unlikely(tx_chksum_flag)) {
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM,
-							&pmac,
-							desc_0,
-							desc_1,
-							dp_info2);
-			set_chksum(&pmac, tcp_type, ip_offset,
-				   ip_offset_hw_adjust, tcp_h_offset);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		} else { /*w/ pmac */
-			DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
-							desc_0, desc_1,
-							dp_info2);
-			DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
-		}
-	}
-	desc_3->field.data_len = skb->len;
 
-	if (unlikely(dp_dbg_flag)) {
-		if (insert_pmac_f)
-			dp_xmit_dbg("After", skb, ep, len, flags, &pmac,
-				    rx_subif, insert_pmac_f, skb_is_gso(skb),
-				    tx_chksum_flag);
-		else
-			dp_xmit_dbg("After", skb, ep, len, flags, NULL,
-				    rx_subif, insert_pmac_f, skb_is_gso(skb),
-				    tx_chksum_flag);
-	}
+	res = dp_port_prop[inst].info.dp_tx(rx_if, rx_subif, skb, len, flags);
 
-#if IS_ENABLED(CONFIG_LTQ_TOE_DRIVER)
-	if (skb_is_gso(skb)) {
-		res = ltq_tso_xmit(skb, &pmac, sizeof(pmac), 0);
-		UP_STATS(dp_info->subif_info[vap].mib.tx_tso_pkt);
-		return res;
-	}
-#endif /* CONFIG_LTQ_TOE_DRIVER */
-
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
-	if (unlikely(!desc_1->field.ep)) {
-		err_ret = DP_XMIT_ERR_EP_ZERO;
-		goto lbl_err_ret;
-	}
-#endif
-	if (insert_pmac_f) {
-		data.pmac = (u8 *)&pmac;
-		data.pmac_len = sizeof(pmac);
-		data.dp_inst = inst;
-		data.dp_inst = 0;
-	} else {
-		data.pmac = NULL;
-		data.pmac_len = 0;
-		data.dp_inst = inst;
-		data.dp_inst = 0;
-	}
-	res = cbm_cpu_pkt_tx(skb, &data, 0);
-	UP_STATS(dp_info->subif_info[vap].mib.tx_cbm_pkt);
 	return res;
-
-lbl_err_ret:
-	switch (err_ret) {
-	case DP_XMIT_ERR_NOT_INIT:
-		PR_RATELIMITED("dp_xmit failed for dp no init yet\n");
-		break;
-	case DP_XMIT_ERR_IN_IRQ:
-		PR_RATELIMITED("dp_xmit not allowed in interrupt context\n");
-		break;
-	case DP_XMIT_ERR_NULL_SUBIF:
-		PR_RATELIMITED("dp_xmit failed for rx_subif null\n");
-		UP_STATS(PORT_INFO(inst, 0, tx_err_drop));
-		break;
-	case DP_XMIT_ERR_PORT_TOO_BIG:
-		UP_STATS(PORT_INFO(inst, 0, tx_err_drop));
-		PR_RATELIMITED("rx_subif->port_id >= max_ports");
-		break;
-	case DP_XMIT_ERR_NULL_SKB:
-		PR_RATELIMITED("skb NULL");
-		UP_STATS(PORT_INFO(inst, rx_subif->port_id, tx_err_drop));
-		break;
-	case DP_XMIT_ERR_NULL_IF:
-		UP_STATS(PORT_VAP_MIB(inst, ep, vap, tx_pkt_dropped));
-		PR_RATELIMITED("rx_if NULL");
-		break;
-	case DP_XMIT_ERR_REALLOC_SKB:
-		PR_INFO_ONCE("dp_create_new_skb failed\n");
-		break;
-	case DP_XMIT_ERR_EP_ZERO:
-		PR_ERR("Why ep zero in dp_xmit for %s\n",
-		       skb->dev ? skb->dev->name : "NULL");
-		break;
-	case DP_XMIT_ERR_GSO_NOHEADROOM:
-		PR_ERR("No enough skb headerroom(GSO). Need tune SKB buffer\n");
-		break;
-	case DP_XMIT_ERR_CSM_NO_SUPPORT:
-		PR_RATELIMITED("dp_xmit not support checksum\n");
-		break;
-	case DP_XMIT_PTP_ERR:
-		break;
-	default:
-		UP_STATS(dp_info->subif_info[vap].mib.tx_pkt_dropped);
-		PR_INFO_ONCE("Why come to here:%x\n",
-			     dp_port_info[inst][ep].status);
-	}
-	if (skb)
-		dev_kfree_skb_any(skb);
-	return DP_FAILURE;
 }
 EXPORT_SYMBOL(dp_xmit);
 
@@ -2678,6 +1956,7 @@ int dp_set_min_frame_len(s32 dp_port,
 			 s32 min_frame_len,
 			 uint32_t flags)
 {
+	PR_INFO("Dummy dp_set_min_frame_len, need to implement later\n");
 	return DP_SUCCESS;
 }
 EXPORT_SYMBOL(dp_set_min_frame_len);
@@ -2696,6 +1975,7 @@ int dp_rx_enable(struct net_device *netif, char *ifname, uint32_t flags)
 	port_info = PORT(subif.inst, subif.port_id);
 	vap = GET_VAP(subif.subif, port_info->vap_offset,
 		      port_info->vap_mask);
+	
 	STATS_SET(port_info->subif_info[vap].rx_flag, flags ? 1 : 0);
 
 	return DP_SUCCESS;
@@ -2716,9 +1996,9 @@ int dp_vlan_set(struct dp_tc_vlan *vlan, int flags)
 	info.bp = subif.bport;
 	info.dp_port = subif.port_id;
 	info.inst = subif.inst;
-
-	if ((vlan->def_apply == DP_VLAN_APPLY_CTP) &&
-	    (subif.flag_pmapper == 1)) {
+	
+	if ((vlan->def_apply == DP_VLAN_APPLY_CTP) && 
+				(subif.flag_pmapper == 1)) {
 		PR_ERR("cannot apply VLAN rule for pmapper device\n");
 		return DP_FAILURE;
 	} else if (vlan->def_apply == DP_VLAN_APPLY_CTP) {
@@ -2726,7 +2006,7 @@ int dp_vlan_set(struct dp_tc_vlan *vlan, int flags)
 	} else {
 		info.dev_type |= subif.flag_bp;
 	}
-	if (vlan->mcast_flag == DP_MULTICAST_SESSION)
+	if (vlan->mcast_flag == DP_MULTICAST_SESSION) 
 		info.dev_type |= 0x02;
 	DP_DEBUG(DP_DBG_FLAG_PAE, "dev_type:0x%x\n", info.dev_type);
 	if (DP_CB(subif.inst, dp_tc_vlan_set))
@@ -2785,7 +2065,7 @@ void test(void)
 	 *byte 6:port_map=0
 	 *byte 7:port_map2=1
 	 */
-#ifdef CONFIG_LITTLE_ENDIAN
+#if IS_ENABLED(CONFIG_LITTLE_ENDIAN)
 	char example_data[] = {
 		0x00, 0x3a, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
 		0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x0e,
@@ -2830,22 +2110,18 @@ void test(void)
 
 int dp_basic_proc(void)
 {
-#ifdef CONFIG_LTQ_DATAPATH_LOOPETH
 	struct dentry *p_node;
-#endif
 
 	/*mask to reset some field as SWAS required  all others try to keep */
 	memset(dp_port_prop, 0, sizeof(dp_port_prop));
 	memset(dp_port_info, 0, sizeof(dp_port_info));
-#ifdef CONFIG_LTQ_DATAPATH_LOOPETH
 	p_node = dp_proc_install();
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_LOOPETH)
 	dp_loop_eth_dev_init(p_node);
-#else
-	dp_proc_install();
 #endif
 	dp_inst_init(0);
 	dp_subif_list_init();
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	dp_switchdev_init();
 #endif
 	return 0;
@@ -2858,15 +2134,15 @@ int dp_basic_proc(void)
 	if (dp_init_ok) /*alredy init */
 		return 0;
 	register_notifier(0);
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS_VIA_PRX300_TEST
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS_VIA_PRX300_TEST)
 	PR_INFO("\n\n--prx300_test to simulate SLIM QOS drv---\n\n\n");
-#endif /*CONFIG_LTQ_DATAPATH_DUMMY_QOS_VIA_PRX300_TEST*/
+#endif /*CONFIG_INTEL_DATAPATH_DUMMY_QOS_VIA_PRX300_TEST*/
 	register_dp_cap(0);
 	if (request_dp(0)) /*register 1st dp instance */ {
 		PR_ERR("register_dp instance fail\n");
 		return -1;
 	}
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
 	PR_INFO("preempt_count=%x\n", preempt_count());
 	if (preempt_count() & HARDIRQ_MASK)
 		PR_INFO("HARDIRQ_MASK\n");
@@ -2886,19 +2162,19 @@ int dp_basic_proc(void)
 
 	if (dp_init_ok) {
 		DP_LIB_LOCK(&dp_lock);
-		memset(dp_port_info, 0, sizeof(dp_port_info));
-#ifdef CONFIG_LTQ_DATAPATH_MIB
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MIB)
 		dp_mib_exit();
 #endif
 		for (i = 0; i < dp_inst_num; i++) {
 			DP_CB(i, dp_platform_set)(i, DP_PLATFORM_DE_INIT);
 			free_dma_chan_tbl(i);
+			free_dp_port_subif_info(i);
 		}
 		dp_init_ok = 0;
-#ifdef CONFIG_LTQ_DATAPATH_LOOPETH
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_LOOPETH)
 		dp_loop_eth_dev_exit();
 #endif
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 		dp_cpufreq_notify_exit();
 #endif
 		unregister_notifier(0);
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_instance.c b/drivers/net/ethernet/lantiq/datapath/datapath_instance.c
index 9ae2324b2431..66b2b4a3868c 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_instance.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_instance.c
@@ -22,10 +22,7 @@
 #include <linux/clk.h>
 #include <linux/ip.h>
 #include <net/ip.h>
-#include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
-#include <net/datapath_api_skb.h>
 #include "datapath.h"
 #include "datapath_instance.h"
 #include "datapath_swdev_api.h"
@@ -65,7 +62,7 @@ int register_dp_hw_cap(struct dp_hw_cap *info, u32 flag)
 		hw_cap_list[i].valid = 1;
 		hw_cap_list[i].info = info->info;
 		dp_cap_num++;
-#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
 		PR_ERR("Succeed to %s HAL[%d]: type=%d ver=%d dp_cap_num=%d\n",
 		       "Register",
 		       i,
@@ -88,7 +85,7 @@ int register_dp_hw_cap(struct dp_hw_cap *info, u32 flag)
  */
 int dp_request_inst(struct dp_inst_info *info, u32 flag)
 {
-	int i, k;
+	int i, k, j;
 
 	if (!info)
 		return -1;
@@ -130,9 +127,12 @@ int dp_request_inst(struct dp_inst_info *info, u32 flag)
 	}
 	dp_port_prop[i].ops[0] = info->ops[0];
 	dp_port_prop[i].ops[1] = info->ops[1];
-	dp_port_prop[i].mac_ops[2] = info->mac_ops[2];
-	dp_port_prop[i].mac_ops[3] = info->mac_ops[3];
-	dp_port_prop[i].mac_ops[4] = info->mac_ops[4];
+
+	for(j = 0; j < DP_MAX_MAC_HANDLE; j++) {
+		if (info->mac_ops[j])
+			dp_port_prop[i].mac_ops[j] = info->mac_ops[j];
+	}
+	
 	dp_port_prop[i].info = hw_cap_list[k].info;
 	dp_port_prop[i].cbm_inst = info->cbm_inst;
 	dp_port_prop[i].qos_inst = info->qos_inst;
@@ -141,6 +141,10 @@ int dp_request_inst(struct dp_inst_info *info, u32 flag)
 	dp_cpufreq_notify_init(i);
 	DP_DEBUG(DP_DBG_FLAG_COC, "DP registered CPUFREQ notifier\n");
 #endif
+	if (alloc_dp_port_subif_info(i)) {
+		PR_ERR("alloc_dp_port_subif_info fail..\n");
+		return DP_FAILURE;
+	}
 	if (dp_port_prop[i].info.dp_platform_set(i, DP_PLATFORM_INIT) < 0) {
 		dp_port_prop[i].valid = 0;
 		PR_ERR("dp_platform_init failed for inst=%d\n", i);
@@ -204,6 +208,8 @@ struct dp_dev *dp_dev_lookup(struct hlist_head *head,
 	return NULL;
 }
 
+#if IS_ENABLED(CONFIG_PPA)
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,13,0)
 static int dp_ndo_setup_tc(struct net_device *dev, u32 handle,
 			   __be16 protocol, struct tc_to_netdev *tc)
 {
@@ -216,6 +222,15 @@ static int dp_ndo_setup_tc(struct net_device *dev, u32 handle,
 	PR_ERR("Cannot support ndo_setup_tc\n");
 	return -1;
 }
+#else
+static int dp_ndo_setup_tc(struct net_device *dev,
+				enum tc_setup_type type,
+				void *type_data)
+{
+	return -1;
+}
+#endif /* LINUX_VERSION_CODE */
+#endif /* CONFIG_PPA */
 
 /*Note:
  *dev and subif_name: only one will be used for the hash index calculation.
@@ -230,8 +245,9 @@ int dp_inst_add_dev(struct net_device *dev, char *subif_name, int inst,
 	u8 new_f = 0;
 	u32 idx;
 	struct subif_basic *subif;
+#if IS_ENABLED(CONFIG_PPA)
 	int err = DP_SUCCESS;
-
+#endif
 	if (!dev && !subif_name) {
 		PR_ERR("Why dev/subif_name both NULL?\n");
 		return -1;
@@ -239,7 +255,7 @@ int dp_inst_add_dev(struct net_device *dev, char *subif_name, int inst,
 	idx = dp_dev_hash(dev, subif_name);
 	subif = kmalloc(sizeof(*subif), GFP_KERNEL);
 	if (!subif) {
-		PR_ERR("failed to alloc %d bytes\n", sizeof(*subif));
+		PR_ERR("failed to alloc %zd bytes\n", sizeof(*subif));
 		return -1;
 	}
 
@@ -266,7 +282,7 @@ int dp_inst_add_dev(struct net_device *dev, char *subif_name, int inst,
 		}
 	}
 	if (!dp_dev) {
-		PR_ERR("Failed to kmalloc %d bytes\n", sizeof(*dp_dev));
+		PR_ERR("Failed to kmalloc %zd bytes\n", sizeof(*dp_dev));
 		kfree(subif);
 		return -1;
 	}
@@ -296,11 +312,11 @@ int dp_inst_add_dev(struct net_device *dev, char *subif_name, int inst,
 				return DP_FAILURE;
 		}
 #endif
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	if (!(flag & DP_F_SUBIF_LOGICAL))
 		dp_port_register_switchdev(dp_dev, dev);
 #endif
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 	dp_register_ptp_ioctl(dp_dev, dev, inst);
 #endif
 	}
@@ -409,7 +425,7 @@ int dp_inst_insert_mod(struct module *owner, u16 ep, u32 inst, u32 flag)
 		}
 	}
 	if (!dp_mod) {
-		PR_ERR("Failed to kmalloc %d bytes\n", sizeof(*dp_mod));
+		PR_ERR("Failed to kmalloc %zd bytes\n", sizeof(*dp_mod));
 		return -1;
 	}
 	if (new_f)
@@ -494,7 +510,7 @@ int proc_inst_dev_dump(struct seq_file *s, int pos)
 			&dp_dev_list[dev_hash_index])->first,
 			struct dp_dev, hlist);
 	}
-	seq_printf(s, "Hash=%u pos=%d dev=%s(@%p) inst=%d ep=%d bp=%d ctp=%d count=%d @%p\n",
+	seq_printf(s, "Hash=%u pos=%d dev=%s(@%px) inst=%d ep=%d bp=%d ctp=%d count=%d @%px\n",
 		   dev_hash_index,
 		   pos,
 		   dp_dev_proc->dev ? dp_dev_proc->dev->name :
@@ -577,7 +593,7 @@ int proc_inst_mod_dump(struct seq_file *s, int pos)
 			&dp_mod_list[mod_hash_index])->first,
 			struct dp_mod, hlist);
 	}
-	seq_printf(s, "Hash=%u pos=%d owner=%s(@%p) ep=%d inst=%d\n",
+	seq_printf(s, "Hash=%u pos=%d owner=%s(@%px) ep=%d inst=%d\n",
 		   mod_hash_index,
 		   pos,
 		   dp_mod_proc->mod->name,
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_instance.h b/drivers/net/ethernet/lantiq/datapath/datapath_instance.h
index 5e70633818c0..ca134659e0e7 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_instance.h
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_instance.h
@@ -21,6 +21,11 @@ extern struct dp_hw_cap hw_cap_list[DP_MAX_HW_CAP];
 #define DP_MOD_HASH_BIT_LENGTH 10
 #define DP_MOD_HASH_SIZE ((1 << DP_MOD_HASH_BIT_LENGTH) - 1)
 
+#define NO_NEED_PMAC(flags)  ((flags & \
+		(DP_F_FAST_WLAN | DP_F_FAST_DSL)) && \
+		!((flags) & (DP_TX_CAL_CHKSUM | DP_TX_DSL_FCS)))
+
+
 extern struct hlist_head dp_dev_list[DP_DEV_HASH_SIZE];
 u32 dp_dev_hash(struct net_device *dev, char *subif_name);
 struct dp_dev *dp_dev_lookup(struct hlist_head *head,
@@ -59,7 +64,7 @@ struct dp_dev {
 	struct net_device_ops new_dev_ops;
 	const struct ethtool_ops *old_ethtool_ops;
 	struct ethtool_ops new_ethtool_ops;
-#ifdef CONFIG_NET_SWITCHDEV
+#if IS_ENABLED(CONFIG_NET_SWITCHDEV)
 	struct switchdev_ops *old_swdev_ops;
 	struct switchdev_ops new_swdev_ops;
 #endif
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.c b/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.c
index ebe5d23d8300..f88bf2d643a2 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.c
@@ -1,10 +1,9 @@
 #include "datapath_ioctl.h"
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 static int dp_ndo_ptp_ioctl(struct net_device *dev,
 			    struct ifreq *ifr,
 			    int cmd);
-#endif
 
 static int get_tsinfo(struct net_device *dev,
 		      struct ethtool_ts_info *ts_info)
@@ -30,6 +29,7 @@ static int get_tsinfo(struct net_device *dev,
 		 dev->name);
 	return 0;
 }
+#endif
 
 int dp_ops_set(void **dev_ops, int ops_cb_offset,
 	       size_t ops_size, void **dp_orig_ops_cb,
@@ -64,7 +64,7 @@ int dp_ops_set(void **dev_ops, int ops_cb_offset,
 	return	DP_SUCCESS;
 }
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 static int dp_ndo_ptp_ioctl(struct net_device *dev,
 			    struct ifreq *ifr, int cmd)
 {
@@ -156,7 +156,7 @@ int dp_ops_reset(struct dp_dev *dp_dev,
 		dev->ethtool_ops = dp_dev->old_ethtool_ops;
 		dp_dev->old_ethtool_ops = NULL;
 	}
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	if (dev->switchdev_ops == &dp_dev->new_swdev_ops) {
 		dev->switchdev_ops = dp_dev->old_swdev_ops;
 		dp_dev->old_swdev_ops = NULL;
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.h b/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.h
index 436e378b4723..1935dffc89dc 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.h
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_ioctl.h
@@ -2,11 +2,10 @@
 #define DATAPATH_IOCTL_H
 
 #include <net/datapath_api.h>
-#include <net/datapath_api_skb.h>
 #include "datapath.h"
 #include "datapath_instance.h"
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 int dp_register_ptp_ioctl(struct dp_dev *dp_dev,
 			  struct net_device *dp_port, int inst);
 #endif
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_logical_dev.c b/drivers/net/ethernet/lantiq/datapath/datapath_logical_dev.c
index f3a63cea61a7..c6c89db269da 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_logical_dev.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_logical_dev.c
@@ -21,9 +21,7 @@
 #include <linux/clk.h>
 #include <linux/ip.h>
 #include <net/ip.h>
-#include <lantiq_soc.h>
 #include <net/datapath_api.h>
-#include <net/datapath_api_skb.h>
 #include <linux/if_vlan.h>
 #include "datapath.h"
 #include "datapath_instance.h"
@@ -35,6 +33,7 @@ struct net_device *get_base_dev(struct net_device *dev, int level);
  */
 int get_vlan_via_dev(struct net_device *dev, struct vlan_prop *vlan_prop)
 {
+#if IS_ENABLED(CONFIG_VLAN_8021Q)
 	struct vlan_dev_priv *vlan;
 	struct net_device *base1, *base2;
 
@@ -45,7 +44,7 @@ int get_vlan_via_dev(struct net_device *dev, struct vlan_prop *vlan_prop)
 	if (!is_vlan_dev(dev))
 		return 0;
 	base1 = get_base_dev(dev, 1);
-	vlan = vlan_dev_priv(dev);
+	vlan = dp_vlan_dev_priv(dev);
 	if (!base1) { /*single vlan */
 		PR_ERR("Not 1st VLAN interface no base\n");
 		return -1;
@@ -64,8 +63,7 @@ int get_vlan_via_dev(struct net_device *dev, struct vlan_prop *vlan_prop)
 		vlan_prop->num = 2;
 		vlan_prop->in_proto = vlan->vlan_proto;
 		vlan_prop->in_vid = vlan->vlan_id;
-
-		vlan = vlan_dev_priv(base1);
+		vlan = dp_vlan_dev_priv(base1);
 		vlan_prop->out_proto = vlan->vlan_proto;
 		vlan_prop->out_vid = vlan->vlan_id;
 		vlan_prop->base = base2;
@@ -76,6 +74,7 @@ int get_vlan_via_dev(struct net_device *dev, struct vlan_prop *vlan_prop)
 	vlan_prop->out_proto = vlan->vlan_proto;
 	vlan_prop->out_vid = vlan->vlan_id;
 	vlan_prop->base = base1;
+#endif
 	return 0;
 }
 
@@ -161,7 +160,7 @@ int add_logic_dev(int inst, int port_id, struct net_device *dev,
 	}
 	logic_dev_tmp = kmalloc(sizeof(*logic_dev_tmp), GFP_KERNEL);
 	if (!logic_dev_tmp) {
-		DP_DEBUG(DP_DBG_FLAG_LOGIC, "kmalloc fail for %d bytes\n",
+		DP_DEBUG(DP_DBG_FLAG_LOGIC, "kmalloc fail for %zd bytes\n",
 			 sizeof(*logic_dev_tmp));
 		return -1;
 	}
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_misc.c b/drivers/net/ethernet/lantiq/datapath/datapath_misc.c
index 6749b0c1fd21..5ee13a1c4870 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_misc.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_misc.c
@@ -14,22 +14,23 @@
 #include <linux/types.h>
 #include <linux/version.h>
 #include <linux/if_ether.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/if_vlan.h>
+
 #include <linux/ethtool.h>
 #include <linux/proc_fs.h>
 #include <linux/delay.h>
 #include <linux/init.h>
 #include <linux/clk.h>
-#include <linux/if_ether.h>
-#include <linux/if_vlan.h>
 #include <linux/clk.h>
 #include <linux/ip.h>
 #include <net/ip.h>
-#include <lantiq_soc.h>
 #include <net/datapath_api.h>
 #include "datapath.h"
-#include <net/lantiq_cbm_api.h>
-#if IS_ENABLED(CONFIG_LTQ_PPA_API_SW_FASTPATH)
-#include <net/ppa_api.h>
+#if IS_ENABLED(CONFIG_PPA_API_SW_FASTPATH) || \
+	IS_ENABLED(CONFIG_LTQ_PPA_API_SW_FASTPATH)
+#include <net/ppa/ppa_api.h>
 #endif
 
 #if defined(CONFIG_LTQ_HWMCPY) && CONFIG_LTQ_HWMCPY
@@ -41,7 +42,7 @@
 #define dp_memcpy(x, y, z)   memcpy(x, y, z)
 #endif
 
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#ifdef CONFIG_INTEL_DATAPATH_CPUFREQ
 #include <linux/cpufreq.h>
 static int dp_coc_cpufreq_transition_notifier(struct notifier_block *nb,
 					      unsigned long event, void *data);
@@ -153,7 +154,7 @@ void dump_parser_flag(char *buf)
 	 * flags: FLAG_L2TPFLAG_NO
 	 * 00 00 00 00 80 18 80 00
 	 */
-	PR_INFO("paser flag at 0x%p: ", buf);
+	PR_INFO("paser flag at 0x%px: ", buf);
 	len = 0;
 	for (i = 0; i < 8; i++)
 		len += sprintf(p + len, "%02x ", *(pflags - 7 + i));
@@ -205,7 +206,7 @@ void dp_dump_raw_data(char *buf, int len, char *prefix_str)
 		PR_ERR("kmalloc failed: %d\n", bytes);
 		return;
 	}
-	sprintf(s, "%s in hex at 0x%p\n",
+	sprintf(s, "%s in hex at 0x%px\n",
 		prefix_str ? (char *)prefix_str : "Data", p);
 	PR_INFO("%s", s);
 
@@ -268,7 +269,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 
 	if (info->ip_ver == DP_IP_VER4) {	/*ipv4 */
 		ip_hdr_size = (p[0] & 0xf) << 2;
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 			 "IPV4 pkt with protocol 0x%x with ip hdr size %d\n",
 			 p[9], ip_hdr_size);
@@ -279,7 +280,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 		    (info->proto == PROTOCOL_TCP)) {
 			if ((iphdr->frag_off & IP_MF) ||
 			    (iphdr->frag_off & IP_OFFSET)) {
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 					 "frag pkt:off=%x,IP_MF=%x,IP_OFFSET=%x\n",
 					 iphdr->frag_off, IP_MF, IP_OFFSET);
@@ -288,7 +289,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 				info->is_fragment = 1;
 				return -1;
 			}
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 				 "%s packet with src/dst port:%u/%u\n",
 				 (p[9] ==
@@ -306,7 +307,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 			info->next_ip_hdr_offset = (p[0] & 0x0f) << 2;
 			return 0;
 		}
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 			 "Not supported extension hdr:0x%x\n", p[9]);
 #endif
@@ -320,7 +321,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 		ip_hdr_size = IPV6_HDR_SIZE;
 		udp_tcp_h_offset = IPV6_HDR_SIZE;
 		next_hdr = p[6];
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 		if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX) {
 			int i;
 
@@ -352,7 +353,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 					    IPV6_EXTENSION_SIZE + p[1];
 
 				info->udp_tcp_offset = udp_tcp_h_offset;
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 					 "IP6 UDP:src/dst port:%u/%u udp_tcp_off=%d\n",
 					 *(unsigned short *)(pdata +
@@ -375,7 +376,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 				info->is_fragment = 1;
 				return -1;
 			}
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 				 "Skip extension hdr:0x%x\n", next_hdr);
 #endif
@@ -395,7 +396,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 			}
 			next_hdr = p[0];
 			if (udp_tcp_h_offset > len) {
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 				DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 					 "\n- Wrong IPV6 packet header ?\n");
 #endif
@@ -408,7 +409,7 @@ int get_ip_hdr_info(u8 *pdata, int len, struct ip_hdr_info *info)
 	return -1;
 }
 
-#ifdef CONFIG_LTQ_DATAPATH_MANUAL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MANUAL_PARSE)
 int ip_offset_hw_adjust = 8;
 
 /*parse protol and get the ip_offset/tcp_h_offset and its type:
@@ -422,7 +423,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 	u8 *p = p_l2_mac + TWO_MAC_SIZE;
 	struct ip_hdr_info pkt_info[2];
 	u8 ip_num = 0;
-#ifdef CONFIG_LTQ_DATAPATH_DBG
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	int i;
 #endif
 	int len;
@@ -433,7 +434,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 	*ip_offset = 0;
 	*tcp_h_offset = 0;
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	if (dp_dbg_flag)
 		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 			 "flags DP_TX_CAL_CHKSUM is set\n");
@@ -445,14 +446,14 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 	if ((p[0] == 0x88) && (p[1] == 0x64))	/*skip pppoe header */
 		p += PPPOE_HDR_SIZE;
 
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
 		 "To find ip header:%02x %02x %02x %02x %02x %02x %02x %02x\n",
 		 p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7]);
 #endif
 	if (((p[0] != 0x08) || (p[1] != 0x00)) &&
 	    ((p[0] != 0x86) && (p[1] != 0xdd))) {
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "None IP type:%02x%02x\n", p[0],
 			 p[1]);
 #endif
@@ -463,7 +464,8 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 
 	while (1) {
 		if (get_ip_hdr_info(p, len, &pkt_info[ip_num]) == 0) {
-			pkt_info[ip_num].ip_offset = (u32)p - (u32)p_l2_mac;
+			pkt_info[ip_num].ip_offset = (uintptr_t)p -
+				(unsigned long)p_l2_mac;
 
 			if (pkt_info[ip_num].next_ip_hdr_offset) {
 				p += pkt_info[ip_num].next_ip_hdr_offset;
@@ -490,7 +492,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 			return -1;
 		}
 	}
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX) {
 		for (i = 0; i < ip_num; i++) {
 			DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
@@ -630,7 +632,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 
 	return -1;
 }
-#else	/* CONFIG_LTQ_DATAPATH_MANUAL_PARSE */
+#else	/* CONFIG_INTEL_DATAPATH_MANUAL_PARSE */
 /*parse protol and get the ip_offset/tcp_h_offset and its type
  * based on skb_inner_network_header/skb_network_header/
  *           skb_inner_transport_header/skb_transport_header
@@ -648,7 +650,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 	unsigned char *l4_p;
 
 	if (skb->ip_summed != CHECKSUM_PARTIAL) {
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
 			 "No need HW checksum Support\n");
 #endif
@@ -672,7 +674,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 		l4_p = skb_transport_header(skb);
 	}
 	if (((int)(ip_offset) <= 0) || ((int)(tcp_h_offset) <= 0)) {
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
 			 "Wrong IP offset(%d) or TCP/UDP offset(%d)\n",
 			 ((int)(ip_offset) <= 0), ((int)(tcp_h_offset) <= 0));
@@ -703,13 +705,13 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 		tcph = (struct tcphdr *)l4_p;
 		tcph->check = 0;	/*clear original UDP checksum */
 	}
-#ifdef CONFIG_LTQ_DATAPATH_DBG_PROTOCOL_PARSE
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG_PROTOCOL_PARSE)
 	DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM, "Found tcp_type=%u ip_offset=%u\n",
 		 *tcp_type, *ip_offset);
 #endif
 	return 0;
 }
-#endif				/* CONFIG_LTQ_DATAPATH_MANUAL_PARSE */
+#endif				/* CONFIG_INTEL_DATAPATH_MANUAL_PARSE */
 
 /*  Make a copy of both an &sk_buff and part of its data, located
  * in header. Fragmented data remain shared. This is used since
@@ -724,7 +726,7 @@ int get_offset_clear_chksum(struct sk_buff *skb, u32 *ip_offset,
 struct sk_buff *dp_create_new_skb(struct sk_buff *skb)
 {
 	struct sk_buff *new_skb;
-#ifndef CONFIG_LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+#ifndef CONFIG_INTEL_DATAPATH_COPY_LINEAR_BUF_ONLY
 	/* seems CBM driver does not support it yet */
 	void *p;
 	const skb_frag_t *frag;
@@ -746,7 +748,7 @@ struct sk_buff *dp_create_new_skb(struct sk_buff *skb)
 		dev_kfree_skb_any(skb);
 		return NULL;
 	}
-#ifndef CONFIG_LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+#ifndef CONFIG_INTEL_DATAPATH_COPY_LINEAR_BUF_ONLY
 	new_skb = cbm_alloc_skb(skb->len + 8, GFP_ATOMIC);
 #else
 	linear_len = skb->len - skb->data_len;
@@ -759,7 +761,7 @@ struct sk_buff *dp_create_new_skb(struct sk_buff *skb)
 		dev_kfree_skb_any(skb);
 		return NULL;
 	}
-#ifndef CONFIG_LTQ_DATAPATH_COPY_LINEAR_BUF_ONLY
+#ifndef CONFIG_INTEL_DATAPATH_COPY_LINEAR_BUF_ONLY
 	p = new_skb->data;
 	dp_memcpy(p, skb->data, skb->len - skb->data_len);
 	p += skb->len - skb->data_len;
@@ -796,10 +798,12 @@ struct sk_buff *dp_create_new_skb(struct sk_buff *skb)
 	new_skb->dev = skb->dev;
 	new_skb->priority = skb->priority;
 	new_skb->truesize += skb->data_len;
+#ifdef DATAPATH_SKB_HACK
 	new_skb->DW0 = skb->DW0;
 	new_skb->DW1 = skb->DW1;
 	new_skb->DW2 = skb->DW2;
 	new_skb->DW3 = skb->DW3;
+#endif
 
 	/*copy other necessary fields for checksum calculation case */
 	new_skb->ip_summed = skb->ip_summed;
@@ -1048,6 +1052,7 @@ int high_10dec(u64 x)
 
 int get_vlan_info(struct net_device *dev, struct vlan_info *vinfo)
 {
+#if IS_ENABLED(CONFIG_VLAN_8021Q)
 	struct vlan_dev_priv *vlan;
 	struct net_device *lower_dev;
 	struct list_head *iter;
@@ -1055,8 +1060,7 @@ int get_vlan_info(struct net_device *dev, struct vlan_info *vinfo)
 
 	if (is_vlan_dev(dev)) {
 		num++;
-		vlan = vlan_dev_priv(dev);
-
+		vlan = dp_vlan_dev_priv((const struct net_device *)dev);
 		DP_DEBUG(DP_DBG_FLAG_DBG,
 			 "vlan proto:%x VID:%d real devname:%s\n",
 			 vlan->vlan_proto, vlan->vlan_id,
@@ -1066,7 +1070,7 @@ int get_vlan_info(struct net_device *dev, struct vlan_info *vinfo)
 				num++;
 				vinfo->in_proto = vlan->vlan_proto;
 				vinfo->in_vid = vlan->vlan_id;
-				vlan = vlan_dev_priv(lower_dev);
+				vlan = dp_vlan_dev_priv(lower_dev);
 				DP_DEBUG(DP_DBG_FLAG_DBG,
 					 "%s:%x VID:%d %s:%s\n",
 					 "Outer vlan proto",
@@ -1087,6 +1091,7 @@ int get_vlan_info(struct net_device *dev, struct vlan_info *vinfo)
 		PR_ERR("Not a VLAN device\n");
 		return -1;
 	}
+#endif
 	return 0;
 }
 
@@ -1186,7 +1191,7 @@ int dp_meter_del(struct net_device *dev, struct dp_meter_cfg *meter,
 }
 EXPORT_SYMBOL(dp_meter_del);
 
-#if (!IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV))
+#if (!IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV))
 int dp_get_fid_by_brname(struct net_device *dev, int *inst)
 {
 	PR_ERR("API not support when SWDEV disabled\n");
@@ -1314,7 +1319,7 @@ int32_t dp_sync_subifid(struct net_device *dev, char *subif_name,
 		subif_data = (void *)subif_name;
 	/*check flag for register / deregister to update/del */
 	if (flags & DP_F_DEREGISTER) {
-
+		/* subif info not required for data->ctp_dev */
 		if (dp_get_netif_subifid_priv(dev, NULL, subif_data, NULL,
 					      &subif_id[0], 0))
 			*f_subif_up = 0;
@@ -1376,7 +1381,7 @@ int32_t dp_sync_subifid_priv(struct net_device *dev, char *subif_name,
 	return 0;
 }
 
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#ifdef CONFIG_INTEL_DATAPATH_CPUFREQ
 static int dp_coc_cpufreq_policy_notifier(struct notifier_block *nb,
 					  unsigned long event, void *data)
 {
@@ -1472,8 +1477,8 @@ u32 get_dma_chan_idx(int inst, int num_dma_chan)
 	}
 
 	for (base = 0; base < DP_MAX_DMA_CHAN; base++) {
-		for (match = 0; (match < num_dma_chan) && ((base + match)
-						< DP_MAX_DMA_CHAN); match++) {
+		for (match = 0; (match < num_dma_chan) &&
+		     ((base + match) < DP_MAX_DMA_CHAN); match++) {
 			if (atomic_read(&(dp_dma_chan_tbl[inst] +
 					(base + match))->ref_cnt))
 				break;
@@ -1481,7 +1486,7 @@ u32 get_dma_chan_idx(int inst, int num_dma_chan)
 		if (match == num_dma_chan)
 			return base;
 	}
-	PR_ERR("No free chan available from chan table!!\n");
+	DP_ERR("No free chan available from chan table!!\n");
 	return DP_FAILURE;
 }
 
@@ -1493,7 +1498,7 @@ u32 get_dma_chan_idx(int inst, int num_dma_chan)
 u32 alloc_dma_chan_tbl(int inst)
 {
 	dp_dma_chan_tbl[inst] = kzalloc((sizeof(struct dma_chan_info) *
-					DP_MAX_DMA_CHAN), GFP_KERNEL);
+					DP_MAX_DMA_CHAN), GFP_ATOMIC);
 
 	if (!dp_dma_chan_tbl[inst]) {
 		PR_ERR("Failed for kmalloc: %zu bytes\n",
@@ -1504,6 +1509,48 @@ u32 alloc_dma_chan_tbl(int inst)
 }
 
 /**
+ * alloc_dp_port_info: Dynamic allocation of alloc_dp_port_info.
+ * @inst: DP instance.
+ * Return: DP_SUCCESS on success DP_FAILURE on failure.
+ */
+u32 alloc_dp_port_subif_info(int inst)
+{
+	int port_id;
+	int max_dp_ports;	/* max dp ports */
+	int max_subif;		/* max subif per port */
+	struct inst_info *info = NULL;
+
+	if (inst < 0 || inst >= DP_MAX_INST)
+		return DP_FAILURE;
+
+	/* Retrieve the hw capabilities */
+	info = &dp_port_prop[inst].info;
+	max_dp_ports = info->cap.max_num_dp_ports;
+	max_subif = info->cap.max_num_subif_per_port;
+
+	dp_port_info[inst] = kzalloc((sizeof(struct pmac_port_info) *
+				     max_dp_ports), GFP_KERNEL);
+	if (!dp_port_info[inst]) {
+		PR_ERR("Failed for kmalloc: %zu bytes\n",
+		       (sizeof(struct pmac_port_info) * max_dp_ports));
+		return DP_FAILURE;
+	}
+	for (port_id = 0; port_id < max_dp_ports; port_id++) {
+		dp_port_info[inst][port_id].subif_info =
+			kzalloc(sizeof(struct dp_subif_info) * max_subif,
+				GFP_KERNEL);
+		if (!dp_port_info[inst][port_id].subif_info) {
+			PR_ERR("Failed for kmalloc: %zu bytes\n",
+			       max_subif * sizeof(struct dp_subif_info));
+			while (--port_id >= 0)
+				kfree(dp_port_info[inst][port_id].subif_info);
+			return DP_FAILURE;
+		}
+	}
+	return DP_SUCCESS;
+}
+
+/**
  * free_dma_chan_tbl: Free dp_dma_chan_tbl.
  * @inst: DP instance.
  */
@@ -1512,3 +1559,27 @@ void free_dma_chan_tbl(int inst)
 	/* free dma chan tbl */
 	kfree(dp_dma_chan_tbl[inst]);
 }
+
+/**
+ * free_dp_port_subif_info: free port subif info.
+ * @inst: DP instance.
+ */
+void free_dp_port_subif_info(int inst)
+{
+	int port_id;
+	int max_dp_ports;
+	struct pmac_port_info *port_info;
+	struct inst_info *info = NULL;
+
+	/* Retrieve the hw capabilities */
+	info = &dp_port_prop[inst].info;
+	max_dp_ports = info->cap.max_num_dp_ports;
+
+	if (dp_port_info[inst]) {
+		for (port_id = 0; port_id < max_dp_ports; port_id++) {
+			port_info = &dp_port_info[inst][port_id];
+			kfree(port_info->subif_info);
+		}
+		kfree(dp_port_info[inst]);
+	}
+}
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_notifier.c b/drivers/net/ethernet/lantiq/datapath/datapath_notifier.c
index 2bf6b16f335f..909933c221f0 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_notifier.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_notifier.c
@@ -37,7 +37,7 @@ int unregister_notifier(u32 flag)
 
 int dp_event(struct notifier_block *this, unsigned long event, void *ptr)
 {
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	struct net_device *dev;
 	u8 *addr;
 	int i;
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_platform_dev.c b/drivers/net/ethernet/lantiq/datapath/datapath_platform_dev.c
index 1ef23301f5ec..6c053b9daab8 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_platform_dev.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_platform_dev.c
@@ -9,7 +9,8 @@
 
 #include<linux/init.h>
 #include<linux/module.h>
-
+#include <linux/platform_device.h>
+#include <linux/of_address.h>
 #include <net/datapath_api.h>
 #include "datapath.h"
 
@@ -38,7 +39,7 @@ static int dp_release(struct platform_device *pdev)
 }
 
 static const struct of_device_id dp_match[] = {
-	{.compatible  = "lantiq,datapath-lib"},
+	{.compatible = "lantiq,datapath-lib", },
 	{},
 };
 
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_proc.c b/drivers/net/ethernet/lantiq/datapath/datapath_proc.c
index d8a7199102da..26dc53d19d89 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_proc.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_proc.c
@@ -11,11 +11,8 @@
 #include <net/datapath_proc_api.h>	/*for proc api */
 #include <net/datapath_api.h>
 #include <net/datapath_api_vlan.h>
+#include <linux/version.h>
 
-#ifdef CONFIG_LTQ_VMB
-#include <asm/ltq_vmb.h>	/*vmb */
-#include <asm/ltq_itc.h>	/*mips itc */
-#endif
 #include <linux/list.h>
 #include <linux/of_device.h>
 #include <linux/of_platform.h>
@@ -43,7 +40,7 @@
 static int tmp_inst;
 static ssize_t proc_port_write(struct file *file, const char *buf,
 			       size_t count, loff_t *ppos);
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 static void proc_dbg_read(struct seq_file *s);
 static ssize_t proc_dbg_write(struct file *, const char *, size_t, loff_t *);
 #endif
@@ -60,12 +57,14 @@ int proc_port_dump(struct seq_file *s, int pos)
 {
 	int i, j;
 	int cqm_p;
+	int dma_ch_offset;
 	int (*print_ctp_bp)(struct seq_file *s, int inst,
 			    struct pmac_port_info *port,
 			    int subif_index, u32 flag);
 	struct pmac_port_info *port = get_port_info(tmp_inst, pos);
 	u16 start = 0;
-	int dma_ch_offset;
+	int loop;
+	struct inst_info *info = NULL;
 
 	if (!capable(CAP_SYS_PACCT))
 		return -1;
@@ -73,6 +72,7 @@ int proc_port_dump(struct seq_file *s, int pos)
 		PR_ERR("Why port is NULL\n");
 		return -1;
 	}
+	info = &dp_port_prop[tmp_inst].info;
 	print_ctp_bp = DP_CB(tmp_inst, proc_print_ctp_bp_info);
 	DP_CB(tmp_inst, get_itf_start_end)(port->itf_info, &start, NULL);
 
@@ -82,9 +82,10 @@ int proc_port_dump(struct seq_file *s, int pos)
 				   "Reserved Port: rx_err_drop=0x%08x  tx_err_drop=0x%08x\n",
 				   STATS_GET(port->rx_err_drop),
 				   STATS_GET(port->tx_err_drop));
-			if (print_ctp_bp) /*just to print bridge
-					   *port zero's member
-					   */
+			if (print_ctp_bp && pos) /* just to print bridge
+						  * port zero's member.
+						  * CPU port no ctp/bridge port
+						  */
 				print_ctp_bp(s, tmp_inst, port, 0, 0);
 			i = 0;
 			seq_printf(s, "          : qid/node:    %d/%d\n",
@@ -93,6 +94,7 @@ int proc_port_dump(struct seq_file *s, int pos)
 			seq_printf(s, "          : port/node:    %d/%d\n",
 				   port->subif_info[i].cqm_deq_port,
 				   port->subif_info[i].qos_deq_port);
+			
 
 		} else
 			seq_printf(s,
@@ -105,10 +107,10 @@ int proc_port_dump(struct seq_file *s, int pos)
 	}
 
 	seq_printf(s,
-		   "%02d:%s=0x0x%0x(%s:%8s) %s=%02d %s=%02d %s=%d(%s) %s=%d\n",
+		   "%02d:%s=0x%0lx(%s:%8s) %s=%02d %s=%02d %s=%d(%s) %s=%d\n",
 		   pos,
 		   "module",
-		   (u32)port->owner,
+		   (uintptr_t)port->owner,
 		   "name",
 		   port->owner->name,
 		   "dev_port",
@@ -130,7 +132,7 @@ int proc_port_dump(struct seq_file *s, int pos)
 	seq_puts(s, "\n");
 	seq_printf(s, "    mode:              %d\n", port->cqe_lu_mode);
 	seq_printf(s, "    LCT:               %d\n", port->lct_idx);
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	seq_printf(s, "    Swdev:             %d\n", port->swdev_en);
 #endif
 	seq_printf(s, "    cb->rx_fn:         0x%0x\n", (u32)port->cb.rx_fn);
@@ -148,22 +150,31 @@ int proc_port_dump(struct seq_file *s, int pos)
 	seq_printf(s, "    deq_port_num:      %d\n", port->deq_port_num);
 	seq_printf(s, "    num_dma_chan:      %d\n", port->num_dma_chan);
 	seq_printf(s, "    dma_chan:          0x%x\n", port->dma_chan);
+	seq_printf(s, "    gpid_base:         %d\n", port->gpid_base);
+	seq_printf(s, "    gpid_num:          %d\n", port->gpid_num);
+	seq_printf(s, "    gpid_base:         %d\n", port->policy_base);
+	seq_printf(s, "    gpid_num:          %d\n", port->policy_num);
 	seq_printf(s, "    tx_pkt_credit:     %d\n", port->tx_pkt_credit);
 	seq_printf(s, "    tx_b_credit:       %02d\n", port->tx_b_credit);
-	seq_printf(s, "    tx_ring_addr:      0x%x\n", port->tx_ring_addr);
+	seq_printf(s, "    tx_ring_addr:      0x%px\n", port->tx_ring_addr);
+	seq_printf(s, "    tx_ring_addr_push: 0x%px\n", port->tx_ring_addr_push);
 	seq_printf(s, "    tx_ring_size:      %d\n", port->tx_ring_size);
 	seq_printf(s, "    tx_ring_offset:    %d(to next dequeue port)\n",
 		   port->tx_ring_offset);
-	for (i = 0; i < port->ctp_max; i++) {
+	if (pos == 0)
+		loop = info->cap.max_num_subif_per_port;
+	else 
+		loop = port->ctp_max;
+	for (i = 0; i < loop; i++) {
 		if (!port->subif_info[i].flags)
 			continue;
 		seq_printf(s,
-			   "      [%02d]:%s=0x%04x %s=0x%0x(%s=%s),%s=%s\n",
+			   "      [%02d]:%s=0x%04x %s=0x%0lx(%s=%s),%s=%s\n",
 			i,
 			"subif",
 			port->subif_info[i].subif,
 			"netif",
-			(u32)port->subif_info[i].netif,
+			(uintptr_t)port->subif_info[i].netif,
 			"netif",
 			port->subif_info[i].netif ?
 			port->subif_info[i].netif->name : "NULL/DSL",
@@ -210,9 +221,11 @@ int proc_port_dump(struct seq_file *s, int pos)
 		dma_ch_offset = dp_deq_port_tbl[tmp_inst][cqm_p].dma_ch_offset;
 		if (port->num_dma_chan && dp_dma_chan_tbl[tmp_inst])
 			seq_printf(s, "          : tx_dma_ch:    0x%x(ref=%d)\n",
-				   dp_deq_port_tbl[tmp_inst][cqm_p].dma_chan,
-				   atomic_read(&(dp_dma_chan_tbl[tmp_inst] +
-					       dma_ch_offset)->ref_cnt));
+			   dp_deq_port_tbl[tmp_inst][cqm_p].dma_chan,
+			   atomic_read(&(dp_dma_chan_tbl[tmp_inst] +
+				       dma_ch_offset)->ref_cnt));
+		seq_printf(s, "          : gpid:           %d\n",
+			   port->subif_info[i].gpid);
 		if (port->subif_info[i].ctp_dev &&
 		    port->subif_info[i].ctp_dev->name)
 			seq_printf(s, "          : ctp_dev = %s\n",
@@ -267,10 +280,10 @@ int display_port_info(int inst, u8 pos, int start_vap, int end_vap, u32 flag)
 
 	DP_CB(tmp_inst, get_itf_start_end)(port->itf_info, &start, NULL);
 
-	PR_INFO("%02d: %s=0x0x%0x(name:%8s) %s=%02d %s=%02d itf_base=%d(%s)\n",
+	PR_INFO("%02d: %s=0x0x%0lx(name:%8s) %s=%02d %s=%02d itf_base=%d(%s)\n",
 		pos,
 		"module",
-		(u32)port->owner, port->owner->name,
+		(uintptr_t)port->owner, port->owner->name,
 		"dev_port",
 		port->dev_port,
 		"dp_port",
@@ -289,26 +302,26 @@ int display_port_info(int inst, u8 pos, int start_vap, int end_vap, u32 flag)
 	PR_INFO("\n");
 
 	if (!flag) {
-		PR_INFO("    cb->rx_fn:         0x%0x\n",
-			(u32)port->cb.rx_fn);
-		PR_INFO("    cb->restart_fn:    0x%0x\n",
-			(u32)port->cb.restart_fn);
-		PR_INFO("    cb->stop_fn:       0x%0x\n",
-			(u32)port->cb.stop_fn);
-		PR_INFO("    cb->get_subifid_fn:0x%0x\n",
-			(u32)port->cb.get_subifid_fn);
+		PR_INFO("    cb->rx_fn:         0x%0lx\n",
+			(uintptr_t)port->cb.rx_fn);
+		PR_INFO("    cb->restart_fn:    0x%0lx\n",
+			(uintptr_t)port->cb.restart_fn);
+		PR_INFO("    cb->stop_fn:       0x%0lx\n",
+			(uintptr_t)port->cb.stop_fn);
+		PR_INFO("    cb->get_subifid_fn:0x%0lx\n",
+			(uintptr_t)port->cb.get_subifid_fn);
 		PR_INFO("    num_subif:         %02d\n", port->num_subif);
 	}
 
 	for (i = start_vap; i < end_vap; i++) {
 		if (port->subif_info[i].flags) {
 			PR_INFO
-			    ("      [%02d]:%s=0x%04x %s=0x%0x(%s=%s),%s=%s\n",
+			    ("      [%02d]:%s=0x%04x %s=0x%0lx(%s=%s),%s=%s\n",
 			     i,
 			     "subif",
 			     port->subif_info[i].subif,
 			     "netif",
-			     (u32)port->subif_info[i].netif,
+			     (uintptr_t)port->subif_info[i].netif,
 			     "device_name",
 			     port->subif_info[i].netif ? port->subif_info[i].
 			     netif->name : "NULL/DSL",
@@ -410,7 +423,7 @@ ssize_t proc_port_write(struct file *file, const char *buf, size_t count,
 	return count;
 }
 
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 void proc_dbg_read(struct seq_file *s)
 {
 	int i;
@@ -429,14 +442,14 @@ void proc_dbg_read(struct seq_file *s)
 
 	seq_puts(s, "\n\n");
 
-	seq_printf(s, "dp_drop_all_tcp_err=%d @ 0x%p\n", dp_drop_all_tcp_err,
+	seq_printf(s, "dp_drop_all_tcp_err=%d @ 0x%px\n", dp_drop_all_tcp_err,
 		   &dp_drop_all_tcp_err);
-	seq_printf(s, "dp_pkt_size_check=%d @ 0x%p\n", dp_pkt_size_check,
+	seq_printf(s, "dp_pkt_size_check=%d @ 0x%px\n", dp_pkt_size_check,
 		   &dp_pkt_size_check);
 
-	seq_printf(s, "dp_rx_test_mode=%d @ 0x%p\n", dp_rx_test_mode,
+	seq_printf(s, "dp_rx_test_mode=%d @ 0x%px\n", dp_rx_test_mode,
 		   &dp_rx_test_mode);
-	seq_printf(s, "dp_dbg_err(flat to print error or not)=%d @ 0x%p\n",
+	seq_printf(s, "dp_dbg_err(flat to print error or not)=%d @ 0x%px\n",
 		   dp_dbg_err,
 		   &dp_dbg_err);
 	print_parser_status(s);
@@ -452,7 +465,6 @@ ssize_t proc_dbg_write(struct file *file, const char *buf, size_t count,
 	int f_enable;
 	char *tmp_buf;
 	#define BUF_SIZE_TMP 2000
-
 	if (!capable(CAP_SYS_ADMIN))
 		return -EPERM;
 
@@ -506,9 +518,206 @@ ssize_t proc_dbg_write(struct file *file, const char *buf, size_t count,
 }
 #endif
 
+struct property_info {
+	char *name;
+	int type;
+};
+
+enum PROPERTY_TYPE {
+	PROP_UNKNOWN = 0,
+	PROP_STRING,
+	PROP_REG,
+	PROP_RANGER,
+	PROP_U32_OCT,
+	PROP_U32_HEX,
+	PROP_HANDLE,
+	PROP_REFERENCE
+};
+
+struct property_info prop_info[] = {
+	{"compatible", PROP_STRING},
+	{"status", PROP_STRING},
+	{"name", PROP_STRING},
+	{"label", PROP_STRING},
+	{"model", PROP_STRING},
+	{"reg-names", PROP_STRING},
+	{"reg", PROP_REG},
+	{"interrupts", PROP_U32_OCT},
+	{"ranges", PROP_RANGER},
+	{"dma-ranges", PROP_RANGER},
+	{"phandle", PROP_HANDLE},
+	{"interrupt-parent", PROP_HANDLE}
+
+};
+
+int get_property_info(char *name)
+{
+	int i;
+
+	if (!name)
+		return PROP_UNKNOWN;
+	for (i = 0; i < ARRAY_SIZE(prop_info); i++) {
+		if (dp_strncmpi(name, prop_info[i].name, strlen(prop_info[i].name)) == 0)
+			return prop_info[i].type;
+	}
+
+	return PROP_UNKNOWN;
+}
+
+/*0--not string
+ *1--is string
+ */
+/*#define LOCAL_STRING_PARSE*/
+int is_print_string(char *p, int len)
+{
+	int i;
+
+	if (!p || !len)
+		return 0;
+	if (p[len - 1] != 0)
+		return 0;
+	for (i = 0; i < len - 1; i++) {
+#ifdef LOCAL_STRING_PARSE
+		if (!(((p[i] >= 'a') && (p[i] <= 'z')) ||
+		      ((p[i] >= 'A') && (p[i] <= 'Z')) ||
+		      ((p[i] >= '0') && (p[i] <= '9')) ||
+		      (p[i] == '.') ||
+		      (p[i] == '/')))
+#else
+		if (!isprint(p[i]) && p[i] != 0) /*string list */
+#endif
+			return 0;
+	}
+	if (p[0] == 0)
+		return 0;
+
+	return 1;
+}
+
+#define INDENT_BASE 3 /*3 Space */
+void print_property(struct device_node *node, struct property *p, char *indent)
+{
+	int type;
+	int k, times, i;
+
+	if (!p || !node)
+		return;
+	type = get_property_info(p->name);
+	if (type == PROP_UNKNOWN) {
+		if (is_print_string(p->value, p->length))
+			type = PROP_STRING;
+		else if ((p->length % 4) == 0)
+			type = PROP_U32_OCT;
+	}
+	if (type == PROP_STRING) {
+		char *s = (char *)p->value;
+		int k = 0;
+
+		PR_INFO("%s  %s=", indent, p->name);
+		do {
+			PR_INFO("\"%s\"", s);
+			k += strlen(s) + 1;
+			if (k < p->length) {
+				s += strlen(s) + 1;
+				PR_INFO(",");
+				continue;
+			}
+			PR_INFO("\n");
+			break;
+		} while (1);
+	} else if (type == PROP_U32_OCT) { /*each item is 4 bytes*/
+		PR_INFO("%s  %s=<", indent, p->name);
+		times = p->length / 4;
+		if (times) {
+			for (k = 0; k < times; k++)
+				PR_INFO("%d ", *(int *)(p->value + k * 4));
+		}
+		PR_INFO(">\n");
+	} else if (type == PROP_U32_HEX) { /*each item is 4 bytes*/
+		PR_INFO("%s  %s=<", indent, p->name);
+		times = p->length / 4;
+		if (times) {
+			for (k = 0; k < times; k++)
+				PR_INFO("0x%x ", *(int *)(p->value + k * 4));
+		}
+		PR_INFO(">\n");
+	} else if (type == PROP_REG) {/*two tuple: address and size */
+		int n = (of_n_addr_cells(node) + of_n_size_cells(node));
+		int j;
+
+		PR_INFO("%s  %s=<", indent, p->name);
+		times = p->length / (4 * n);
+		if (times) {
+			for (k = 0; k < times; k++) {
+				if (k)
+					PR_INFO("%s    ", indent);
+				for (j = 0; j < n; j++)
+					PR_INFO("0x%x ",
+						*(int *)(p->value + k * 8 +
+						4 * j));
+				if (k != (times - 1))
+					PR_INFO("\n");
+			}
+		}
+		PR_INFO(">\n");
+	} else if (type == PROP_RANGER) {
+		/*triple: child-bus-address, parent-bus-address, length */
+		PR_INFO("%s  %s=<", indent, p->name);
+		times = p->length / (4 * 3);
+		if (times) {
+			for (k = 0; k < times; k++) {
+				if (!k)
+					PR_INFO("0x%x 0x%x 0x%x",
+						*(int *)(p->value + k * 8),
+						*(int *)(p->value + k * 8 + 4),
+						*(int *)(p->value + k * 8 + 8));
+				else
+					PR_INFO("%s    0x%x 0x%x 0x%x", indent,
+						*(int *)(p->value + k * 8),
+						*(int *)(p->value + k * 8 + 4),
+						*(int *)(p->value + k * 8 + 8));
+				if (k != (times - 1))
+					PR_INFO("\n");
+			}
+		}
+		PR_INFO(">\n");
+	} else if (type == PROP_HANDLE) {
+		struct device_node *tmp = of_find_node_by_phandle(
+			be32_to_cpup((u32 *)p->value));
+		int offset = 0;
+
+		if (tmp) {
+			PR_INFO("%s  %s=<&%s", indent, p->name, tmp->name);
+			offset = 1;
+		} else {
+			PR_INFO("%s  %s=<", indent, p->name);
+		}
+		if (p->length >= 4) {
+			int times = p->length / 4;
+
+			if (times) {
+				for (k = offset; k < times; k++)
+					PR_INFO("%d ",
+						*(int *)(p->value + k * 4));
+			}
+		}
+		PR_INFO(">\n");
+	} else {
+		PR_INFO("%s  %s length=%d\n", indent, p->name, p->length);
+		if (p->length) {
+			char *s = (unsigned char *)p->value;
+
+			PR_INFO("%s   ", indent);
+			for (i = 0; i < p->length; i++)
+				PR_INFO("0x%02x ", s[i]);
+			PR_INFO("\n");
+		}
+	}
+}
+
 static struct dp_proc_entry dp_proc_entries[] = {
 	/*name single_callback_t multi_callback_t/_start write_callback_t */
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 	{PROC_DBG, proc_dbg_read, NULL, NULL, proc_dbg_write},
 #endif
 	{PROC_PORT, NULL, proc_port_dump, proc_port_init, proc_port_write},
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c b/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c
index 9358835e13da..5a2c42ac1fbb 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_proc_api.c
@@ -199,7 +199,7 @@ static int dp_seq_show(struct seq_file *s, void *v)
 			local_dbg("multiple call");
 			p->pos = p->multi_callback(s, p->pos);
 		} else if (p->single_callback) {
-			local_dbg("single call: %p", p->single_callback);
+			local_dbg("single call: %px", p->single_callback);
 			p->single_callback(s);
 			p->pos = -1;
 		}
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_proc_qos.c b/drivers/net/ethernet/lantiq/datapath/datapath_proc_qos.c
index 1f5b437a0994..839bd961671d 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_proc_qos.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_proc_qos.c
@@ -601,7 +601,7 @@ struct q_print_info *collect_info(struct seq_file *s,
 			q_info->sch_box[i][j] = &q_info->box[q_info->box_num];
 			q_info->box_num++;
 			if (q_info->box_num == ARRAY_SIZE(q_info->box)) {
-				PR_ERR("sched+port (%d) in one node: %s<%d\n",
+				PR_ERR("sched+port (%d) in one node: %s<%zd\n",
 				       q_info->box_num,
 				       "expect",
 				       ARRAY_SIZE(q_info->box));
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_qos.c b/drivers/net/ethernet/lantiq/datapath/datapath_qos.c
index b5655638a5ea..bac3eec3d356 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_qos.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_qos.c
@@ -228,6 +228,19 @@ int dp_qos_level_get(struct dp_qos_level *cfg, int flag)
 }
 EXPORT_SYMBOL(dp_qos_level_get);
 
+int dp_qos_get_q_logic(struct dp_qos_q_logic *cfg, int flag)
+{
+	if (!cfg)
+		return DP_FAILURE;
+	if (!dp_port_prop[cfg->inst].info.dp_qos_platform_set) {
+		cfg->q_logic_id = cfg->q_id; /* For GRX500 */
+		return DP_SUCCESS;
+	}
+	return dp_port_prop[cfg->inst].info.
+		dp_qos_platform_set(QOS_Q_LOGIC, cfg, flag);
+}
+EXPORT_SYMBOL(dp_qos_get_q_logic);
+
 int dp_qos_global_info_get(struct dp_qos_cfg_info *info, int flag)
 {
 	if (!dp_port_prop[info->inst].info.dp_qos_platform_set)
@@ -235,4 +248,4 @@ int dp_qos_global_info_get(struct dp_qos_cfg_info *info, int flag)
 	return dp_port_prop[info->inst].info.
 		dp_qos_platform_set(QOS_GLOBAL_CFG_GET, info, flag);
 }
-EXPORT_SYMBOL(dp_qos_global_info_get);
+EXPORT_SYMBOL(dp_qos_global_info_get);
\ No newline at end of file
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_soc.c b/drivers/net/ethernet/lantiq/datapath/datapath_soc.c
index 7a5306bb35d6..1f197e19289d 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_soc.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_soc.c
@@ -11,32 +11,43 @@
 #include <linux/kernel.h>
 #include <linux/version.h>
 #include <linux/if_ether.h>
+#include <linux/skbuff.h>
 #include <linux/ethtool.h>
-#include <lantiq_soc.h>
 #include <net/datapath_api.h>
 #include "datapath.h"
 #include "datapath_instance.h"
 #include "datapath_swdev_api.h"
 
-#ifdef CONFIG_PRX300_CQM
-#define LTQ_DATAPATH_SOC_PRX300
+#if IS_ENABLED(CONFIG_PRX300_CQM)
+#define INTEL_DATAPATH_SOC_PRX300
 #endif
 
 int request_dp(u32 flag)
 {
 	struct dp_inst_info info;
+	int i = 0;
+	u32 mac_ifcnt = gsw_get_mac_subifcnt(0);
 
-#if IS_ENABLED(CONFIG_PRX300_CQM) || \
-	IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31) /*testing only */
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SIMULATE_GSWIP32) || \
+	#ifdef DP_SKB_HACK
+	info.type = GSWIP32_TYPE;
+	info.ver = GSWIP32_VER;
+	info.ops[0] = gsw_get_swcore_ops(0);
+	info.ops[1] = gsw_get_swcore_ops(0);
+	info.mac_ops[0] = NULL;
+	info.mac_ops[1] = NULL;
+	for(i = 0; i < mac_ifcnt; i++)
+		info.mac_ops[i + 2] = gsw_get_mac_ops(0, i + 2);
+#elif IS_ENABLED(CONFIG_PRX300_CQM) || \
+	IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31) /*testing only */
 	info.type = GSWIP31_TYPE;
 	info.ver = GSWIP31_VER;
 	info.ops[0] = gsw_get_swcore_ops(0);
 	info.ops[1] = gsw_get_swcore_ops(0);
 	info.mac_ops[0] = NULL;
 	info.mac_ops[1] = NULL;
-	info.mac_ops[2] = gsw_get_mac_ops(0, 2);
-	info.mac_ops[3] = gsw_get_mac_ops(0, 3);
-	info.mac_ops[4] = gsw_get_mac_ops(0, 4);
+	for(i = 0; i < mac_ifcnt; i++)
+		info.mac_ops[i + 2] = gsw_get_mac_ops(0, i + 2);
 #else
 	info.type = GSWIP30_TYPE;
 	info.ver = GSWIP30_VER;
@@ -54,11 +65,15 @@ int request_dp(u32 flag)
 
 int register_dp_cap(u32 flag)
 {
-#ifdef CONFIG_LTQ_DATAPATH_HAL_GSWIP31
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_HAL_GSWIP32)
+	register_dp_cap_gswip32(0);
+#endif
+
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_HAL_GSWIP31)
 	register_dp_cap_gswip31(0);
 #endif
 
-#ifdef CONFIG_LTQ_DATAPATH_HAL_GSWIP30
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_HAL_GSWIP30)
 	register_dp_cap_gswip30(0);
 #endif
 	return 0;
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_swdev.c b/drivers/net/ethernet/lantiq/datapath/datapath_swdev.c
index 237cd72da2f2..29a1a743799e 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_swdev.c
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_swdev.c
@@ -691,7 +691,7 @@ int dp_del_br_if(struct net_device *dev, struct net_device *br_dev,
 	return 0;
 }
 
-//#define CONFIG_LTQ_DATAPATH_SWDEV_TEST
+//#define CONFIG_INTEL_DATAPATH_SWDEV_TEST
 
 static int dp_swdev_port_attr_set(struct net_device *dev,
 				  const struct switchdev_attr *attr,
@@ -699,7 +699,7 @@ static int dp_swdev_port_attr_set(struct net_device *dev,
 {
 	int err = -EOPNOTSUPP;
 	struct net_device *br_dev;
-#ifdef CONFIG_LTQ_DATAPATH_SWDEV_TEST
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWDEV_TEST)
 	{
 		struct net_device *br_dev =
 			netdev_master_upper_dev_get(attr->orig_dev);
@@ -819,7 +819,7 @@ static int dp_swdev_port_obj_add(struct net_device *dev,
 {
 	int err = -EOPNOTSUPP;
 	struct net_device *br_dev;
-#ifdef CONFIG_LTQ_DATAPATH_SWDEV_TEST
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWDEV_TEST)
 	{
 		struct net_device *br_dev = netdev_master_upper_dev_get(dev);
 
@@ -866,7 +866,7 @@ static int dp_swdev_port_obj_del(struct net_device *dev,
 {
 	int err = -EOPNOTSUPP;
 	return err;//TODO
-#ifdef CONFIG_LTQ_DATAPATH_SWDEV_TEST
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWDEV_TEST)
 	{
 		struct net_device *br_dev = netdev_master_upper_dev_get(dev);
 
@@ -894,10 +894,12 @@ static int dp_swdev_port_fdb_dump(struct net_device *dev,
 				  struct switchdev_obj_port_fdb *fdb_obj,
 				  switchdev_obj_dump_cb_t *cb)
 {
+#if 0
 	int err = 0;
 	struct fdb_tbl *fdb_d = NULL;
-
-	list_for_each_entry(fdb_d, &fdb_tbl_list, fdb_list) {
+	
+	extern struct list_head fdb_tbl_list_31;
+	list_for_each_entry(fdb_d, &fdb_tbl_list_31, fdb_list) {
 		if (fdb_d) {
 			if (fdb_d->port_dev != dev) {
 				continue;
@@ -913,6 +915,7 @@ static int dp_swdev_port_fdb_dump(struct net_device *dev,
 			break;
 		}
 	}
+#endif
 	return 0;
 }
 
@@ -924,7 +927,7 @@ static int dp_swdev_port_obj_dump(struct net_device *dev,
 
 	DP_DEBUG(DP_DBG_FLAG_SWDEV, "dp_swdev_port_obj_dump\r\n");
 	switch (obj->id) {
-#ifdef CONFIG_LTQ_DATAPATH_SWDEV_TEST
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWDEV_TEST)
 	case SWITCHDEV_OBJ_ID_PORT_VLAN:
 		err = dp_swdev_port_vlan_dump(mlxsw_sp_port,
 					      SWITCHDEV_OBJ_PORT_VLAN(obj),
@@ -951,7 +954,7 @@ static int dp_ndo_bridge_setlink(struct net_device *dev,
 
 	DP_DEBUG(DP_DBG_FLAG_SWDEV, "ndo_bridge_setlink: dev=%s\n",
 		 dev ? dev->name : "NULL");
-#ifdef CONFIG_LTQ_DATAPATH_SWDEV_TEST
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWDEV_TEST)
 	struct nlattr *attr, *br_spec;
 	int rem;
 	u16 mode = 0;
diff --git a/drivers/net/ethernet/lantiq/datapath/datapath_swdev.h b/drivers/net/ethernet/lantiq/datapath/datapath_swdev.h
index af322d58faae..ba53def11eba 100644
--- a/drivers/net/ethernet/lantiq/datapath/datapath_swdev.h
+++ b/drivers/net/ethernet/lantiq/datapath/datapath_swdev.h
@@ -57,7 +57,6 @@ struct fdb_tbl {
 	__be16 vid;
 };
 
-extern struct list_head fdb_tbl_list;
 extern struct hlist_head
 	g_bridge_id_entry_hash_table[DP_MAX_INST][BR_ID_ENTRY_HASH_TABLE_SIZE];
 int dp_swdev_bridge_id_entry_free(int instance);
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig b/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig
index eab61ae22d7b..3c33b5dfa665 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/Kconfig
@@ -1,19 +1,18 @@
-menuconfig LTQ_DATAPATH_HAL_GSWIP30
+menuconfig INTEL_DATAPATH_HAL_GSWIP30
 	bool "Datapath HAL_GSWIP30"
 	default y
-	depends on LTQ_DATAPATH && GRX500_CBM
+	depends on INTEL_DATAPATH && GRX500_CBM
 	---help---
 	  Datapath Lib is to provide common rx/tx wrapper Lib without taking
 	  care of much HW knowledge and also provide common interface for legacy
 	  devices and different HW like to CBM or LRO.
 	  Take note: All devices need to register to datapath Lib first
 
-if LTQ_DATAPATH_HAL_GSWIP30
-config LTQ_DATAPATH_HAL_GSWIP30_MIB
+if INTEL_DATAPATH_HAL_GSWIP30
+config INTEL_DATAPATH_HAL_GSWIP30_MIB
 	bool "Datapath aggregated mib support"
-	depends on LTQ_DATAPATH_HAL_GSWIP30 && SOC_GRX500 && LTQ_TMU && LTQ_PPA_TMU_MIB_SUPPORT
+	depends on INTEL_DATAPATH_HAL_GSWIP30 && SOC_GRX500 && LTQ_TMU && LTQ_PPA_TMU_MIB_SUPPORT
 	default y
 	---help---
 	  It is to aggregate GSWIP-L/R, TMU and driver's MIB counter
-
 endif
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile b/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile
index d87291f9acf0..f71d2a34f707 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/Makefile
@@ -1,11 +1,12 @@
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_misc.o datapath_gswip.o datapath_proc.o datapath_lookup_proc.o
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_misc.o datapath_gswip.o datapath_proc.o datapath_lookup_proc.o
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_rx.o datapath_tx.o
 
-ifneq ($(CONFIG_LTQ_DATAPATH_HAL_GSWIP30_MIB),)
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_mib.o
+ifneq ($(CONFIG_INTEL_DATAPATH_HAL_GSWIP30_MIB),)
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_mib.o
 endif
 
-ifneq ($(CONFIG_LTQ_DATAPATH_CPUFREQ),)
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_coc.o
+ifneq ($(CONFIG_INTEL_DATAPATH_CPUFREQ),)
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_coc.o
 endif
 
 
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c
index 1fb4ff9ebd97..959f8fa53dd2 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_gswip.c
@@ -10,7 +10,6 @@
 #include <linux/kernel.h>
 #include <linux/types.h>
 #include <linux/etherdevice.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include "../datapath.h"
 #include "datapath_misc.h"
@@ -233,7 +232,7 @@ int dp_pmac_set_30(int inst, u32 port, dp_pmac_cfg_t *pmac_cfg)
 
 			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_MPE2FLG)
 				egcfg.bMpe2Flag = pmac_cfg->eg_pmac.mpe2_flag;
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 			if (dp_dbg_flag) {
 				DP_DEBUG(DP_DBG_FLAG_DBG,
 					 "\nPMAC %d egcfg configuration:\n",
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c
index 96d1363673d9..0ce1c5e5d4a1 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_lookup_proc.c
@@ -18,12 +18,10 @@
 
 #include <lantiq.h>
 #include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #define DATAPATH_HAL_LAYER   /*must put before include datapath_api.h in
 			      *order to avoid include another platform's
 			      *DMA descriptor and pmac header files
 			      */
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include <net/datapath_api_gswip31.h>
 #include "../datapath.h"
@@ -398,6 +396,8 @@ ssize_t proc_get_qid_via_index30(struct file *file, const char *buf,
 	char *param_list[10];
 	int num;
 
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
 	len = (count >= sizeof(data)) ? (sizeof(data) - 1) : count;
 	DP_DEBUG(DP_DBG_FLAG_LOOKUP, "len=%d\n", len);
 
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c
index 48c5e76bc740..768357bc2dad 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_mib.c
@@ -23,11 +23,9 @@
 #include <linux/clk.h>
 
 #include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include <net/datapath_proc_api.h>
 #include "../datapath.h"
-#include <net/lantiq_cbm_api.h>
 #ifdef CONFIG_LTQ_TMU
 #include <net/drv_tmu_ll.h>
 #endif
@@ -187,7 +185,7 @@ struct task_struct *thread;
 static struct timer_list exp_timer;	/*timer setting */
 #endif
 
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 static int32_t (*tmu_hal_get_qos_m_local)(struct net_device *dev,
 					  dp_subif_t *subif_id,
 					  s32 queue_id,
@@ -567,7 +565,7 @@ static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag)
 	GSW_return_t ret;
 	struct mibs_low_lvl_port *curr;
 	dp_subif_t tmp;
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 	int update_flag, i;
 	struct pmac_port_info *port;
 #endif
@@ -615,7 +613,7 @@ static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag)
 	if (ret)/*workaroud */
 		curr->r = last[tmp.port_id].r;
 
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 	/* collect all mib per VAP for TMU and MPE MIB */
 	tmu_hal_get_qos_m_local = tmu_hal_get_qos_mib_hook_fn;
 	port = get_port_info(tmp.port_id);
@@ -665,7 +663,7 @@ static int update_port_mib_lower_lvl(dp_subif_t *subif, u32 flag)
 					  &curr->redir);
 		if (ret)	/*workaroud */
 			curr->redir = last[tmp.port_id].redir;
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 		tmu_hal_get_csum_ol_m_local =
 			tmu_hal_get_csum_ol_mib_hook_fn;
 		update_flag = 0;
@@ -765,7 +763,7 @@ static int update_vap_mib_lower_lvl(dp_subif_t *subif, u32 flag)
 		PR_ERR("get_gsw_itf_rmon failed for port/vap(%d/%d)", port_id,
 		       vap);
 	}
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 	/*get TMU mib */
 	tmu_hal_get_qos_m_local = tmu_hal_get_qos_mib_hook_fn;
 	if (!tmu_hal_get_qos_m_local) {
@@ -1619,7 +1617,7 @@ int dp_clear_netif_mib_30(dp_subif_t *subif, void *priv, u32 flag)
 		gsw_mib_reset_30(1, 0);
 		tmu_reset_mib_all(flag);
 		dp_clear_all_mib_inside(flag);
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 		tmu_hal_clear_qos_m_local =
 			tmu_hal_clear_qos_mib_hook_fn;
 		if (tmu_hal_clear_qos_m_local)
@@ -1709,7 +1707,7 @@ int dp_clear_netif_mib_30(dp_subif_t *subif, void *priv, u32 flag)
 		gsw_core_api((dp_gsw_cb)gsw_r->gsw_rmon_ops.RMON_Clear,
 			     gsw_r, &rmon);
 
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 		tmu_hal_clear_csum_ol_m_local =
 			tmu_hal_clear_csum_ol_mib_hook_fn;
 		if (tmu_hal_clear_csum_ol_m_local)
@@ -1730,7 +1728,7 @@ int dp_clear_netif_mib_30(dp_subif_t *subif, void *priv, u32 flag)
 		gsw_core_api((dp_gsw_cb)gsw_r->gsw_rmon_ops.RMON_Clear,
 			     gsw_r, &rmon);
 	}
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 	tmu_hal_clear_qos_m_local = tmu_hal_clear_qos_mib_hook_fn;
 	if (tmu_hal_clear_qos_m_local)
 		tmu_hal_clear_qos_m_local(NULL, subif, -1, flag);
@@ -1831,7 +1829,7 @@ int proc_mib_port_dump(struct seq_file *s, int pos)
 ssize_t proc_mib_port_write(struct file *file, const char *buf, size_t count,
 			    loff_t *ppos)
 {
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 	int len;
 	char str[64];
 	int i, num, res;
@@ -1955,7 +1953,7 @@ ssize_t proc_mib_port_write(struct file *file, const char *buf, size_t count,
 	return count;
 #endif
 	return count;
-#ifdef CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_MIB_TMU_MPE_MIB)
 help:
 	PR_INFO("usage:\n");
 	PR_INFO("  test qos_mib  api:      echo qos_mib        > %s\n",
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c
index 5dcd309d3ad9..e5a970cdfb26 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.c
@@ -24,15 +24,10 @@
 #include <linux/clk.h>
 #include <linux/ip.h>
 #include <net/ip.h>
-
-#include <lantiq.h>
-#include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #define DATAPATH_HAL_LAYER   /*must put before include datapath_api.h in
 			      *order to avoid include another platform's
 			      *DMA descriptor and pmac header files
 			      */
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include <net/datapath_api_gswip30.h>
 #include "../datapath.h"
@@ -40,7 +35,7 @@
 #include "datapath_misc.h"
 #include "datapath_mib.h"
 
-#ifdef CONFIG_LTQ_TMU
+#if IS_ENABLED(CONFIG_LTQ_TMU)
 #include <net/drv_tmu_ll.h>
 #endif
 
@@ -74,7 +69,7 @@ static void init_dma_desc_mask(void)
 static void init_dma_pmac_template(int portid, u32 flags)
 {
 	int i;
-	struct pmac_port_info2 *dp_info = &dp_port_info2[0][portid];
+	struct pmac_port_info *dp_info = &dp_port_info[0][portid];
 
 	/*Note:
 	 * final tx_dma0 = (tx_dma0 & dma0_mask_template) | dma0_template
@@ -413,7 +408,7 @@ static void dump_tx_pmac(struct pmac_tx_hdr *pmac)
 
 static void mib_init(u32 flag)
 {
-#ifdef CONFIG_LTQ_DATAPATH_MIB
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MIB)
 	dp_mib_init(0);
 #endif
 	gsw_mib_reset_30(0, 0); /* GSW L */
@@ -424,13 +419,13 @@ static void mib_init(u32 flag)
 
 void dp_sys_mib_reset_30(u32 flag)
 {
-#ifdef CONFIG_LTQ_DATAPATH_MIB
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MIB)
 	dp_reset_sys_mib(0);
 #else
 	gsw_mib_reset_30(0, 0); /* GSW L */
 	gsw_mib_reset_30(1, 0); /* GSW R */
 	dp_clear_all_mib_inside(0);
-#ifdef CONFIG_LTQ_TMU
+#if IS_ENABLED(CONFIG_LTQ_TMU)
 	tmu_reset_mib_all(flag);
 #endif
 #endif
@@ -451,7 +446,7 @@ static int dp_platform_set(int inst, u32 flag)
 	if (!inst)
 		mib_init(0);
 	dp_get_gsw_parser_30(NULL, NULL, NULL, NULL);
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 	if (!inst) {
 		dp_coc_cpufreq_init();
 		if (flag == DP_PLATFORM_DE_INIT)
@@ -462,18 +457,12 @@ static int dp_platform_set(int inst, u32 flag)
 	return 0;
 }
 
-static int dev_platform_set(int inst, u8 ep, struct dp_dev_data *data,
-			     u32 flags)
-{
-	return 0;
-}
-
 static int port_platform_set(int inst, u8 ep, struct dp_port_data *data,
 			     u32 flags)
 {
 	int idx, i;
-	struct pmac_port_info *port_info = &dp_port_info[inst][ep];
 	u32 dma_chan, dma_ch_base;
+	struct pmac_port_info *port_info = &dp_port_info[inst][ep];
 
 	dp_port_info[inst][ep].ctp_max = MAX_SUBIF_PER_PORT;
 	dp_port_info[inst][ep].vap_offset = 8;
@@ -483,8 +472,6 @@ static int port_platform_set(int inst, u8 ep, struct dp_port_data *data,
 	dma_ch_base = port_info->dma_ch_base;
 	for (i = 0; i < port_info->deq_port_num; i++) {
 		dp_deq_port_tbl[inst][i + idx].dp_port = ep;
-
-		/* For G.INT num_dma_chan 8 or 16, for other 1 */
 		if (port_info->num_dma_chan > 1) {
 			dp_deq_port_tbl[inst][i + idx].dma_chan = dma_chan++;
 			dp_deq_port_tbl[inst][i + idx].dma_ch_offset =
@@ -497,7 +484,7 @@ static int port_platform_set(int inst, u8 ep, struct dp_port_data *data,
 		DP_DEBUG(DP_DBG_FLAG_DBG, "deq_port_tbl[%d][%d].dma_chan=%x\n",
 			 inst, (i + idx), dma_chan);
 	}
-#ifdef CONFIG_LTQ_DATAPATH_MIB
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MIB)
 	if (flags & DP_F_DEREGISTER) {
 		reset_gsw_itf(ep);
 		return 0;
@@ -539,12 +526,12 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 		return -1;
 	}
 	cqe_deq = port_info->deq_port_base + deq_port_idx;
-	port_info->subif_info[subif_ix].cqm_deq_port = cqe_deq;
 	dma_ch_offset = dp_deq_port_tbl[inst][cqe_deq].dma_ch_offset;
+	port_info->subif_info[subif_ix].cqm_deq_port = cqe_deq;
 	dp_deq_port_tbl[inst][cqe_deq].ref_cnt++;
 	if (port_info->num_dma_chan)
 		atomic_inc(&(dp_dma_chan_tbl[inst] + dma_ch_offset)->ref_cnt);
-	DP_DEBUG(DP_DBG_FLAG_REG, "cbm[%d].ref_cnt=%d DMATXCH_Ref.cnt=%d\n",
+	DP_DEBUG(DP_DBG_FLAG_REG, "cbm[%d].ref_cnt=%d tx_dma_chan: (ref=%d)\n",
 		 cqe_deq,
 		 dp_deq_port_tbl[inst][cqe_deq].ref_cnt,
 		 atomic_read(&(dp_dma_chan_tbl[inst] +
@@ -585,7 +572,7 @@ static int subif_hw_reset(int inst, int portid, int subif_ix,
 	dp_deq_port_tbl[inst][cqe_deq].ref_cnt--;
 	if (port_info->num_dma_chan)
 		atomic_dec(&(dp_dma_chan_tbl[inst] + dma_ch_offset)->ref_cnt);
-	DP_DEBUG(DP_DBG_FLAG_REG, "cbm[%d].ref_cnt=%d DMATXCH_Ref_cnt=%d\n",
+	DP_DEBUG(DP_DBG_FLAG_REG, "cbm[%d].ref_cnt=%d tx_dma_chan: (ref=%d)\n",
 		 cqe_deq,
 		 dp_deq_port_tbl[inst][cqe_deq].ref_cnt,
 		 atomic_read(&(dp_dma_chan_tbl[inst] +
@@ -641,7 +628,7 @@ static void update_port_vap(int inst, u32 *ep, int *vap,
 static void get_dma_pmac_templ(int index, struct pmac_tx_hdr *pmac,
 			       struct dma_tx_desc_0 *desc_0,
 			       struct dma_tx_desc_1 *desc_1,
-			       struct pmac_port_info2 *dp_info)
+			       struct pmac_port_info *dp_info)
 {
 	if (likely(pmac))
 		memcpy(pmac, &dp_info->pmac_template[index], sizeof(*pmac));
@@ -675,7 +662,6 @@ int register_dp_cap_gswip30(int flag)
 	cap.info.ver = GSWIP30_VER;
 	cap.info.dp_platform_set = dp_platform_set;
 	cap.info.port_platform_set = port_platform_set;
-	cap.info.dev_platform_set = dev_platform_set;
 	cap.info.subif_platform_set_unexplicit = subif_platform_set_unexplicit;
 	cap.info.proc_print_ctp_bp_info = NULL;
 	cap.info.init_dma_pmac_template = init_dma_pmac_template;
@@ -696,11 +682,13 @@ int register_dp_cap_gswip30(int flag)
 	cap.info.dp_pmac_set = dp_pmac_set_30;
 	cap.info.dp_set_gsw_parser = dp_set_gsw_parser_30;
 	cap.info.dp_get_gsw_parser = dp_get_gsw_parser_30;
-#ifdef CONFIG_LTQ_DATAPATH_HAL_GSWIP30_MIB
+	cap.info.dp_rx = dp_rx_30;
+	cap.info.dp_tx = dp_xmit_30;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_HAL_GSWIP30_MIB)
 	cap.info.dp_get_port_vap_mib = dp_get_port_vap_mib_30;
 	cap.info.dp_clear_netif_mib = dp_clear_netif_mib_30;
 #endif
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 	cap.info.dp_handle_cpufreq_event = dp_handle_cpufreq_event_30;
 #endif
 	cap.info.cap.tx_hw_chksum = 1;
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h
index 1d86070bc87f..248401bff67a 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_misc.h
@@ -58,6 +58,9 @@ int dp_set_gsw_parser_30(u8 flag, u8 cpu, u8 mpe1, u8 mpe2, u8 mpe3);
 int dp_get_gsw_parser_30(u8 *cpu, u8 *mpe1, u8 *mpe2, u8 *mpe3);
 int gsw_mib_reset_30(int dev, u32 flag);
 int dp_pmac_set_30(int inst, u32 port, dp_pmac_cfg_t *pmac_cfg);
+int32_t dp_rx_30(struct sk_buff *skb, u32 flags);
+int32_t dp_xmit_30(struct net_device *rx_if, dp_subif_t *rx_subif,
+		   struct sk_buff *skb, int32_t len, uint32_t flags);
 
 static inline GSW_return_t gsw_core_api(dp_gsw_cb func,
 					void *ops, void *param)
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_rx.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_rx.c
new file mode 100644
index 000000000000..a7ebf2ab6aba
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_rx.c
@@ -0,0 +1,334 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/etherdevice.h>
+#include <net/datapath_api.h>
+#include "../datapath.h"
+#include "datapath_misc.h"
+#if IS_ENABLED(CONFIG_PPA_API_SW_FASTPATH)
+#include <net/ppa/ppa_api.h>
+#endif
+
+static void rx_dbg(u32 f, struct sk_buff *skb, struct dma_rx_desc_0 *desc0,
+	       struct dma_rx_desc_1 *desc1, struct dma_rx_desc_2 *desc2,
+	       struct dma_rx_desc_3 *desc3, unsigned char *parser,
+	       struct pmac_rx_hdr *pmac, int paser_exist)
+{
+	int inst = 0;
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
+		 "\ndp_rx:skb->data=%p Loc=%x offset=%d skb->len=%d\n",
+		 skb->data, desc2->field.data_ptr,
+		 desc3->field.byte_offset, skb->len);
+	if ((f) & DP_DBG_FLAG_DUMP_RX_DATA)
+		dp_dump_raw_data(skb->data,
+				(skb->len >
+				(dp_print_len)) ? skb->len : (dp_print_len),
+				"Original Data");
+	DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "parse hdr size = %d\n",
+		 paser_exist);
+	if ((f) & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
+		dp_port_prop[inst].info.dump_rx_dma_desc(desc0, (desc1),
+							 desc2, desc3);
+	if (paser_exist && (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_PASER))
+		dump_parser_flag(parser);
+	if ((f) & DP_DBG_FLAG_DUMP_RX_PMAC)
+		dp_port_prop[inst].info.dump_rx_pmac(pmac);
+}
+
+#define PRINT_INTERVAL  (5 * HZ) /* 5 seconds */
+unsigned long dp_err_interval = PRINT_INTERVAL;
+static void rx_dbg_zero_port(struct sk_buff *skb, struct dma_rx_desc_0 *desc0,
+			     struct dma_rx_desc_1 *desc1,
+			     struct dma_rx_desc_2 *desc2,
+			     struct dma_rx_desc_3 *desc3,
+			     unsigned char *parser,
+			     struct pmac_rx_hdr *pmac, int paser_exist,
+			     u32 ep, u32 port_id, int vap)
+{
+	int inst = 0;
+	static unsigned long last;
+
+	if (!dp_dbg_err) /*bypass dump */
+		return;
+	if (time_before(jiffies, last + dp_err_interval))
+		/* not print in order to keep console not busy */
+		return;
+	last = jiffies;
+	DP_DEBUG(-1, "%s=%d vap=%d\n",
+		 (ep) ? "ep" : "port_id", port_id, vap);
+	PR_ERR("\nDrop for ep and source port id both zero ??\n");
+	dp_port_prop[inst].info.dump_rx_dma_desc(desc0, desc1, desc2, desc3);
+
+	if (paser_exist)
+		dump_parser_flag(parser);
+	if (pmac)
+		dp_port_prop[inst].info.dump_rx_pmac(pmac);
+	dp_dump_raw_data((char *)(skb->data),
+			(skb->len >
+			 dp_print_len) ? skb->len : dp_print_len,
+			"Recv Data");
+}
+
+/* clone skb to send one copy to lct dev for multicast/broadcast
+ * otherwise for unicast send only to lct device
+ * return 0 - Caller will not proceed handling i.e. for unicast do rx only for
+ *	      LCT port
+ *	  1 - Caller continue to handle rx for other device
+ */
+static int dp_handle_lct(struct pmac_port_info *dp_port,
+			 struct sk_buff *skb, dp_rx_fn_t rx_fn)
+{
+	struct sk_buff *lct_skb;
+	int vap, ret;
+
+	vap = dp_port->lct_idx;
+	skb->dev = dp_port->subif_info[vap].netif;
+	if (skb->data[PMAC_SIZE] & 0x1) {
+		/* multicast/broadcast */
+		DP_DEBUG(DP_DBG_FLAG_PAE, "LCT mcast or broadcast\n");
+		if((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+			return 1;
+		}
+		lct_skb = skb_clone(skb, GFP_ATOMIC);
+		if (!lct_skb) {
+			PR_ERR("LCT mcast/bcast skb clone fail\n");
+			return -1;
+		}
+		lct_skb->dev = dp_port->subif_info[vap].netif;	
+		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_rxif_pkt);
+		DP_DEBUG(DP_DBG_FLAG_PAE, "pkt sent lct(%s) ret(%d)\n",
+			 lct_skb->dev->name ? lct_skb->dev->name : "NULL",
+			 ret);
+		rx_fn(lct_skb->dev, NULL, lct_skb, lct_skb->len);
+		return 1;
+	} else if (memcmp(skb->data + PMAC_SIZE, skb->dev->dev_addr, 6) == 0) {
+		/* unicast */
+		DP_DEBUG(DP_DBG_FLAG_PAE, "LCT unicast\n");
+		DP_DEBUG(DP_DBG_FLAG_PAE, "unicast pkt sent lct(%s) ret(%d)\n",
+				 skb->dev->name ? skb->dev->name : "NULL", ret);
+		if((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+			dev_kfree_skb_any(skb);
+			return 0;
+		}
+		rx_fn(skb->dev, NULL, skb, skb->len);
+		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_rxif_pkt);
+		return 0;
+	}
+	return 1;
+}
+
+int32_t dp_rx_30(struct sk_buff *skb, u32 flags)
+{
+	int res = DP_SUCCESS;
+	struct dma_rx_desc_0 *desc_0 = (struct dma_rx_desc_0 *)&skb->DW0;
+	struct dma_rx_desc_1 *desc_1 = (struct dma_rx_desc_1 *)&skb->DW1;
+	struct dma_rx_desc_2 *desc_2 = (struct dma_rx_desc_2 *)&skb->DW2;
+	struct dma_rx_desc_3 *desc_3 = (struct dma_rx_desc_3 *)&skb->DW3;
+	struct pmac_rx_hdr *pmac;
+	unsigned char *parser = NULL;
+	int rx_tx_flag = 0;	/*0-rx, 1-tx */
+	u32 ep = desc_1->field.ep;	/* ep: 0 -15 */
+	int vap; /*vap: 0-15 */
+	int paser_exist;
+	u32 port_id = ep; /*same with ep now, later set to sspid if ep is 0 */
+	struct net_device *dev;
+	dp_rx_fn_t rx_fn;
+	char decryp = 0;
+	u8 inst = 0;
+	struct pmac_port_info *dp_port;
+	struct mac_ops *ops;
+	int ret_lct = 1;
+
+	dp_port = &dp_port_info[inst][0];
+	if (!skb) {
+		PR_ERR("skb NULL\n");
+		return DP_FAILURE;
+	}
+	if (!skb->data) {
+		PR_ERR("skb->data NULL\n");
+		return DP_FAILURE;
+	}
+
+	paser_exist = parser_enabled(port_id, desc_1);
+	if (paser_exist)
+		parser = skb->data;
+	pmac = (struct pmac_rx_hdr *)(skb->data + paser_exist);
+
+	if (unlikely(dp_dbg_flag))
+		rx_dbg(dp_dbg_flag, skb, desc_0, desc_1, desc_2,
+		       desc_3, parser, pmac, paser_exist);
+	if (paser_exist) {
+		skb_pull(skb, paser_exist);	/*remove parser */
+#if IS_ENABLED(CONFIG_PPA_API_SW_FASTPATH)
+		skb->mark |= FLG_PPA_PROCESSED;
+#endif
+	}
+#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
+	/*Sanity check */
+	if (unlikely(dp_port_prop[inst].info.not_valid_rx_ep(ep))) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Wrong: why ep=%d??\n", ep);
+		rx_dbg(-1, skb, desc_0, desc_1, desc_2, desc_3,
+		       parser, pmac, paser_exist);
+		goto RX_DROP;
+	}
+	if (unlikely(dp_drop_all_tcp_err && desc_1->field.tcp_err)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "\n----dp_rx why tcp_err ???\n");
+		rx_dbg(-1, skb, desc_0, desc_1, desc_2, desc_3, parser,
+		       pmac, paser_exist);
+		goto RX_DROP;
+	}
+#endif
+
+	if (port_id == PMAC_CPU_ID) { /*To CPU and need check src pmac port */
+		dp_port_prop[inst].info.update_port_vap(inst, &port_id, &vap,
+			skb,
+			pmac, &decryp);
+	} else {		/*GSWIP-R already know the destination */
+		rx_tx_flag = 1;
+		vap = GET_VAP(desc_0->field.dest_sub_if_id,
+			      dp_port_info[inst][port_id].vap_offset,
+			      dp_port_info[inst][port_id].vap_mask);
+	}
+	if (unlikely(!port_id)) { /*Normally shouldnot go to here */
+		rx_dbg_zero_port(skb, desc_0, desc_1, desc_2, desc_3, parser,
+				 pmac, paser_exist, ep, port_id, vap);
+		goto RX_DROP;
+	}
+	dp_port = &dp_port_info[inst][port_id];
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+	if (dp_port->f_ptp) {
+		ops = dp_port_prop[inst].mac_ops[port_id];
+		if (ops)
+			ops->do_rx_hwts(ops, skb);
+	}
+#endif
+	/*PON traffic always have timestamp attached,removing Timestamp */
+	if (dp_port->alloc_flags & (DP_F_GPON | DP_F_EPON)) {
+		/* Stripping of last 10 bytes timestamp */
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+		if (!dp_port->f_ptp)
+			__pskb_trim(skb, skb->len - DP_TS_HDRLEN);
+#else
+		__pskb_trim(skb, skb->len - DP_TS_HDRLEN);
+#endif
+	}
+
+	rx_fn = dp_port->cb.rx_fn;
+	if (likely(rx_fn && dp_port->status)) {
+		/*Clear some fields as SWAS V3.7 required */
+		//desc_1->all &= dma_rx_desc_mask1.all;
+		desc_3->all &= dma_rx_desc_mask3.all;
+		skb->priority = desc_1->field.classid;
+		skb->dev = dp_port->subif_info[vap].netif;
+		dev = dp_port->subif_info[vap].netif;
+		if (decryp) { /*workaround mark for bypass xfrm policy*/
+			desc_1->field.dec = 1;
+			desc_1->field.enc = 1;
+		}
+		if (!dev &&
+		    ((dp_port->alloc_flags & DP_F_FAST_DSL) == 0)) {
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+			goto RX_DROP;
+		}
+
+		if (unlikely(dp_dbg_flag)) {
+			DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "%s=%d vap=%d\n",
+				 (ep) ? "ep" : "port_id", port_id, vap);
+
+			if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DATA) {
+				dp_dump_raw_data(skb->data, PMAC_SIZE,
+						 "pmac to top drv");
+				dp_dump_raw_data(skb->data + PMAC_SIZE,
+						 ((skb->len - PMAC_SIZE) >
+							dp_print_len) ?
+							skb->len - PMAC_SIZE :
+							dp_print_len,
+						 "Data to top drv");
+			}
+			if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
+				dp_port_prop[inst].info.dump_rx_dma_desc(
+					desc_0, desc_1,
+					desc_2, desc_3);
+		}
+#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
+		if (unlikely(ltq_mpe_fasthook_rx_fn))
+			ltq_mpe_fasthook_rx_fn(skb, 1, NULL);	/*with pmac */
+#endif
+		if (unlikely((enum TEST_MODE)dp_rx_test_mode ==
+			DP_RX_MODE_LAN_WAN_BRIDGE)) {
+			/*for datapath performance test only */
+			dp_lan_wan_bridging(port_id, skb);
+			/*return DP_SUCCESS;*/
+		}
+		/*If switch h/w acceleration is enabled,setting of this bit
+		 *avoid forwarding duplicate packets from linux
+		 */
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
+			if (dp_port->subif_info[vap].fid > 0)
+				skb->offload_fwd_mark = 1;
+#endif
+		if (rx_tx_flag == 0) {
+			if (dp_port->lct_idx > 0)
+				ret_lct = dp_handle_lct(dp_port, skb, rx_fn);
+			if (ret_lct) {
+				if((STATS_GET(dp_port->subif_info[vap].
+								rx_flag) <= 0)) {
+					UP_STATS(dp_port->subif_info[vap].
+							mib.rx_fn_dropped);
+					goto RX_DROP2;
+				}
+				rx_fn(dev, NULL, skb, skb->len);
+				UP_STATS(dp_port->subif_info[vap].mib.
+								rx_fn_rxif_pkt);
+			}
+		} else {
+			if((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
+				UP_STATS(dp_port->subif_info[vap].mib.
+						rx_fn_dropped);
+				goto RX_DROP2;
+			}
+			rx_fn(NULL, dev, skb, skb->len);
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_txif_pkt);
+		}
+
+		return DP_SUCCESS;
+	}
+
+	if (unlikely(port_id >=
+	    dp_port_prop[inst].info.cap.max_num_dp_ports - 1)) {
+		PR_ERR("Drop for wrong ep or src port id=%u ??\n",
+		       port_id);
+		goto RX_DROP;
+	} else if (unlikely(dp_port->status == PORT_FREE)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Drop for port %u free\n",
+			 port_id);
+		goto RX_DROP;
+	} else if (unlikely(!rx_fn)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
+			 "Drop for subif of port %u not registered yet\n",
+			 port_id);
+		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+		goto RX_DROP2;
+	} else {
+		pr_info("Unknown issue\n");
+	}
+RX_DROP:
+	UP_STATS(dp_port->rx_err_drop);
+RX_DROP2:
+	if (skb)
+		dev_kfree_skb_any(skb);
+	return res;
+}
+
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_tx.c b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_tx.c
new file mode 100644
index 000000000000..8dfbec91b1bc
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip30/datapath_tx.c
@@ -0,0 +1,437 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/etherdevice.h>
+#include <net/datapath_api.h>
+#include "../datapath.h"
+#include "datapath_misc.h"
+#include "../datapath_instance.h"
+
+void dp_xmit_dbg(
+	char *title,
+	struct sk_buff *skb,
+	s32 ep,
+	s32 len,
+	u32 flags,
+	struct pmac_tx_hdr *pmac,
+	dp_subif_t *rx_subif,
+	int need_pmac,
+	int gso,
+	int checksum)
+{
+#ifdef DP_SKB_HACK
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+		 "%s: dp_xmit:skb->data/len=0x%p/%d data_ptr=%x from port=%d and subitf=%d\n",
+		 title,	skb->data, len,
+		 ((struct dma_tx_desc_2 *)&skb->DW2)->field.data_ptr,
+		 ep, rx_subif->subif);
+#endif
+	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DATA) {
+		if (pmac) {
+			dp_dump_raw_data((char *)pmac, PMAC_SIZE, "Tx Data");
+			dp_dump_raw_data(skb->data,
+					(skb->len > dp_print_len) ?
+					skb->len :
+					dp_print_len,
+					"Tx Data");
+		} else
+			dp_dump_raw_data(skb->data,
+					(skb->len > dp_print_len) ?
+					skb->len : dp_print_len,
+					"Tx Data");
+	}
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+		 "ip_summed=%s(%d) encapsulation=%s\n",
+		 dp_skb_csum_str(skb), skb->ip_summed,
+		 skb->encapsulation ? "Yes" : "No");
+	if (skb->encapsulation)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "inner ip start=0x%x(%d), transport=0x%x(%d)\n",
+			 (unsigned int)skb_inner_network_header(skb),
+			 (int)(skb_inner_network_header(skb) -
+			 skb->data),
+			 (unsigned int)
+			 skb_inner_transport_header(skb),
+			 (int)(skb_inner_transport_header(skb) -
+			 skb_inner_network_header(skb)));
+	else
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "ip start=0x%x(%d), transport=0x%x(%d)\n",
+			 (unsigned int)(unsigned int)
+			 skb_network_header(skb),
+			 (int)(skb_network_header(skb) - skb->data),
+			 (unsigned int)skb_transport_header(skb),
+			 (int)(skb_transport_header(skb) -
+			 skb_network_header(skb)));
+
+	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR)
+#ifdef DP_SKB_HACK
+		dp_port_prop[0].info.dump_tx_dma_desc(
+				(struct dma_tx_desc_0 *)&skb->DW0,
+				(struct dma_tx_desc_1 *)&skb->DW1,
+				(struct dma_tx_desc_2 *)&skb->DW2,
+				(struct dma_tx_desc_3 *)&skb->DW3);
+#endif
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "flags=0x%x skb->len=%d\n",
+		 flags, skb->len);
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+		 "skb->data=0x%p with pmac hdr size=%u\n", skb->data,
+		 sizeof(struct pmac_tx_hdr));
+	if (need_pmac) { /*insert one pmac header */
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "need pmac\n");
+		if (pmac && (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR))
+			dp_port_prop[0].info.dump_tx_pmac(pmac);
+	} else {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "no pmac\n");
+	}
+	if (gso)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "GSO pkt\n");
+	else
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "Non-GSO pkt\n");
+	if (checksum)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "Need checksum offload\n");
+	else
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "No need checksum offload pkt\n");
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "\n\n");
+}
+
+int32_t dp_xmit_30(struct net_device *rx_if, dp_subif_t *rx_subif,
+		   struct sk_buff *skb, int32_t len, uint32_t flags)
+{
+		struct dma_tx_desc_0 *desc_0;
+		struct dma_tx_desc_1 *desc_1;
+		struct dma_tx_desc_2 *desc_2;
+		struct dma_tx_desc_3 *desc_3;
+		struct pmac_port_info *dp_info = NULL;
+		struct pmac_tx_hdr pmac = {0};
+		u32 ip_offset, tcp_h_offset, tcp_type;
+		char tx_chksum_flag = 0; /*check csum cal can be supported or not */
+		char insert_pmac_f = 1; /*flag to insert one pmac */
+		int res = DP_SUCCESS;
+		int ep, vap;
+		enum dp_xmit_errors err_ret = 0;
+		int inst = 0;
+		struct cbm_tx_data data;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+		struct mac_ops *ops;
+		int rec_id = 0;
+#endif
+	
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+		if (unlikely(!dp_init_ok)) {
+			err_ret = DP_XMIT_ERR_NOT_INIT;
+			goto lbl_err_ret;
+		}
+		if (unlikely(!rx_subif)) {
+			err_ret = DP_XMIT_ERR_NULL_SUBIF;
+			goto lbl_err_ret;
+		}
+		if (unlikely(!skb)) {
+			err_ret = DP_XMIT_ERR_NULL_SKB;
+			goto lbl_err_ret;
+		}
+#endif
+		ep = rx_subif->port_id;
+		if (unlikely(ep >= dp_port_prop[inst].info.cap.max_num_dp_ports)) {
+			err_ret = DP_XMIT_ERR_PORT_TOO_BIG;
+			goto lbl_err_ret;
+		}
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+		if (unlikely(in_irq())) {
+			err_ret = DP_XMIT_ERR_IN_IRQ;
+			goto lbl_err_ret;
+		}
+#endif
+		dp_info = &dp_port_info[inst][ep];
+		vap = GET_VAP(rx_subif->subif, dp_info->vap_offset, dp_info->vap_mask);
+		if (unlikely(!rx_if && /*For atm pppoa case, rx_if is NULL now */
+			     !(dp_info->alloc_flags & DP_F_FAST_DSL))) {
+			err_ret = DP_XMIT_ERR_NULL_IF;
+			goto lbl_err_ret;
+		}
+#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
+		if (unlikely(ltq_mpe_fasthook_tx_fn))
+			ltq_mpe_fasthook_tx_fn(skb, 0, NULL);
+#endif
+		if (unlikely(dp_dbg_flag))
+			dp_xmit_dbg("\nOrig", skb, ep, len, flags,
+				    NULL, rx_subif, 0, 0, flags & DP_TX_CAL_CHKSUM);
+	
+		/*No PMAC for WAVE500 and DSL by default except bonding case */
+		if (unlikely(NO_NEED_PMAC(dp_info->alloc_flags)))
+			insert_pmac_f = 0;
+	
+		/**********************************************
+		 *Must put these 4 lines after INSERT_PMAC
+		 *since INSERT_PMAC will change skb if needed
+		 *********************************************/
+#ifdef DP_SKB_HACK
+		desc_0 = (struct dma_tx_desc_0 *)&skb->DW0;
+		desc_1 = (struct dma_tx_desc_1 *)&skb->DW1;
+		desc_2 = (struct dma_tx_desc_2 *)&skb->DW2;
+		desc_3 = (struct dma_tx_desc_3 *)&skb->DW3;
+#endif
+		if (flags & DP_TX_CAL_CHKSUM) {
+			int ret_flg;
+	
+			if (!dp_port_prop[inst].info.check_csum_cap()) {
+				err_ret = DP_XMIT_ERR_CSM_NO_SUPPORT;
+				goto lbl_err_ret;
+			}
+			ret_flg = get_offset_clear_chksum(skb, &ip_offset,
+							  &tcp_h_offset, &tcp_type);
+			if (likely(ret_flg == 0))
+				/*HW can support checksum offload*/
+				tx_chksum_flag = 1;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+			else if (ret_flg == -1)
+				pr_info_once("packet can't do hw checksum\n");
+#endif
+		}
+	
+		/*reset all descriptors as SWAS required since SWAS 3.7 */
+		/*As new SWAS 3.7 required, MPE1/Color/FlowID is set by applications */
+		desc_0->all &= dma_tx_desc_mask0.all;
+		desc_1->all &= dma_tx_desc_mask1.all;
+		/*desc_2->all = 0;*/ /*remove since later it will be set properly */
+		if (desc_3->field.dic) {
+			desc_3->all = 0; /*keep DIC bit to support test tool*/
+			desc_3->field.dic = 1;
+		} else {
+			desc_3->all = 0;
+		}
+	
+		if (flags & DP_TX_OAM) /* OAM */
+			desc_3->field.pdu_type = 1;
+		desc_1->field.classid = (skb->priority >= 15) ? 15 : skb->priority;
+		desc_2->field.data_ptr = (uint32_t)skb->data;
+	
+		/*for ETH LAN/WAN */
+		if (dp_info->alloc_flags & (DP_F_FAST_ETH_LAN | DP_F_FAST_ETH_WAN |
+		    DP_F_GPON | DP_F_EPON)) {
+			/*always with pmac*/
+			if (likely(tx_chksum_flag)) {
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else {
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			}
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588_SW_WORKAROUND)
+			if (dp_info->f_ptp)
+#else
+			if (dp_info->f_ptp &&
+			    (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP))
+#endif
+		{
+			ops = dp_port_prop[inst].mac_ops[dp_info->port_id];
+				if (!ops) {
+					err_ret = DP_XMIT_PTP_ERR;
+					goto lbl_err_ret;
+				}
+				rec_id = ops->do_tx_hwts(ops, skb);
+				if (rec_id < 0) {
+					err_ret = DP_XMIT_PTP_ERR;
+					goto lbl_err_ret;
+				}
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_PTP, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				pmac.record_id_msb = rec_id;
+			}
+#endif
+		} else if (dp_info->alloc_flags & DP_F_FAST_DSL) { /*some with pmac*/
+			if (unlikely(flags & DP_TX_CAL_CHKSUM)) { /* w/ pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+				if (aca_portid > 0)
+					desc_1->field.ep = aca_portid;
+#endif
+			} else if (flags & DP_TX_DSL_FCS) {/* after checksum check */
+				/* w/ pmac for FCS purpose*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_OTHERS, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+				insert_pmac_f = 1;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+				if (aca_portid > 0)
+					desc_1->field.ep = aca_portid;
+#endif
+			} else { /*no pmac */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, NULL,
+								desc_0, desc_1,
+								dp_info);
+			}
+		} else if (dp_info->alloc_flags & DP_F_FAST_WLAN) {/*some with pmac*/
+			/*normally no pmac. But if need checksum, need pmac*/
+			if (unlikely(tx_chksum_flag)) { /*with pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+				if (aca_portid > 0)
+					desc_1->field.ep = aca_portid;
+#endif
+			} else { /*no pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, NULL,
+								desc_0, desc_1,
+								dp_info);
+			}
+		} else if (dp_info->alloc_flags & DP_F_DIRECTLINK) { /*always w/ pmac*/
+			if (unlikely(flags & DP_TX_CAL_CHKSUM)) { /* w/ pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else if (flags & DP_TX_TO_DL_MPEFW) { /*w/ pmac*/
+				/*copy from checksum's pmac template setting,
+				 *but need to reset tcp_chksum in TCP header
+				 */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_OTHERS, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else { /*do like normal directpath with pmac */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			}
+		} else { /*normal directpath: always w/ pmac */
+			if (unlikely(tx_chksum_flag)) {
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM,
+								&pmac,
+								desc_0,
+								desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else { /*w/ pmac */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			}
+		}
+		desc_3->field.data_len = skb->len;
+	
+		if (unlikely(dp_dbg_flag)) {
+			if (insert_pmac_f)
+				dp_xmit_dbg("After", skb, ep, len, flags, &pmac,
+					    rx_subif, insert_pmac_f, skb_is_gso(skb),
+					    tx_chksum_flag);
+			else
+				dp_xmit_dbg("After", skb, ep, len, flags, NULL,
+					    rx_subif, insert_pmac_f, skb_is_gso(skb),
+					    tx_chksum_flag);
+		}
+	
+#if IS_ENABLED(CONFIG_LTQ_TOE_DRIVER)
+		if (skb_is_gso(skb)) {
+			res = ltq_tso_xmit(skb, &pmac, sizeof(pmac), 0);
+			UP_STATS(dp_info->subif_info[vap].mib.tx_tso_pkt);
+			return res;
+		}
+#endif /* CONFIG_LTQ_TOE_DRIVER */
+	
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+		if (unlikely(!desc_1->field.ep)) {
+			err_ret = DP_XMIT_ERR_EP_ZERO;
+			goto lbl_err_ret;
+		}
+#endif
+		if (insert_pmac_f) {
+			data.pmac = (u8 *)&pmac;
+			data.pmac_len = sizeof(pmac);
+			data.dp_inst = inst;
+			data.dp_inst = 0;
+		} else {
+			data.pmac = NULL;
+			data.pmac_len = 0;
+			data.dp_inst = inst;
+			data.dp_inst = 0;
+		}
+		res = cbm_cpu_pkt_tx(skb, &data, 0);
+		UP_STATS(dp_info->subif_info[vap].mib.tx_cbm_pkt);
+		return res;
+	
+	lbl_err_ret:
+		switch (err_ret) {
+		case DP_XMIT_ERR_NOT_INIT:
+			PR_RATELIMITED("dp_xmit failed for dp no init yet\n");
+			break;
+		case DP_XMIT_ERR_IN_IRQ:
+			PR_RATELIMITED("dp_xmit not allowed in interrupt context\n");
+			break;
+		case DP_XMIT_ERR_NULL_SUBIF:
+			PR_RATELIMITED("dp_xmit failed for rx_subif null\n");
+			UP_STATS(PORT_INFO(inst, 0, tx_err_drop));
+			break;
+		case DP_XMIT_ERR_PORT_TOO_BIG:
+			UP_STATS(PORT_INFO(inst, 0, tx_err_drop));
+			PR_RATELIMITED("rx_subif->port_id >= max_ports");
+			break;
+		case DP_XMIT_ERR_NULL_SKB:
+			PR_RATELIMITED("skb NULL");
+			UP_STATS(PORT_INFO(inst, rx_subif->port_id, tx_err_drop));
+			break;
+		case DP_XMIT_ERR_NULL_IF:
+			UP_STATS(PORT_VAP_MIB(inst, ep, vap, tx_pkt_dropped));
+			PR_RATELIMITED("rx_if NULL");
+			break;
+		case DP_XMIT_ERR_REALLOC_SKB:
+			PR_INFO_ONCE("dp_create_new_skb failed\n");
+			break;
+		case DP_XMIT_ERR_EP_ZERO:
+			PR_ERR("Why ep zero in dp_xmit for %s\n",
+			       skb->dev ? skb->dev->name : "NULL");
+			break;
+		case DP_XMIT_ERR_GSO_NOHEADROOM:
+			PR_ERR("No enough skb headerroom(GSO). Need tune SKB buffer\n");
+			break;
+		case DP_XMIT_ERR_CSM_NO_SUPPORT:
+			PR_RATELIMITED("dp_xmit not support checksum\n");
+			break;
+		case DP_XMIT_PTP_ERR:
+			break;
+		default:
+			UP_STATS(dp_info->subif_info[vap].mib.tx_pkt_dropped);
+			PR_INFO_ONCE("Why come to here:%x\n",
+				     dp_port_info[inst][ep].status);
+		}
+		if (skb)
+			dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+
+}
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/Kconfig b/drivers/net/ethernet/lantiq/datapath/gswip31/Kconfig
index 4695da0b9ee6..bac97977d6e3 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/Kconfig
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/Kconfig
@@ -1,15 +1,15 @@
-menuconfig LTQ_DATAPATH_HAL_GSWIP31
+menuconfig INTEL_DATAPATH_HAL_GSWIP31
 	bool "Datapath HAL_GSWIP31"
 	default y
-	depends on LTQ_DATAPATH && PRX300_CQM
+	depends on INTEL_DATAPATH && PRX300_CQM
 	---help---
 	  Datapath Lib is to provide common rx/tx wrapper Lib without taking
 	  care of much HW knowledge and also provide common interface for legacy
 	  devices and different HW like to CBM or LRO.
 	  Take note: All devices need to register to datapath Lib first
 
-if LTQ_DATAPATH_HAL_GSWIP31
-config LTQ_DATAPATH_HAL_GSWIP31_MIB
+if INTEL_DATAPATH_HAL_GSWIP31
+config INTEL_DATAPATH_HAL_GSWIP31_MIB
 	bool "Datapath aggregated mib support"
 	depends on LTQ_DATAPATH_HAL_GSWIP30 && SOC_GRX500 && LTQ_TMU && LTQ_PPA_TMU_MIB_SUPPORT
 	default y
@@ -35,7 +35,7 @@ config LTQ_DATAPATH_DUMMY_QOS_VIA_PRX300_TEST
 	default y
 	depends on (LTQ_PPV4_QOS || LTQ_PPV4) && !LTQ_PPV4_QOS_SLIM && LTQ_DATAPATH_DUMMY_QOS
 
-config LTQ_DATAPATH_QOS_HAL
+config INTEL_DATAPATH_QOS_HAL
 	bool "datapath QOS hal"
 	default n
 	depends on (LTQ_PPV4_QOS || LTQ_PPV4) && !LTQ_DATAPATH_DUMMY_QOS_VIA_PRX300_TEST
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/Makefile b/drivers/net/ethernet/lantiq/datapath/gswip31/Makefile
index 3941e417722c..7f9984bf35c9 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/Makefile
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/Makefile
@@ -1,19 +1,20 @@
-ifneq ($(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31),)
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_gswip_simulate.o
+ifneq ($(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31),)
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_gswip_simulate.o
 endif
 
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_misc.o datapath_gswip.o datapath_proc.o
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_ppv4.o
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_lookup_proc.o datapath_ppv4_api.o
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_misc.o datapath_gswip.o datapath_proc.o
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_ppv4.o
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_lookup_proc.o datapath_ppv4_api.o
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_rx.o datapath_tx.o 
 
-ifneq ($(CONFIG_LTQ_DATAPATH_HAL_GSWIP31_MIB),)
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_mib.o
+ifneq ($(CONFIG_INTEL_DATAPATH_HAL_GSWIP31_MIB),)
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_mib.o
 endif
 
-ifneq ($(CONFIG_LTQ_DATAPATH_CPUFREQ),)
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_coc.o
+ifneq ($(CONFIG_INTEL_DATAPATH_CPUFREQ),)
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_coc.o
 endif
 
-ifneq ($(CONFIG_LTQ_DATAPATH_SWITCHDEV),)
-obj-$(CONFIG_LTQ_DATAPATH) += datapath_switchdev.o datapath_ext_vlan.o datapath_tc_asym_vlan.o
+ifneq ($(CONFIG_INTEL_DATAPATH_SWITCHDEV),)
+obj-$(CONFIG_INTEL_DATAPATH) += datapath_switchdev.o datapath_ext_vlan.o datapath_tc_asym_vlan.o
 endif
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_coc.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_coc.c
index f37f65413987..ace300199a9b 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_coc.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_coc.c
@@ -91,7 +91,7 @@ struct ltq_cpufreq_module_info dp_coc_feature_fss = {
 	.ltq_cpufreq_pwr_feature_switch = dp_coc_fss_ena,
 };
 
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 static char *get_sub_module_str(uint32_t flag)
 {
 	if (flag == DP_COC_REQ_DP)
@@ -146,6 +146,7 @@ int update_coc_rmon_timer(enum ltq_cpufreq_state new_state, uint32_t flag)
 
 static int update_coc_cfg(enum ltq_cpufreq_state new_state,
 			  enum ltq_cpufreq_state old_state, uint32_t flag)
+{
 	return 0;
 }
 
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip.c
index a93371f40e0a..249ffc7e9afa 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip.c
@@ -10,11 +10,10 @@
 #include <linux/kernel.h>
 #include <linux/types.h>
 #include <linux/etherdevice.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include "../datapath.h"
 #include "datapath_misc.h"
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31)
 #include "datapath_gswip_simulate.h"
 #endif
 
@@ -91,7 +90,7 @@ static char *ctp_mode_string(GSW_LogicalPortMode_t type)
 	return "Undef";
 }
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31)
 GSW_return_t gsw_core_api_ddr_simu31(dp_gsw_cb func, void *ops, void *param)
 {
 	if (func == (dp_gsw_cb)dp_port_prop[0].ops[0]->
@@ -394,7 +393,7 @@ int dp_pmac_set_31(int inst, u32 port, dp_pmac_cfg_t *pmac_cfg)
 
 			if (pmac_cfg->eg_pmac_flags & EG_PMAC_F_MPE2FLG)
 				egcfg.bMpe2Flag = pmac_cfg->eg_pmac.mpe2_flag;
-#if defined(CONFIG_LTQ_DATAPATH_DBG) && CONFIG_LTQ_DATAPATH_DBG
+#if defined(CONFIG_INTEL_DATAPATH_DBG) && CONFIG_INTEL_DATAPATH_DBG
 			if (dp_dbg_flag) {
 				DP_DEBUG(DP_DBG_FLAG_DBG,
 					 "\nPMAC %d egcfg configuration:\n",
@@ -643,13 +642,13 @@ struct gsw_itf *ctp_port_assign(int inst, u8 ep, int bp_default,
 	dp_port_info[inst][ep].ctp_max = ctp_assign.nNumberOfCtpPort;
 	dp_port_info[inst][ep].vap_offset = assign->vap_offset;
 	dp_port_info[inst][ep].vap_mask = assign->vap_mask;
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	dp_port_info[inst][ep].swdev_en = assign->swdev_enable;
 #endif
 	return &itf_assign[ep];
 }
 
-int set_port_lookup_mode(int inst, u8 ep, u32 flags)
+int set_port_lookup_mode_31(int inst, u8 ep, u32 flags)
 {
 	int i, alloc_flag;	
 	struct ctp_assign *assign = &ctp_assign_def;
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip_simulate.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip_simulate.c
index 42f14318ee73..2195b295426a 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip_simulate.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_gswip_simulate.c
@@ -10,7 +10,6 @@
 #include <linux/kernel.h>
 #include <linux/types.h>
 #include <linux/etherdevice.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include "../datapath.h"
 #include "datapath_misc.h"
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_lookup_proc.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_lookup_proc.c
index 924896f2e685..26863e2b34d1 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_lookup_proc.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_lookup_proc.c
@@ -27,12 +27,10 @@
 
 #include <lantiq.h>
 #include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #define DATAPATH_HAL_LAYER   /*must put before include datapath_api.h in
 			      *order to avoid include another platform's
 			      *DMA descriptor and pmac header files
 			      */
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include <net/datapath_api_gswip31.h>
 #include "../datapath.h"
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_mib.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_mib.c
index b0622c6eca3f..7b3632ce2f15 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_mib.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_mib.c
@@ -23,11 +23,9 @@
 #include <linux/clk.h>
 
 #include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include <net/datapath_proc_api.h>
 #include "../datapath.h"
-#include <net/lantiq_cbm_api.h>
 
 #define WRAPAROUND32   0xFFFFFFFF
 /*timer interval for mib wraparound handling:
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.c
index 73f5443f3f8d..53c509b36fec 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.c
@@ -27,12 +27,10 @@
 
 #include <lantiq.h>
 #include <lantiq_soc.h>
-#include <net/lantiq_cbm_api.h>
 #define DATAPATH_HAL_LAYER   /*must put before include datapath_api.h in
 			      *order to avoid include another platform's
 			      *DMA descriptor and pmac header files
 			      */
-#include <net/lantiq_cbm_api.h>
 #include <net/datapath_api.h>
 #include <net/datapath_api_gswip31.h>
 #include "../datapath.h"
@@ -41,7 +39,7 @@
 #include "datapath_ppv4.h"
 #include "datapath_misc.h"
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 #include "datapath_switchdev.h"
 #endif
 
@@ -75,7 +73,7 @@ static void init_dma_desc_mask(void)
 static void init_dma_pmac_template(int portid, u32 flags)
 {
 	int i;
-	struct pmac_port_info2 *dp_info = &dp_port_info2[0][portid];
+	struct pmac_port_info *dp_info = &dp_port_info[0][portid];
 
 	/*Note:
 	 * final tx_dma0 = (tx_dma0 & dma0_mask_template) | dma0_template
@@ -99,7 +97,7 @@ static void init_dma_pmac_template(int portid, u32 flags)
 			dp_info->dma0_template[i].field.redir = 1;
 			dp_info->dma0_mask_template[i].field.redir = 0;
 		}
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
 		dp_info->pmac_template[TEMPL_PTP].ptp = 1;
 #endif
 	} else if (flags & DP_F_DIRECTLINK) { /*always with pmac*/
@@ -434,7 +432,7 @@ static void dump_tx_pmac(struct pmac_tx_hdr *pmac)
 
 static void mib_init(u32 flag)
 {
-#ifdef CONFIG_LTQ_DATAPATH_MIB
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MIB)
 	dp_mib_init(0);
 #endif
 	gsw_mib_reset_31(0, 0); /* GSW O */
@@ -442,7 +440,7 @@ static void mib_init(u32 flag)
 
 void dp_sys_mib_reset_31(u32 flag)
 {
-#ifdef CONFIG_LTQ_DATAPATH_MIB
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_MIB)
 	dp_reset_sys_mib(0);
 #else
 	gsw_mib_reset_31(0, 0); /* GSW L */
@@ -451,7 +449,7 @@ void dp_sys_mib_reset_31(u32 flag)
 #endif
 }
 
-#ifndef CONFIG_LTQ_DATAPATH_QOS_HAL
+#ifndef CONFIG_INTEL_DATAPATH_QOS_HAL
 int alloc_q_to_port(struct ppv4_q_sch_port *info, u32 flag)
 {
 	struct ppv4_queue q;
@@ -487,7 +485,7 @@ int alloc_q_to_port(struct ppv4_q_sch_port *info, u32 flag)
 	q.qid = -1;
 	q.parent = port.node_id;
 	q.inst = inst;
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS)
 	q.dq_port = info->cqe_deq; /*for qos slim driver only */
 #endif
 	if (dp_pp_alloc_queue(&q)) {
@@ -533,8 +531,7 @@ int alloc_q_to_port(struct ppv4_q_sch_port *info, u32 flag)
 		 link.p_node_id.cqm_deq_port, info->cqe_deq);
 	return 0;
 }
-#endif /*CONFIG_LTQ_DATAPATH_QOS_HAL*/
-
+#endif /*CONFIG_INTEL_DATAPATH_QOS_HAL*/
 #define PRIO0	0
 #define PRIO1	1
 #define PRIO2	2
@@ -1111,7 +1108,7 @@ int dp_platform_queue_set(int inst, u32 flag)
 	/*Alloc queue/scheduler/port per CPU port */
 	cpu_data.dp_inst = inst;
 	cpu_data.cbm_inst = dp_port_prop[inst].cbm_inst;
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31)
 	cpu_data.dq_tx_push_info[0].deq_port = 0;
 	cpu_data.dq_tx_push_info[1].deq_port = -1;
 	cpu_data.dq_tx_push_info[2].deq_port = -1;
@@ -1243,7 +1240,7 @@ static int dp_platform_set(int inst, u32 flag)
 		if (!inst) /*only inst zero will support mib feature */
 			mib_init(0);
 		dp_get_gsw_parser_31(NULL, NULL, NULL, NULL);
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 	if (!inst)
 		dp_coc_cpufreq_init();
 #endif
@@ -1382,7 +1379,7 @@ static int port_platform_set(int inst, u8 ep, struct dp_port_data *data,
 		PR_ERR("priv is NULL\n");
 		return DP_FAILURE;
 	}
-	set_port_lookup_mode(inst, ep, flags);
+	set_port_lookup_mode_31(inst, ep, flags);
 	if (flags & DP_F_DEREGISTER) {
 		dp_node_reserve(inst, ep, NULL, flags);
 		return 0;
@@ -1429,7 +1426,7 @@ static int port_platform_set(int inst, u8 ep, struct dp_port_data *data,
 
 	dp_node_reserve(inst, ep, data, flags);
 	dp_port_spl_cfg(inst, ep, data, flags);
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	if (DP_DBG_FLAG_QOS & dp_dbg_flag) {
 		for (i = 0; i < port_info->deq_port_num; i++) {
 			PR_INFO("cqm[%d]: addr=%x credit=%d size==%d\n",
@@ -1506,10 +1503,10 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 		CBM_QUEUE_MAP_F_MPE2_DONTCARE |
 		CBM_QUEUE_MAP_F_TC_DONTCARE;
 	int subif, deq_port_idx = 0, bp = -1;
+	int dma_ch_offset = 0;
 	struct pmac_port_info *port_info;
 	struct hal_priv *priv = HAL(inst);
 	int q_flag = 0;
-	int dma_ch_offset = 0;
 
 	if (!data || !data->subif_data) {
 		PR_ERR("data NULL or subif_data NULL\n");
@@ -1581,7 +1578,7 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 		PR_ERR("priv NULL\n");
 		return -1;
 	}
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	if (unlikely(dp_dbg_flag & DP_DBG_FLAG_QOS)) {
 		DP_DEBUG(DP_DBG_FLAG_QOS, "cqe_deq=%d\n", q_port.cqe_deq);
 		DP_DEBUG(DP_DBG_FLAG_QOS, "priv=%p deq_port_stat=%p qdev=%p\n",
@@ -1602,6 +1599,7 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 	q_port.dp_port = portid;
 	q_port.ctp = subif_ix;
 
+	dma_ch_offset = dp_deq_port_tbl[inst][q_port.cqe_deq].dma_ch_offset;
 	if (data->subif_data->flag_ops & DP_SUBIF_SPECIFIC_Q) {
 		q_flag = DP_SUBIF_SPECIFIC_Q;
 	} else if (data->subif_data->flag_ops & DP_SUBIF_AUTO_NEW_Q) {
@@ -1610,8 +1608,6 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 		if (!dp_deq_port_tbl[inst][q_port.cqe_deq].f_first_qid)
 			q_flag = DP_SUBIF_AUTO_NEW_Q; /*no queue created yet*/
 	}
-
-	dma_ch_offset = dp_deq_port_tbl[inst][q_port.cqe_deq].dma_ch_offset;
 	DP_DEBUG(DP_DBG_FLAG_QOS, "Queue decision:%s\n", q_flag_str(q_flag));
 	if (q_flag == DP_SUBIF_AUTO_NEW_Q) {
 		int cqe_deq;
@@ -1646,7 +1642,6 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 		if (port_info->num_dma_chan)
 			atomic_inc(&(dp_dma_chan_tbl[inst] +
 				   dma_ch_offset)->ref_cnt);
-
 		dp_deq_port_tbl[inst][cqe_deq].qos_port = q_port.port_node;
 		if (!dp_deq_port_tbl[inst][cqe_deq].f_first_qid) {
 			dp_deq_port_tbl[inst][cqe_deq].first_qid = q_port.qid;
@@ -1719,7 +1714,7 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 				   dma_ch_offset)->ref_cnt);
 	}
 	DP_DEBUG(DP_DBG_FLAG_QOS,
-		 "%s:%s=%d %s=%d q[%d].cnt=%d cqm_p[%d].cnt=%d DMATXCH_Ref.cnt=%d\n",
+		 "%s:%s=%d %s=%d q[%d].cnt=%d cqm_p[%d].cnt=%d tx_dma_chan: (ref=%d)\n",
 		 "subif_hw_set",
 		 "dp_port", portid,
 		 "vap", subif_ix,
@@ -1727,7 +1722,7 @@ static int subif_hw_set(int inst, int portid, int subif_ix,
 		 q_port.cqe_deq, dp_deq_port_tbl[inst][q_port.cqe_deq].ref_cnt,
 		 atomic_read(&(dp_dma_chan_tbl[inst] +
 			     dma_ch_offset)->ref_cnt));
-#ifdef CONFIG_LTQ_DATAPATH_QOS_HAL
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_QOS_HAL)
 	if (dp_deq_port_tbl[inst][q_port.cqe_deq].ref_cnt == 1) /*first CTP*/
 		data->act = TRIGGER_CQE_DP_ENABLE;
 #else
@@ -1781,6 +1776,7 @@ static int subif_hw_reset(int inst, int portid, int subif_ix,
 
 	qid = port_info->subif_info[subif_ix].qid;
 	cqm_deq_port = port_info->subif_info[subif_ix].cqm_deq_port;
+	dma_ch_offset = dp_deq_port_tbl[inst][cqm_deq_port].dma_ch_offset;
 	bp = port_info->subif_info[subif_ix].bp;
 
 	if (!dp_dma_chan_tbl[inst]) {
@@ -1804,9 +1800,7 @@ static int subif_hw_reset(int inst, int portid, int subif_ix,
 		       inst, bp, dp_bp_dev_tbl[inst][bp].ref_cnt);
 		return DP_FAILURE;
 	}
-	dma_ch_offset = dp_deq_port_tbl[inst][cqm_deq_port].dma_ch_offset;
-
-	/* update queue/port/sched/bp_pmapper/dma_tx_ch table's ref_cnt */
+	/* update queue/port/sched/bp_pmapper table's ref_cnt */
 	dp_q_tbl[inst][qid].ref_cnt--;
 	dp_deq_port_tbl[inst][cqm_deq_port].ref_cnt--;
 	if (port_info->num_dma_chan)
@@ -1829,7 +1823,7 @@ static int subif_hw_reset(int inst, int portid, int subif_ix,
 			 bp, subif_ix);
 		free_bridge_port(inst, bp);
 	}
-#ifdef CONFIG_LTQ_DATAPATH_QOS_HAL
+#ifdef CONFIG_INTEL_DATAPATH_QOS_HAL
 	qid = port_info->subif_info[subif_ix].qid;
 	cqm_deq_port = dp_q_tbl[inst][qid].cqm_dequeue_port;
 
@@ -1861,7 +1855,7 @@ static int subif_hw_reset(int inst, int portid, int subif_ix,
 		DP_DEBUG(DP_DBG_FLAG_QOS, "q_id[%d] dont need freed\n", qid);
 	}
 	DP_DEBUG(DP_DBG_FLAG_QOS,
-		 "%s:%s=%d %s=%d q[%d].cnt=%d cqm_p[%d].cnt=%d DMATXCH_Ref_cnt=%d\n",
+		 "%s:%s=%d %s=%d q[%d].cnt=%d cqm_p[%d].cnt=%d tx_dma_chan: (ref=%d)\n",
 		 "subif_hw_reset",
 		 "dp_port", portid,
 		 "vap", subif_ix,
@@ -1876,7 +1870,7 @@ static int subif_hw_reset(int inst, int portid, int subif_ix,
 			port_info->subif_info[subif_ix].qos_deq_port);
 	priv->deq_port_stat[port_info->subif_info[subif_ix].cqm_deq_port].flag =
 		PP_NODE_FREE;
-#endif /* CONFIG_LTQ_DATAPATH_QOS_HAL */
+#endif /* CONFIG_INTEL_DATAPATH_QOS_HAL */
 
 	if (!port_info->num_subif &&
 	    dp_deq_port_tbl[inst][cqm_deq_port].ref_cnt) {
@@ -1978,7 +1972,9 @@ static void update_port_vap(int inst, u32 *ep, int *vap,
 			    struct pmac_rx_hdr *pmac, char *decryp)
 {
 	//*ep = pmac->igp_egp; /*get the port_id from pmac's sppid */
+#ifdef DP_SKB_HACK
 	*ep = (skb->DW1 >> 4) & 0xF; /*get the port_id from pmac's sppid */
+#endif
 	if (dp_port_info[inst][*ep].alloc_flags & DP_F_LOOPBACK) {
 		/*get the real source port from VAP for ipsec */
 		/* related tunnel decap case */
@@ -1990,8 +1986,12 @@ static void update_port_vap(int inst, u32 *ep, int *vap,
 		*decryp = 1;
 	} else {
 		struct dma_rx_desc_1 *desc_1;
-
+#ifdef DP_SKB_HACK
 		desc_1 = (struct dma_rx_desc_1 *)&skb->DW1;
+#else
+	//error "Please add proper logic here"
+	return;
+#endif
 		*vap = desc_1->field.session_id;
 	}
 }
@@ -1999,7 +1999,7 @@ static void update_port_vap(int inst, u32 *ep, int *vap,
 static void get_dma_pmac_templ(int index, struct pmac_tx_hdr *pmac,
 			       struct dma_tx_desc_0 *desc_0,
 			       struct dma_tx_desc_1 *desc_1,
-			       struct pmac_port_info2 *dp_info)
+			       struct pmac_port_info *dp_info)
 {
 	if (likely(pmac))
 		memcpy(pmac, &dp_info->pmac_template[index], sizeof(*pmac));
@@ -2064,12 +2064,14 @@ int register_dp_cap_gswip31(int flag)
 	cap.info.dp_meter_alloc = dp_meter_alloc_31;
 	cap.info.dp_meter_add = dp_meter_add_31;
 	cap.info.dp_meter_del = dp_meter_del_31;
-#ifdef CONFIG_LTQ_DATAPATH_HAL_GSWIP31_MIB
+	cap.info.dp_rx = dp_rx_31;
+	cap.info.dp_tx = dp_xmit_31;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_HAL_GSWIP31_MIB)
 	cap.info.dp_get_port_vap_mib = dp_get_port_vap_mib_31;
 	cap.info.dp_clear_netif_mib = dp_clear_netif_mib_31;
 #endif
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	cap.info.swdev_flag = 1;
 	cap.info.swdev_alloc_bridge_id = dp_swdev_alloc_bridge_id;
 	cap.info.swdev_free_brcfg = dp_swdev_free_brcfg;
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.h b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.h
index e1a2e6c455e9..f37edc8d7759 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.h
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_misc.h
@@ -129,7 +129,7 @@ int proc_print_ctp_bp_info(struct seq_file *s, int inst,
 			   struct pmac_port_info *port,
 			   int subif_index, u32 flag);
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 int dp_gswip_mac_entry_add(int bport, int fid, int inst, u8 *addr);
 int dp_gswip_mac_entry_del(int bport, int fid, int inst, u8 *addr);
 int set_gswip_ext_vlan(struct core_ops *ops, struct ext_vlan_info *vlan,
@@ -172,15 +172,21 @@ int dp_meter_del_31(struct net_device *dev,
 		    struct dp_meter_cfg *meter,
 		    int flag, struct dp_meter_subif *mtr_subif);
 int dp_qos_global_info_get_31(struct dp_qos_cfg_info *info, int flag);
-
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31)
+int32_t dp_rx_31(struct sk_buff *skb, u32 flags);
+int32_t dp_xmit_31(struct net_device *rx_if, dp_subif_t *rx_subif,
+		struct sk_buff *skb, int32_t len, uint32_t flags);
+void set_chksum(struct pmac_tx_hdr *pmac, u32 tcp_type,
+		       u32 ip_offset, int ip_off_hw_adjust,
+		       u32 tcp_h_offset);
+
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31)
 GSW_return_t gsw_core_api_ddr_simu31(dp_gsw_cb func, void *ops, void *param);
 #define GSW_SIMUTE_DDR_NOT_MATCH  0x1234
 #endif
 
 static inline GSW_return_t gsw_core_api(dp_gsw_cb func, void *ops, void *param)
 {
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31)
 	{
 		GSW_return_t res;
 
@@ -188,7 +194,7 @@ static inline GSW_return_t gsw_core_api(dp_gsw_cb func, void *ops, void *param)
 		if (res != GSW_SIMUTE_DDR_NOT_MATCH)
 			return res;
 	}
-#endif /*CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31*/
+#endif /*CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31*/
 	if (!func)
 		return DP_FAILURE;
 	return func(ops, param);
@@ -224,7 +230,7 @@ int get_p_mib(int inst, int pid,
 	      u32 *green /* bytes*/,
 	      u32 *yellow /*bytes*/);
 int cpu_vlan_mod_dis(int inst);
-int set_port_lookup_mode(int inst, u8 ep, u32 flags);
+int set_port_lookup_mode_31(int inst, u8 ep, u32 flags);
 int tc_vlan_set_31(struct core_ops *ops, struct dp_tc_vlan *vlan,
 		   struct dp_tc_vlan_info *info,
 		   int flag);
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.c
index 14690cc8938b..e8196bec3c06 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.c
@@ -49,7 +49,7 @@ struct pp_qos_dev *(*qos_dev_open)(unsigned int id);
 int (*qos_dev_init)(struct pp_qos_dev *qos_dev,
 		    struct pp_qos_init_param *conf);
 
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS)
 struct fixed_q_port {
 	int deq_port; /*cqm dequeue port */
 	int queue_id; /*queue physical id*/
@@ -331,7 +331,7 @@ s32 qos_node_config(struct qos_node_api_param *param)
 }
 #endif /*DUMMY_PPV4_QOS_API_OLD*/
 
-#endif /*CONFIG_LTQ_DATAPATH_DUMMY_QOS*/
+#endif /*CONFIG_INTEL_DATAPATH_DUMMY_QOS*/
 
 void init_qos_fn(void)
 {
@@ -627,11 +627,11 @@ int dp_pp_alloc_queue(struct ppv4_queue *info)
 	struct hal_priv *priv = HAL(info->inst);
 	struct pp_qos_dev *qos_dev = priv->qdev;
 
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS)
 	qos_dev->dq_port = info->dq_port;
 #endif
 	if (qos_queue_allocate(qos_dev, &q_node_id)) {
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS)
 		PR_ERR("qos_queue_allocate fail for dq_port %d\n",
 		       info->dq_port);
 #else
@@ -678,7 +678,7 @@ int init_ppv4_qos(int inst, int flag)
 	union qos_init *t = NULL;
 	int res = DP_FAILURE, i;
 	struct hal_priv *priv = HAL(inst);
-#ifdef CONFIG_LTQ_DATAPATH_QOS_HAL
+#ifdef CONFIG_INTEL_DATAPATH_QOS_HAL
 	unsigned int q, idx;
 	struct cbm_tx_push *flush_port;
 	struct cbm_cpu_port_data cpu_data = {0};
@@ -736,7 +736,7 @@ int init_ppv4_qos(int inst, int flag)
 		 priv->cqm_drop_p, dp_deq_port_tbl[inst][idx].tx_ring_addr,
 		 dp_deq_port_tbl[inst][idx].tx_ring_size,
 		 dp_deq_port_tbl[inst][idx].tx_pkt_credit);
-#ifdef CONFIG_LTQ_DATAPATH_QOS_HAL
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_QOS_HAL)
 	DP_DEBUG(DP_DBG_FLAG_DBG, "priv=%p deq_port_stat=%p q_dev=%p\n",
 		 priv, priv ? priv->deq_port_stat : NULL,
 		 priv ? priv->qdev : NULL);
@@ -756,7 +756,7 @@ int init_ppv4_qos(int inst, int flag)
 	t->p_conf.credit = dp_deq_port_tbl[inst][idx].tx_pkt_credit;
 	t->p_conf.disable = 1; /*not allowed for dequeue*/
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_DBG)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DBG)
 	if (dp_dbg_flag & DP_DBG_FLAG_QOS) {
 		DP_DEBUG(DP_DBG_FLAG_QOS,
 			 "qos_port_set param: %d/%d for drop pot:\n",
@@ -811,7 +811,7 @@ int init_ppv4_qos(int inst, int flag)
 		 priv->ppv4_drop_q, q,
 		 priv->cqm_drop_p,
 		 priv->ppv4_drop_p);
-#endif /* end of CONFIG_LTQ_DATAPATH_QOS_HAL */
+#endif /* end of CONFIG_INTEL_DATAPATH_QOS_HAL */
 	DP_DEBUG(DP_DBG_FLAG_DBG, "init_ppv4_qos done\n");
 	res = DP_SUCCESS;
 
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.h b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.h
index 1f473db9ebd5..7a02abef6d43 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.h
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4.h
@@ -10,7 +10,7 @@
 #ifndef DATAPATH_PPV4_H
 #define DATAPATH_PPV4_H
 
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS)
 struct pp_qos_dev {
 	int dq_port;
 };
@@ -49,7 +49,7 @@ struct ppv4_queue {
 	u16 parent; /* -1 means no parent.
 		     * it is used for shared dropping queueu purpose
 		     */
-#ifdef CONFIG_LTQ_DATAPATH_DUMMY_QOS
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_DUMMY_QOS)
 	int dq_port; /* cqm dequeue port for qos slim driver queue alloc */
 #endif
 };
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4_api.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4_api.c
index 184c770a4201..a0662660e202 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4_api.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_ppv4_api.c
@@ -12,7 +12,6 @@
 #include <net/pp_qos_drv.h>
 #include "../datapath.h"
 #include "datapath_misc.h"
-#include <net/lantiq_cbm_api.h>
 
 #define FLUSH_RESTORE_LOOKUP BIT(0)
 
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_proc.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_proc.c
index d1d9a71513d5..53e519507009 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_proc.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_proc.c
@@ -287,7 +287,7 @@ int proc_print_ctp_bp_info(struct seq_file *s, int inst,
 static struct dp_proc_entry dp_proc_entries[] = {
 	/*name single_callback_t multi_callback_t/_start write_callback_t */
 	{PROC_PARSER, proc_parser_read, NULL, NULL, proc_parser_write},
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 	{PROC_COC, proc_coc_read, NULL, NULL, proc_coc_write},
 #endif
 	{DP_PROC_CBMLOOKUP, NULL, lookup_dump31, lookup_start31,
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_rx.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_rx.c
new file mode 100644
index 000000000000..8ce58cdb0048
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_rx.c
@@ -0,0 +1,342 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/etherdevice.h>
+#include <net/datapath_api.h>
+#include "../datapath.h"
+#include "datapath_misc.h"
+
+static void rx_dbg(u32 f, struct sk_buff *skb, struct dma_rx_desc_0 *desc0,
+	       struct dma_rx_desc_1 *desc1, struct dma_rx_desc_2 *desc2,
+	       struct dma_rx_desc_3 *desc3, unsigned char *parser,
+	       struct pmac_rx_hdr *pmac, int paser_exist)
+
+{
+	int inst = 0;
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
+		 "\ndp_rx:skb->data=%p Loc=%x offset=%d skb->len=%d\n",
+		 skb->data, desc2->field.data_ptr,
+		 desc3->field.byte_offset, skb->len);
+	if ((f) & DP_DBG_FLAG_DUMP_RX_DATA)
+		dp_dump_raw_data(skb->data,
+				(skb->len >
+				(dp_print_len)) ? skb->len : (dp_print_len),
+				"Original Data");
+	DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "parse hdr size = %d\n",
+		 paser_exist);
+	if ((f) & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
+		dp_port_prop[inst].info.dump_rx_dma_desc(desc0, (desc1),
+							 desc2, desc3);
+	if (paser_exist && (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_PASER))
+		dump_parser_flag(parser);
+	if ((f) & DP_DBG_FLAG_DUMP_RX_PMAC)
+		dp_port_prop[inst].info.dump_rx_pmac(pmac);
+}
+
+#define PRINT_INTERVAL  (5 * HZ) /* 5 seconds */
+unsigned long dp_err_interval = PRINT_INTERVAL;
+static void rx_dbg_zero_port(struct sk_buff *skb, struct dma_rx_desc_0 *desc0,
+			     struct dma_rx_desc_1 *desc1,
+			     struct dma_rx_desc_2 *desc2,
+			     struct dma_rx_desc_3 *desc3,
+			     unsigned char *parser,
+			     struct pmac_rx_hdr *pmac, int paser_exist,
+			     u32 ep, u32 port_id, int vap)
+{
+	int inst = 0;
+	static unsigned long last;
+
+	if (!dp_dbg_err) /*bypass dump */
+		return;
+	if (time_before(jiffies, last + dp_err_interval))
+		/* not print in order to keep console not busy */
+		return;
+	last = jiffies;
+	DP_DEBUG(-1, "%s=%d vap=%d\n",
+		 (ep) ? "ep" : "port_id", port_id, vap);
+	PR_ERR("\nDrop for ep and source port id both zero ??\n");
+	dp_port_prop[inst].info.dump_rx_dma_desc(desc0, desc1, desc2, desc3);
+
+	if (paser_exist)
+		dump_parser_flag(parser);
+	if (pmac)
+		dp_port_prop[inst].info.dump_rx_pmac(pmac);
+	dp_dump_raw_data((char *)(skb->data),
+			(skb->len >
+			 dp_print_len) ? skb->len : dp_print_len,
+			"Recv Data");
+}
+
+/* clone skb to send one copy to lct dev for multicast/broadcast
+ * otherwise for unicast send only to lct device
+ * return 0 - Caller will not proceed handling i.e. for unicast do rx only for
+ *	      LCT port
+ *	  1 - Caller continue to handle rx for other device
+ */
+static int dp_handle_lct(struct pmac_port_info *dp_port,
+			 struct sk_buff *skb, dp_rx_fn_t rx_fn)
+{
+	struct sk_buff *lct_skb;
+	int vap, ret;
+
+	vap = dp_port->lct_idx;
+	skb->dev = dp_port->subif_info[vap].netif;
+	if (skb->data[PMAC_SIZE] & 0x1) {
+		/* multicast/broadcast */
+		DP_DEBUG(DP_DBG_FLAG_PAE, "LCT mcast or broadcast\n");
+		if((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+			return 1;
+		}
+		lct_skb = skb_clone(skb, GFP_ATOMIC);
+		if (!lct_skb) {
+			PR_ERR("LCT mcast/bcast skb clone fail\n");
+			return -1;
+		}
+		lct_skb->dev = dp_port->subif_info[vap].netif;	
+		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_rxif_pkt);
+		DP_DEBUG(DP_DBG_FLAG_PAE, "pkt sent lct(%s) ret(%d)\n",
+			 lct_skb->dev->name ? lct_skb->dev->name : "NULL",
+			 ret);
+		rx_fn(lct_skb->dev, NULL, lct_skb, lct_skb->len);
+		return 1;
+	} else if (memcmp(skb->data + PMAC_SIZE, skb->dev->dev_addr, 6) == 0) {
+		/* unicast */
+		DP_DEBUG(DP_DBG_FLAG_PAE, "LCT unicast\n");
+		DP_DEBUG(DP_DBG_FLAG_PAE, "unicast pkt sent lct(%s) ret(%d)\n",
+			 skb->dev->name ? skb->dev->name : "NULL", ret);
+		if ((STATS_GET(dp_port->subif_info[vap].rx_flag) <= 0)) {
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+			dev_kfree_skb_any(skb);
+			return 0;
+		}
+		rx_fn(skb->dev, NULL, skb, skb->len);
+		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_rxif_pkt);
+		return 0;
+	}
+	return 1;
+}
+
+int32_t dp_rx_31(struct sk_buff *skb, u32 flags)
+{
+	int res = DP_SUCCESS;
+#ifdef DP_SKB_HACK
+	struct dma_rx_desc_0 *desc_0 = (struct dma_rx_desc_0 *)&skb->DW0;
+	struct dma_rx_desc_1 *desc_1 = (struct dma_rx_desc_1 *)&skb->DW1;
+	struct dma_rx_desc_2 *desc_2 = (struct dma_rx_desc_2 *)&skb->DW2;
+	struct dma_rx_desc_3 *desc_3 = (struct dma_rx_desc_3 *)&skb->DW3;
+#endif
+	struct pmac_rx_hdr *pmac;
+	unsigned char *parser = NULL;
+	int rx_tx_flag = 0;	/*0-rx, 1-tx */
+	u32 ep = desc_1->field.ep;	/* ep: 0 -15 */
+	int vap; /*vap: 0-15 */
+	int paser_exist;
+	u32 port_id = ep; /*same with ep now, later set to sspid if ep is 0 */
+	struct net_device *dev;
+	dp_rx_fn_t rx_fn;
+	char decryp = 0;
+	u8 inst = 0;
+	struct pmac_port_info *dp_port;
+	struct mac_ops *ops;
+	int ret_lct = 1;
+
+	dp_port = &dp_port_info[inst][0];
+	if (!skb) {
+		PR_ERR("skb NULL\n");
+		return DP_FAILURE;
+	}
+	if (!skb->data) {
+		PR_ERR("skb->data NULL\n");
+		return DP_FAILURE;
+	}
+
+	paser_exist = parser_enabled(port_id, desc_1);
+	if (paser_exist)
+		parser = skb->data;
+	pmac = (struct pmac_rx_hdr *)(skb->data + paser_exist);
+
+	if (unlikely(dp_dbg_flag))
+		rx_dbg(dp_dbg_flag, skb, desc_0, desc_1, desc_2,
+		       desc_3, parser, pmac, paser_exist);
+	if (paser_exist) {
+		skb_pull(skb, paser_exist);	/*remove parser */
+#if IS_ENABLED(CONFIG_PPA_API_SW_FASTPATH)
+		skb->mark |= FLG_PPA_PROCESSED;
+#endif
+	}
+#ifdef CONFIG_LTQ_DATAPATH_EXTRA_DEBUG
+	/*Sanity check */
+	if (unlikely(dp_port_prop[inst].info.not_valid_rx_ep(ep))) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Wrong: why ep=%d??\n", ep);
+		rx_dbg(-1, skb, desc_0, desc_1, desc_2, desc_3,
+		       parser, pmac, paser_exist);
+		goto RX_DROP;
+	}
+	if (unlikely(dp_drop_all_tcp_err && desc_1->field.tcp_err)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "\n----dp_rx why tcp_err ???\n");
+		rx_dbg(-1, skb, desc_0, desc_1, desc_2, desc_3, parser,
+		       pmac, paser_exist);
+		goto RX_DROP;
+	}
+#endif
+
+	if (port_id == PMAC_CPU_ID) { /*To CPU and need check src pmac port */
+		dp_port_prop[inst].info.update_port_vap(inst, &port_id, &vap,
+			skb,
+			pmac, &decryp);
+	} else {		/*GSWIP-R already know the destination */
+		rx_tx_flag = 1;
+		vap = GET_VAP(desc_0->field.dest_sub_if_id,
+			      dp_port_info[inst][port_id].vap_offset,
+			      dp_port_info[inst][port_id].vap_mask);
+	}
+	if (unlikely(!port_id)) { /*Normally shouldnot go to here */
+		rx_dbg_zero_port(skb, desc_0, desc_1, desc_2, desc_3, parser,
+				 pmac, paser_exist, ep, port_id, vap);
+		goto RX_DROP;
+	}
+	dp_port = &dp_port_info[inst][port_id];
+#if IS_ENABLED(CONFIG_LTQ_DATAPATH_PTP1588)
+	if (dp_port->f_ptp) {
+		ops = dp_port_prop[inst].mac_ops[port_id];
+		if (ops)
+			ops->do_rx_hwts(ops, skb);
+	}
+#endif
+	/*PON traffic always have timestamp attached,removing Timestamp */
+	if (dp_port->alloc_flags & (DP_F_GPON | DP_F_EPON)) {
+		/* Stripping of last 10 bytes timestamp */
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+		if (!dp_port->f_ptp)
+			__pskb_trim(skb, skb->len - DP_TS_HDRLEN);
+#else
+		__pskb_trim(skb, skb->len - DP_TS_HDRLEN);
+#endif
+	}
+
+	rx_fn = dp_port->cb.rx_fn;
+	if (likely(rx_fn && dp_port->status)) {
+		/*Clear some fields as SWAS V3.7 required */
+		//desc_1->all &= dma_rx_desc_mask1.all;
+		desc_3->all &= dma_rx_desc_mask3.all;
+		skb->priority = desc_1->field.classid;
+		skb->dev = dp_port->subif_info[vap].netif;
+		if (((dp_port->alloc_flags & DP_F_FAST_DSL) == 0) && /*non-dsl*/
+			dp_port->subif_info[vap].flags) { /*not de-registered */
+			dev = dp_port->subif_info[vap].netif;
+		}
+		if (decryp) { /*workaround mark for bypass xfrm policy*/
+			desc_1->field.dec = 1;
+			desc_1->field.enc = 1;
+		}
+		if (!dev &&
+		    ((dp_port->alloc_flags & DP_F_FAST_DSL) == 0)) {
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+			goto RX_DROP;
+		}
+
+		if (unlikely(dp_dbg_flag)) {
+			DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "%s=%d vap=%d\n",
+				 (ep) ? "ep" : "port_id", port_id, vap);
+
+			if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DATA) {
+				dp_dump_raw_data(skb->data, PMAC_SIZE,
+						 "pmac to top drv");
+				dp_dump_raw_data(skb->data + PMAC_SIZE,
+						 ((skb->len - PMAC_SIZE) >
+							dp_print_len) ?
+							skb->len - PMAC_SIZE :
+							dp_print_len,
+						 "Data to top drv");
+			}
+			if (dp_dbg_flag & DP_DBG_FLAG_DUMP_RX_DESCRIPTOR)
+				dp_port_prop[inst].info.dump_rx_dma_desc(
+					desc_0, desc_1,
+					desc_2, desc_3);
+		}
+#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
+		if (unlikely(ltq_mpe_fasthook_rx_fn))
+			ltq_mpe_fasthook_rx_fn(skb, 1, NULL);	/*with pmac */
+#endif
+		if (unlikely((enum TEST_MODE)dp_rx_test_mode ==
+			DP_RX_MODE_LAN_WAN_BRIDGE)) {
+			/*for datapath performance test only */
+			dp_lan_wan_bridging(port_id, skb);
+			/*return DP_SUCCESS;*/
+		}
+		/*If switch h/w acceleration is enabled,setting of this bit
+		 *avoid forwarding duplicate packets from linux
+		 */
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
+			if (dp_port->subif_info[vap].fid > 0)
+				skb->offload_fwd_mark = 1;
+		#endif
+		if (rx_tx_flag == 0) {
+			if (dp_port->lct_idx > 0)
+				ret_lct = dp_handle_lct(dp_port, skb, rx_fn);
+			if (ret_lct) {
+				if ((STATS_GET(dp_port->subif_info[vap].
+					rx_flag) <= 0) &&
+					((dp_port->alloc_flags & DP_F_FAST_DSL)
+						== 0)) {
+					UP_STATS(dp_port->subif_info[vap].
+							mib.rx_fn_dropped);
+					goto RX_DROP2;
+				}
+				rx_fn(dev, NULL, skb, skb->len);
+				UP_STATS(dp_port->subif_info[vap].mib.
+								rx_fn_rxif_pkt);
+			}
+		} else {
+			if ((STATS_GET(dp_port->subif_info[vap].
+					rx_flag) <= 0) &&
+					((dp_port->alloc_flags & DP_F_FAST_DSL)
+						== 0)) {
+				UP_STATS(dp_port->subif_info[vap].mib.
+						rx_fn_dropped);
+				goto RX_DROP2;
+			}
+			rx_fn(NULL, dev, skb, skb->len);
+			UP_STATS(dp_port->subif_info[vap].mib.rx_fn_txif_pkt);
+		}
+
+		return DP_SUCCESS;
+	}
+
+	if (unlikely(port_id >=
+	    dp_port_prop[inst].info.cap.max_num_dp_ports - 1)) {
+		PR_ERR("Drop for wrong ep or src port id=%u ??\n",
+		       port_id);
+		goto RX_DROP;
+	} else if (unlikely(dp_port->status == PORT_FREE)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX, "Drop for port %u free\n",
+			 port_id);
+		goto RX_DROP;
+	} else if (unlikely(!rx_fn)) {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_RX,
+			 "Drop for subif of port %u not registered yet\n",
+			 port_id);
+		UP_STATS(dp_port->subif_info[vap].mib.rx_fn_dropped);
+		goto RX_DROP2;
+	} else {
+		pr_info("Unknown issue\n");
+	}
+RX_DROP:
+	UP_STATS(dp_port->rx_err_drop);
+RX_DROP2:
+	if (skb)
+		dev_kfree_skb_any(skb);
+	return res;
+}
+
+
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tc_asym_vlan.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tc_asym_vlan.c
index 2e0e41ac52ac..7c9cbb792210 100644
--- a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tc_asym_vlan.c
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tc_asym_vlan.c
@@ -411,17 +411,6 @@ static int tc_vlan_filter(struct core_ops *ops,
 		j++;
 	}
 
-	/* Check if we have anything to configure */
-	if (j <= 0) {
-		/* Update bridge port */
-		ret = update_bp(ops,
-				(u32)info->bp,
-				vlan->dir == DP_DIR_INGRESS,
-				NULL,
-				NULL);
-		goto EXIT;
-	}
-
 	if (untagged < 0)
 		untagged = 0;
 	if (tagged < 0)
diff --git a/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tx.c b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tx.c
new file mode 100644
index 000000000000..c09575bc3a39
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/datapath/gswip31/datapath_tx.c
@@ -0,0 +1,437 @@
+/*
+ * Copyright (C) Intel Corporation
+ * Author: Shao Guohua <guohua.shao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 as published
+ * by the Free Software Foundation.
+ */
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/etherdevice.h>
+#include <net/datapath_api.h>
+#include "../datapath.h"
+#include "datapath_misc.h"
+#include "../datapath_instance.h"
+
+void dp_xmit_dbg(
+	char *title,
+	struct sk_buff *skb,
+	s32 ep,
+	s32 len,
+	u32 flags,
+	struct pmac_tx_hdr *pmac,
+	dp_subif_t *rx_subif,
+	int need_pmac,
+	int gso,
+	int checksum)
+{
+#ifdef DP_SKB_HACK
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+		 "%s: dp_xmit:skb->data/len=0x%p/%d data_ptr=%x from port=%d and subitf=%d\n",
+		 title,	skb->data, len,
+		 ((struct dma_tx_desc_2 *)&skb->DW2)->field.data_ptr,
+		 ep, rx_subif->subif);
+#endif
+	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DATA) {
+		if (pmac) {
+			dp_dump_raw_data((char *)pmac, PMAC_SIZE, "Tx Data");
+			dp_dump_raw_data(skb->data,
+					(skb->len > dp_print_len) ?
+					skb->len :
+					dp_print_len,
+					"Tx Data");
+		} else
+			dp_dump_raw_data(skb->data,
+					(skb->len > dp_print_len) ?
+					skb->len : dp_print_len,
+					"Tx Data");
+	}
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+		 "ip_summed=%s(%d) encapsulation=%s\n",
+		 dp_skb_csum_str(skb), skb->ip_summed,
+		 skb->encapsulation ? "Yes" : "No");
+	if (skb->encapsulation)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "inner ip start=0x%x(%d), transport=0x%x(%d)\n",
+			 (unsigned int)skb_inner_network_header(skb),
+			 (int)(skb_inner_network_header(skb) -
+			 skb->data),
+			 (unsigned int)
+			 skb_inner_transport_header(skb),
+			 (int)(skb_inner_transport_header(skb) -
+			 skb_inner_network_header(skb)));
+	else
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX_SUM,
+			 "ip start=0x%x(%d), transport=0x%x(%d)\n",
+			 (unsigned int)(unsigned int)
+			 skb_network_header(skb),
+			 (int)(skb_network_header(skb) - skb->data),
+			 (unsigned int)skb_transport_header(skb),
+			 (int)(skb_transport_header(skb) -
+			 skb_network_header(skb)));
+
+	if (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR)
+#ifdef DP_SKB_HACK
+		dp_port_prop[0].info.dump_tx_dma_desc(
+				(struct dma_tx_desc_0 *)&skb->DW0,
+				(struct dma_tx_desc_1 *)&skb->DW1,
+				(struct dma_tx_desc_2 *)&skb->DW2,
+				(struct dma_tx_desc_3 *)&skb->DW3);
+#endif
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "flags=0x%x skb->len=%d\n",
+		 flags, skb->len);
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+		 "skb->data=0x%p with pmac hdr size=%u\n", skb->data,
+		 sizeof(struct pmac_tx_hdr));
+	if (need_pmac) { /*insert one pmac header */
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX,
+			 "need pmac\n");
+		if (pmac && (dp_dbg_flag & DP_DBG_FLAG_DUMP_TX_DESCRIPTOR))
+			dp_port_prop[0].info.dump_tx_pmac(pmac);
+	} else {
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "no pmac\n");
+	}
+	if (gso)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "GSO pkt\n");
+	else
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "Non-GSO pkt\n");
+	if (checksum)
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "Need checksum offload\n");
+	else
+		DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "No need checksum offload pkt\n");
+
+	DP_DEBUG(DP_DBG_FLAG_DUMP_TX, "\n\n");
+}
+
+int32_t dp_xmit_31(struct net_device *rx_if, dp_subif_t *rx_subif,
+		   struct sk_buff *skb, int32_t len, uint32_t flags)
+{
+		struct dma_tx_desc_0 *desc_0;
+		struct dma_tx_desc_1 *desc_1;
+		struct dma_tx_desc_2 *desc_2;
+		struct dma_tx_desc_3 *desc_3;
+		struct pmac_port_info *dp_info = NULL;
+		struct pmac_tx_hdr pmac = {0};
+		u32 ip_offset, tcp_h_offset, tcp_type;
+		char tx_chksum_flag = 0; /*check csum cal can be supported or not */
+		char insert_pmac_f = 1; /*flag to insert one pmac */
+		int res = DP_SUCCESS;
+		int ep, vap;
+		enum dp_xmit_errors err_ret = 0;
+		int inst = 0;
+		struct cbm_tx_data data;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+		struct mac_ops *ops;
+		int rec_id = 0;
+#endif
+	
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+		if (unlikely(!dp_init_ok)) {
+			err_ret = DP_XMIT_ERR_NOT_INIT;
+			goto lbl_err_ret;
+		}
+		if (unlikely(!rx_subif)) {
+			err_ret = DP_XMIT_ERR_NULL_SUBIF;
+			goto lbl_err_ret;
+		}
+		if (unlikely(!skb)) {
+			err_ret = DP_XMIT_ERR_NULL_SKB;
+			goto lbl_err_ret;
+		}
+#endif
+		ep = rx_subif->port_id;
+		if (unlikely(ep >= dp_port_prop[inst].info.cap.max_num_dp_ports)) {
+			err_ret = DP_XMIT_ERR_PORT_TOO_BIG;
+			goto lbl_err_ret;
+		}
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+		if (unlikely(in_irq())) {
+			err_ret = DP_XMIT_ERR_IN_IRQ;
+			goto lbl_err_ret;
+		}
+#endif
+		dp_info = &dp_port_info[inst][ep];
+		vap = GET_VAP(rx_subif->subif, dp_info->vap_offset, dp_info->vap_mask);
+		if (unlikely(!rx_if && /*For atm pppoa case, rx_if is NULL now */
+			     !(dp_info->alloc_flags & DP_F_FAST_DSL))) {
+			err_ret = DP_XMIT_ERR_NULL_IF;
+			goto lbl_err_ret;
+		}
+#ifdef CONFIG_LTQ_DATAPATH_MPE_FASTHOOK_TEST
+		if (unlikely(ltq_mpe_fasthook_tx_fn))
+			ltq_mpe_fasthook_tx_fn(skb, 0, NULL);
+#endif
+		if (unlikely(dp_dbg_flag))
+			dp_xmit_dbg("\nOrig", skb, ep, len, flags,
+				    NULL, rx_subif, 0, 0, flags & DP_TX_CAL_CHKSUM);
+	
+		/*No PMAC for WAVE500 and DSL by default except bonding case */
+		if (unlikely(NO_NEED_PMAC(dp_info->alloc_flags)))
+			insert_pmac_f = 0;
+	
+		/**********************************************
+		 *Must put these 4 lines after INSERT_PMAC
+		 *since INSERT_PMAC will change skb if needed
+		 *********************************************/
+#ifdef DP_SKB_HACK
+		desc_0 = (struct dma_tx_desc_0 *)&skb->DW0;
+		desc_1 = (struct dma_tx_desc_1 *)&skb->DW1;
+		desc_2 = (struct dma_tx_desc_2 *)&skb->DW2;
+		desc_3 = (struct dma_tx_desc_3 *)&skb->DW3;
+#endif
+		if (flags & DP_TX_CAL_CHKSUM) {
+			int ret_flg;
+	
+			if (!dp_port_prop[inst].info.check_csum_cap()) {
+				err_ret = DP_XMIT_ERR_CSM_NO_SUPPORT;
+				goto lbl_err_ret;
+			}
+			ret_flg = get_offset_clear_chksum(skb, &ip_offset,
+							  &tcp_h_offset, &tcp_type);
+			if (likely(ret_flg == 0))
+				/*HW can support checksum offload*/
+				tx_chksum_flag = 1;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+			else if (ret_flg == -1)
+				pr_info_once("packet can't do hw checksum\n");
+#endif
+		}
+	
+		/*reset all descriptors as SWAS required since SWAS 3.7 */
+		/*As new SWAS 3.7 required, MPE1/Color/FlowID is set by applications */
+		desc_0->all &= dma_tx_desc_mask0.all;
+		desc_1->all &= dma_tx_desc_mask1.all;
+		/*desc_2->all = 0;*/ /*remove since later it will be set properly */
+		if (desc_3->field.dic) {
+			desc_3->all = 0; /*keep DIC bit to support test tool*/
+			desc_3->field.dic = 1;
+		} else {
+			desc_3->all = 0;
+		}
+	
+		if (flags & DP_TX_OAM) /* OAM */
+			desc_3->field.pdu_type = 1;
+		desc_1->field.classid = (skb->priority >= 15) ? 15 : skb->priority;
+		desc_2->field.data_ptr = (uint32_t)skb->data;
+	
+		/*for ETH LAN/WAN */
+		if (dp_info->alloc_flags & (DP_F_FAST_ETH_LAN | DP_F_FAST_ETH_WAN |
+		    DP_F_GPON | DP_F_EPON)) {
+			/*always with pmac*/
+			if (likely(tx_chksum_flag)) {
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else {
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			}
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588)
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_PTP1588_SW_WORKAROUND)
+			if (dp_info->f_ptp)
+#else
+			if (dp_info->f_ptp &&
+			    (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP))
+#endif
+		{
+			ops = dp_port_prop[inst].mac_ops[dp_info->port_id];
+				if (!ops) {
+					err_ret = DP_XMIT_PTP_ERR;
+					goto lbl_err_ret;
+				}
+				rec_id = ops->do_tx_hwts(ops, skb);
+				if (rec_id < 0) {
+					err_ret = DP_XMIT_PTP_ERR;
+					goto lbl_err_ret;
+				}
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_PTP, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				pmac.record_id_msb = rec_id;
+			}
+#endif
+		} else if (dp_info->alloc_flags & DP_F_FAST_DSL) { /*some with pmac*/
+			if (unlikely(flags & DP_TX_CAL_CHKSUM)) { /* w/ pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+				if (aca_portid > 0)
+					desc_1->field.ep = aca_portid;
+#endif
+			} else if (flags & DP_TX_DSL_FCS) {/* after checksum check */
+				/* w/ pmac for FCS purpose*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_OTHERS, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+				insert_pmac_f = 1;
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+				if (aca_portid > 0)
+					desc_1->field.ep = aca_portid;
+#endif
+			} else { /*no pmac */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, NULL,
+								desc_0, desc_1,
+								dp_info);
+			}
+		} else if (dp_info->alloc_flags & DP_F_FAST_WLAN) {/*some with pmac*/
+			/*normally no pmac. But if need checksum, need pmac*/
+			if (unlikely(tx_chksum_flag)) { /*with pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_ACA_CSUM_WORKAROUND)
+				if (aca_portid > 0)
+					desc_1->field.ep = aca_portid;
+#endif
+			} else { /*no pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, NULL,
+								desc_0, desc_1,
+								dp_info);
+			}
+		} else if (dp_info->alloc_flags & DP_F_DIRECTLINK) { /*always w/ pmac*/
+			if (unlikely(flags & DP_TX_CAL_CHKSUM)) { /* w/ pmac*/
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else if (flags & DP_TX_TO_DL_MPEFW) { /*w/ pmac*/
+				/*copy from checksum's pmac template setting,
+				 *but need to reset tcp_chksum in TCP header
+				 */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_OTHERS, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else { /*do like normal directpath with pmac */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			}
+		} else { /*normal directpath: always w/ pmac */
+			if (unlikely(tx_chksum_flag)) {
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_CHECKSUM,
+								&pmac,
+								desc_0,
+								desc_1,
+								dp_info);
+				set_chksum(&pmac, tcp_type, ip_offset,
+					   ip_offset_hw_adjust, tcp_h_offset);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			} else { /*w/ pmac */
+				DP_CB(inst, get_dma_pmac_templ)(TEMPL_NORMAL, &pmac,
+								desc_0, desc_1,
+								dp_info);
+				DP_CB(inst, set_pmac_subif)(&pmac, rx_subif->subif);
+			}
+		}
+		desc_3->field.data_len = skb->len;
+	
+		if (unlikely(dp_dbg_flag)) {
+			if (insert_pmac_f)
+				dp_xmit_dbg("After", skb, ep, len, flags, &pmac,
+					    rx_subif, insert_pmac_f, skb_is_gso(skb),
+					    tx_chksum_flag);
+			else
+				dp_xmit_dbg("After", skb, ep, len, flags, NULL,
+					    rx_subif, insert_pmac_f, skb_is_gso(skb),
+					    tx_chksum_flag);
+		}
+	
+#if IS_ENABLED(CONFIG_LTQ_TOE_DRIVER)
+		if (skb_is_gso(skb)) {
+			res = ltq_tso_xmit(skb, &pmac, sizeof(pmac), 0);
+			UP_STATS(dp_info->subif_info[vap].mib.tx_tso_pkt);
+			return res;
+		}
+#endif /* CONFIG_LTQ_TOE_DRIVER */
+	
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_EXTRA_DEBUG)
+		if (unlikely(!desc_1->field.ep)) {
+			err_ret = DP_XMIT_ERR_EP_ZERO;
+			goto lbl_err_ret;
+		}
+#endif
+		if (insert_pmac_f) {
+			data.pmac = (u8 *)&pmac;
+			data.pmac_len = sizeof(pmac);
+			data.dp_inst = inst;
+			data.dp_inst = 0;
+		} else {
+			data.pmac = NULL;
+			data.pmac_len = 0;
+			data.dp_inst = inst;
+			data.dp_inst = 0;
+		}
+		res = cbm_cpu_pkt_tx(skb, &data, 0);
+		UP_STATS(dp_info->subif_info[vap].mib.tx_cbm_pkt);
+		return res;
+	
+	lbl_err_ret:
+		switch (err_ret) {
+		case DP_XMIT_ERR_NOT_INIT:
+			PR_RATELIMITED("dp_xmit failed for dp no init yet\n");
+			break;
+		case DP_XMIT_ERR_IN_IRQ:
+			PR_RATELIMITED("dp_xmit not allowed in interrupt context\n");
+			break;
+		case DP_XMIT_ERR_NULL_SUBIF:
+			PR_RATELIMITED("dp_xmit failed for rx_subif null\n");
+			UP_STATS(PORT_INFO(inst, 0, tx_err_drop));
+			break;
+		case DP_XMIT_ERR_PORT_TOO_BIG:
+			UP_STATS(PORT_INFO(inst, 0, tx_err_drop));
+			PR_RATELIMITED("rx_subif->port_id >= max_ports");
+			break;
+		case DP_XMIT_ERR_NULL_SKB:
+			PR_RATELIMITED("skb NULL");
+			UP_STATS(PORT_INFO(inst, rx_subif->port_id, tx_err_drop));
+			break;
+		case DP_XMIT_ERR_NULL_IF:
+			UP_STATS(PORT_VAP_MIB(inst, ep, vap, tx_pkt_dropped));
+			PR_RATELIMITED("rx_if NULL");
+			break;
+		case DP_XMIT_ERR_REALLOC_SKB:
+			PR_INFO_ONCE("dp_create_new_skb failed\n");
+			break;
+		case DP_XMIT_ERR_EP_ZERO:
+			PR_ERR("Why ep zero in dp_xmit for %s\n",
+			       skb->dev ? skb->dev->name : "NULL");
+			break;
+		case DP_XMIT_ERR_GSO_NOHEADROOM:
+			PR_ERR("No enough skb headerroom(GSO). Need tune SKB buffer\n");
+			break;
+		case DP_XMIT_ERR_CSM_NO_SUPPORT:
+			PR_RATELIMITED("dp_xmit not support checksum\n");
+			break;
+		case DP_XMIT_PTP_ERR:
+			break;
+		default:
+			UP_STATS(dp_info->subif_info[vap].mib.tx_pkt_dropped);
+			PR_INFO_ONCE("Why come to here:%x\n",
+				     dp_port_info[inst][ep].status);
+		}
+		if (skb)
+			dev_kfree_skb_any(skb);
+		return DP_FAILURE;
+
+}
+
diff --git a/include/net/datapath_api.h b/include/net/datapath_api.h
index 778d23a72e1c..20fe977784eb 100644
--- a/include/net/datapath_api.h
+++ b/include/net/datapath_api.h
@@ -14,23 +14,40 @@
 #include <linux/etherdevice.h>
 #include <linux/atmdev.h>
 
-#ifndef DATAPATH_HAL_LAYER
 #if IS_ENABLED(CONFIG_PRX300_CQM) || \
-	IS_ENABLED(CONFIG_LTQ_DATAPATH_DDR_SIMULATE_GSWIP31) /*testing only */
+	IS_ENABLED(CONFIG_GRX500_CBM)
+	#include <net/lantiq_cbm_api.h>
+#else
+	#include <net/intel_cbm_api.h>
+#endif
+
+#ifndef DATAPATH_HAL_LAYER
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SIMULATE_GSWIP32) || \
+	IS_ENABLED(CONFIG_SOC_LGM) || \
+	IS_ENABLED(CONFIG_X86_INTEL_LGM)
+#include <net/datapath_api_gswip32.h>
+#include <net/datapath_api_ppv4.h>
+#elif IS_ENABLED(CONFIG_PRX300_CQM) || \
+	IS_ENABLED(CONFIG_INTEL_DATAPATH_DDR_SIMULATE_GSWIP31) /*testing only */
 #include <net/datapath_api_gswip31.h>
-#else /*GRX500 GSWIP30*/
+#elif IS_ENABLED(CONFIG_GRX500_CBM) /*GRX500 GSWIP30*/
 #include <net/datapath_api_gswip30.h>
+#else
+#error "wrong DP HAL selected"
 #endif
 #endif /*DATAPATH_HAL_LAYER */
+#include <net/datapath_api_umt.h>
 #include <net/datapath_api_vlan.h>
 #include <net/switch_api/lantiq_gsw_api.h>
 #include <net/switch_api/lantiq_gsw_flow.h>
 #include <net/switch_api/lantiq_gsw.h>
 #include <net/switch_api/gsw_dev.h>
 #include <net/switch_api/gsw_flow_ops.h>
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 #include <linux/cpufreq.h>
-#endif /*CONFIG_LTQ_DATAPATH_CPUFREQ*/
+#include <cpufreq/ltq_cpufreq.h>
+
+#endif /*CONFIG_INTEL_DATAPATH_CPUFREQ*/
 
 /*! @mainpage Datapath Manager API
  * @section Basic Datapath Registration API
@@ -91,8 +108,28 @@
 #define DP_RXOUT_PKT_SIZE_DEF 2048 /*!< Default size of RXOUT normal pkt */
 #define DP_RXOUT_PKt_SIZE_DEF_JUMBO 10240 /*!< Default size of RXOUT jumbo pkt*/
 
+#define DP_RX_RING_NUM 2  /*!< maximum number of ACA RX ring
+			   *   For GRX500/PRX300, only support 1 ring
+			   *   For LGM, maximum up to 2 rings
+			   */
+#define DP_TX_RING_NUM 8 /*!< maximum number of ACA RXOUT ring
+			   *   For GRX500/PRX300, only support 1 ring
+			   *   For 5G, it needs to support up to 16 ring.
+			   */
+#define DP_MAX_UMT DP_RX_RING_NUM /*!< maximum number of UMT port per DC
+				   *   For GRX500/PRX300, only support 1
+				   *      umt port
+				   *   For LGM docsis, it can support up to 2
+				   */
+#define DP_MAX_POLICY_GPID 4     /*!< maximum number of policy per GPID
+				  *   for HW automatically free BM buffer
+				  *   In LGM, it is 4. Not valid for all other
+				  *   existing products
+				  */
+#define DP_TS_HDRLEN	10    /*!< Befault Timestamp Header Length to strip */
+#define DP_DFL_SESS_NUM 16    /*!< Maximum default egress session per subif */
 /*! @addtogroup Datapath_Driver_Structures */
-/*! @brief  PPA Sub-interface Data structure
+/*! @brief  DP Sub-interface Data structure
  *@param port_id  Datapath Port Id corresponds to PMAC Port Id
  *@param subif    Sub-interface Id info. In GRX500, this 15 bits,
  *		only 13 bits in PAE are handled [14, 11:0]
@@ -141,6 +178,7 @@ enum DP_F_FLAG {
 	DP_F_EPON     = BIT(13), /*!< For EPON device */
 	DP_F_GINT     = BIT(14), /*!< For GINT device */
 	DP_F_DOCSIS   = BIT(15), /*!< For DOCSIS device support */
+	DP_F_CPU      = BIT(16), /*!< For CPU */
 
 	DP_F_SHARE_RES = BIT(22), /*!< Wave600 multiple radio share same ACA */
 	DP_F_ACA       = BIT(23), /*!< peripheral PCI device via ACA*/
@@ -217,11 +255,33 @@ enum DP_PMAP_MODE {
 	DP_PMAP_MAX       /*!< Not valid */
 };
 
+/*! @brief DP Special Connectivity Type*/
+enum DP_SPL_TYPE {
+	DP_SPL_LRO = 0, /*!< Special connectivity type: LRO */
+	DP_SPL_TSO, /*!< Special connectivity type: TSO */
+	DP_SPL_VOICE, /*!< Special connectivity type: VOICE */
+	DP_SPL_VPN, /*!< Special connectivity type: VPN Adaptor */
+	DP_SPL_PP_2ND_PATH, /*!< Special connectivity type: a second pass via
+			     *   PPV4
+			     */
+	DP_SPL_APP_LITEPATH, /*!< Special connectivity type: For Application
+			      *   Litepath
+			      */
+	DP_SPL_PPV4_NFS, /*!< Special connectivity type:For PPV4 uCs-
+			  *   Fragmenter, Reassembler, Multicast, TurboDox
+			  */
+	DP_SPL_MAX /*!< Special connectivity type: NOT VALID */
+};
+
 #define DP_PMAP_PCP_NUM 8  /*!< @brief  Max pcp entries supported per pmapper*/
 #define DP_PMAP_DSCP_NUM 64 /*!<@brief  Max dscp entries supported per pmapper*/
 #define DP_MAX_CTP_PER_DEV  64  /*!< @brief  max CTP per dev:
 				 *  Note: its value should be like
 				 *     max(DP_PMAP_DSCP_NUM, DP_PMAP_PCP_NUM)
+				 *   ? Maybe we can reduce from 64 to 8 since
+				 *     PON currently only needs 8 CTP per
+				 *     pmapper althogh GSIWP support 64
+				 *     in pcp mode
 				 */
 #define DP_PMAPPER_DISCARD_CTP 0xFFFF  /*!<@brief Discard ctp flag for pmapper*/
 /*! @brief structure for pmapper */
@@ -253,15 +313,27 @@ typedef struct dp_subif {
 			*   no use for dp_register_subif_ext
 			*/
 	union {
-		s32 subif; /*!< Sub-interface Id as HW defined
-			    * in full length
-			    * In GRX500/PRX300, it is 15 bits
+		s32 subif; /*!< [in/out] Sub-interface Id as HW defined
 			    */
-		s32 subif_list[DP_MAX_CTP_PER_DEV]; /*!< subif list */
+		s32 subif_list[DP_MAX_CTP_PER_DEV]; /*!< [in/out] subif list
+						     *   Normally 1 subif per
+						     *   dev. But for PON
+						     *   pmapper case, multiple
+						     *   subif per pmapper
+						     *   device
+						     */
 	};
-
-	int lookup_mode; /*!< CQM lookup mode for this device (dp_port based)*/
-	int alloc_flag; /*!< the flag is used during dp_alloc_port
+	u16 gpid; /*!< [out] gpid which is mapped from dpid + subif
+		   *   normally one GPID per subif for non PON device.
+		   *   For PON case, one GPID per bridge port
+		   */
+	u16 def_qid; /*!< [out] default physical queue id assigned by DP */
+	int lookup_mode; /*!< [out] CQM lookup mode for this device
+			  *   (dp_port based)
+			  *   valid for dp_get_netif_subifid only
+			  */
+	int alloc_flag; /*!< [out] the flag value is from the top level driver
+			 *    during calling dp_alloc_port_ext
 			 *   output for dp_get_netif_subifid
 			 *   no use for dp_register_subif_ext
 			 *   This is requested by PPA/DCDP to get original flag
@@ -278,18 +350,25 @@ typedef struct dp_subif {
 					     *   provided to DP during
 					     *   dp_register_subif_ext
 					     */
-	u32 flag_bp : 1; /*!< output: flag to indicate whether this device is
+	u32 flag_bp : 1; /*!< [out] flag to indicate whether this device is
 			  *   bridge port device or GEM device
-			  *   if it is bridge port device, it will be set to 1
-			  *   otherwise, it is 0
+			  *   For PON CTP device under pmapper: 0.
+			  *   For PON pmapper or normal registered subif: 1
+			  *   For example: eth1, pmapper device and so on.
 			  *   Valid only for API output of dp_get_netif_subifid
 			  *   It will be used for asymmetric VLAN case
 			  *   in case need call API dp_vlan_set to apply VLAN
 			  *   rule to CTP or bridge port
 			  */
-	u32 flag_pmapper : 1; /*!< output: flag to indicate whether this
-			       *   device is pmapper device
+	u32 flag_pmapper : 1; /*!< [out] flag to indicate whether this
+			       *   device is pmapper device.
+			       *   For PON pmappper device: 1
+			       *   For PON CTP device or other non PON device:0
+			       *   valid for dp_get_netif_subifid only
 			       */
+	u16 dfl_eg_sess[DP_DFL_SESS_NUM]; /*!< [out] default egress session id
+			*   This is for CPU TX to DC only
+			*/
 } dp_subif_t;
 
 typedef dp_subif_t PPA_SUBIF; /*!< @brief structure type dp_subif PPA_SUBIF*/
@@ -359,11 +438,11 @@ typedef int32_t(*dp_get_mib_fn_t)(dp_subif_t *subif, dp_drv_mib_t *,
 typedef int32_t(*dp_get_netif_subifid_fn_t)(struct net_device *netif,
 	struct sk_buff *skb, void *subif_data, uint8_t dst_mac[DP_MAX_ETH_ALEN],
 	dp_subif_t *subif, uint32_t flags);	/*!< @brief   get subifid */
-#if defined(CONFIG_LTQ_DATAPATH_CPUFREQ)
+#if defined(CONFIG_INTEL_DATAPATH_CPUFREQ) && defined(CONFIG_LTQ_CPUFREQ)
 typedef int32_t(*dp_coc_confirm_stat)(int new_state,
 	int old_st, uint32_t f); /*!< @brief Confirm state
-						     *   by COC
-						     */
+				  *   by COC
+				  */
 #endif
 /*!
  *@brief Datapath Manager Registration Callback
@@ -398,7 +477,7 @@ typedef struct dp_cb {
 	int (*aca_fw_stop)(struct dp_aca_stop *cfg, int flags); /*!< callback to
 								 *   stop ACA FW
 								 */
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 	dp_coc_confirm_stat dp_coc_confirm_stat_fn; /*!< once COC confirm the
 						     *state changed, Datatpath
 						     *will notify Ethernet/
@@ -627,7 +706,7 @@ struct pon_subif_d {
 		*   -1: non valid pcp value
 		*/
 };
-
+#define DP_F_DATA_LCT_SUBIF DP_SUBIF_LCT
 /*! @brief enum DP_SUBIF_DATA_FLAG */
 enum DP_SUBIF_DATA_FLAG {
 	DP_SUBIF_AUTO_NEW_Q = BIT(0), /*!< create new queue for this subif */
@@ -637,7 +716,7 @@ enum DP_SUBIF_DATA_FLAG {
 				       *  be created by caller itself, or
 				       *  by last call of dp_register_subif_ext
 				       */
-	DP_F_DATA_LCT_SUBIF = BIT(2), /*!< Register as LCT port */
+	DP_SUBIF_LCT = BIT(2), /*!< Register as LCT port */
 };
 
 /*! @brief dp_subif_id struct for get_netif_subif */
@@ -653,6 +732,26 @@ struct dp_subif_cache {
 	struct rcu_head rcu;
 };
 
+struct dp_gpid_tx_info {
+	/* Note for GPID max packet lengh setting, DP should get it from
+	 *      struct dp_tx_ring's tx_pkt_size
+	 */
+	u32 f_min_pkt_len : 1; /*!< flag to indicate whether min_pkt_len is
+				*   set or not by caller
+				*   1: min_pkt_len is set by caller
+				*   0: min_pkt_len is not set by caller.
+				*/
+	u32 seg_en : 1; /*!< support FSQM buffer or not
+			 *   For stream port: should set to 1.
+			 *   For non_stream port: shoudl set to 0
+			 */
+
+	u16 min_pkt_len; /*!< minimum packet length in bytes
+			  *   valid if f_min_pkt_len is set
+			  */
+
+};
+
 /*! @brief struct dp_subif_data */
 struct dp_subif_data {
 	s8 deq_port_idx;  /*!< [in] range: 0 ~ its max deq_port_num - 1
@@ -667,30 +766,56 @@ struct dp_subif_data {
 		   * Note: this queue can be created by caller,
 		   *         or by dp_register_subif_ext itself in Pmapper case
 		   */
-	struct net_device *ctp_dev; /*Optional CTP device if there is one bridge
-				     *port device
+	struct net_device *ctp_dev; /*!<  Optional CTP device.
+				     * Mainly for PON CTP device under pmapper.
 				     */
-	dp_rx_fn_t rx_fn; /*!< [in] for subif level rx_fn callback.
-			   *   Mainly for docsis/voice special handling.
-			   *   For wave/VRX618/518, just set to NULL
+	dp_cb_t *dp_cb; /*!< [in] for subif level callback.
+			 *   Mainly for docsis/voice special handling.
+			 *   For wave/VRX618/518, just set to NULL.
+			 */
+	u16 f_tx_policy : 1;   /*!< [in] flag to indicate whether need new
+				*   policy for this subif or not.
+				*   if this flat is set, it needs new txin
+				*       policy
+				*   otherwise DP will use its existing base
+				*       policy which is create during
+				*       dp_register_dev_ext
+				*/
+	u16 tx_pkt_size;  /*!< [in] maximum packet size required
+			   *   to alloc new policy for different cqm dequeue
+			   *   port
+			   *   valid only if f_tx_policy set
 			   */
+	struct dp_gpid_tx_info gpid_tx_info; /*!< [in] for GPID tx information
+					      *   Valid only if \ref
+					      *   f_tx_policy set
+					      */
+	u16 txin_base_policy; /*!< [out] txin_policy
+			       *   if f_txin_policy set, this subif will need
+			       *       create new policy
+			       *   else DP will use its base policy which is
+			       *       create during dp_register_dev_ext
+			       */
+
 	int txin_ring_size;  /*!< [in/out] ACA TXIN Ring size.
 			      *   if input value is not zero, DP try to tune
 			      *   down the pre-allocated TXIN ring buffer size.
 			      *   Only allowed to tune down.
 			      */
 	void *txin_ring_phy_addr; /*!< [out] ACA TXIN Ring Buffer physical
-				   *   address
+				   *   address based on deq_port_idx
 				   */
 	void *credit_add_phy_addr; /*!< [out] PPv4 credit add physical address
 				    *   which is valid only if flag
 				    *   DP_F_NON_ACA_PORT is set during
-				    *   dp_alloc_port_ext
+				    *   dp_alloc_port_ext.
+				    *   So far for 5G without using CQM DC port
 				    */
 	void *credit_left_phy_addr; /*!< [out] PPv4 credit left physical address
 				     *   which is valid only if flag
 				     *   DP_F_NON_ACA_PORT is set during
 				     *   dp_alloc_port_ext
+				     *   So far for 5G without using CQM DC port
 				     */
 	#define DP_MAC_LEARNING_EN 0
 	#define DP_MAC_LEARNING_DIS 1
@@ -706,11 +831,20 @@ enum dp_port_data_flag {
 	DP_F_DATA_RESV_Q = BIT(3), /*!< reserve QOS queue */
 	DP_F_DATA_RESV_SCH = BIT(4), /*!< reserve QOS scheduler */
 	DP_F_DATA_FCS_DISABLE = BIT(5), /*!< Disable FCS for PON port on SOC */
+	DP_F_DATA_NO_CQM_DEQ = BIT(6), /*!< No mapped CQM dequeue port needed,
+				    *   instead DC device directly dequeue
+				    *   packet from PP QOS port via credit left
+				    *   and credit add
+				    */
+	DP_F_DATA_CONTINOUS_Q_RESV = BIT(7) /*!< reserve continous physical
+					     *   queue ID
+					     */
 };
 
 /*! @brief typedef struct dp_port_data */
 struct dp_port_data {
-	int flag_ops; /*!< flag operation, refer to enum dp_port_data_flag */
+	int flag_ops; /*!< [in] flag operation, refer to enum dp_port_data_flag
+		       */
 	u32 resv_num_port; /*!< valid only if DP_F_DATA_RESV_CQM_PORT is set.
 			    * the number of cqm dequeue port to reserve.
 			    * Currently mainly for Wave600 multiple radio but
@@ -725,136 +859,350 @@ struct dp_port_data {
 			     *   Valid only if DP_F_DATA_RESV_SCH bit valid in
 			     *   \ref flag_ops
 			     */
-	int deq_port_base; /*!< output: the CQM dequeue port base. Mainly for
-			    *          PON
+	int deq_port_base; /*!< output: the CQM dequeue port base for the
+			    *   traffic to this device.
 			    */
-	int enq_num;  /*!< [out] the number of enqueue port allcoated */
-	int deq_num;  /*!< [out] the number of dequeue port allocated */
+	int deq_num;  /*!< [out] the number of dequeue port allocated for the
+		       *         traffic to this device
+		       */
 };
 
-/*! @brief typedef struct dp_dev_data */
-struct dp_dev_data {
-#define DP_RXOUT_RING_NUM 2  /*!< maximum number of ACA TXOUT ring support
-			      *   For GRX500/PRX300, only support 1 ring
-			      *   For LGM, maximum up to 2 rings
-			      */
-	int rxout_ring_size[DP_RXOUT_RING_NUM]; /*!< [in/out]
-						 *   rxout ring buf size
-						 *   If 0, then auto set by DP
-						 *   otherwise try to set as
-						 *   requested. Only allowed to
-						 *   tune down.
-						 *   GRX350/PRX300: 1 ring
-						 *   LGM: up to 2 rings
-						 */
-	void *rxout_phy_addr[DP_RXOUT_RING_NUM]; /*!< [out] rxout ring buf
-						  *   physical address
-						  *   GRX350/PRX300: 1 ring
-						  *   LGM: up to 2 rings
-						  *   If NULL, it means no
-						  *   valid
-						  */
-	int rxout_pkt_num[DP_RXOUT_RING_NUM]; /*!< [in/out] the number of packet
-					       *   if input is zero, set by DP
-					       *   with DP_RXOUT_RING_SIZE_DEF
-					       */
-	int rxout_pkt_size[DP_RXOUT_RING_NUM]; /*!< [in/out] the size of each
-						*   packet buffer.
-						*   if input is zero, auto set
-						*   by DP
-						*/
-	void *rxout_pkt_phy_addr[DP_RXOUT_RING_NUM]; /*!< [out] packet buffer
-						      *   list's physical
-						      *   address which will be
-						      *   usedin rxout ring to
-						      *   store the packet
-						      *   content
-						      */
-	int rxin_ring_size[DP_RXOUT_RING_NUM]; /*!< [in/out]
-						*   rxin ring buf size
-						*   If 0, then auto set by DP
-						*   otherwise try to set as
-						*   requested. Only allowed to
-						*   tune down.
-						*   GRX350/PRX300: 1 ring
-						*   LGM: up to 2 rings
-						*/
-	void *rxin_phy_addr[DP_RXOUT_RING_NUM]; /*!< [out] rxin ring buf
-						 *  physical address
-						 *  GRX350/PRX300: 1 ring
-						 *  LGM: up to 2 rings
-						 *  If NULL, it means no
-						 *  valid
+/* DC/ACA Rings
+ *  4 Ring with 1 DC dequeue port
+ *  |-----| ------1 TXIN (Pkt+Desc)-----------> |-----------|
+ *  |     |    (via UMT TX Msg Cnt to dequeue)  |           |
+ *  |     |                                     |           |
+ *  |     | <-----1 TXOUT(Pkt Free)-----------  |           |
+ *  | Host|                                     | DC Device |
+ *  |     | <-----1 RXOUT (PKt+Desc) ---------- | (via ACA) |
+ *  |     |                                     |           |
+ *  |     |  -----1 RXINT (Pkt Alloc)---------> |           |
+ *  |     |    (via UMT RX Msg to Alloc )       |           |
+ *  |-----| ----------------------------------> |-----------|
+ *
+ *  4 Ring with Multipe QOS dequeue ports
+ *  |-----| ------Multiple TXIN (Pkt+Desc)----> |-----------|
+ *  |     |    (Poll Each QOS port Credit_Add ) |           |
+ *  |     |                                     |           |
+ *  |     | <-----1 TXOUT(Pkt Free)-----------  |           |
+ *  | Host|                                     | DC Device |
+ *  |     | <-----1 RXOUT (PKt+Desc) ---------- | (via ACA) |
+ *  |     |                                     |           |
+ *  |     |  -----1 RXINT (Pkt Alloc)---------> |           |
+ *  |     |    (via UMT RX Msg to Alloc )       |           |
+ *  |-----| ----------------------------------> |-----------|
+ *
+ *  3 Ring with 1 DC dequeue port
+ *  |-----| ------1 TXIN (Pkt+Desc)-----------> |-----------|
+ *  |     |    (via UMT TX Msg Cnt to dequeue)  |           |
+ *  |     |                                     |           |
+ *  |     | <-----1 TXOUT(Pkt Free)-----------  |           |
+ *  | Host|                                     | DC Device |
+ *  |     | <-----1 RXOUT (PKt+Desc) ---------- | (via ACA) |
+ *  |     |    (via UMT RX Msg to recycle )     |           |
+ *  |-----| ----------------------------------> |-----------|
+ *
+ *  3 Ring with Multiple QOS dequeue ports
+ *  |-----| -------Multiple TXIN (Pkt+Desc)---> |-----------|
+ *  |     |   (Poll Each QOS port Credit_Add )  |           |
+ *  |     |                                     |           |
+ *  |     | <-----1 TXOUT(Pkt Free)-----------  |           |
+ *  | Host|                                     | DC Device |
+ *  |     | <-----1 RXOUT (PKt+Desc) ---------- | (via ACA) |
+ *  |     |    (via UMT RX Msg to recycle )     |           |
+ *  |-----| ----------------------------------> |-----------|
+ */
+
+/*! @brief struct dp_buf_type for free ACA/DC buffer */
+struct dp_dc_buf {
+	u16 f_policy_pool : 1; /*!< flag to indicate policy/pool valid or not */
+	u16 policy; /*!< buffer policy, valid if f_policy_pool is set */
+	u16 pool; /*!< buffer pool, valid if f_policy_pool is set.
+		   *   For PRX300, it is a must to provide pool id or extract
+		   *   from DP local table
+		   */
+
+	u16 num; /*!< number of buffers in the buffer list */
+	void *buf; /*!< buffer list pointer */
+};
+
+/*! @brief struct dp_buf_info for free ACA/DC buffer */
+struct dp_buf_info {
+	int inst; /*!< [in] DP instance ID */
+	int dp_port; /*!< [in] DP port ID */
+	struct dp_dc_buf rx[DP_RX_RING_NUM]; /* [in] buffers in the rx ring
+						 * to free
 						 */
-	void *umt_msg_phy_addr; /*!< [in] umt message physical address */
-	void *umt_msg_virt_addr; /*!< [in] umt message virtual address */
-	int  umt_msg_timer; /*!< [in/out] ACA UMT MSG Interval in us */
-#define DP_UMT_MSG_ENDIAN_LITTLE 0 /*!< umt msg endian mode when writing to
-				    *   peripheral side
-				    */
-#define DP_UMT_MSG_ENDIAN_BIG    1 /*!< umt msg endian when writing to
-				    *   peripheral side
-				    */
-	int umt_msg_endian; /*!< [in] UMT message endian */
-
-#define DP_UMT_MODE_AUTO    0 /*!< UMT setting auto set by DP */
-#define DP_UMT_MODE_HW_SELF 1 /*!< HW UMT self couting mode */
-#define DP_UMT_MODE_HW_USER 2 /*!< HW UMT user Mode */
-#define DP_UMT_MODE_SW      3 /*!< SW UMT */
-	int umt_mode; /*!< [in/out] UMT  mode: HW self couting, HW User, SW
-		       *   if input value == DP_UMT_MODE_AUTO, set by DP
-		       *   otherwise set as specified by caller if possible
-		       */
-#define DP_UMT_MSG_MODE_AUTO  0  /*!< UMT message mode auto set by DP */
-#define DP_UMT_MSG_MODE_ACCU  1  /*!< Accumulated msg mode */
-#define DP_UMT_MSG_MODE_INCRE 2  /*!< Incremental msg mode */
-	int umt_rx_msg_mode; /*!< [in/out] UMT RX MSG mode:
-			      *   if umt_rx_msg_mode == DP_UMT_MSG_MODE_AUTO,
-			      *      auto set by DP
-			      *   else set as specified by caller if possible
-			      */
-	int umt_tx_msg_mode; /*!< [in/out] UMT TX MSG mode:
-			      *   if umt_tx_msg_mode == DP_UMT_MSG_MODE_AUTO,
-			      *      auto set by DP
-			      *   else set as specified by caller if possible
-			      */
+	struct dp_dc_buf tx; /* [in] buffers in the rx ring to free */
+};
 
-	int txin_ring_size;  /*!< [in/out] ACA TXIN Ring Buffer size
-			      *   address (for legacy ACA back-compatible
-			      *   only, like wave500).
-			      *   For legacy ACA with CQM port: maximum 32
-			      *   For non ACA port based: like 5G,
-			      *         just pass zero here. Later can tune with
-			      *         dp_register_subif_ext
-			      *   For DP, here we just return first
-			      *   TXIN ring buffer size
-			      */
-	void *txin_ring_phy_addr; /*!< [out] ACA TXIN Ring Buffer physical
-				   *   address (for legacy ACA back-compatible
-				   *   only for wave500 case).
-				   *   For DP, here just return first
-				   *  TXIN ring buffer address
+/*! @addtogroup Datapath_Driver_API */
+/*! @brief  dp_free_dc_buf is used to free the buffer which is allocated by
+ *          DP or from HW BM
+ *  @note: DP will internal make assumption:
+ *         a) For 3 ring case: tx is BM buffer and rx is linux system buffer
+ *         b) For 4 ring case: both are using BM buffer
+ *         c) in case caller does not provide policy/pool information, DP will
+ *            use default policy to free it
+ */
+int dp_free_dc_buf(struct dp_buf_info *buf, int flag);
+
+/**
+ * @brief dp_gpid_tx_info
+ */
+#define DP_DFT_MAX_PKT_LEN 1600 /*!< Default maximal packet length ??? Not sure need or not */
+#define DP_DFT_MIN_PKT_LEN 60 /*!< Default minimal packet length ??? Not sure need or not */
+/*! @addtogroup Datapath_Driver_Structures */
+/*! @brief  PPA Sub-interface Data structure
+ *@param port_id  Datapath Port Id corresponds to PMAC Port Id
+ *@param subif    Sub-interface Id info. In GRX500, this 15 bits,
+ *                only 13 bits in PAE are handled [14, 11:0]
+ *\note
+ */
+enum DP_UMT_MODE {
+	DP_UMT_MODE_HW_SELF, /*!< HW UMT self couting mode */
+	DP_UMT_MODE_HW_USER, /*!< HW UMT user Mode */
+	DP_UMT_MODE_SW, /*!< SW UMT: no need to call UMT API */
+	DP_UMT_MODE_MAX, /*!< Not valid UMT mode */
+};
+
+enum DP_UMT_MSG_MODE {
+	DP_UMT_MSG_MODE_ACCU,  /*!< Accumulated msg mode */
+	DP_UMT_MSG_MODE_INCRE, /*!< Accumulated msg mode */
+	DP_UMT_MSG_MODE_MAX  /*!< Not valid UMT msg mode */
+};
+
+enum DP_RXOUT_MSG_MODE {
+	DP_RXOUT_MSG_ADD = 0, /*!< rxout_add */
+	DP_RXOUT_MSG_SUB, /*!< rxout_sub */
+};
+
+enum DP_RXOUT_QOS_MODE {
+	DP_RXOUT_BYPASS_QOS_ONLY = 0, /*!< bypass QOS but with FSQM */
+	DP_RXOUT_QOS, /*!< with QOS */
+	DP_RXOUT_BYPASS_QOS_FSQM, /*!< bypass QOS and FSQM */
+	DP_RXOUT_QOS_MAX /*!< Not valid RXOUT qos mode */
+};
+
+enum DP_UMT_MSG_ENDIAN {
+	DP_UMT_MSG_ENDIAN_LITTLE = 0, /*!< UMT message in little endian */
+	DP_UMT_MSG_ENDIAN_BIG, /*!< UMT message in big endian */
+	DP_UMT_MSG_ENDIAN_MAX  /*!< Not valid UMT msg endian */
+};
+
+/*! @brief struct dp_rx_ring, which is used for DirectConnected (DC)
+ *  applications
+ */
+struct dp_rx_ring {
+	int out_enq_ring_size;  /*!< [in/out]
+				 *   rxout enqueue ring size, ie, burst size
+				 *   for Peripheral device to enqueue packets to
+				 *   Host side via CQM or DMA in burst.
+				 *   If 0, then auto set by DP/CQM.
+				 *   Note: this paramater will be forced to tune
+				 *         down to HW capability
+				 */
+	u32   out_enq_port_id; /*!< [out] CQM enqueue port based ID */
+	void *out_enq_paddr;   /*!< [out] rxout ring physical address
+				*   For GRX350/PRX300, it is DMA Descriptor base
+				*      address
+				*   For LGM: it is CQM enqueue register address
+				*   If NULL, it means not valid
+				*/
+	u32 out_dma_ch_to_gswip; /*!< [out] DMA TX channel base to GSWIP for
+				  *   forwarding rxout packet to GSWIP
+				  */
+	u32 num_out_tx_dma_ch; /*!< [out] number of DMA tx channel assigned */
+	u32 out_cqm_deq_port_id; /*!< [out] CQM dequeue port to GSWIP for rxout
+				  *   packet
+				  */
+	u32 num_out_cqm_deq_port; /*!< [out] number of CQM dequeue port to GSWIP
+				   *   for rxout packet
 				   */
-	int txout_ring_size;/*!< [out] ACA TXOUT Free Ring Buffer size */
-	void *txout_ring_base_phy_addr; /*!< [out] ACA TXOUT(Free) base register
-					 *   physical address
-					 */
-	int txout_policy_base; /*!< [out] For PRX300: For legacy ACA to free
-				*   BM buffer
-				*         for LGM, it is base policy.
-				*   Note: For LGM, each ACA device needs to
-				*   support 4 policy to let HW auto free/return
-				*   the buffer since its information may lost
+	int in_alloc_ring_size; /*!< [out] rxin ring size, ie, maximum number of
+				 *   burst alloc buffers size supported.
+				 */
+	void *in_alloc_paddr; /*!< [out] rxin ring buf allocation physical
+			       *     address. It is for 4 ring case only
+			       *   Note:
+			       *   1. GRX350/PRX300: not support
+			       */
+	u32 num_pkt; /*!< [in/out] nuber of packet for this policy */
+	int rx_pkt_size; /*!< [in/out] rx packet buffer size
+			  *   requirement rxout packets.
+			  *   DP/CQM will adjust to most
+			  *   matched BM pool
+			  */
+	u16 rx_policy_base; /*!< [out] the rx_policy based on @rx_pkt_size
+			     *      requirement.
+			     */
+	int prefill_pkt_num; /*!< [in] the number of pre-fill packet buffer
+			      *       required.
+			      * For LGM, normally no need and caller just set it
+			      *     to 0.
+			      * For GRX350/PRX300, Normally needed to pre-fill
+			      *     The buffer size should based on @rx_pkt_size
+			      *     requirement
+			      */
+	void *pkt_base_paddr; /*!< [out] packet list base physical address,
+			       *    which stored  @prefill_pkt_num of packet
+			       *    physical addressin
+			       * For LGM, normally no need and caller just set it
+			       *     to 0.
+			       * For GRX350/PRX300, Normally needed to pre-fill
+			       *     The buffer size should based on @rx_pkt_size
+			       *     requirement
+			       */
+	enum DP_RXOUT_MSG_MODE out_msg_mode; /*!< [in] rxout msg mode */
+	enum DP_RXOUT_QOS_MODE out_qos_mode; /*!< [in] rxout qos mode */
+};
+
+/*! @brief struct dp_tx_ring, which is used for DirectConnected (DC)
+ *  applications
+ */
+struct dp_tx_ring {
+	int in_deq_ring_size; /*!< [in/out] ACA TXIN Ring burst size, ie,
+			       * size of maximum number of
+			       * buffer can be dequeue in one time
+			       * For GRX500/PRX300 CQM DC: maximum 32
+			       * For 5G with PP QOS port only, ???
+			       */
+	void *in_deq_paddr; /*!< [out] txin ring/dequeue physical base
+			     *   address
+			     */
+	int out_free_ring_size;/*!< [out] txout ring/free buffer burst size,
+				*     the number of buffer can be freed in
+				*     in one free operation.
 				*/
-	int txout_poolid; /*!< [out] For legacy ACA to free BM buffer in
-			   *   in PRX300
-			   */
+	void *out_free_paddr; /*!< [out] txout/free buffer
+			       *     physica address
+			       */
+	u32 num_tx_pkt; /*!< [in] nuber of packet */
+	int tx_pkt_size; /*!< [in] maximum packet size
+			  *   requirement to the packet
+			  *   buffer used in tx ring
+			  *   For LGM, need provide up to
+			  *      @DP_MAX_POLICY_GPID
+			  *   For PRX300, only support 1
+			  *   For GRX500, only support 1
+			  */
+	int txout_policy_base; /*!< [out] It should based on @tx_pkt_size and
+				*          @dp_gpid_tx_info to get the proper
+				*          BM pool.
+				*   gpid_info to generate the policy
+				*   Not valid for GRX500
+				*   In case multiple policy is allocated, only
+				*   first policy is really configured properly
+				*   and can be used by, all other policy should
+				*   be dummy one and cannot allcoate via it now.
+				*   later peripheral drivce should call
+				*   dp_register_subif_ext to create the
+				*   remaining policies
+				*   This is also used to configure CQM DQ port
+				*   with the egress base policy if
+				*   f_txout_auto_free is set to 1
+				*/
+	int policy_num;  /*!< [out] the number of policy create
+			  *   a) For PRX300: it should be 1.
+			  *   b) For LGM: it should always 4
+			  *   c) For GRX500, not valid
+			  */
+	u16 tx_poolid; /*!< [out] Only for PRX300, it should be passed for
+			*     device to free the packet buffer in tx ring
+			*/
+	struct dp_gpid_tx_info gpid_info; /*!< [in] for GPID tx information
+					   *   Valid only if @f_gpid valid.
+					   */
+
+	int f_out_auto_free : 1; /*!< [in] flag to indicate whether need txout
+				  *      base policy to auto free TXIN buffer.
+				  * Once f_txout_auto_free is set, this
+				  * device can only support maximum up to 4
+				  * continuous policy and later not allowed to
+				  * create new policy during
+				  * dp_register_subif_ext. Otherwise auto free
+				  * will cause problem since CQM in LGM only
+				  * support 4 policy only.
+				  * For those DC device which can keep
+				  * policy/pool information, no need
+				  * to enable this flag and it can support
+				  * more than 4 policies
+				  * Note, this setting is not valid for
+				  *GRX500/FLM
+				  */
+};
+
+/*! @brief struct dp_umt, which only used for DirectConnected (DC)
+ *  applications
+ */
+struct dp_umt {
+	u8 enable : 1; /*!< [in] enable flag to indicate whether need to
+			*   use this UMT or not
+			*/
+	u32 umt_msg_timer; /*!< [in] UMT msg update interval in us */
+
+	void *umt_msg_paddr; /*!< [in] umt message physical base address.
+			      *   Note: umt rx/tx share same base address.
+			      *   The msg sequence is rx first, followed by tx
+			      *   For SW UMT case, it should be NULL
+			      */
+	void *umt_msg_vaddr; /*!< [in] umt message virtual base address
+			      *    If HW UMT , it should be NULL
+			      */
+	enum DP_UMT_MODE umt_mode; /*!< [in] UMT mode */
+	enum DP_UMT_MSG_MODE umt_msg_mode; /*!< [in] UMT RX MSG mode
+					    */
+	/* Note: remove enum dp_umt_rx_src umt_rx_src for LGM;
+	 * Basic rule to set inside DP:
+	 *     1) bypass both QOS and FSQM: set mode DP_UMT_RX_FROM_DMA
+	 *     2) otherwise set mode DP_UMT_RX_FROM_CQEM
+	 */
+	enum dp_umt_sw_msg usr_msg; /*!< [in] For UMT HW user mode only
+				     *    For HW_SELF counting mode, always with
+				     *      msg rx + tx
+				     */
+};
+
+/*! @brief struct dp_dev_data, which used for DirectConnected (DC)
+ *  applications
+ */
+struct dp_dev_data {
+	u8 num_rx_ring;   /*!< [in] number of rx ring from DC device to Host.
+			    *   num_rx_ring requirement:
+			    *   @num_rings <= @DP_RX_RING_NUM
+			    *   GRX350/PRX300:1 rx ring
+			    *   LGM: up to 2 rx ring, like Docsis can use 2 rings
+			    *   For two ring case:
+			    *    1st rxout ring without qos
+			    *    2nd rxout ring with qos
+			    */
+	u8 num_tx_ring;   /*!< [in] number of tx ring from Host to DC device
+			    *   num_rx_ring requirement:
+			    *   @num_rings <= @DP_TX_RING_NUM
+			    *   Normally it is 1 TX ring only.
+			    *   But for 5G, it can support up to 8 TX ring
+			    *   For docsis, alhtough it is 16 dequeue port to WIB.
+			    *   But the final ring only 1, ie, WIB to Dcosis
+			    */
+	u8 num_umt_port;   /*!< [in] number of UMT port.
+			    *    Normally is 1 only. But Docsis can use up to 2
+			    */
+	struct dp_rx_ring rx_ring[DP_RX_RING_NUM]; /*!< [in/out] DC rx ring info
+						    */
+	struct dp_tx_ring tx_ring[DP_TX_RING_NUM]; /*!< [in/out] DC tx ring info
+						     */
+	struct dp_gpid_tx_info gpid_info; /*!< [in] for GPID tx information
+					   *   Valid only if @f_gpid valid.
+					   */
+	struct dp_umt umt[DP_MAX_UMT]; /*!< [in/out] DC umt information */
+	u32 enable_cqm_meta : 1; /*!< enable CQM buffer meta data marking */
+
 	u16 max_ctp;    /*!< [in] maximum subif required which will be mapped to
 			 * GSWIP continuous CTP block.
 			 * Since very limited CTP in GSWIP and it is already
 			 * out of range, some drivers have to specify this
 			 * parameter to save the system resource, for example
-			 * of G.INIT in PRX300:
+			 * of G.INIT in falcon_mx:
 			 * 1) single LAN port only: it is value should be 16
 			 * 2) two Lan Ports:
 			 *      a) 1st lan port: 8 CPT with 8 subif only
@@ -867,6 +1215,14 @@ struct dp_dev_data {
 			 * move the CTP allocation from dp_alloc_port to
 			 * dp_register_dev
 			 */
+	u16 max_gpid;  /*!< [in] maximum subif required which will be mapped to
+			* PP continious GPID block. The continuous limitation is
+			* from GSWIP (subif->GPID mapping design), not because
+			* of PP itself.
+			* since overall number of GPID < nubmer of CTP in HW,
+			* DP need to add this parameter to fully use of shared
+			* HW resource.
+			*/
 };
 
 /*! @addtogroup Datapath_Driver_API */
@@ -1106,7 +1462,7 @@ int dp_get_port_subitf_via_ifname(char *ifname, dp_subif_t *subif);
  */
 int dp_get_port_subitf_via_dev(struct net_device *dev,
 			       dp_subif_t *subif);
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_CPUFREQ)
 
 /*!
  *@brief  The API is for dp_get_port_subitf_via_dev
@@ -1125,7 +1481,8 @@ int dp_coc_new_stat_req(int new_state, uint32_t flag);
 /*! DP's submodule to call it */
 /*int dp_set_rmon_threshold(struct dp_coc_threshold *threshold,
 			  uint32_t flags);*/
-#endif /*! CONFIG_LTQ_DATAPATH_CPUFREQ*/
+#endif /*! CONFIG_INTEL_DATAPATH_CPUFREQ*/
+
 /*! get port flag. for TMU proc file cat /proc/tmu/queue1 and /proc/tmu/eqt */
 u32 get_dp_port_flag(int k);
 
@@ -1301,5 +1658,67 @@ int dp_dma_chan_irq_rx_enable(int inst, struct dp_dma_ch *ch, int flag);
  */
 int dp_get_fid_by_brname(struct net_device *dev, int *inst);
 
+struct dp_spl_conn {
+	enum DP_SPL_TYPE type; /*!< [in] Special Connectity Type */
+	u32 f_subif : 1; /*!< [in] need allocate subif */
+	u32 f_gpid : 1; /*!< [in] need allocate GPID */
+	u32 f_gpid_policy : 1; /*!< [in] need allocate policy or not.
+				*   valid only if f_gpid set
+				*   For LGM:
+				*     Required only for Voice CPU DQ port.
+				*     TSO - Not required (No Dequeue )
+				*     LRO - Not required (No GPID )
+				*     VPN-A: Not required.(reuses input buffer)
+				*     App Litepath: Not required
+				*       (reuses the CPU DQ ports for the host).
+				*     Fragmenter NF: Not required
+				*       (GPID will not be used as Egress port
+				*     Other NFs: Not required (No GPIDs).
+				*/
+	dp_cb_t *dp_cb; /*!< [in] for subif level callback.
+			 *   Valid only if f_subif valid.
+			 *   Mainly for voice related applicaton only
+			 */
+	int dp_port; /*!< [out] dp_port ID, normally it is CPU 0.
+		      *   if -1, then not applicable for this special connect
+		      */
+	u8 num_rx_ring;   /*!< [in] number of rx ring from DC device to Host.
+		    *   num_rx_ring requirement:
+		    *   @num_rings <= @DP_RX_RING_NUM
+		    *   GRX350/PRX300:1 rx ring
+		    *   LGM: up to 2 rx ring, like Docsis can use 2 rings
+		    *   For two ring case:
+		    *    1st rxout ring without qos
+		    *    2nd rxout ring with qos
+		    */
+	u8 num_tx_ring;   /*!< [in] number of tx ring from Host to DC device
+			    *   num_rx_ring requirement:
+			    *   @num_rings <= @DP_TX_RING_NUM
+			    *   Normally it is 1 TX ring only.
+			    *   But for 5G, it can support up to 8 TX ring
+			    *   For docsis, alhtough it is 16 dequeue port to WIB.
+			    *   But the final ring only 1, ie, WIB to Dcosis
+			    */
+	u8 num_umt_port;   /*!< [in] number of UMT port.
+			     *    Normally is 1 only. But Docsis can use up to 2
+			     */
+	struct dp_rx_ring rx_ring[DP_RX_RING_NUM]; /*!< [in/out] DC rx ring info
+						    */
+	struct dp_tx_ring tx_ring[DP_TX_RING_NUM]; /*!< [in/out] DC tx ring info
+						     */
+	struct dp_gpid_tx_info gpid_info; /*!< [in] for GPID tx information
+					   *   Valid only if @f_gpid valid.
+					   */
+	struct dp_umt umt[DP_MAX_UMT]; /*!< [in/out] DC umt information */
+};
+
+/*!
+ *@brief Datapath Manager Initialize Speical Connectivity API
+ *@param[in] inst: DP instance ID
+ *@param[in] conn: Special Connect information
+ *@return Returns DP_SUCCESS on succeed and DP_FAILURE on failure
+ */
+int dp_connect_spl_path(int inst, struct dp_spl_conn *conn);
+
 #endif /*DATAPATH_API_H */
 
diff --git a/include/net/datapath_api_qos.h b/include/net/datapath_api_qos.h
index 92983c2fdda5..4670b99944b4 100644
--- a/include/net/datapath_api_qos.h
+++ b/include/net/datapath_api_qos.h
@@ -992,6 +992,7 @@ struct dp_q_map_mask {
 	u32	subif:1; /*!< subif don't care */
 	u32	dp_port:1; /*!< logical port don't care */
 	u32	class:1; /*!< Traffic Class don't care */
+	u32	egflag :1; /*!< egflag don't care */
 };
 
 /*! @brief queue_map_set*/
@@ -1013,6 +1014,7 @@ struct dp_queue_map_entry {
 struct dp_queue_map_get {
 	int inst; /*!< input: dp instance. For SOC side, it is always zero */
 	int q_id; /*!<  queue id */
+	u32 egflag; /*!< eglag map to different table: for LGM only */
 	int num_entry; /*!< output: the number of entries mapped to specified
 			*           qid
 			*/
@@ -1263,6 +1265,25 @@ struct dp_qos_cfg_info {
  */
 int dp_qos_global_info_get(struct dp_qos_cfg_info *info, int flag);
 
+/*!
+ * @struct dp_qos_q_logic
+ *
+ * Structure defining the conversion from physical to logical queue ID
+ *
+ */
+struct dp_qos_q_logic {
+	int inst;  /*!< [in] DP instance */
+	int q_id;  /*!< [in] physical queue id */
+	u32 q_logic_id; /*!< [out] q_logical id */
+};
+
+/*!< dp_qos_get_q_logic: convert physical queue ID to logical queue ID
+ *   @param [in/out] cfg
+ *   @param [in] flag: reserved only
+ *   @return failure DP_FAILURE
+ *           succeed DP_SUCCESS
+ */
+int dp_qos_get_q_logic(struct dp_qos_q_logic *cfg, int flag);
 
 #ifdef ENABLE_QOS_EXAMPLE
 /*! \ingroup APIs_dp_qos_example
diff --git a/include/net/datapath_api_umt.h b/include/net/datapath_api_umt.h
new file mode 100644
index 000000000000..5cac7e55caff
--- /dev/null
+++ b/include/net/datapath_api_umt.h
@@ -0,0 +1,121 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ *  Copyright (C) 2018 Intel Corporation.
+ *  Zhu YiXin <Yixin.zhu@intel.com>
+ */
+
+//----define register and macro start
+#define DP_UMT_NOT_SENDING_ZERO_COUNT	BIT(0)
+#define DP_UMT_SENDING_RX_COUNT_ONLY	BIT(1)
+#define DP_UMT_SUSPEND_SENDING_COUNT	BIT(2)
+#define DP_UMT_ENABLE			BIT(3)
+
+//----define register and macro end
+
+//----define enum start
+enum dp_umt_rx_src {
+	DP_UMT_RX_FROM_CQEM,
+	DP_UMT_RX_FROM_DMA
+};
+
+enum dp_umt_msg_mode {
+	DP_UMT_SELFCNT_MODE = 0,
+	DP_UMG_USER_MSG_MODE = 1,
+};
+
+enum dp_umt_sw_msg { /* for DP_UMG_USER_MSG_MODE only */
+	DP_UMT_MSG0_ONLY = 0,
+	DP_UMT_MSG1_ONLY,
+	DP_UMT_MSG0_MSG1,
+};
+
+//----define enum end
+
+//----define structure here start
+/**
+ * struct dp_umt_param
+ * id: umt HW ID. (0 - 7)
+ * rx_src: indicate rx msg source.
+ * dma_id: it contains DMA controller ID, DMA port ID and base DMA channel ID.
+ * dma_ch_num: number of dma channels used by this UMT port.
+ * cqm_enq_pid: cqm enqueue port ID.
+ * cqm_dq_pid: cqm dequeue port ID.
+ * daddr: UMT message destination address.
+ * msg_mode: UMT message mode.
+ * period: UMT message interval period.
+ * sw_msg: software message mode.
+ * flag:  UMT message control flag.
+ */
+struct dp_umt_param {
+	u8			id; /* [in/out] 0xff -- auto assign,
+	 				othe value: caller provide
+	 			     */
+	enum dp_umt_rx_src	rx_src; /* [in] */
+	u32			dma_id;  /* [in] */
+	u8			dma_ch_num; /* [in] */
+	u8			cqm_enq_pid; /* [in] */
+	u8			cqm_dq_pid; /* [in] */
+	u32			daddr;  /* [in] */
+	enum dp_umt_msg_mode	msg_mode; /* [in] */
+	u32			period; /* [in] */
+	enum dp_umt_sw_msg	sw_msg; /* [in] */
+	unsigned long		flag; /* [in] control flag*/
+};
+
+/**
+ * struct dp_umt_priv
+ * dev: platform device.
+ * membase: UMT register base address.
+ * umt_num: number of UMT entries.
+ * umts: umt entry list.
+ */
+struct dp_umt_priv {
+	struct device		*dev;
+	void __iomem		*membase;
+	u8			umt_num;
+	struct dp_umt_entry	*umts;
+};
+
+/**
+ * struct dp_umt_entry
+ * param: umt configure parameters.
+ * alloced: umt entry status.
+ * enabled: umt entry status.
+ * halted:  umt control status.
+ * not_snd_zero_cnt: umt control status.
+ * snd_rx_only: umt control status.
+ * max_dam_ch_num: support max DMA channel numbers.
+ * debugfs: debugfs proc.
+ */
+struct dp_umt_entry {
+	struct dp_umt_param	param;
+	int			alloced:1;
+	int			enabled:1;
+	int			halted:1;
+	int			not_snd_zero_cnt:1;
+	int			snd_rx_only:1;
+	int			max_dma_ch_num;
+	struct dentry		*debugfs;
+};
+
+//----define structure here end
+
+//----declare APIs start
+int dp_umt_request(struct dp_umt_param *umt, unsigned long flag);
+
+/* set flag for period  */
+#define DP_UMT_SET_Period BIT(0)
+int dp_umt_set(struct dp_umt_param *umt, unsigned long flag);
+
+int dp_umt_enable(struct dp_umt_param *umt, unsigned long flag, int enable);
+int dp_umt_suspend_sending(struct dp_umt_param *umt,
+			   unsigned long flag, int halt);
+
+//----declare APIs end
+
+/**
+ * debug proc should support:
+ * 1. register content dump
+ * 2. RX/TX trigger
+ * 3. UMT status
+ */
diff --git a/include/net/datapath_inst.h b/include/net/datapath_inst.h
index 87c0036a421e..4a7d01fedd43 100644
--- a/include/net/datapath_inst.h
+++ b/include/net/datapath_inst.h
@@ -28,13 +28,15 @@ struct gsw_itf;
 /*! enum for DP HW capability type */
 enum DP_HW_CAP_TYPE {
 	GSWIP30_TYPE = 0,
-	GSWIP31_TYPE
+	GSWIP31_TYPE,
+	GSWIP32_TYPE
 };
 
 /*! enum for DP HW version */
 enum DP_HW_CAP_VER {
 	GSWIP30_VER = 0,
-	GSWIP31_VER
+	GSWIP31_VER,
+	GSWIP32_VER
 };
 
 struct dp_meter_subif {
@@ -89,7 +91,7 @@ struct inst_info {
 	void (*get_dma_pmac_templ)(int index, struct pmac_tx_hdr *pmac,
 				   struct dma_tx_desc_0 *desc_0,
 				   struct dma_tx_desc_1 *desc_1,
-				   struct pmac_port_info2 *dp_info);
+				   struct pmac_port_info *dp_info);
 	int (*get_itf_start_end)(struct gsw_itf *itf_info, u16 *start,
 				 u16 *end);
 	void (*dump_rx_dma_desc)(struct dma_rx_desc_0 *desc_0,
@@ -126,7 +128,11 @@ struct inst_info {
 			    struct dp_meter_cfg *meter, int flag,
 			    struct dp_meter_subif *mtr_subif);
 
-#if IS_ENABLED(CONFIG_LTQ_DATAPATH_SWITCHDEV)
+	int32_t (*dp_rx)(struct sk_buff *skb, uint32_t flags);
+	int32_t (*dp_tx)(struct net_device *rx_if, dp_subif_t *rx_subif,
+			 struct sk_buff *skb, int32_t len, uint32_t flags);
+
+#if IS_ENABLED(CONFIG_INTEL_DATAPATH_SWITCHDEV)
 	int swdev_flag;
 	int (*swdev_alloc_bridge_id)(int inst);
 	int (*swdev_free_brcfg)(int inst, u16 fid);
@@ -142,9 +148,10 @@ struct inst_info {
 	int (*dp_tc_vlan_set)(struct core_ops *ops, struct dp_tc_vlan *vlan,
 			      struct dp_tc_vlan_info *info,
 			      int flag);
-#ifdef CONFIG_LTQ_DATAPATH_CPUFREQ
+#ifdef CONFIG_INTEL_DATAPATH_CPUFREQ
 	int (*dp_handle_cpufreq_event)(int event_id, void *cfg);
 #endif
+	int (*dp_qos_get_q_logic)(int cmd_id, void *cfg, int flag);
 };
 
 struct dp_inst {
@@ -171,6 +178,7 @@ struct inst_property {
 
 int register_dp_cap_gswip30(int flag);
 int register_dp_cap_gswip31(int flag);
+int register_dp_cap_gswip32(int flag);
 int register_dp_hw_cap(struct dp_hw_cap *info, u32 flag);
 
 /*! request a new DP instance based on its HW type/version */
diff --git a/include/net/datapath_proc_api.h b/include/net/datapath_proc_api.h
index ff59a7621530..938cab237501 100644
--- a/include/net/datapath_proc_api.h
+++ b/include/net/datapath_proc_api.h
@@ -62,20 +62,12 @@ void dp_replace_ch(char *p, int len, char orig_ch, char new_ch);
  */
 int dp_split_buffer(char *buffer, char *array[], int max_param_num);
 
-#ifdef LTQ_DATAPATH_MPE_FASTHOOK_TEST
-/*add the macro in order to be back-compatible with old MPE FW HOOK */
-#define ltq_proc_entry dp_proc_entry
-#define ltq_proc_file_entry dp_proc_file_entry
-
-#define ltq_proc_entry_create dp_proc_entry_create
-
+/* below ltq_xxx api is for back-compatible only */
 #define ltq_atoi dp_atoi
 #define ltq_strncmpi dp_strncmpi
 #define ltq_replace_ch dp_replace_ch
 #define ltq_remove_leading_whitespace dp_remove_leading_whitespace
 #define ltq_split_buffer dp_split_buffer
-#endif /*LTQ_DATAPATH_MPE_FASTHOOK_TEST*/
-
 void set_start_end_id(unsigned int new_start, unsigned int new_end,
 		      unsigned int max_start, unsigned int max_end,
 		      unsigned int default_start, unsigned int default_end,
diff --git a/include/net/lantiq_cbm_api.h b/include/net/lantiq_cbm_api.h
index 376b12ee782f..3f5aaa47e9ac 100644
--- a/include/net/lantiq_cbm_api.h
+++ b/include/net/lantiq_cbm_api.h
@@ -543,6 +543,13 @@ struct cbm_dp_alloc_data {
 	u32 tx_ring_addr;  /*port ring address. should follow HW defintion*/
 	u32 tx_ring_size; /*ring size */
 	u32 tx_ring_offset;  /*next tx_ring_addr = current tx_ring_addr + tx_ring_offset */
+	void *tx_ring_addr_txpush; /* port ring physical base address/TXIN address  
+				    *  to configured to QOS TX Push register.
+	                            *  In falcon_mx, it needs to left
+				    *  shift some bits.
+				    *  In LGM,  ???
+				    */
+
 	u32 num_dma_chan;
 };
 
